"TicketID","TransactionID","CreatedDate","SubjectNoHTML","TransactionContent"
"3030438","70125636","2025-07-02 13:46:01","iHARP: Moving Lambda Scalar 2U Intel from iHARP suite","The email appears to be a discussion between Nikki Monczewski and Roy Prouty about relocating a server from the iHARP Institute at UMBC. The context suggests that the current location of the server is not ideal due to power supply issues, and they are exploring options for moving it to a more suitable location.  Here's a summary of the key points:  * Nikki Monczewski reaches out to Roy Prouty about relocating a server from the iHARP Institute at UMBC. * The current location of the server is not ideal due to power supply issues. * Roy Prouty suggests that the server could be moved to a more suitable location, possibly in the DoIT Research Computing Team's data center. * Max Breitmeyer, a DOIT Unix Infra Student Worker, chimes in and offers to help with the relocation process.  Overall, the email chain appears to be a discussion about finding a solution to relocate the server to a more reliable and suitable location."
"3049472","68021822","2025-03-06 14:21:53","Trouble Accessing Taki","Since this is an old ticket, it isn't recommended to reopen a ticket for a new issue.  Please create a new ticket here (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/), under Research computing. In addition to the error message, let us know the command you are running and in which directory you are running the command. On Wed Mar 05 15:51:57 2025, [USER] wrote: Hello, I am a long-time taki user, but I am using it after some time.  I am having trouble with display, I get the following message: X11 connection rejected because of wrong authentication. WINDOW: Unable to connect to X Windows display: localhost:8.0 WINDOW: Unable to open X Windows display. Is your DISPLAY environment variable set correctly? I am not sure if it is my local x-window problem - because the display works with other servers! Your help will be appreciated. Thank you. [USER] On Fri, Oct 4, 2024 at 10:10 AM via RT [EMAIL] wrote: Greetings, This message has been automatically generated in response to the creation of a ticket regarding: Subject: Trouble Accessing Taki Message: Hi [USER], Thank you for calling TSC today! We discussed an issue you were having with the taki computer which was that you were trying to access a certain directory, but it tells you that it doesn't exist. You have done the basic troubleshooting steps such as logging out and logging back in, restarting the device, and checking the wireless internet connection, and nothing seemed to work. Please stand by for further assistance and have a good day! -- Customer Information Campus ID*: [USER] Username: [USERNAME] Phone*: [PHONE] -- [STAFF] Student Consultant DoIT Technology Support Center 410-455-3838 -- There is no need to reply to this message right now. Your ticket has been assigned an ID of [TSC Support #XXXXXXX] or you can go there directly by clicking the link below. Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=XXXXXXX> You can login to view your open tickets at any time by visiting http://my.umbc.edu and clicking on 'Help' and 'Request Help'. Alternately you can click on http://my.umbc.edu/help Thank you -- Best, [STAFF]"
"3060210","66993907","2025-01-17 15:05:55","Other Account Request: [USER]","Sorry for the delay - here's the list of docker images: root@[SERVER]# docker ps --format 'table {{.ID}}\t{{.Image}}\t{{.Names}}' CONTAINER ID   IMAGE                                NAMES f3dabee1db0f  ghcr.io/[COMPANY]/frontend:latest    frontend 243f2712b616  [COMPANY]/blockscout:latest          backend b1420a05bff9  ghcr.io/[COMPANY]/stats:latest      stats 57221f2b1775  ghcr.io/[COMPANY]/user-ops-indexer:latest user-ops-indexer 46bb79445266  postgres:15                         db 69188055a88a  postgres:15                         stats-db 01ac88fe8509  ghcr.io/[COMPANY]/visualizer:latest   visualizer b1919a9fc4bd  ghcr.io/[COMPANY]/sig-provider:latest sig-provider 6c088a3975f0  traefik:2.10.6                      kurtosis-reverse-proxy--[TOKEN] 7891c6ede0ef  timberio/vector:0.31.0-debian       kurtosis-logs-aggregator Regards, On Thu Jan 09 14:24:50 2025, [STAFF] wrote: Can you send us a list if the docker images if possible so we can identify the ones to be deleted. Regards [USER] On Thu, Jan 9, 2025, 2:22 PM John Riddle via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3060210&ticketowner=[EMAIL]&ticketsubject=Other%20Account%20Request:%20[USER]%20<[EMAIL]> If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3060210> Thank You _______________________________________ R e s o l u t i o n: Hi, I was able to clear up enough space to get logins working again, but here's only ~25GB space available on the system disk. Was wondering if some of the docker images could be removed, -- John Riddle UNIX Systems Administrator Division of Information Technology University of Maryland, Baltimore County _______________________________________ Original Request: Requestors: [USER] First Name:       James Last Name:         [LASTNAME] Email:             [EMAIL] Campus ID:        [CAMPUSID] System:            Other Request Type:     Account Request Hi, [SERVER] seems to be up, as I have a couple of web apps that are responding when I go to them. But, I am unable to ssh into [SERVER]. I receive message, 'Permission denied, please try again.' I am able to ssh into its sister, [SERVER], so I do not believe this to be an issue with my account. Thanks! [USER] -- John Riddle UNIX Systems Administrator Division of Information Technology University of Maryland, Baltimore County"
"3073834","67010194","2025-01-17 20:19:32","Other Account Request: [USER]","Hi [USER], Sorry this got dropped for a bit. Were you able to figure out the API? Happy to schedule a synchronous meeting. On Mon Dec 02 10:56:37 2024, [USER] wrote: Hi [STAFF]- Thank you. Do you have time for a quick call to discuss the limitations/billing on the API? My cell is [PHONE NUMBER]. Thanks [USER]. On Mon, Dec 2, 2024 at 8:56 AM [STAFF] via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3073834&ticketowner=[EMAIL]&ticketsubject=Other Account Request: [USER] If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3073834 > Thank You _________________________________________ R e s o l u t i o n: Hi [USER], I've generated a Google Cloud Project for you titled '[PROJECT NAME]' and I have enabled the 'Street View Static API'. Navigate to console.cloud.google.com and let me know if you have any questions. Project name [PROJECT NAME] Project number 1009251544078 Project ID [PROJECT NAME] -- [STAFF] Appointment Calendar: https://calendar.app.google/iorJbqg6p7N5oPbD9 [STAFF].info Original Request: Requestors: [USER] First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS ID] System: Other Request Type: Account Request Hello I am looking to use the Google API to download a large number of google street images in Baltimore for my research. Is it possible to setup the API through my UMBC account? Thanks [USER]."
"3078596","67738235","2025-02-20 14:39:26","ada Account Request: [USER]","Hello [USER], I have given you a write access to [SERVER]. In the future, if you have any new issues please create a new ticket. On Wed Feb 19 12:43:57 2025, [STAFF] wrote: I need access to write to [SERVER]. Could you look into this at your earliest? On Mon Dec 02 14:54:42 2024, [STAFF] wrote: I have given user [USER] access to just [SERVER] storage and linked it to the users home directory as [DIRECTORY]. The user is still part of [GROUP] group. On Fri Nov 29 11:16:18 2024, [STAFF] wrote: If there's a way to just give her access to my storage, let me know. That will be better than making an account under my PI group. Best, [STAFF]. On Tue, Nov 26, 2024 at 3:33 PM RT API via RT <[EMAIL]> wrote: This e-mail is a notification that ada Account Request: [USER] has requested an account for the ada cluster environment in your research group. As the PI we request that you acknowledge and approve this account creation by replying to this message. Alternatively you can go to this link and review the ticket and indicate your decision here - Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=3078596> Once we have your approval and the account request is reviewed we will create the account and you and the new user will receive another e-mail notifying you that the account has been created. If you have any other questions or concerns please contact us. Thanks, HPCF support staff"
"3079361","67726149","2025-02-19 21:17:30","ada - Request to increase the storage by 10TB","Resolved in a separate ticket. -- [STAFF] Appointment Calendar: https://calendar.app.google/[CALENDAR_ID] [EMAIL]"
"3082092","67633449","2025-02-14 16:46:07","Other Account Request: [USER]","Unfortunately we cannot increase your quota without space being purchased. We have had our allocation from Google severely curtailed and are working to reduce usage. If you're interested in reading more please visit https://doit.umbc.edu/cloud-storage-changes/. If you're interested in purchasing more storage we can do so but it is sold in increments of 100GB for $20 per year. [USER NAME] Hi Roy I am currently looking for a virtual machine (AWS EC2 GCP or UMBC cloud) where I can do data processing and analytics. I will work with large volumes of data (100s of GBs). So I think a CPU-based virtual machine with 16 cores 64GB system RAM and 1TB storage capacity would be optimal. [USER NAME] Hi Sujan Could you explain your needs a bit more? What sort of compute resources are you looking for? How much storage? And for how long? Further these requests generally come from staff or faculty member who can vouch for long-term ownership. Do you have a PI/advisor within GESTARR-II that might be appropriate? Sorry for the long wait hoping we can get you the resources you need soon. [USER NAME] Hi I am a graduate research assistant working on research projects involving machine learning and big data at the GESTAR II department. I am in need of computing resource in the form of virtual machine from UMBC to store and process data and train machine learning models. I would really appreciate it if you could approve this request."
"3089529","67485316","2025-02-07 14:48:23","Other - AWS New Account Shell setup with iHARP credits","[STAFF], This account has been created and added to Kion. Please share the link with the appropriate users and let me know if there are reports of problems. Have a nice weekend. -- [STAFF] DoIT, Windows System Administrator [EMAIL] (XXX)-XXX-XXXX"
"3089889","67375062","2025-02-03 18:33:41","Other - AWS New Account Shell setup with iHARP credits","This account has been configured in Kion and a budget notification has been set at 3500. Please share the logon link with the iHARP user, and let [STAFF] know if they run into any problems. Have a nice day. -- [STAFF] DoIT, Windows System Administrator [EMAIL]"
"3092269","66713274","2025-01-02 19:03:52","Common Name: [SERVER] - Expires :  01/08/2025","Seven day notice. -- [STAFF] [EMAIL]"
"3092561","66731663","2025-01-03 17:23:08","taki - ImportError: libbz2.so.1.0: cannot open shared object file: No such file or directory","It is also possible to module load bzip2. When you module load bzip2 it will update GCCcore/11.2.0 to GCCcore/12.2.0. After running the command module load bzip2, import bz2 wasn't returning an error. I recommend trying module load bzip2, let me know if you still have the error. On Fri Jan 03 [STAFF] wrote: I added this to my slurm script and to my bash script which calls slurm and I still get the same error message. Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=[ID]> Last Update From Ticket: Hello [USER], If we edit /etc/ld.so.conf, it may break other peoples code. I would first recommend adding /usr/lib64 to the PATH variable. (PATH=/usr/lib64:$PATH). I am hoping it will make libbz2.so.1.0 easily discoverable. Let us know, if you still get the error. On Mon Dec [DATE] [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] System: taki Request Type: General Support I am running into this ImportError: libbz2.so.1.0: cannot open shared object file: No such file or directory More of the traceback message says: import bz2 File '/usr/cluster/contrib/Python/3.7.6-intel-2019a-2018/lib/python3.7/bz2.py', line 19, in from _bz2 import BZ2Compressor, BZ2Decompressor ImportError: libbz2.so.1.0: cannot open shared object file: No such file or directory When I looked online to try to fix this error, I saw this suggestion: https://stackoverflow.com/questions/20842732/libpython2-7-so-1-0-cannot-open-shared-object-file-no-such-file-or-directory The basic steps suggest: 1) run command: whereis libpython2.7.so.1.0 (output says: libpython2.7.so.1: /usr/lib64/libpython2.7.so.1.0) 2) paste /usr/lib64 to /etc/ld.so.conf 3) run ldconfig Can you look into this and help me solve this error? I don't want to accidentally break anything. I am using python venv to install local packages as needed but this error requires more steps Best, [STAFF]"
"3093471","67905558","2025-02-28 17:32:52","taki - publications to post","We have added the 2 publication below to the website. On Fri Jan 17 18:00:28 2025, [STAFF] wrote: > Hi, [USER], wonderful. I appreciate how little time you have. Have a great weekend! But may I remind you that we also had these two, I quote the whole e-mail that I had forward you once: Hello [USER], I wanted to share with you a couple of recent publications of ours that utilized the UMBC HPCF for data analysis. The publications are: 1. B. Joshi, T. A. Smith, and Y. Shih, Phys. Rev. A *110*, L031702 (2024) (doi: 10.1103/PhysRevA.110.L031702). 2. B. Joshi, T. A. Smith, and Y. Shih, Appl. Phys. Lett. *125*, 241105 (2024) (doi: 10.1063/5.0243508). Thanks for your support! Regards, [USER] Graduate student Department of Physics, UMBC On Fri, Jan 17, 2025 at 5:17 PM [STAFF] via RT <[EMAIL]> wrote: > If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3093471&ticketowner=proutry1%40umbc.edu&ticketsubject=taki - publications to post > If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3093471 > Thank You > > ______________________________________ > Resolution: Done! Sorry for the lag. Finally found some time in the week to get to this. Take care On Mon Jan 13 14:27:56 2025, [STAFF] wrote: > Hi, [USER], Yes, the 3 posted pubs (2 tech. rep. plus 1 conference paper) look good. In my original ticket, the limited number of characters cut off the 4th publication like: Michael O. Chen, Julian Hodge, Peter L. Jin, Ella Protz, Elizabeth Wong, Ruth Obe, Ehsan Shakeri, Mostafa Cham, Matthias K. Gobbert, Carlos A. Barajas The PDF file for this is BigDataREU2024Team2REUSymposium.pdf If you open that, you can see the title and rest of author list. It should be: Michael O. Chen, Julian Hodge, Peter L. Jin, Ella Protz, Elizabeth Wong, Ruth Obe, Ehsan Shakeri, Mostafa Cham, Matthias K. Gobbert, Carlos A. Barajas, Vijay R. Sharma, Sina Mossahebi, Lei Ren, Stephen W. Peterson, and Jerimy C. Polf. Improving Gamma Imaging in Proton Therapy by Sanitizing Compton Camera Simulated Patient Data using Neural Networks through the BRIDE Pipeline. It is the same conference, so copy the rest of the citation from the other IEEE Big Data paper. I hope this makes sense. Glad to hear that the tech. rep. server will continue to exist. Matthias -- [USER] Appointment Calendar: https://calendar.app.google/iorJbqg6p7N5oPbD9 royprouty.info > > __________________________________ Original Request: Requestors: [STAFF] First Name: [STAFF] Last Name: [STAFF] Email: [EMAIL] Campus ID: [USER] System: taki Request Type: General Support Hi, [STAFF] and all, I sincerely hope that we will still maintain the publications page at the HPCF webpage, under the Research tab. Here are four publications to please post. If I had still access, I would have done it; let me know. I already put the PDF files into the standard location, which I am listing under each as a fully qualified location. Recently, also one user contacted me for two other publications. I will forward that e-mail to [STAFF]. Thanks, [USER] Olivia Zhang, Brianna Grissom, Julian Pulido, Kenia Munoz-Ordaz, Jonathan He, Mostafa Cham, Haotong Jing, Weikang Qian, Yixin Wen, and Jianwu Wang. Accurate and interpretable radar quantitative precipitation estimation with symbolic regression. Technical Report HPCF–2024–4, UMBC High Performance Computing Facility, University of Maryland, Baltimore County, 2024. PDF file at http://hpcf-files.umbc.edu/research/papers/BigDataREU2024Team1.pdf Michael O. Chen, Julian Hodge, Peter L. Jin, Ella Protz, Elizabeth Wong, Ruth Obe, Ehsan Shakeri, Mostafa Cham, Matthias K. Gobbert, Carlos A. Barajas, Zhuoran Jiang, Vijay R. Sharma, Lei Ren, Sina Mossahebi, Stephen W. Peterson, and Jerimy C. Polf. Using neural networks to sanitize Compton camera simulated data through the BRIDE pipeline for improving gamma imaging in proton therapy on the ada cluster. Technical Report HPCF–2024–5, UMBC High Performance Computing Facility, University of Maryland, Baltimore County, 2024. PDF file at http://hpcf-files.umbc.edu/research/papers/BigDataREU2024Team2.pdf Olivia Zhang, Brianna Grissom, Julian Pulido, Kenia Munoz-Ordaz, Jonathan He, Mostafa Cham, Haotong Jing, Weikang Qian, Yixin Wen, and Jianwu Wang. Accurate and interpretable radar quantitative precipitation estimation with symbolic regression. In 2024 IEEE International Conference on Big Data (IEEE Big Data 2024), in press (2024). PDF file at http://hpcf-files.umbc.edu/research/papers/BigDataREU2024Team1IEEEBigData.pdf Michael O. Chen, Julian Hodge, Peter L. Jin, Ella Protz, Elizabeth Wong, Ruth Obe, Ehsan Shakeri, Mostafa Cham, Matthias K. Gobbert, Carlos A. Barajas"
"3094216","66786961","2025-01-08 14:47:52","taki - ImportError: No module named pathlib","Hello [USER], Glad you got everything sorted out. I will close the ticket for you. Best, On Fri Jan 03 16:55:06 2025, [STAFF] wrote: I found out the error. The problem was the virtual environment variable in bin/activate was incorrect. It works now, but I don't see how to close the ticket. Sorry for the inconvenience On Fri, Jan 3, 2025 at 4:46 PM via RT <[EMAIL]> wrote: Greetings, This message has been automatically generated in response to the creation of a ticket regarding: Subject: '[SYSTEM] - ImportError: No module named pathlib' Message: First Name: [USER] Last Name: [STAFF] Email: [EMAIL] Campus ID: [ID] System: [SYSTEM] Request Type: General Support I am using venv python and I have a script that worked a few hours ago but now it doesn't work and I don't understand what I might have done to break it. The error comes from the line: File '/umbc/xfs1/cybertrn/reu2022/team2/[USER]/research/Triples/data_cleaning-stage1and2/Stage3and4//data_pipeline_manager.py', line 4, in copyRequisiteFilesAndFolders from pathlib import Path ImportError: No module named pathlib When I try to pip3 install pathlib into my virtual environment, I get: Defaulting to user installation because normal site-packages is not writeable Requirement already satisfied: pathlib in /umbc/xfs1/gobbert/users/[USER]/.local/lib/python3.7/site-packages (1.0.1) So then I try to add this to my PATH (export PATH=/umbc/xfs1/gobbert/users/[USER]/.local/lib/python3.7/site-packages:$PATH) and I still get the same error. I assume it had to do with a module I loaded before but how do I get this to work all in virtual environment?"
"3094459","66793024","2025-01-08 16:21:32","taki Account Request: [USER]","Hi [STAFF], Your account ([USER]) has been created on [SERVER]. Your primary group is [GROUP]. Your home directory has 500M of storage. Your home directory has two symbolic links to your group storage space. Please read through the documentation found at [SERVER]. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://[LINK]/) Best wishes, On Sat Jan 04 19:50:38 2025, [STAFF] wrote: > [USER]"
"3094497","66793890","2025-01-08 16:32:59","taki Account Request: [USER]","Hi [USER],  Your account ([USERNAME]) has been created on [SERVER]. Your primary group is [GROUP]. Your home directory has 500M of storage. Your home directory has two symbolic links to your group storage space. Please read through the documentation found at [WEBSITE]. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://[WEBSITE]/)  Best wishes,   On Sat Jan 04 22:30:47 2025, [STAFF] wrote: > Please authorize [USER], > Thanks, >  [STAFF], > Sent from my iPhone  On Jan 5, 2025, at 8:57AM, RT API via RT <[EMAIL]> wrote: > Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=3094497> Last Update From Ticket: First Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] System: [SYSTEM] Request Type: Account Request Position Title: Undergraduate Student Affiliation UMBC Department: Biological Sciences Phone: [PHONE] Alt E-Mail: [EMAIL] Sponsor Information: Name: [STAFF] Department: Biological Sciences Email: [EMAIL] Phone: [PHONE] Research Title: Artificial Intelligence for Precision Oncology: A Multi-Omics Knowledge Network for Personalized Lung Cancer Treatment Abstract: Lung cancer, particularly non-small-cell lung cancer (NSCLC), is a significant health concern... People: [STAFF] Comments: I'm looking to create an account for [SERVER] to use for her research lab and need access to her student directories."
"3095182","66796651","2025-01-08 17:25:40","ada Account Request: [USER]","Hi [STAFF], Your account ([USER]) has been created on ada.rs.umbc.edu. Your primary group is pi_tjo. Your home directory has 500M of storage. Your home directory has two symbolic links to your group storage space. Please read through the documentation found at hpcf.umbc.edu. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) Best, On Mon Jan [DATE] [TIME], [STAFF] wrote: > [USER]"
"3095250","66794440","2025-01-08 16:44:26","taki Account Request: [USER]","Your account ([USER]) has been created on [SERVER]. Your primary group is [GROUP]. Your home directory has 500M of storage. Your home directory has two symbolic links to your group storage space. Please read through the documentation found at [SERVER]. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. On Mon Jan [DATE] [TIME], [STAFF] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [CAMPUSID] >  > System:                    [SERVER] >  > Request Type:              Account Request >  > Position Title:            Graduate Student >  > Affiliation                [AFFILIATION] > Department:                [DEPARTMENT] > Phone:                     [PHONE] > Address:                   [ADDRESS] >  > Role:                      Member of the research group >  > Sponsor Information: >    Name:                       [STAFF] >    Department:                 [DEPARTMENT] >    Email:                      [EMAIL] >    Phone:                      [PHONE] >  > Research Title:            [TITLE] >  > Abstract:                  [ABSTRACT]. People:                    [STAFF] Comments:                  I am looking to create an account for [SERVER] to use for her research lab and need access to her student directories."
"3096965","66830808","2025-01-09 20:01:03","[USER] - Running into error","Thanks, it worked. On Thu, Jan 9, 2025 at 2:45 PM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Yes, that certainly could be the reason for this issue. Correcting the listed file path in the slurm script should resolve your issue. I cannot be entirely sure what the cause was, but either the topmon file was moved to a different directory, or the path specified in the slurm script was changed, which resulted in the script being unable to find the proper file. If you need any other assistance, please feel free to reach out! Kind regards, [STAFF] DOIT Unix Infra Student Worker On Thu Jan 09 14:22:18 2025, [USER] wrote: The jobs used to work without issue before so could this mean I accidentally changed the location of the file without noticing? On Thu, Jan 9, 2025 at 1:49 PM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: After investigating, it appears that the 'topmon' file, supposedly located in '/home/[USER]/tjo_common/groupshared/[USER]/6-10/src/topmon' does not exist. It appears that the directory '6-10' does not exist in /home/[USER]/tjo_common/groupshared/[USER]. However, it appears that the topmon file is located in '.../[USER]/0ther_files/src/topmon', so I would suggest editing line 14 of your slurm script to 'PROG=/home/[USER]/tjo_common/groupshared/[USER]/0ther_files/src/topmon'. Kind regards, [STAFF] DOIT Unix Infra Student Worker On Thu Jan 09 13:40:06 2025, [USER] wrote: Here is the script: #!/bin/bash #SBATCH --job-name=L287_re # Job name #SBATCH --output=slurm.out # Output file name #SBATCH --error=slurm.err # Error file name #SBATCH --partition=cpu2021 # Partition #SBATCH --qos=medium+ # Queue #SBATCH --time=4:00:00 # Time limit #SBATCH --nodes=1 # Number of nodes #SBATCH --ntasks-per-node=1 # MPI processes per node echo 'PWD is ' $PWD PROG=/home/[USER]/tjo_common/groupshared/[USER]/6-10/src/topmon echo 'path to PROG is ' $PROG for job in relax;do echo $job cp -f 'fort.4.$job' fort.4 $PROG if tail -n 1 'run1a.dat' | grep 'Program';then echo 'valid finish' else echo 'invalid finish' exit 0 fi cp -f config1a.dat fort.77 mv -f run1a.dat 'run.$job' mv -f config1a.dat 'config.$job' mv -f movie1a.dat 'movie.$job' mv -f fort.12 'fort12.$job' mv -f box1config1a.xyz 'box1config.$job' mv -f box2config1a.xyz 'box2config.$job' mv -f box1movie1a.xyz 'box1movie.$job' mv -f box2movie1a.xyz 'box2movie.$job' done cd $PWD sbatch run_cool.sh The output files are usually generated in the same folder as the input files. The path to that folder is /home/[USER]/tjo_common/groupshared/[USER]/H20. Thank you!"
"3098616","66872661","2025-01-13 13:20:47","ada - Assistance Needed with SSH Connection Issue","Hi [USER], It appeared that we had a load spike overnight which was keeping users from connecting to the login node. This should be resolved now. Please let us know if you have any further issues. On Mon Jan 13 04:11:18 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] System: ada Request Type: General Support Hi, I am experiencing an issue while attempting to connect to the server at [SERVERNAME].rs.umbc.edu using SSH (ssh [USERNAME]@[SERVERNAME].rs.umbc.edu -p 22). I receive the error: 'kex_exchange_identification: read: Connection reset by peer Connection reset by [IPADDRESS] port 22' I have verified that my SSH client, network, and credentials are correct, and I have also tried connecting from a different network, but the issue persists. I would appreciate your assistance in resolving this problem. Thank you for your time and support. Best regards, [USER] Data Scientist -- Best, [STAFF]"
"3098901","66913540","2025-01-14 16:56:32","ada - Follow-up on High Load Git Operations","There is nothing specifically about git operations, but all I mean to say is use SLURM/the cluster to allocate yourself resources like you would a normal job, and then have the git operations run there. You can do this using srun, sbatch, or an interactive job. Here are the basics for requesting resources via slurm on Ada. Hopefully this helps. https://hpcf.umbc.edu/ada/slurm/overview/. On Tue Jan 14 11:41:48 2025, [USER] wrote: I couldn't find the link on the HPCF website that describes the procedure of running git operations in a slurm allocation. Could you refer me to that link? Thanks. That seems very likely if you're attempting to run github copilot locally on the login node and not as an API. Running this git operations is not necessarily a problem, it's running them on the login node. As was suggested in the email, run these operations in a slurm allocation as defined on the ada website, and it shouldn't be a problem. Please let me know if you have any other questions about this, or if you feel I've adequately answered your question. I turned them off a while ago AFAIR and again I turned them off today after receiving the email from [STAFF]. FYI, I was using GitHub Copilot and I uninstalled that too. Is it related to that? I am asking this to clarify because I might install that again. Hi [USER], Just to clarify, did you just turn them off? Or did you turn them off a while ago? Here is the load that we saw before we killed the operations: PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM TIME+ COMMAND 17477 [USER]    20   0  925456 770844    276 R  41.6  6.3 1058:02 git 15117 [USER]    20   0  830540 675944    272 R  41.3  5.5 836:16.54 git 15322 [USER]    20   0  773192 629160    272 R  38.9  5.1 733:27.47 git 14481 [USER]    20   0  827920 673256    272 R  38.3  5.5 833:14.53 git 24828 [USER]    20   0  938496 783896    276 R  37.6  6.4 1097:48 git 5874 [USER]    20   0  782256 638280    272 R  36.6  5.2 759:00.46 git 24916 [USER]    20   0  937968 783372    276 R  36.3  6.4 1097:47 git 16908 [USER]    20   0  907472 630508    264 D   7.3  5.1 1015:10 git 3183 [USER]    20   0  898256 613400    264 D   6.6  5.0 989:28.39 git 17955 [USER]    20   0 1148616 558132    264 D   6.3  4.5 1688:03 git 27844 [USER]    20   0  912804 629744    264 D   5.9  5.1 1029:03 git 27862 [USER]    20   0 1097216 519064    264 D   5.9  4.2 1565:41 git 32542 [USER]    20   0  932028 623724    272 D   5.9  5.1 1086:46 git 29912 [USER]    20   0 1096732 540448    264 D   5.6  4.4 1563:56 git 11909 [USER]    20   0 1520268 491832    264 D   5.3  4.0 2985:25 git 13917 [USER]    20   0 1480640 481424    264 D   5.3  3.9 2805:23 git Did you run any commands recently? First Name:                [USER]. Last Name:                 [USER]. Email:                     [EMAIL]. Campus ID:                 [CAMPUSID]. System:                    ada. Request Type:              General Support. Hi, I recently received an email from HPCF regarding a high load of git operations originating from my login node, which is affecting other users on Ada. I sincerely apologize for any inconvenience this has caused. I have already turned off all GitHub syncs and backups, but I am unsure what might still be contributing to this issue. Could you let me know what steps I should take to ensure this doesn’t happen again? Additionally, I would appreciate it if you could provide details about the specific git operations responsible for this load. Thanks."
"3099133","66922099","2025-01-14 19:57:30","taki - Latex","It looks like there was an issue with LaTeX compilation on the taki system due to an outdated installation. The problem has since been resolved by installing a newer version of TeX Live.  Here's a summary of the conversation:  * Sergio DeSouza-Machado reported an issue with compiling a manuscript using the American Meteorological Society (AMS) LaTeX package on the taki system. * He received an error message indicating that the xkeyval package was loaded before \documentclass, which is typically caused by an outdated LaTeX installation. * Max Breitmeyer from the DOIT Unix Infra team responded to the issue and installed a newer version of TeX Live, which resolved the problem. * Sergio confirmed that he could now compile his manuscript successfully using the updated LaTeX installation.  I hope this summary helps! Let me know if you have any further questions."
"3100018","67043552","2025-01-21 16:03:31","[USER] has an account but working under a different [STAFF].","To access [STAFF]'s group, create a new account request ticket: https://doit.umbc.edu/request-tracker-rt/doit-research-computing/. Once created and approved by [STAFF], you will have access to [STAFF]'s group. I will resolve this ticket. On Tue Jan 21 10:48:47 2025, [USER] wrote: > I did not. They are still using Taki, so if you can give me access to Taki under [STAFF]'s account, that would be great. Do you know when Taki will no longer be available for the math/[STAFF] group? I'll be working in [STAFF]'s lab until end of February early March. > Thanks, [USER]. On Jan 21, 2025, at 10:31 AM, [STAFF] via RT wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3100018 Last Update From Ticket: I am not sure if you saw my earlier email. I asked the type of account you wanted. Dr. [STAFF] doesn't have a chip account yet. However, I can give you access to Taki under pi [STAFF]. If you want an account under [STAFF] where you will have your own directory and can run a job under [STAFF]'s group, then you will need to create an account request ticket. Do you want personal directory in Dr. [STAFF]'s storage? or Do you just need access to the data [STAFF] owns ? On Tue Jan 21 08:04:44 2025, [USER] wrote: Hello Do you still need use Taki under Dr. [STAFF]'s group? First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USER] Request Type: Other Hi, I have an account for the Lobo lab under [STAFF] that I will be using ongoing however for the next 6 weeks I will need to use Taki/Chip for a different lab under Dr. [STAFF] in the math dept. Not sure what needs to be changed for usage accounting. Could you please advise for this temporary access?"
"3100547","67101228","2025-01-23 00:02:18","taki - !","Here's some background on the email from [STAFF]. Happy to discuss later tonight or tomorrow AM. --  [STAFF] Appointment Calendar: https://calendar.app.google/[CALENDAR_LINK] [EMAIL]"
"3101319","66968804","2025-01-16 16:18:17","ada - Hogging-up of the ADA cluster","Hi [USER], I understand your frustration regarding job scheduling. Currently, the user [USER] has 1000 array jobs submitted, with 13 running and the rest pending. Jobs are pending primarily due to priority settings in Slurm, as [USER] has been deprioritized based on resource usage. While Ada is a shared resource, the priority setup ensures fair access for all users. Once the running jobs complete, other users' jobs will likely move to the front of the queue. Notably, job age in the queue also affects priority—the longer a job waits, the higher its chance of running next. I recommend submitting your jobs even if resources aren’t immediately available, as they will be prioritized once current jobs finish. You can learn more about priority on our page https://hpcf.umbc.edu/ada/slurm/priority/. On Thu Jan 16 06:23:49 2025, [STAFF] wrote: > First Name: [USER] > Last Name: [USER] > Email: [EMAIL] > Campus ID: [CAMPUS_ID] >=20 > System: ada >=20 > Request Type: General Support >=20 > I tried to run some jobs but couldn’t get anything through because the user [USER] has run a 1000-array job which has the entire cluster tied up. Requesting 1000 GPUs is extremely unprofessional. On top of that, all the gnodes are being used by the job. If the jobs can run on the 2080s, there is no reason for the user to hog up the higher-memory 8000s."
"3102087","66990971","2025-01-17 13:50:24","ada - [USER] can occupy all of the HPCF! this is absolutely crazy!!","I don't see any of your jobs in the queue, so I am assuming this issue is resolved. Remember that jobs should never be expected to immediately run on a shared resource. Jobs that don't immediately run are then in a 'pending' or 'PD' state. Slurm determines which job from the set of PD jobs should run next based on three factors: 1) How long the PD jobs has been waiting to run, 2) How frequently the user's group has been running jobs, and 3) How large the job is (smaller jobs have slightly more priority). Item 1 means that any job you desire to run should be submitted ASAP and left for slurm to run when slurm can identify the resources. Item 2 means that users who have been 'hogging' the cluster quickly see their jobs de-prioritized in favor of users who have submitted jobs but not used the cluster as much. Item 3 doesn't factor much into the issue I believe you're communicating, but exists nonetheless. Further, no job can run on requested resources for more than 72 hours. This is due to preemption rules that exist on the cluster, but this preemption don't seem to have been at play given the timeframe of this ticket. All of these usage rules were discussed and set by the PIs of the original NSF MRI that funded ada. In the near future, faculty-led governance groups will be established and these rules may be revisited. I'm happy to take note of your concern and bring it up to these groups. Any changes would be announced on the HPCF myUMBC group. On Thu Jan 16 21:25:18 2025, [USER] wrote: First Name: [USER], Last Name: [USER], Email: [EMAIL], Campus ID: [CAMPUS_ID]. System: ada. Request Type: General Support. To whom it may concern: I am trying to run my code using multiple gpu in ADA, however it is hard for me to find a spot for even a single GPU!!. Attached screenshots are from last night (9.15pm, Jan-16-2025). With all due respect, each user should have some limit on GPU usage, as we have deadlines too to run our experiments!. Thank you for your understanding. / [USER] [EMAIL]."
"3102116","66993198","2025-01-17 14:49:26","taki - Sparse Network Simulation Question","Hi [USER], From what I can find there is no way to force slurm to run all at the same time, but there are a few workarounds we can try. First, you can specify nodes which are in the 'idle' state using the '--nodelist' flag. Note that using this flag will make it so that your jobs will only run on the specified node list so make sure you do the math on the resources requested. Second, you can use '--hold' flag in the command to put all your jobs into a pending state until the resources are available. You'll then have to manually release the job using 'scontrol release $job_number' once you see the available nodes. As an aside, one of the nice things about using sbatch is that you can put all of the flags/options in the slurm file that you are submitting as an sbatch, and not have to rewrite it every time you want to resubmit the job. For example in your slurm file here you could write: '#!/bin/bash #SBATCH --time=30 #SBATCH --qos=normal+ #SBATCH --account=[STAFF] #SBATCH --partition=cpu_2021 #SBATCH --cpus-per-task=1 #SBATCH --array=0-5 #SBATCH --hold' Finally, note that there is no partition called 'batch' anymore. The names of the partitions can be found here https://hpcf.[EMAIL]/system-description-taki/. Hope this helps, and let me know if you need further assistance. On [DATE], [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] System:                    taki Request Type:              General Support Hello, I want to start doing some experiments again for my side project that involve simulating sparse networks on Taki. The last time I did one of these experiments, which has been months at this point, I used a Slurm command along the lines of this: sbatch --time=30 --qos=normal+ --account=[STAFF] --partition=batch -c 1 --array=0-199 `pwd`/ddlserver.slurm $modelfolder 200 buildnetwork $seed The issue with this command was that, depending on the load on the cluster, some fraction of the intended 200 jobs used to simulate the 200 node network would be launched, but they would timeout before the rest of the 200 jobs were launched. In order for the code to run correctly, all 200 jobs need to be running at the same time. Is there a way to let Slurm know that all the jobs need to be launched at the same time and that they should be held until that is possible? Is there also some way to let Slurm know that the jobs primarily spend their time sleeping while they wait for other nodes on the network to finish processing their data? The last time I worked on this project, I did try to look through the Slurm documentation to look for flags and environment variables that could help the simulations run more smoothly, but I never was able to find anything that worked the way I wanted it to. Please let me know if you have any ideas for the best way for me to proceed. Thank you, [USER]"
"3102734","67524484","2025-02-10 17:16:40","[USER] - Adding accounts to group is789sp24 for [USER]'s class","Hi [STAFF], sorry about the delay. The student has been added, he was incorrectly set up using his campus id instead of UMBC username. Additionally, at your request I have removed all other users, except for you, from the is789sp24 slurm account. On Sun Feb 09 10:02:40 2025, [USER] wrote: Any update on this? The student still cannot log in to Taki. On Thu, Feb 6, 2025 at 11:02 AM [STAFF] wrote: So far, most students were able to use Taki successfully for my course. Thanks for the help. I do have two requests: 1. One student just cannot log in after many tries. I can see his account (jm30411) was set up, and his group is correct. How should we deal with this? I notice his UMBC email is [EMAIL], assume either jm30411 or [EMAIL] could be his account. Maybe we could remove jm30411 account, and add [EMAIL] to the is789sp25 group. 2. Can you remove all accounts for is789sp24 except me? We currently have one account belonging to both groups and it has caused some issues. On Thu, Jan 30, 2025 at 9:34 AM [STAFF] wrote: Thanks. Let's not delete the old directory yet. During the semester, I might need to check back in case the new folder misses something. We can safely delete it around the end of this semester. On Thu, Jan 30, 2025 at 9:16 AM [STAFF] via RT wrote: Ticket Last Update From Ticket: Hi [STAFF], The new users have been added. Have you transferred everything out of the old group so that we can delete it? On Wed Jan 29 18:35:31 2025, [USER] wrote: The new group works fine now. Thanks! I do have two more students added to the class. Please add them at taki. Thanks Yashaswini Prashanth Kumar mu81931@umbc.edu Umme Kulsum bp18014@umbc.edu On Thu, Jan 23, 2025 at 10:28 AM [STAFF] via RT wrote: Ticket Last Update From Ticket: Good morning [STAFF], I modified the permissions of the is789sp25 group folder and the folders beneath it to match the permissions set on the is789sp24 folder. Though one change I made is to set the group sticky bit on the is789sp25/common folder so that files created there are created with the matching group ownership. When you have a chance could you poke at the group directories again to make sure everything is working correctly? Regarding reusing the is789sp24 group - I think some wires got crossed when I was discussing this request with the team, and I assumed you intended to create a new group. I apologize for the confusion on this regard, but if you're okay with the new group then we'll stick with it. Thank you, [STAFF] On Wed Jan 22 13:21:32 2025, [USER] wrote: Thanks. My original request was to reuse is789sp24 and /umbc/rs/is789sp24/, which should be easier. But creating a new group is fine with me. I tried the /umbc/rs/is789sp25/ folder and the two new symbolic links at my home directory (~/is789sp25_user and ~/is789sp25_common) and got the following errors. [jianwu@taki-usr1 is789sp24_common]$ cd /umbc/rs/is789sp25/ bash: cd: /umbc/rs/is789sp25/: Permission denied [jianwu@taki-usr1 is789sp24_common]$ ls -lt ~/is789sp25_common lrwxrwxrwx 1 [STAFF] is789sp25 25 Jan 21 11:52 /home/[STAFF]/is789sp25_common -> /umbc/rs/is789sp25/common [jianwu@taki-usr1 is789sp24_common]$ ls -lt /umbc/rs/is789sp25/ ls: cannot open directory /umbc/rs/is789sp25/: Permission denied [jianwu@taki-usr1 is789sp24_common]$ cd ~/is789sp25_user bash: cd: /home/[STAFF]/is789sp25_user: Permission denied [jianwu@taki-usr1 is789sp24_common]$ cd ~/is789sp25_common bash: cd: /home/[STAFF]/is789sp25_common: No such file or directory [jianwu@taki-usr1 is789sp24_common]$ ls -lt ~/is789sp25_user lrwxrwxrwx 1 [STAFF] is789sp25 25 Jan 21 11:52 /home/[STAFF]/is789sp25_user -> /umbc/rs/is789sp24/users/[USER] On Tue, Jan 21, 2025 at 3:47 PM [USER] wrote: First Name: [STAFF] Last Name: Wang Email: [EMAIL] Campus ID: [USER] System: taki Request Type: General Support I'm teaching course IS 789 (big data) this Spring and the course requires taki cluster like last year. I’m attaching enrolled student info. Please add them to group is789sp24. Feel free to remove current members of the group except me and [EMAIL] who will be a RA for the course. Their folders at /umbc/rs/is789sp24/users/ can also be removed. Thanks! Attachment 1: IS 789 Roaster Spring 2025 1-17.xls (https://umbc.box.com/s/esulprw2gpkxj4q1q0fjr5nw24v35hf1)"
"3104301","67032752","2025-01-21 13:21:16","Other Account Request: [USER]","Here's another: bivashka On Tue Jan 21 08:14:59 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] System:                    Other Request Type:              Account Request Please add users [USER], [USER], [USER], and [USER] to chip cluster and give access to pi_lobo partition. Ping me on webex when done and sanity checked."
"3104657","67051411","2025-01-21 18:04:03","ada - Resource Usage Concern on ada","Hi [STAFF], anyone should be able to run `id <user>` to see which group any user belongs to. In this case, the user '[USER]' is a member of the pi_ryus PI group out of CSEE. Importantly, the user `[USER]` is running single GPU card jobs on the RTX 6000 nodes. The job you've highlighted (job ID 405825) is required to run on eight RTX 8000 machines. The RTX 8000 machines are being used by another three users running another ten jobs. As I write this, g03 with 8x 2080Ti GPU cards is free. The other job submitted by a user in your group (job ID 405901) is required to run on RTX 6000 GPU cards and is slated to start in the next day or so, but may run sooner if the jobs run by user '[USER]' end ahead of their 72 hour preemption timelimit. On usage in general: Jobs that don't immediately run post-submission are put in a 'pending' or 'PD' state. Slurm determines which job from the set of PD jobs should run next based on a few factors: 1) How long the PD job has been waiting to run, 2) How frequently the user's group has been running jobs, and 3) How large the job is (smaller jobs have slightly more priority). Item 1 means that any job you desire to run should be submitted ASAP and left for slurm to run when slurm can identify the resources. Item 2 means that users who have been 'hogging' the cluster quickly see their jobs de-prioritized in favor of users who have submitted jobs but not used the cluster as much. All of that said, while the usage of the cluster due to user '[USER]' is high, I can see already that jobs submitted by this user are being de-prioritized in favor of others. Slurm takes this into consideration when resources become free. A separate faculty slurm doesn't seem to be factoring into its estimated start time is the preemption policy on ada that limits jobs to no more than three days of runtime if the hardware is requested by another job. I am in no way suggesting this usage us ideal, but just that (1) the output of squeue can make it seem like the user is using more than they actually are and (2) the user is not yet running afoul of any usage rules. These usage rules were discussed and set by the PIs of the original NSF MRI that funded ada back in 2020. In the near future, faculty-led governance groups will be established and these rules stand to be revisited. I'm happy to take note of your concern and bring it up to these groups and key all PIs into the process."
"3104697","67049019","2025-01-21 17:32:19","ada - Unable to access GPU","Hi [USER], I see your two pending jobs in the ada slurm queue. Remember that jobs should never be expected to immediately run on a shared resource. Sometimes they do run immediately, but other times they do not. It all depends on the usage of the system. Jobs that don't immediately run are put in a 'pending' or 'PD' state. Slurm determines which job from the set of PD jobs should run next based on three factors: 1) How long the PD jobs has been waiting to run 2) How frequently the user's group has been running jobs 3) How large the job is (smaller jobs have slightly more priority). Item 1 means that any job you desire to run should be submitted ASAP and left for slurm to run when slurm can identify the resources. Item 2 means that users who have been 'hogging' the cluster quickly see their jobs de-prioritized in favor of users who have submitted jobs but not used the cluster as much. Item 3 doesn't factor much into the issue I believe you're communicating, but exists nonetheless. Further, no job can run on requested resources for more than 72 hours. This is due to preemption rules that exist on the cluster, and is separate from any conversation on priority. All of these usage rules were discussed and set by the PIs of the original NSF MRI that funded ada. In the near future, faculty-led governance groups will be established and these rules may be revisited. I'm happy to take note of your concern and bring it up to these groups. Any changes would be announced on the HPCF myUMBC group. I hope this information helps. Your jobs will run so long as they stay in the slurm queue. On Tue Jan 21 12:03:48 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] System: ada Request Type: General Support Hello, Good Morning! I am facing a challenge accessing GPU after submitting a slurm script. Earlier, I would get access to a GPU immediately after I submitted a slurm script. I submitted a job yesterday afternoon and one this morning. But both the jobs are in PD status. This has been happening on and off since last week. Please help me out so that I can access the GPU easily. I have attached the jupyter slurm script I have used. I tried changing the constraint from rtx_8000 to rtx_6000, but the issue persists. I have also noticed that most of the GPUs are accessed by one user, '[USER]'. Sincerely, [USER]."
"3105940","67090463","2025-01-22 18:32:03","ada - CUDA_HOME","That's a common environment variable set by the CUDA module you need to load in order to have access to the drivers/CUDA stack. Please find the most appropriate module from the output of `module spider CUDA`, load that module, and then probe the BASH variable with `echo $CUDA_HOME`. On Wed Jan 22 13:29:06 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CID] System:                    ada Request Type:              General Support What is the path for the cuda? I have to set CUDA_HOME to install some libraries. Thanks."
"3106512","67318032","2025-01-31 13:19:03","Other - Assistance with chip Account","Dear [USER], No worries! :) The issue has now been resolved. Thank-you! Best, [STAFF] On Tue, Jan 28, 2025, 11:18 AM [USER] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=3106512> Last Update From Ticket: I am so sorry about this issue! I meant to change ownership when I copied the file, perhaps I forgot. However, I just fixed the issue, and I added the bash_profile and bash_logout files. We believe there was an issue with the home directory mounts when creating your user, which resulted in the files not being created in the proper place. Here is the output of ls -la on your home directory. drwx------ 3 [USER] pi_gobbert 258 Jan 28 11:16 . drwxr-xr-x 34 root root 0 Jan 27 14:32 .. -rw------- 1 [USER] pi_gobbert 883 Jan 27 19:25 .bash_history -rw-r--r-- 1 [USER] pi_gobbert 18 Jan 28 11:15 .bash_logout -rw-r--r-- 1 [USER] pi_gobbert 141 Jan 28 11:16 .bash_profile -rw-r--r-- 1 [USER] pi_gobbert 508 Jan 23 11:11 .bashrc lrwxrwxrwx 1 [USER] pi_gobbert 23 Jan 22 09:59 gobbert_common -> /umbc/rs/gobbert/common lrwxrwxrwx 1 [USER] pi_gobbert 28 Jan 22 10:00 gobbert_saved -> /umbc/rs/gobbert/group_saved lrwxrwxrwx 1 [USER] pi_gobbert 30 Jan 22 10:00 gobbert_user -> /umbc/rs/gobbert/users/gobbert drwx------ 2 [USER] pi_gobbert 118 Jan 23 09:44 .ssh -rw------- 1 [USER] pi_gobbert 803 Jan 27 19:20 .viminfo I apologize for the issues, and I hope you have a great day! On Mon Jan 27 19:25:06 2025, [USER] wrote: Hi [STAFF], Thanks for your help. Below is the output of 'll -A' in my home directory. [ehsans1@chip ~]$ ll -A total 152 -rw------- 1 [USER] pi_gobbert 856 Jan 27 13:46 .bash_history -rw-r--r-- 1 root root 508 Jan 23 11:11 .bashrc lrwxrwxrwx 1 [USER] pi_gobbert 23 Jan 22 09:59 gobbert_common -> /umbc/rs/gobbert/common lrwxrwxrwx 1 [USER] pi_gobbert 28 Jan 22 10:00 gobbert_saved -> /umbc/rs/gobbert/group_saved lrwxrwxrwx 1 [USER] pi_gobbert 30 Jan 22 10:00 gobbert_user -> /umbc/rs/gobbert/users/gobbert drwx------ 2 [USER] pi_gobbert 118 Jan 23 09:44 .ssh Indeed, the file .bashrc is there. But are the owner and group 'root' correct? This way, I'm not able to edit my .bashrc. Also, my advisor Dr. Gobbert has more files, such as .bash_profile and .bash_logout. We are not sure if these files are automatically created but wanted to bring this up. Could you please check? Thank you, [USER]"
"3106774","67965757","2025-03-04 14:41:43","taki Account Request: [USER]","Please submit separate tickets for separate issues. Since this was an account request and the account has been generated, I'm closing this ticket. On Sun Mar 02 12:04:17 2025, [USER] wrote: Hello, I just tried to load XMM as shown here, and I got a permission error: [almcewen@taki-usr1 ~]$ module load XMM-SAS/21.0.0 The following have been reloaded with a version change: 1) GCCcore/11.2.0 => GCCcore/10.3.0 2) zlib/1.2.11-GCCcore-11.2.0 => zlib/1.2.11-GCCcore-10.3.0 sh: /cm/shared/apps/x86_64-pc-linux-gnu-libc2.17/headas-init.sh: Permission denied Also, I saw on the website that my storage area should be what is linked in my home directory ([USER]) but I don't have access to that directory. Is there something I need to do to use it? Cheers, -[USER] On Feb 21, 2025, at 11:58, [STAFF] via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey. On Thu Jan 30 11:56:15 2025, [USER] wrote: Hello We are working installing XMM-SAS suite and its dependencies. Thank you for your patience, I will let you know when everything is installed and ready. On Mon Jan 27 12:13:54 2025, [USER] wrote: Hello Roy, Excellent, thanks so much. I can start setting things up there. One thing that I will need to be installed is the XMM-SAS suite, which can be found/downloaded here. That also has a few significant dependencies, like ds9 and Heasoft especially (those are linked on the SAS website). Is it possible to get these installed? George has said that he does not need an account for now. Let me know if there is more information you need. Thanks, -[USER] On Jan 25, 2025, at 13:16, [STAFF] via RT <[EMAIL]> wrote: Ticket First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USER] System: taki Request Type: Account Request Position Title: Faculty Affiliation UMBC Department: CSST Phone: [PHONE NUMBER] Alt E-Mail: [EMAIL] Address: [ADDRESS] Role: UMBC Faculty/PI Research Title: Search for Long-Period Magnetars in Archival XMM Data Abstract: Magnetars are the strongest magnets in the universe. Additionally, as a class of neutron star, they are among the most dense objects known aside from black holes. These qualities make magnetars unique laboratories for studies of both intense magnetism and gravitation. Every new source discovered provides an important insight into these incredible stars, and given that there are only 24 confirmed magnetars despite population modeling suggesting many thousands in the Galaxy, searches for new sources are crucial for building a sufficient dataset for study. All of the known sources have been discovered serendipitously by wide-field instruments when the star undergoes an energetic but uncommon outburst; however, recent studies have begun to uncover a subpopulation of magnetars with much longer rotational periods (~100s of seconds rather than 1-12 s). As a part of a related study by the PI, we expect there to be many slower magnetars in the publicly-available XMM-Newton dataset that should be well over the instrument's sensitivity limit. For these reasons, we intend to search these data for slow period sources using our previously designed search pipeline. People: [USER], George Younes Comments: The code has already been written to utilize the Slurm scheduling system, and is composed of many single tasks run as an array. In total, there are approximately 1500 XMM observations that will be included in the search. Individual job processing times can vary due to observation duration, but typically complete within a few minutes and up to an hour. In total, previous processing of a similar search with the same code completed in a few days time on a comparable HPC. Memory requirements are not significant, and a single GB per task is sufficient. Disk space requirements may be the most significant, as each of the observations may require one to several GB, and files generated in the processing may also take up to a GB. However, the pipeline removes the observation files after each task, and so this space will not be consumed all at once."
"3107194","67131887","2025-01-24 00:40:32","Other - REDCap System Issue","I restarted the old [SERVER] server, we'll have to take it back offline next week to try the updates again. I'm going to resolve this [TICKET] as there is another for the security issue that necessitates the update."
"3107497","68945761","2025-04-25 18:44:23","Other - large data set storage","It looks like you've shared a long email conversation between Michelle Starz-Gaiano and Roy Prouty from the University of Maryland, Baltimore County (UMBC) about data storage options for Michelle's research project.  To summarize:  * Michelle is working on an NSF-funded research project and needs to store around 40TB of image data. * She reaches out to Roy Prouty from the DoIT Research Computing Team at UMBC to inquire about transferring the data to cloud storage or other options. * Roy responds, suggesting a meeting to discuss the project's requirements, including data lifecycle, security needs, and potential funding sources. * Michelle provides some initial answers to these questions, indicating that the data will be needed for an extended period (start date/end date) and doesn't require special security measures beyond what UMBC already provides. * Roy mentions exploring cloud storage options within UMBC's infrastructure or high-performance storage solutions.  The conversation appears to be ongoing, with Roy mentioning working on a solution and Michelle awaiting further updates."
"3107844","67435396","2025-02-05 16:32:51","Create new AWS account","Hello! This AWS account has been created, and [STAFF] given admin access. Our vendor should reach out to [STAFF] for Pcard details. To login to the AWS account, please go to https://awslogin.[DOMAIN] - once logged in, you should see your account and AdministratorAccess role. Thanks! [STAFF]"
"3108265","67161498","2025-01-25 16:08:17","ada - [STAFF] reported that a few users tried utilizing all possible resources on the ADA clusters","I don't see any of your jobs in the queue currently or in the screenshots, so I am assuming this issue is resolved. Remember that jobs should never be expected to immediately run on a shared resource. Jobs that don't immediately run are then in a 'pending' or 'PD' state. Slurm determines which job from the set of PD jobs should run next based on three factors: 1) How long the PD jobs has been waiting to run 2) How frequently the user's group has been running jobs 3) How large the job is (smaller jobs have slightly more priority). Item 1 means that any job you desire to run should be submitted ASAP and left for slurm to run when slurm can identify the resources. Item 2 means that users who have been 'hogging' the cluster quickly see their jobs de-prioritized in favor of users who have submitted jobs but not used the cluster as much. As I write this [STAFF] is unable to run additional jobs due to this deprioritization and jobs submitted by [USER] are slated next to run (see output below). Item 3 doesn't factor much into the issue, but exists nonetheless. Further, no job can run on requested resources for more than 72 hours. I am not suggesting that this usage pattern is ideal, only that the user is operating within the rules set out by the PIs of the original NSF MRI that funded ada (along with DoIT). In the near future, faculty-led governance groups will be established and these rules may be revisited. On Fri Jan 24 20:58:18 2025, [STAFF] wrote: First Name: [USER], Last Name: [USER], Email: [EMAIL], Campus ID: [USER]. System: ada. Request Type: General Support. Hi, recently I had difficulty in requesting resources on ADA clusters. I understand it is a first come first serve, but few people requested all possible resources when they worked, and nobody else could work. like today, I attached screenshot as example. This is wild. Maybe You can limit each account to request a certain amount of resources at a time? Thank you."
"3108536","67164016","2025-01-26 02:16:03","ada - g12 is down","Hi [USER], g12 is experiencing network connection issues. I'll try to have someone on campus to diagnose tomorrow or Monday AM. Sorry for the inconvenience. On Sat Jan 25 21:05:41 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] System:                    ada Request Type:              General Support g12 is down again. Is it possible to make it run again? Thanks for the help."
"3109491","67603305","2025-02-13 16:14:16","ada - There is no resource","Hello [USER] Ada is a shared resource, thus that jobs should never be expected to run immediately. The priority setup ensures fair access for all users. Once the running jobs complete, other users' jobs will likely move to the front of the queue. Notably, job age in the queue also affects priority—the longer a job waits, the higher its chance of running next. Jobs that don't immediately run are then in a 'pending' or 'PD' state. Slurm determines which job from the set of PD jobs should run next based on three factors: 1) How long the PD jobs has been waiting to run 2) How frequently the user's group has been running jobs 3) How large the job is (smaller jobs have slightly more priority). Item 1) means that any job you desire to run should be submitted ASAP and left for slurm to run when slurm can identify the resources. Item 2) means that users who have been 'hogging' the cluster quickly see their jobs de-prioritized in favor of users who have submitted jobs but not used the cluster as much. Further, no job can run on requested resources for more than 72 hours. This is due to preemption rules that exist on the cluster. All of these usage rules were discussed and set by the PIs of the original NSF MRI that funded ada. In the near future, faculty-led governance groups will be established and these rules may be revisited. I'm happy to take note of your concern and bring it up to these groups. Any changes would be announced on the HPCF myUMBC group. I hope this information helps. I'll mark this as resolved. On Mon Jan 27 12:22:01 2025, [STAFF] wrote: First Name: [USER] Last Name: [LAST NAME] Email: [EMAIL] Campus ID: [CAMPUS ID] System: ada Request Type: General Support Hi, I’ve been unable to access cloud computing resources for the past three hours. When I ran the 'squeue' command, I noticed that one person is using more than one resource. I’ve attached a screenshot of the command output. Could you please assist me in securing a resource? Thank you!"
"3109989","67218411","2025-01-28 14:29:10","taki Account Request: [USER]","Hi [USER],  Your account ([CAMPUS_ID]) has been created on [SERVER]. Your primary group is [GROUP]. Your home directory has 500M of storage. Your home directory has two symbolic links to your group storage space. Please read through the documentation found at [WEBSITE]. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://[REQUEST_TRACKER_URL]/) On Mon Jan 27 16:25:44 2025, [STAFF] wrote: > Approved.  Best regards,  [STAFF] -- [STAFF] [TITLE] [DEPARTMENT] [UNIVERSITY] Homepage: [WEBSITE] [LAB]: [WEBSITE] Personal Webex room: [WEBEX_URL] On Mon, Jan 27, 2025 at 4:12 PM The RT System itself via RT <[EMAIL]> wrote: > Dear [STAFF], This e-mail is a notification that taki Account Request: [USER] <[CAMPUS_ID]> has requested an account for the UMBC HPCF in your user group. As the PI we request that you acknowledge and approve this account creation by replying to this message. Alternatively, you can go to this link and review the ticket and indicate your decision here - Ticket [TICKET_URL] Once we have your approval and the account request is reviewed we will create the account and you and the new user will receive another e-mail notifying you that the account has been created. If you have any other questions or concerns please contact us. See link: [CONTACT_URL] or point of contact [STAFF] <[EMAIL]> Thanks, HPCF support staff Best, Max Breitmeyer DOIT Unix Infra Student Worker"
"3110033","67786665","2025-02-22 01:12:02","Other Account Request: [USER]","Thank you so much for your email and for informing us about the logistics of the account. I will be in touch if I have any questions. Thanks, [STAFF]. Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3110033 > Last Update From Ticket: The group pi_[USER] now exists on ada. Members of this group can therefore access and contribute to the research storage space allocated to the group. This storage is located at /umbc/rs/[USER] and currently has a quota of 500G. Please review documentation on the hpcf.umbc.edu website. Submit any questions or issues as separate RT Tickets at the following URL: https://doit.umbc.edu/request-tracker-rt/doit-research-computing/. Additionally, Your account ([USER]) has been created on ada.rs.umbc.edu. Your primary group is pi_[USER]. Your home directory has 500M of storage. Your home directory has two symbolic links to your group storage space. Please read through the documentation found at hpcf.umbc.edu. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) Please inform me of any other users that you would like added to this group. On Mon Jan 27 16:44:51 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] On Behalf Of: [STAFF] ([EMAIL], [CAMPUSID]) System: Other Request Type: Account Request We are requesting the setup of an HPC group for the [STAFF] Lab to support a project focused on creating a machine learning model to annotate and count different cell types in breast cancer images. The following tools and environments are required: Development Environment: JupyterLab tmux Machine Learning Frameworks: PyTorch TensorFlow scikit-learn Programming Tools and Libraries: MATLAB pandas numpy Deep Learning Tools: YOLO (You Only Look Once) Data and Code Management: Kaggle GitHub (git) Best, [STAFF] DOIT Unix Infra Student Worker"
"3110133","67217921","2025-01-28 14:24:57","Adding a user to my account","Hi [STAFF], [USER] has been added to your group. Please let us know if she has any issues. On Mon Jan 27 19:58:42 2025, [EMAIL] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: Other Please add [USER] to my space on Taki. She will help with my cell migration project. Thanks, [STAFF]"
"3110738","67274468","2025-01-29 19:16:52","Other - check on .bashrc etc. files for [USER]","Hi [STAFF],  I have gone ahead and added user [USER] to the Chip cluster and made them a part of the pi_[STAFF] group. I have verified that the hidden files in the home directory are properly configured.  If you have any further questions or concerns, please feel free to reach out. I hope you have a great day! -- Kind regards, [STAFF]. On Tue Jan 28 12:44:46 2025, [USER] wrote: > Hi, [STAFF], > Good catch. I had not noticed him missing. This user [USER] should be [USER]. Notice that I, as regular user, have no ability to look up such Campus ID or usernames of people who are NOT active students or faculty/staff.  He was in my list of requests. Can you please create his chip account? Thank you. > Matthias > Matthias K. Gobbert, Ph.D., Professor of Mathematics > Department of Mathematics and Statistics > Center for Interdisciplinary Research and Consulting (circ.umbc.edu) > UMBC High Performance Computing Facility (hpcf.umbc.edu) > REU Site: Online Interdisciplinary Big Data Analytics ([EMAIL]) > University of Maryland, Baltimore County > 1000 Hilltop Circle, Baltimore, MD 21250 > http://www.umbc.edu/~[USER]. On Tue, Jan 28, 2025 at 12:32 PM [STAFF] via RT < UMBCHelp@rt.umbc.edu> wrote: > Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=[NUMBER]> > Last Update From Ticket: > Dear [STAFF], > It appears user [USER] does not exist on chip, However I have gone ahead and ensured that .bash_profile, .bashrc, and .bash_logout are in each of the other users home directories and have the proper file permissions. Here is the output of ls -la for each of those users home directories. dkelly7: drwx------ 3 dkelly7 pi_[STAFF] 139 Jan 28 12:18 . drwxr-xr-x 34 root    root         0 Jan 28 12:20 .. -rw------- 1 dkelly7 pi_[STAFF] 66 Jan 23 15:49 .bash_history -rw-r--r-- 1 dkelly7 pi_[STAFF] 18 Jan 28 12:18 .bash_logout -rw-r--r-- 1 dkelly7 pi_[STAFF] 141 Jan 28 12:18 .bash_profile -rw------- 1 dkelly7 pi_[STAFF] 164 Jan 23 15:41 .bashrc drwx------ 2 dkelly7 pi_[STAFF] 89 Dec 19 13:20 .ssh ehsans1: -rw------- 1 ehsans1 pi_[STAFF] 883 Jan 27 19:25 .bash_history -rw-r--r-- 1 ehsans1 pi_[STAFF] 18 Jan 28 11:15 .bash_logout -rw-r--r-- 1 ehsans1 pi_[STAFF] 141 Jan 28 11:16 .bash_profile -rw-r--r-- 1 ehsans1 pi_[STAFF] 508 Jan 23 11:11 .bashrc lrwxrwxrwx 1 ehsans1 pi_[STAFF] 23 Jan 22 09:59 gobbert_common -> /umbc/rs/[USER]/common lrwxrwxrwx 1 ehsans1 pi_[STAFF] 28 Jan 22 10:00 gobbert_saved -> /umbc/rs/[USER]/group_saved lrwxrwxrwx 1 ehsans1 pi_[STAFF] 30 Jan 22 10:00 gobbert_user -> /umbc/rs/[USER]/users/[USER] drwx------ 2 ehsans1 pi_[STAFF] 118 Jan 23 09:44 .ssh -rw------- 1 ehsans1 pi_[STAFF] 803 Jan 27 19:20 .viminfo hlewis3: drwx------ 2 hlewis3 pi_[STAFF] 86 Jan 28 12:19 . drwxr-xr-x 34 root    root         0 Jan 28 12:20 .. -rw-r--r-- 1 hlewis3 pi_[STAFF] 18 Jan 28 12:19 .bash_logout -rw-r--r-- 1 hlewis3 pi_[STAFF] 141 Jan 28 12:19 .bash_profile -rw------- 1 hlewis3 pi_[STAFF] 164 Jan 23 16:01 .bashrc mmusce1: drwx------ 3 mmusce1 pi_[STAFF] 139 Jan 28 12:20 . drwxr-xr-x 34 root    root         0 Jan 28 12:20 .. -rw------- 1 mmusce1 pi_[STAFF] 4 Dec 19 13:45 .bash_history -rw-r--r-- 1 mmusce1 pi_[STAFF] 18 Jan 28 12:20 .bash_logout -rw-r--r-- 1 mmusce1 pi_[STAFF] 141 Jan 28 12:20 .bash_profile -rw------- 1 mmusce1 pi_[STAFF] 164 Jan 23 16:03 .bashrc drwx------ 2 mmusce1 pi_[STAFF] 89 Dec 19 13:45 .ssh jpolf: drwx------ 2 jpolf pi_[STAFF] 86 Jan 28 12:20 . drwxr-xr-x 34 root    root         0 Jan 28 12:20 .. -rw-r--r-- 1 jpolf pi_[STAFF] 18 Jan 28 12:20 .bash_logout -rw-r--r-- 1 jpolf pi_[STAFF] 141 Jan 28 12:20 .bash_profile -rw------- 1 jpolf pi_[STAFF] 164 Jan 23 16:01 .bashrc swpeters: drwx------ 3 swpeters pi_[STAFF] 139 Jan 28 12:22 . drwxr-xr-x 34 root     root         0 Jan 28 12:20 .. -rw------- 1 swpeters pi_[STAFF] 5 Jan 23 16:05 .bash_history -rw-r--r-- 1 swpeters pi_[STAFF] 18 Jan 28 12:22 .bash_logout -rw-r--r-- 1 swpeters pi_[STAFF] 141 Jan 28 12:22 .bash_profile -rw------- 1 swpeters pi_[STAFF] 164 Jan 23 16:04 .bashrc drwx------ 2 swpeters pi_[STAFF] 89 Jan 23 16:05 .ssh barajasc: drwx------ 2 barajasc pi_[STAFF] 86 Jan 28 12:22 . drwxr-xr-x 34 root     root         0 Jan 28 12:20 .. -rw-r--r-- 1 barajasc pi_[STAFF] 18 Jan 28 12:22 .bash_logout -rw-r--r-- 1 barajasc pi_[STAFF] 141 Jan 28 12:22 .bash_profile -rw------- 1 barajasc pi_[STAFF] 164 Jan 23 15:51 .bashrc I apologize for the inconvenience caused by these issues, I hope I was able to assist! If you have any questions or run into any issues, please feel free to reach out! Thanks, have a great day! -- Kind regards, [STAFF]. On Tue Jan 28 12:04:46 2025, [USER] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [NUMBER] > System:                    Other > Request Type:              General Support > Hi, > This is on chip; there is no 'chip' in the pulldown menu in the Help Request, so I selected 'Other'. This is a followup to ticket 3106512 worked on by [STAFF]. That ticket was on checking that Ehsan Shakeri's account on chip was set up by providing .bashrc and other files and with ownership changed to the user (instead of root). Could you please check and let me know that also the other accounts under my pi_[STAFF] group are set up correctly? I am trying to avoid having each file tickets on this. These are the users dkelly7,ehsans1,hlewis3,mmusce1,[USER],jpolf,swpeters,barajasc > [USER]."
"3111760","67673353","2025-02-17 22:22:56","Chip Software Installation","Evening all! Happy to report that abinit has successfully been installed, and module file for it has been created. It can be loaded with the command 'module load abinit/10.0.7'. Note that you originally requested abinit 10.0.5. Attempting to download this from the source simply returns 10.0.7 version, so hopefully this is ok. I also ran the tests that are provided with abinit and all of them ran cleanly with the exception of the 'wannier90' test. This failed because the library is not currently present on the system, and I wanted to get this out to you as soon as possible. That being said, if you find it is necessary to your work, let me know and I will be happy to work with you. I'll leave this open a few days to see if you all have any issues with it. If so, let me know and we can hopefully work through it together. Otherwise, I'll close it! Thanks again for your patience! Hi all, Abinit is taking some time. Hoping to have it successfully in the next week. Happy to report that QuantumEspresso V 7.3.1 has been successfully installed. This can be found by running 'module keyword espresso'. If it does not appear, try 'module --ignore_cache keyword espresso'. To load, run 'module load QuantumESPRESSO/7.3.1-intel-2023a'. We've begun work on installing Abinit, but this may take sometime as we don't have a pre-existing module available for V10.0.5 (the most recent version available to us in this way is 9.10.3). We'll keep you updated as we make more progress. Hi all, Just to keep you updated, we're hitting an issue right now where Quantum Espresso requires openBLAS 0.3.23. Unfortunately OpenBLAS didn't add support for CPUs (emerald Rapids) until 0.3.28. We're looking into what the options are right now, and will hopefully have an answer for you soon. Hi [STAFF] and [STAFF], We very much appreciate you taking the time to do these installations. Each of these open source codes, Quantum Espresso and ABINIT, includes a file system with input test and timing files that we would also need access after they're installed as modules. That way we can adjust our input files as needed using the latest variables, functions, and formatting that are up to date with each different release. If you have any questions or need help, please don't hesitate to get in touch with us. We can provide input test files and also run tests ourselves. Thank you, [USER] On Thu Jan 30 13:33:45 2025, [STAFF] wrote: Thank you very much! Anthony Casale On Thu, Jan 30, 2025 at 12:16 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3111760> Last Update From Ticket: Hi [USER], wanted to let you know we have seen this and are working on it. Some of the installs are taking longer than expected but are progressing none-the-less. We'll update once it's finished! On Wed Jan 29 12:14:01 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USERID] Request type: General Support Hello! The Bennett group needs some software installed on Chip. Could you please install xmgrace, the LibXC Library (a library of exchange correlation functionals), Quantum Espresso v7.3.1 and ABINIT v10.0.5. Please link quantum espresso and abinit to the LibXC library, as many functions don't work without it. Thank you! [USER]"
"3112270","67290214","2025-01-30 14:20:31","taki Account Request: [USER]","Hi [STAFF], Your account ([USER]) has been created on taki.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Your home directory has two symbolic links to your group storage space. Please read through the documentation found at hpcf.umbc.edu. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/). On Wed Jan 29 22:35:01 2025, [USER] wrote: First Name: [STAFF] Last Name: [STAFF] Email: [EMAIL] Campus ID: [CAMPUSID]. System: taki. Request Type: Account Request Position Title: Graduate Student Affiliation: University of Colorado Boulder Department: Atmospheric and Oceanic Sciences Phone: [PHONE] Address: University of Colorado Boulder 311 UCB Boulder, CO 80309 Role: Non-UMBC Faculty/PI Sponsor Information: Name: [STAFF] Department: Physics Email: [EMAIL] Phone: [PHONE]. Research Title: Comparing AIRS L1C observations with a global climate model. Abstract: Radiance observations from NASA’s AIRS instrument provide an information rich, multi-decade record of climate change and variability. Directly comparing these observations with earth system models, however, is made difficult by definitional differences with model output and the absence of gridded, level-3 radiance datasets. I will create a level-3 dataset of AIRS radiances and compare these data with AIRS-like radiances produced by a satellite simulator tool running in an earth system model. People: [STAFF] and [STAFF], UMBC Comments: Please put [USER] into the pi_[STAFF] group and allow him to login to strowinteract1."
"3113543","67355465","2025-02-03 12:58:19","[USER] - MATLAB licenses failing","Hi [USER], The license expired but should be good to go now. I'll mark this as resolved, if you're still having issues you can respond to this message and it will reopen. Otherwise, have a great day! On Fri Jan 31 10:50:54 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] System: taki Request Type: General Support [EMAIL]$ matlab MATLAB is selecting SOFTWARE OPENGL rendering. License checkout failed. License Manager Error -15 Unable to connect to the license server. Check that the network license manager has been started, and that the client machine can communicate with the license server. Troubleshoot this issue by visiting: https://www.mathworks.com/support/lme/15 Diagnostic Information: Feature: MATLAB License path: 1701@license5.[DOMAIN]:1701@license6.[DOMAIN]:1701@license7.[DOMAIN]:/[USER]/.matlab/R2023b_licenses:/[DOMAIN]/ebuild-soft/skylake/software/MATLAB/2023b/licenses/license.dat:/[DOMAIN]/ebuild-soft/skylake/software/MATLAB/2023b/licenses/network.lic Licensing error: -15,570. System Error: 115 [EMAIL]$"
"3113578","67331226","2025-01-31 18:22:15","taki - MATLAB license lost on [SERVER]","working for me too now thnx [STAFF] Ticket Last Update From Ticket This was a license expiration Its been replaced now and seems to be working for me Roy Prouty hehimhis  On Fri Jan 31 2025 at 1128 RT API via RT wrote Request 3113578 was acted upon Transaction Ticket created by [USER] Queue DoITResearchComputing Subject taki MATLAB license lost on strowinteract Owner Nobody Nobody in particular Requestors [EMAIL] Status new First Name [USER] Last Name [USER] Email [EMAIL] Campus ID [ID] System taki Request Type General Support Good Morning this morning Friday 31 Jan whilst working with Matlab 2024a on strowinteract a series of messages about loss of the license eventually lead to MATLAB no longer running Could you restore MATLAB on strowinteract plz [USER]"
"3113737","67355490","2025-02-03 13:00:21","ada - Access problem","Hi [USER], Please fill out the proper request form (found here: https://doit.umbc.edu/request-tracker-rt/doit-research-computing/), and cc [STAFF] so he can confirm you're a student in his lab, and we can add you to his group.  On Fri Jan 31 12:24:27 2025, [USER] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [CAMPUSID] >  > System:                    ada >  > Request Type:              General Support >  > My research computing requires ada, hence my request to have an account. >  > Advisor: [STAFF] [LABNAME] -- Best, [STAFF]"
"3114400","67372635","2025-02-03 17:54:57","ada - Problem in executing ollama library","Dear [STAFF], Unfortunately, I am unable to replicate this error. I have looked through the virtual environments you have been using and attempted to replicate the error and was unable to. What steps did you perform to install ollama inside the conda virtual environment? I was able to properly install ollama inside a new conda virtual environment by performing the following steps. First, I used the command 'conda create --name=*venv-name*' to create a conda virtual environment, then I activated that with 'conda activate *venv-name*'. After this, I was able to install ollama with 'pip install ollama'. This allowed me to run ollama commands without receiving the 'command not found' error. In addition, unless there is a specific use case that requires ollama to be run within python, you should be able to use the available module on ada to access ollama. The version built and available on ada is ollama/0.3.14 and can be accessed by using 'module load ollama/0.3.14'."
"3115364","67364371","2025-02-03 15:30:25","ada - Account creation","Hi [USER],  Your account ([CAMPUSID]) has been created on ada.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Your home directory has two symbolic links to your group storage space. Please read through the documentation found at hpcf.umbc.edu. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) On Mon Feb 03 10:12:06 2025, [STAFF] wrote: > Approved. Best, [STAFF] On Mon, Feb 3, 2025 at 10:10 AM RT API via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3115364> Last Update From Ticket: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] System: ada Request Type: General Support My research computing requires ada, hence my request to have an account. Advisor: Prof [STAFF] [USER]'s Lab"
"3115531","68171055","2025-03-13 19:18:28","ada - Request to Install Singularity on the ada Cluster","Here are the commands I ran. Before loading apptainer, use 'srun' to start a session. Then apptainer can be loaded: module load shared module load apptainer/1.4.0-rc.2 apptainer build --sandbox <Name-of-the-container> docker://<link-to-the-environment> # Please replace the name of the container you want to create, and the link to the remote docker container you want to pull. apptainer shell --nv -B <path-to-your-repository> <path-to-your-container/Name-of-the-container> # <path-to-your-repository> is the path to the project (here I'm working on a github repo I cloned from https://github.com/[ORGANIZATION]/[REPO]). # <path-to-your-container/Name-of-the-container> is the container created by 'apptainer build' command Apptainer> export PYTHONPATH=$PWD:$PWD/<path-to-your-container/Name-of-the-container> Apptainer> python <python script you want to run> Please let me know if you have any other problems with it. I am still learning how to use apptainer myself. Thank you, [STAFF]"
"3115980","67553231","2025-02-11 15:14:24","Other - is cybertrn mounted on chip?","They have been added. Let me know if anyone is still having issues. On Mon Feb 10 11:59:10 2025, [STAFF] wrote: Hi, [STAFF], I see the directory now. However, students cannot access. I believe it is because they are not members of the Unix group cybertrn. Can you please add [USER],[USER],[USER],[USER],[USER],[USER],[USER],[USER] to the cybertrn group on chip? Thanks for the explanation! On Mon, Feb 10, 2025 at 10:40 AM Max Breitmeyer via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey. If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at Ticket The cybertrn volume is now available on chip under /umbc/rs/cybertrn. Due to the sheer volume of stuff we're doing right now, we have been waiting for users who are on chip to tell us if additional volumes are needed from their previous groups. Once taki and ada are rolled into chip, everything will be mounted, but for now it's just a request system. Sorry for the inconvenience, and let us know if you have other issues! On Mon Feb 03 16:21:24 2025, [STAFF] wrote: Request Type General Support Hi, On taki, the area in question is /umbc/xfs1/cybertrn Is this mounted on chip? Can it please be mounted? It would help me understand the context better, if you could explain the pros and cons of such things. Is not all of the taki storage going to be mounted? At least eventually? [USER]"
"3116157","67400086","2025-02-04 15:42:26","could not create conda env.","Hello [USER], I have fixed the permission issues. You should be able to create a conda environment now. Let us know if you still get a similar error. On Mon Feb 03 21:34:27 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [ID] Request type:                 General Support Hello, I am trying to create my environment using Conda in ADA, however, it shows a write permission issue as follows. Could you please help me resolve the issue?? NotWritableError: The current user does not have write permissions to a required path. path: /home/[USER]/.conda/envs/.conda_envs_dir_test uid: [ID] gid: [ID] If you feel that permissions on this path are set incorrectly, you can manually change them by executing $ sudo chown [ID]:[ID] /home/[USER]/.conda/envs/.conda_envs_dir_test"
"3116660","67489398","2025-02-07 16:30:09","ada Account Request: [USER]","Hi [STAFF], Your account ([USER]) has been created on ada.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Your home directory has two symbolic links to your group storage space. Please read through the documentation found at hpcf.umbc.edu. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) On [DATE], [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] On Behalf Of: [STAFF] ([EMAIL], [CAMPUS_ID]) System: ada Request Type: Account Request Username: [USER] Requested Action: become a user in an existing ada PI Group Primary HPCF PI Group Owner: [EMAIL] Supplemental HPCF PI Group Owners: Project Keywords: - Artificial Intelligence Additional Notes and Comments: He is a Master's student and needs access to the satellite data stored under the ihrap folder. Please add to discussion mailing list."
"3116664","67410426","2025-02-04 18:54:51","ada Account Request: [USER]","Approved  ------------------------------------------------------------ [STAFF]  Associate Dean for Research and Faculty Development College of Engineering and Information Technology Professor, Information Systems Department, Director NSF HDR Institute-[INSTITUTE]  University of Maryland, Baltimore County A Carnegie R1 Institution Lab : https://mdata.umbc.edu/ NSF Institute: https://iharp.umbc.edu/ webex: [URL]   On Tue, Feb 4, 2025 at 12:25 PM RT API via RT <[EMAIL]> wrote: This e-mail is a notification that ada Account Request: [USER] has requested an account for the ada cluster environment in your research group. As the PI we request that you acknowledge and approve this account creation by replying to this message. Alternatively you can go to this link and review the ticket and indicate your decision here - Ticket https://rt.umbc.edu/Ticket/Display.html?id=3116664 Once we have your approval and the account request is reviewed we will create the account and you and the new user will receive another e-mail notifying you that the account has been created. If you have any other questions or concerns please contact us. Thanks, HPCF support staff"
"3116809","67577369","2025-02-12 16:41:40","taki - Setting up conda and VS Code ssh tunneling","Hi [USER], Please submit a separate ticket with this new question. It will make it easier for us to look into this for our future references. On Mon Feb 10 19:01:23 2025, [STAFF] wrote: Hi [USER], I'm reactivating this ticket for another question as I get going on taking jobs in python that I am then able to use for parallel computing with dask on taki. I'd like to do the same on taki. I'm wondering if I can do that with the python 'PBSCluster' package, and if so what arguments to pass to that function. I've pasted code below for example (the first PBSCluster call is the important part). cluster = PBSCluster(cores=1, memory='3GB', queue='casper', walltime='00:06:00', project='UCUC0007') cluster.scale(16) client = Client(cluster) tiles_by_dask = [] for i, _tile in enumerate(tile_list): outpath = f'/glade/campaign/univ/ucuc0007/AIRS_data/{tile_str}/proc/{_tile.split('/')[-1][:-3]}_deg_{sat_zen_range[0]}_{sat_zen_range[1]}_proc.nc' if not os.path.exists(outpath): tiles_by_dask.append(dask.delayed(AIRS_L1C_process_wrapper)(_tile, outpath, sat_zen_range=sat_zen_range)) tiles_by_dask_computed = dask.compute(*tiles_by_dask) client.shutdown() On Wed, Feb 5, 2025 at 9:08 AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3116809> Last Update From Ticket: Dear [USER], I am glad you were able to figure out a solution to your issue! On the taki cluster, each user's home directory has 500MB of usable space. You can find documentation regarding that on our website: https://hpcf.umbc.edu/system-description-taki/ However, your PI's group has access to additional storage for usage in their groups directory under /umbc/rs/strow/. Files that are large, or would go over the 500 MB limit, can be placed into these directories, additionally, they can be symbolic linked to your home directory."
"3117960","67519554","2025-02-10 15:50:30","ada - Symbolic Links Down","Hi [STAFF], This was a result of moving some directory locations. The issue has been resolved. Let us know if you have any other issues with it. On Wed Feb 05 15:37:08 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] System: ada Request Type: General Support After I log in to the ada cluster, in the home directory, the symbolic links are down and they are pointing to the incorrect paths. See attached screenshot for more details."
"3118971","67489832","2025-02-07 16:38:12","ada Account Request: [USER]","Hi [STAFF], Your account ([USER]) has been created on ada.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Your home directory has two symbolic links to your group storage space. Please read through the documentation found at hpcf.umbc.edu. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) If you have any questions or concerns, please feel free to reach out. Best"
"3119325","67490710","2025-02-07 17:01:34","Other - ssh to chip error","I would like to close this ticket. It was a firewall issue at my job. I can connect now On Fri Feb 07 11:13:56 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] System: Other Request Type: General Support I am able to ssh to chip via my home wifi but when I try to ssh from my job ([COMPANY]), I get errors saying: kex_exchange_identification: read: Connection reset Connection reset by XXX.XXX.XXX.XXX port 22 I submitted a ticket to their help desk and the response back was: The error received 'kex_exchange_identification: read: Connection reset Connection reset by XXX.XXX.XXX.XXX port 22' is the remote end terminating the connection. Can the remote end verify that they are permitting [COMPANY]'s public IP address range of XXX.XXX.XXX.XXX/16? I don't understand why home wifi IP address was accepted but not [COMPANY]'s IP address"
"3119525","67512878","2025-02-10 13:41:13","Other - SSH keys for autologin","You can generate ssh keys for use on [SERVER] (I would recommend using newer encryption: 'ssh-keygen -t ed25519') this will not however bypass the 2-factor requirement. The SSH key would take the place of your password but you would still need to 2-factor during login. The only way to bypass the 2-factor is to connect via the [ORGANIZATION] VPN. This is the case because the VPN already enforces 2-factor. You would then only have to 2-factor during the initial VPN connection and could subsequently use ssh to [SERVER] with the SSH key as long as the VPN session remains active. The underlying security requirement is the 2-factor step must be in the authentication path. Unfortunately the Linux authentication stack does not retain any information on prior successes or failures so each time you must satisfy all steps in the stack, even if you start 2 nearly simultaneous sessions both would have independent authentication paths."
"3119586","67596788","2025-02-13 14:00:25","ada - Ada usage issue","Hi [USER],<br /> <br /> [STAFF] was able to help you with the package installation issues this ticket was originally concerning. Please open separate tickets for separate issues so we can best direct issues to team members. I'll open a new ticket for you this time, but please keep in mind that tickets on specific issues help us to best help users with their problems. I'm resolving this ticket.<br /> <br /> On Wed Feb 12 01:16:37 2025, [USER] wrote:<br /> Thank you for your help. Now i am encountering this problem. WebSocket ping timeout after 90006 ms. WebSocket ping timeout after 119987 ms. Websocket closed #SBATCH --job-name jupyter #SBATCH --gres=gpu:2 #SBATCH --output=jupyter-%j.out #SBATCH --error=jupyter-%j.err #SBATCH --time=550 #SBATCH --mem=5G How to keep SSH Keep-Alive for Remote Servers? I see the run is extremely slow because of the overload. In my opinion, only 10% of the sample model is able to run without any issues. I need help to run the model for at least 60% of the samples. Any help would be greatly appreciated. Thank you"
"3119596","67532507","2025-02-10 19:35:57","Computational job cannot be submitted to [SYSTEM/RESOURCE]","Hi [USER], We're working on building out the gpu side of chip. Going forward, any slurm commands will require an additional flag '--cluster=chip-cpu'. Adding this to your runscript file should work. On Fri Feb 07 14:56:09 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request type: Request new RT form Hello, I encountered the following errors when using sbatch to submit my job to the chip today. The runscript I used worked on Wednesday but not today. I have attached the runscript to this email. Could you please help me fix it? sbatch: error: invalid partition specified: [SERVER] sbatch: error: Batch job submission failed: Invalid partition name specified Best Regards, [USER]"
"3120042","67536440","2025-02-10 21:00:17","ada - Unable to install new conda env","I am not sure if this is the right portal for a suggestion, but it would have been great if you could create a list of known issues and post it on the HPCF website. On Mon Feb 10 14:19:48 2025, [USER] wrote: I closed the VS code and tried the steps in Approach 1 from the terminal and it worked! Thank you so much, great job! You can close the ticket. On Mon Feb 10 13:48:04 2025, [USER] wrote: Hi, Thanks for getting back to me. I also thought about the /tmp folder access while trying pip install but that didn't work eventually, not sure why. Approach 1: mkdir -p /home/[USER]/manas_ada/users/[USER]/.vscode-server rm -rf /home/[USER]/.vscode-server ln -s /home/[USER]/manas_ada/users/[USER]/.vscode-server/ /home/[USER]/.vscode-server Refer to the attached image1 Approach 2: Refer to the attached image2 The attached images verify that both approaches above are executed properly, although I'm still stuck with installing the env. FYI, I'm trying to install the env provided in this repo: https://github.com/[REMOVED]/[REMOVED] On Mon Feb 10 12:54:11 2025, [STAFF] wrote: Dear [USER], I apologize for the double email, but I realized something else that could be causing you problems. Once you provide the commands you were attempting to run, I can know for sure. But, if you were attempting to install a pip package with conda install or pip install, depending on the size of the packages, there can be issues installing things. https://hpcf.umbc.edu/ada/software/python-environments-with-venv/ If you take a look at this link, under the pip section you can see that pip works by downloading the necessary package files in /tmp, and then removing them after install completes. However, if you are attempting to install a large package, the /tmp directory can get filled and result in error. You can manually specify the /tmp directory to a directory on the mounted manas storage with this command: TMPDIR='/nfs/ada/[GROUP]/users/[USER]' pip install [PACKAGE-NAME] I hope this helps! I look forward to hearing back from you!"
"3120434","67523039","2025-02-10 16:51:50","Other Account Request: [USER]","Hi [STAFF], pi_gobbert and cybertrn are two different groups so to have access to cybertrn you need to be in the cybertrn group. I'll go ahead and add you now, but note that groups that you are in on taki will not immediately be the same as on chip as we work to finish other parts of the chip project. If you notice any other differences, please just put in another ticket requesting to be added to said group. On Mon Feb 10 11:13:46 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] System: Other Request Type: Account Request I am a graduate student working under [STAFF] and thus am in pi_gobbert group on taki. I am also part of the cybertrn group on taki. When I try to access the cybertrn directory on chip, it says permission denied -- Best, [STAFF]"
"3120569","67527259","2025-02-10 18:08:00","ada - Account issue","Hi [USER], A few questions: 1. What command are you running that's generating this error? 2. Are you running the command referenced above as a part of a slurm job? 3. What are you trying to do? On Mon Feb 10 12:51:36 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] System: ada Request Type: General Support I have tried both conda and virtual env in all the available user accounts like home directory, user [USER], user [USER], etc. I am getting the same error repeatedly. for chunk in chunks: File '/home/[USER]/.conda/envs/myenvtest/lib/python3.10/site-packages/pip/_internal/cli/progress_bars.py', line 55, in _rich_progress_bar for chunk in iterable: File '/home/[USER]/.conda/envs/myenvtest/lib/python3.10/site-packages/pip/_internal/network/utils.py', line 65, in response_chunks for chunk in response.raw.stream( File '/home/[USER]/.conda/envs/myenvtest/lib/python3.10/site-packages/pip/_vendor/urllib3/response.py', line 622, in stream data = self.read(amt=amt, decode_content=decode_content) File '/home/[USER]/.conda/envs/myenvtest/lib/python3.10/site-packages/pip/_vendor/urllib3/response.py', line 560, in read with self._error_catcher(): File '/home/[USER]/.conda/envs/myenvtest/lib/python3.10/contextlib.py', line 153, in __exit__ self.gen.throw(typ, value, traceback) File '/home/[USER]/.conda/envs/myenvtest/lib/python3.10/site-packages/pip/_vendor/urllib3/response.py', line 455, in _error_catcher raise ProtocolError('Connection broken: %r' % e, e) pip._vendor.urllib3.exceptions.ProtocolError: ('Connection broken: OSError(28, 'No space left on device')', OSError(28, 'No space left on device')) (myenvtest) bash-4.2$"
"3120616","67528555","2025-02-10 18:31:02","ada - Account issue with explanation","First Name: [USER] Last Name: [STAFF] Email: [EMAIL] Campus ID: [CAMPUS_ID] System: ada Request Type: General Support Hello support, Thanks for your reply. /home/[USER]/[USER]_user /home/[USER]/[USER]_ada !pip install torchvision !pip install pyDOE Tried in both terminal/jupyter lab as well"
"3120735","67537718","2025-02-10 21:30:13","ada - Conda is very outdated, certain things may not be downloading in Conda correctly.","Hi [USER], Please consult the output of `module keyword conda` and load a more recent Anaconda module. On Mon Feb 10 14:35:54 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] System: ada Request Type: General Support The default Conda is very outdated, and when I loaded the latest version of the Anaconda module, the same thing happened. There is a message that Conda is outdated, and some of the things I am trying to install in Conda may not be working correctly. It's possible I am using it wrong, though I can't confirm that it's not because Conda is outdated. I have attached a picture of the message in ada. I obviously don't have the privileges to update Conda myself."
"3121834","67549616","2025-02-11 13:54:57","chip - new users in [ID]","[USER], [USER], [USER], [USER], [USER], [USER], [USER]  --   [STAFF]<br /> Appointment Calendar: https://calendar.app.google/[CALENDAR_ID]<br /> [WEBSITE]"
"3121836","67549648","2025-02-11 13:55:31","chip - new users in [ID]","s172, [USER], [USER], [USER]  --  [STAFF] Appointment Calendar: https://[CALENDAR_LINK]/[CALENDAR_CODE] [STAFF].info"
"3121840","67549726","2025-02-11 13:56:47","chip - new users in pi_manas","ndas2 ssaha3 m294 ysaxena1 mohseni1 ssharma8 sriramv1 geraldn1 blagnes1 -- [STAFF] Appointment Calendar: https://calendar.app.google/[CALENDAR_LINK] [STAFF].info"
"3122129","67562011","2025-02-11 19:04:48","Other - add [USER] to chip-gpu and related issues","Hi [STAFF], All of these issues should not be resolved. Let us know if you have any more issues. On Tue Feb 11 13:26:29 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] System: Other Request Type: General Support Hi, please give the same users access to my chip-gpu as chip-cpu. Issue 1 addition to chip-cpu: There is 1 new user, namely [USER], to please add to the CPU cluster under pi_[STAFF]. That is, switch him from a 'student' account to a research account. Also, please add to the cybertrn Unix group. Issue 2 for chip-gpu: The full list of 9 users is now [USER],[USER],[USER],[USER],[USER],[USER],[USER],[USER],[USER] to please add to chip-gpu under pi_[STAFF] and have membership in cybertrn. The [USER] should be research account now, not student. Issue 3 group of a certain directory on taki: The output [gobbert@taki-usr1 cybertrn]$ pwd -P /umbc/xfs1/cybertrn [gobbert@taki-usr1 cybertrn]$ ll -d common drwxrws--- 29 xinh1 pi_jianwu 826 Jul 17 2024 common/ shows that the cybertrn_common directory has strange ownership and group. The group should be 'cybertrn'. I am not sure who the owner should be, but a particular user does not seem right; maybe 'root'? Could you please fix this. Thank you so much! I know these are fiddly details. [STAFF]"
"3122176","67574677","2025-02-12 15:44:47","ada Account Request: [USER]","Your user has been added to iharp as a secondary group. Your home directory has additional symbolic links to your group storage space. Please read through the documentation found at hpcf.[DOMAIN]. Please submit additional questions or issues as separate tickets via the following link. (https://doit.[DOMAIN]/request-tracker-rt/doit-research-computing/) On Tue Feb 11 14:13:49 2025, [STAFF] wrote: > approved  > On Tue, Feb 11, 2025 at 2:07 PM RT API via RT <[EMAIL]> wrote: > This e-mail is a notification that ada Account Request: [USER] has requested an account for the ada cluster environment in your research group. As the PI we request that you acknowledge and approve this account creation by replying to this message. Alternatively you can go to this link and review the ticket and indicate your decision here - Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=3122176> Once we have your approval and the account request is reviewed we will create the account and you and the new user will receive another e-mail notifying you that the account has been created. If you have any other questions or concerns please contact us. Thanks, HPCF support staff"
"3122194","67574822","2025-02-12 15:47:14","ada Account Request: [USER]","Your user has been added to iharp as a secondary group. Your home directory has additional symbolic links to your group storage space. Please read through the documentation found at hpcf.umbc.edu. Please submit additional questions or issues as separate tickets via the following link. On [DATE], [STAFF] wrote: approved. [SERVER] ticket notification for ada Account Request: [USER] has requested an account for the ada cluster environment in your research group. As the PI we request that you acknowledge and approve this account creation by replying to this message. Alternatively you can go to this link and review the ticket and indicate your decision here - Ticket <https://rt.umbc.edu/Ticket/Display.html?id=3131294> Once we have your approval and the account request is reviewed we will create the account and you and the new user will receive another email notifying you that the account has been created. If you have any other questions or concerns please contact us. Thanks, HPCF support staff"
"3122392","67575785","2025-02-12 16:02:47","taki Account Request: [USER]","Hi [USER],  Your account ([USER]) has been created on taki.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Your home directory has two symbolic links to your group storage space. Please read through the documentation found at hpcf.umbc.edu. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) On Wed Feb 12 00:36:10 2025, [STAFF] wrote: > Request approved >  [STAFF]. > Sent from my iPhone >=20 > > On Feb 12, 2025, at 12:23=E2=80=AFAM, RT API via RT <[EMAIL]> > > wrote: > > > > Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=[NUMBER] > > Last Update From Ticket: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [CAMPUS_ID] > System:                    taki > Request Type:              Account Request > Position Title:            Undergraduate Student > Affiliation                UMBC > Department:                Biological Sciences > Role:                      Member of the research group > Sponsor Information: >   Name:                       [STAFF] >   Department:                 Department of Biological Sciences >   Email:                      [EMAIL] > Research Title:            Artificial Intelligence for Precision Oncology: A Multi-Omics Knowledge Network for Personalized Lung Cancer Treatment Abstract:                  Lung cancer, particularly non-small-cell lung cancer (NSCLC), is a significant health concern, with an estimated 238,340 new cases and 127,070 deaths expected in the United States in 2023 alone. Despite advances in targeted therapies and immune checkpoint blockade (ICB), resistance to these treatments is a common occurrence, underscoring the need for novel research approaches. This project aims to address these challenges by developing an artificial intelligence (AI) framework that integrates complex molecular data for the stratification of NSCLC patients. The proposed AI framework will enable personalized therapeutic strategies, overcoming the limitations of current precision oncology approaches. By translating knowledge from literature, functional genomics, and multi-omic patient-specific data, the framework will provide a comprehensive mol People:                    [STAFF] Comments:                  I am looking to create an account for taki to use for her research lab and need access to her student directories."
"3122504","67576364","2025-02-12 16:15:02","chip - 'No space left on device.'","Hi [STAFF], Could you give some more information? What were you trying to do? What directory did this take place in? Have you verified you have space in said directory using 'df -h'? On Wed Feb 12 09:30:48 2025, [EMAIL] wrote: I hope you're doing well. I recently started working on Chip, but when I attempted to transfer a text file, I encountered the error: 'No space left on device.' Could you please check this issue for me? My user ID is [USER]. Thank you for your time and assistance. Best, [STAFF]"
"3122607","67708530","2025-02-19 14:29:50","taki - logins to taki and strowinteract take forever","Apologies for the delay, we're working with [VENDOR] to figure out how to best handle this situation as it appears to be a problem with the cluster manager that helps us administer the cluster. They're telling us to update the version of the cluster manager we use, but to do so will take some downtime we would like to avoid. We're working with them to see what other options we have. On Wed Feb 19 09:12:00 2025, [USER] wrote: Hi [STAFF], Any updates to this issue? It's taking forever x2 now to log into taki, or to load new modules. Thanks On Wed, Feb 12, 2025 at 11:16 AM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hi [USER], We are aware of the issue and working to fix it. We'll keep you updated as we get more information/work to resolve it. On Wed Feb 12 10:50:51 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] System: taki Request Type: General Support For or 2 minutes, whichver is shorter. [STAFF] and [STAFF] also notice the same thing Logiing in is relatively fast, but then loading the modules is very slow >>> this is fas (sergio@strowinteract.rs.[DOMAIN]) Password: Warning: No xauth data; using fake authentication data for X11 forwarding. Last login: Thu Feb 6 06:46:33 2025 from pool-100-16-73-170.bltmmd.fios.verizon.net UMBC High Performance Computing Facility http://hpcf.[DOMAIN] By using this system you agree with and will adhere to the HPCF usage policy. If you have any questions or problems using this system please submit a help request via the 'Help Request' link found on the HPCF website under 'Forms'. Remember that the Division of Information Technology will never ask for your password. Do NOT give out this information under any circumstances. Note that many software packages are available on taki. View these by typing: 'module avail' or learn more about modules with 'man module' >>> this is VERY slow The following have been reloaded with a version change: 1) GCCcore/6.4.0 > GCCcore/11.2.0 2) zlib/1.2.11-GCCcore-6.4.0 > zlib/1.2.11-GCCcore-11.2.0 The following have been reloaded with a version change: 1) GCCcore/11.2.0 > GCCcore/7.3.0 2) Szip/2.1.1-GCCcore-6.4.0 > Szip/2.1.1-GCCcore-7.3.0 3) cURL/7.78.0-GCCcore-11.2.0 > cURL/7.60.0-GCCcore-7.3.0 4) zlib/1.2.11-GCCcore-11.2.0 > zlib/1.2.11-GCCcore-7.3.0 The following have been reloaded with a version change: 1) GCCcore/7.3.0 > GCCcore/8.3.0 2) HDF/4.2.14-GCCcore-6.4.0 > HDF/4.2.14-GCCcore-8.3.0 3) NASM/2.13.03-GCCcore-6.4.0 > NASM/2.14.02-GCCcore-8.3.0 4) Szip/2.1.1-GCCcore-7.3.0 > Szip/2.1.1-GCCcore-8.3.0 5) libjpeg-turbo/1.5.3-GCCcore-6.4.0 > libjpeg-turbo/2.0.3-GCCcore-8.3.0 6) zlib/1.2.11-GCCcore-7.3.0 > zlib/1.2.11-GCCcore-8.3.0 The following have been reloaded with a version change: 1) GCCcore/8.3.0 > GCCcore/11.2.0"
"3122716","67596406","2025-02-13 13:49:50","Request for Increased HPC Storage Quota","I need a little more information to answer that question. When you say environment, are you referring to a python environment? Or a bash environment? Or something else entirely. I'm not familiar with your research so I don't know what you are doing/how you are doing it. On Wed Feb 12 13:45:32 2025, [USER] wrote: > Thank you for letting me know, I will start working there. If you don't mind can you please tell me how can i start working there, as like how can i set up my env there and all? -- Best, [STAFF]"
"3122788","67678790","2025-02-18 02:25:48","Other - List of issues with [USER] on typical deep learning workflow","Hi [STAFF], Thanks for checking into this. The issue seems resolved -- I can now submit jobs with higher time limits. Best [USER]"
"3122908","67901101","2025-02-28 15:32:37","Launching dask clusters on taki","The issue you're encountering stems from using the `PBSCluster` class with a system that utilizes Slurm (Simple Linux Utility for Resource Management) instead of PBS (Portable Batch System). The error message indicates that it's trying to use `sbatch`, which is a Slurm command, but it's not found.  To resolve this issue, you should switch from using `PBSCluster` to `SLURMCluster` as Roy Prouty suggested in the ticket response. This change aligns with the job scheduling system (Slurm) used on the taki cluster.  Here is how you can modify your code to use `SLURMCluster`:  ```python from dask_jobqueue import SLURMCluster from dask.distributed import Client  cluster = SLURMCluster(     cores=1,     memory='3GB',     queue='short',  # Adjust the queue name as necessary for your environment     walltime='00:06:00',     job_extra=['--qos=normal'],  # Optional, adjust according to your needs )  cluster.scale(10) client = Client(cluster)  # Do computing tasks using the cluster  client.shutdown() ```  Please note a few key points: 1. **Queue Name**: Ensure you're specifying a valid queue name (`queue='short'`) for your environment. 2. **Job Extra Parameters**: If needed, adjust `job_extra=['--qos=normal']` according to your specific requirements or remove it if not necessary. 3. **Walltime and Memory**: Adjust the walltime and memory allocations as required by your tasks.  By making these changes, you should be able to successfully launch a Dask cluster on taki using Slurm for job management."
"3123025","67598896","2025-02-13 14:58:59","chip - add [USER] to pi_ laramar","Hi [STAFF], The users have been added to chip. Let us know if you have any other issues. On Wed Feb 12 17:04:57 2025, [USER] wrote: > [USER] ([EMAIL]; [CAMPUS ID]) > [USER] ([EMAIL]; [CAMPUS ID]) > [USER] ([EMAIL]; [CAMPUS ID]) > [USER] ([EMAIL]; [CAMPUS ID]) > [USER] ([EMAIL]; [CAMPUS ID]) > [USER] ([EMAIL]; [CAMPUS ID]) > Best, [STAFF]"
"3123226","67745612","2025-02-20 16:48:26","ada - issue with ssh to node running job","Hi, yes. It works. Thanks Ticket  Last Update From Ticket Hello I wanted to check, were you able to resolve your issue ? On Thu Feb 13 11:50:49 2025, [USER] wrote You have provided helpful information. I am a little confused on what the error is. Is there a screenshot you can provide? Since this error is happening in jupyter which cell is causing this error. On Thu Feb 13 11:36:06 2025, [STAFF] wrote Hello support team, Thank you for your patience and support. My code is stored here */home/[USER]/[CODE_DIR]/* The code I need help with is **Modelcrashes-helpneeded.ipynb* Technically, I need help distributing the job. Although I specify 2 GPU nodes, the model just runs in a single node only. The error message, the model will restart soon that's it. The code is not running for more than 3000 samples so far. Thank you for your time and consideration. On Thu, Feb 13, 2025 at 10:29 AM [STAFF] via RT <[EMAIL]> wrote If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey https//umbc.us2.qualtrics.com/SE/?SID=SV_[ID]&customeremail=[EMAIL]&groupid=EIS&ticketid=3123226&ticketowner=[STAFF]&ticketsubject=[SUBJECT] If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at Ticket https//rt.umbc.edu/Ticket/Display.html?id=3123226 Thank You R e s o l u t i o n Hello [USER] If I understand your issue correctly, you are getting this time out during training. The immediate solution would be to use a python file and submitting a job instead of jupyter to run the models with 100% of your samples. It possible to convert a notebook to .py using the command 'jupyter nbconvert --to script [YOUR_NOTEBOOK].ipynb' If you still want to run the training on jupyter, please provide the full error message. Also, let me know where your code is located. On Thu Feb 13 09:01:40 2025, [USER] wrote i am encountering this problem. WebSocket ping timeout after 90006 ms. WebSocket ping timeout after 119987 ms. Websocket closed #SBATCH --job-name jupyter #SBATCH --gres=gpu:2 #SBATCH --output=jupyter-%j.out #SBATCH --error=jupyter-%j.err #SBATCH --time=550 #SBATCH --mem=5G How to keep SSH Keep-Alive for Remote Servers? I see the run is extremely slow because of the overload. In my opinion, only 10% of the sample model is able to run without any issues. I need help to run the model for at least 60% of the samples. Any help would be greatly appreciated. Thank you [USER] -- Best, [STAFF] DOIT Unix infra Student Worker Original Request Requestors [USER] i am encountering this problem. WebSocket ping timeout after 90006 ms. WebSocket ping timeout after 119987 ms. Websocket closed #SBATCH --job-name jupyter #SBATCH --gres=gpu:2 #SBATCH --output=jupyter-%j.out #SBATCH --error=jupyter-%j.err #SBATCH --time=550 #SBATCH --mem=5G How to keep SSH Keep-Alive for Remote Servers? I see the run is extremely slow because of the overload. In my opinion, only 10% of the sample model is able to run without any issues. I need help to run the model for at least 60% of the samples. Any help would be greatly appreciated. Thank you [USER] -- Best, [STAFF] DOIT Unix infra Student Worker"
"3124258","67632620","2025-02-14 16:27:51","taki Account Request: [USER]","Hi [USER], Your account ([EMAIL]) has been created on [SERVER]. Your primary group is [GROUP]. Your home directory has 500M of storage. Your home directory has two symbolic links to your group storage space. Please read through the documentation found at [SERVER]. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://[LINK]/) Best wishes, On [DATE], [STAFF] wrote: > [USER]"
"3124534","67670710","2025-02-17 20:40:25","taki Account Request: [USER]","Dear [STAFF], I have gone ahead and created a user account for [SERVER]. You should be able to log in with 'ssh [USER]@[SERVER].rs.umbc.edu'. If you require any assistance, I recommend checking out our website at hpcf.umbc.edu. If you cannot find answers to your questions there, please feel free to reach out through an RT ticket! Have a great day! Kind regards, [STAFF] On Fri Feb 14 10:09:31 2025, [USER] wrote: > First Name: [USER] > Last Name: [USER] > Email: [EMAIL] > Campus ID: [ID] > System: [SERVER] > Request Type: Account Request > Position Title: Undergraduate Student > Affiliation UMBC > Department: CSEE > Phone: [PHONE] > Address: [ADDRESS] > Role: Member of the research group > Sponsor Information: Name: [STAFF], Department: CSEE, Email: [EMAIL], Phone: [PHONE] > Research Title: LEO > Abstract: Find the best near-optimal schedule for the execution of a task. People: Dr [STAFF] Comments: None"
"3124547","67720975","2025-02-19 19:15:35","ada - Request to increase the storage 20TB (40TB total)","Hi [USER], I've increased the quota on the directory `/nfs/ada/[STAFF]` from 20TB to 40TB across the ada cluster, but only until April 1. Before April 1, I'd like for us to meet and discuss your anticipated data storage needs so that we can think strategically about where to place the data volumes your research group will need. In the next few weeks, we should have more options. I'll send an email separately to try to find a time to chat. On Fri Feb 14 10:26:38 2025, [USER] wrote: First Name:                [STAFF] Last Name:                 [STAFF] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] System:                    ada Request Type:              General Support Dear Team at DoiT, For a successful research submission to ICCV conference on March 03, 2025, we need an urgent increase in the storage space for /nfs/ada/[STAFF] storage by 20TB (the total would be 40TB). I appreciate your prompt attention. Please feel free to reach out if you have any questions. Regards [STAFF]."
"3125917","67673571","2025-02-17 22:45:09","ada - URGENT: Accidentally performed rm -r on ~","We use symbolic links to connect user home directories to their research storage. [STAFF]'s research directory is still located at /nfs/ada/manas , nothing in there was touched by your `rm` command. On Mon Feb 17 17:37:53 2025, [USER] wrote: Hi [STAFF], Thank you for the help. However, I am mostly concerned that it may have propagated into the research storage node of the group that I was originally linked to and wanted to bring attention to that. Otherwise, I have no issue closing this ticket. On Mon Feb 17 17:31:18 2025, [STAFF] wrote: Hi [USER], Thanks for your ticket. I've replaced your home directory, and I'm happy to report no other home directories were affected. I'll mark this as resolved for now. On Mon Feb 17 16:58:19 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USER] System: ada Request Type: General Support I was attempting to delete an erroneously created folder named ~ on ada servers and negligently performed an 'rm -r' without verifying the target folder was correct, which ended up deleting recursively from my home directory on the login node. I believe this may have impacted more than just that and am reporting ASAP in case of possible damage. My home directory on the login node is not important and had little in it, so a default setup is fine there if that was all that was damaged."
"3125951","67682582","2025-02-18 13:49:35","ada - Unable to access directories in ada","Hi [USER], This is my fault, but fret not, no data has been lost, and your access has not been restricted. The red around the symbolic links you're seeing show that the link is broken. This is because the data was moved to a different location during a migration the other day. The new location for the data is /umbc/rs/cybertrn. New links can be established by removing the old links 'rm cybertrn_common', etc. and then running the command 'ln -s /umbc/rs/cybertrn/common cybertrn_common' from your home directory and doing this for each of the broken links. I apologize for the inconvenience this caused. On Mon Feb 17 18:19:37 2025, [STAFF] wrote: First Name: [USER] Last Name: [LAST NAME] Email: [EMAIL] Campus ID: [CAMPUS ID] System: ada Request Type: General Support Good evening, I am unable to access several directories in Ada: reu2024_team2 (a shortcut to the cybertrn/reu2024/team2 directory), cybertrn_common, and cybertrn_user. I was able to access these directories on Ada a few weeks ago, though. I believe that I still have access to Ada, because I am able to log in, and my PI Professor [STAFF] has extended my HPCF access. I have attached a screenshot of this to this ticket: the directories I am unable to access are in red, for some reason. Do you know why I am unable to access these directories? Is there any way I would be able to view these directories, as I have some important information saved in them? Could these directories be archived possibly? By the way, I do have access to Taki and am able to access all of my prior directories in there. Thank you!"
"3125952","67685990","2025-02-18 15:10:21","taki - Connecting to ultralytics","Hello [USER], Question 1: Is it possible to execute this script on Taki to establish a connection with the Ultralytics server and initiate the training process? I am assuming the script is a python file. Yes, it is possible to establish connection and initiate training process. You can train your model on the cpu's or gpunode001 by submitting a slurm script that executes your python file. Question 2: I was also wondering if the ultralytics library is already installed. If it's not, where should I run the following command to install it? The ultralytics library isn't already installed. In order to install the library, you will need to create a virtual environment, conda or venv. You can find instructions on how to setup a conda environment here https://hpcf.umbc.edu/ada/software/python-environments-with-venv/. When you run your code make sure your conda environment is activated. Let us know if you encounter an issue in this process. The Ultralytics website offers a way to bring our own agents to train a CNN model. I’m interested in running the following Python script on Taki to connect directly with the Ultralytics server. from ultralytics import YOLO, checks, hub checks() hub.login('xxxxxxxxxxxxxxxxxxxxxxx') model = YOLO('https://hub.ultralytics.com/models/xxxxxx') results = model.train() I have a couple of questions regarding that: Is it possible to execute this script on Taki to establish a connection with the Ultralytics server and initiate the training process? I was also wondering if the ultralytics library is already installed. If it's not, where should I run the following command to install it? pip install -U ultralytics"
"3125961","67835828","2025-02-25 18:16:11","Other Account Request: [USER]","[STAFF] wrote: I ran a reconfigure on the hub, please try again."
"3126371","67709356","2025-02-19 14:48:23","taki - Error: No space left on device","This error occurs when pip is downloading large libraries to the '/tmp' directory, which it does as part of its default implementation. To fix this simply put 'TMPDIR=/path/to/some/directory pip install some_library' where it will download the library temporarily and remove it once the installation is complete. On Tue Feb 18 12:56:59 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] System: taki Request Type: General Support Hello, I created a virtual environment (venv) and attempted to install a package, but I encountered the following error: 'No space left on device'. I also ensured that both the environment and the package installation were done in the PI's common space. I appreciate your help. Thank you! Attachment 1: error_msg.PNG -- Best, [STAFF]"
"3126936","67792283","2025-02-23 20:03:19","Request for read-write access to /home/[ID]/manas_ada/users/[ID]/ in ada","Hi [STAFF], Thank you for your response. [USER] has given me write access to the directory of interest. The issue is resolved now. Regards - [STAFF]"
"3127277","67743447","2025-02-20 16:08:04","Other Account Request: [USER]","[STAFF], These users have been added to the requested accounts. Please share the logon URL with them and please let me know if there are reports of problems. Have a nice day. -- [STAFF] DoIT, Windows System Administrator [EMAIL] (###)####"
"3127941","67741687","2025-02-20 15:33:50","chip - add [USER] to pi_lobo","All steps completed and confirmed. New wiki page below: [LINK] On Thu Feb 20 07:57:35 2025, [STAFF] wrote: This will be a few steps for us: 1. Reprovision pi_[USER] from taki/ada on chip. Ensure the group IDs are correct. Ensure storage is available. 2. Add these three users to the general partition within slurm 3. Grant pi_[USER] access to the pi_[USER] partition only (not match or contrib partitions) 4. Test slurm submission that confirms the above 5. Let's get a wiki page going that makes this make sense beyond [STAFF]/[STAFF]/[STAFF] On Thu Feb 20 07:55:35 2025, [STAFF] wrote: Please add the users [USER], [USER], and [USER] to chip and grant access to the pi_[USER] partition. Best, [STAFF]"
"3128023","67776252","2025-02-21 18:00:52","taki - User [USER] account details","Hello I have made the request changes. The user [USER] is part of group pi_gobbert, hpcreu ,cybertrn , and student on taki. In ada, [USER] is part of the group pi_gobbert, hpcreu and cybertrn. Since he didn't have an account on ada I created a new account. On chip, [USER] is part of  pi_gobbert, and cybertrn. These two are the group that have currently migrated to chip, as we migrate other groups the user will part of them too. On Thu Feb 20 09:50:19 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [ID] System:                    taki Request Type:              General Support Hi, Currently, the user [USER] is currently a 'student'. Please change him to pi_gobbert as primary group. Make him also a member of the Unix groups 'cybertrn' and 'hpcreu'. Please also do this on ada as well as on chip. Thank you, [STAFF]"
"3128097","67745909","2025-02-20 16:55:24","Other Account Request: [USER]","Hi [STAFF], What exactly are you requesting? Is this for one of the HPC facilities? On Thu Feb 20 10:55:37 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [USER] System:                    Other Request Type:              Account Request This request is for enabling GPU resources to accelerate computational tasks, such as deep learning, machine learning model training, or large-scale data processing. Access to GPU will significantly improve performance and reduce processing time. Best,  [STAFF]"
"3128334","68566787","2025-04-07 16:13:44","ada Account Request: [USER]","Hi [USER], Please review all the documentation located on our website (hpcf.umbc.edu), https://umbc.atlassian.net/wiki/spaces/faq/pages/1082589207/UMBC+HPCF. You should see a section on user directories and research volumes. All storage for research purposes is mounted to /umbc/rs/pi_name/. There is the common directory, which is shared storage for your PI group, and there is a subdirectory in users specifically for you. I recommend creating symbolic links to that directory for easy access, as well as using symbolic links for your hidden folders (such as .conda) so they do not fill up your home directory space. There is also a page for running jupyter notebooks located here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1104805915/Jupyter+Notebooks -- Kind regards, [STAFF] On Thu Apr 03 18:08:10 2025, [USER] wrote: Hello, I was added to the 'chip' cluster, But I had two questions regarding that: 1. It said that my home directory only had 500Mb storage, but the whole purpose of requiring the chip cluster was that I could process large datasets in jupyter notebooks. So, could you tell me how I could access more space? 2. I am not really familiar with running jupyter notebooks on remote servers, could you tell me if there is any documentation regarding that? Or if you just give me a way to get extra space in my home directory, I guess I could figure out all that stuff on my own. Thank you and regards, [USER] On Wed, Mar 5, 2025 at 8:41 AM [STAFF] via RT wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3128334&ticketowner=bbekele1@umbc.edu&ticketsubject=ada Account Request: [USER] If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3128334 Hi [USER], Sorry for the confusion but we are no longer adding people to the ada or taki clusters at all. I can add you to the new cluster, chip, under Dr. Sherman's pi group. Your account ([USERNAME]) has been created on chip.rs.umbc.edu. Your primary group is pi_sherman. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu. All available modules can be viewed using the command 'module avail'. Could I be added to the cluster now? On Fri, Feb 21, 2025 at 1:10 PM [STAFF] via RT wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3128334 Last Update From Ticket: Hello [USER] We are currently working on setting up a new cluster chip and moving user to chip. Thus all new account, group, and software are being redirected to chip. Once our migration is completed, estimated day is March 3 we will resume account creation. I will add you to pi_sherman group then. You can read more about the migration here: http://my3.my.umbc.edu/groups/hpcf/posts/147513 We apologize for the inconvenience. Original Request: Requestors: [USER] First Name: [USER FIRST NAME] Last Name: [USER LAST NAME] Email: [EMAIL] Campus ID: [CAMPUS ID] System: ada Request Type: Account Request Username: [USERNAME] Requested Action: become a user in an existing ada PI Group Primary HPCF PI Group Owner: sherman@umbc.edu Supplemental HPCF PI Group Owners: Project Keywords: - Computer Vision Additional Notes and Comments: Hello, I am enrolled in the CMSC 652 Cryptography Course. I am going to be working on a group project in which we need to see how different watermarking techniques on CT scans interfere with AI Computer vision Model analysis. We expect the workload to be highly dependent on the GPU because of the Computer vision models. I had talked to Dr. Alan Sherman and he said it would be okay to access the cluster."
"3128578","67788386","2025-02-22 12:36:38","ada Account Request: [USER]","It's located at hpcf.umbc.edu  Forms   [STAFF] (he/him/his)  Have some empathy and please excuse any tpying foibles.   On Fri, Feb 21, 2025 at 17:11 [USER] via RT wrote:  Ticket  Comment From Ticket: Can you send me the request form .please On Fri, Feb 21, 2025, 4:44PM [STAFF]@umbc.edu via RT wrote:  Ticket Last Update From Ticket: Please submit an account request form so the creation of your account can be handled by our team. [STAFF] Appointment Calendar The most dangerous phrase in the language is, 'We've always done it this way.' - Adm Grace Hopper On Fri, Feb 21, 2025 at 4:00PM [USER] via RT wrote: Ticket Comment From Ticket: As I am working under [STAFF] guidance .I require GPU access to efficiently complete my tasks. However, my request for access has been denied . If GPU access is not possible through the current system, could you kindly guide me on alternative ways to proceed? I would really appreciate any suggestions or resources that could help me complete my work effectively. Looking forward to your response. Best regards, [USER] On Fri, Feb 21, 2025 at 8:56AM [STAFF] via RT wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_...&customeremail=[EMAIL]&groupid=EIS&ticketid=3128578&ticketowner=[STAFF]%40umbc.edu&ticketsubject=ada%20Account%20Request:%20[USER]%20%3C[EMAIL]%3E If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3128578 Thank You _________________________________________ R e s o l u t i o n: Hi [USER], You cannot request a new PI group as a graduate student. Further, we are halting all new accounts on the ada HPC. See this post for more details: https://my3.my.umbc.edu/groups/hpcf/posts/147513 On Thu Feb 20 20:01:33 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] System: ada Request Type: Account Request Username: [USERNAME] Requested Action: request a new ada PI Group Sponsor Other accounts: No Project Keywords: - Artificial Intelligence - Computer Vision - Machine Learning - Natural Language Processing Please add to discussion mailing list. -- [STAFF] Appointment Calendar: https://calendar.app.google/[CALENDAR_ID] royprouty.info ______________________________________ Original Request: Requestors: [USER] First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] System: ada Request Type: Account Request Username: [USERNAME] Requested Action: request a new ada PI Group Sponsor Other accounts: No Project Keywords: - Artificial Intelligence - Computer Vision - Machine Learning - Natural Language Processing Please add to discussion mailing list."
"3129200","67784229","2025-02-21 20:59:47","taki - Accessing the [USER] symbolic link","Hi [USER], There was an incorrect permission on the /umbc/rs/deffner volume. That's been fixed, and we're looking into the initial cause. You should be good to go at this point, so I'll resolve this ticket. On Fri Feb 21 14:16:23 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] System:                    taki Request Type:              General Support Hey, so I'm using the HPC for the first time. I want to submit a job but of course not on the user node. However, it appears that I don't have permission to access the Deffner_user symbolic link (I'm in the Deffner group obviously). Is this something I need to reach out to [STAFF] about or can you guys give me access? Thank you!"
"3129212","67784769","2025-02-21 21:12:26","taki - checking my bash script","Whoops, my response got cut off there a bit. The 'Pb-apatite.log' file should then be the output of the pw.x executable run with the 'Pb-apatite.in' file as input parameters and run with MPI. Hope this helps. On Fri Feb 21 16:10:59 2025, [STAFF] wrote: Hi [USER], I am not sure what the pw.x executable does. However, I can prod at some part of the command I see and try to give my best guess. `mpirun ./pw.x < Pb-apatite.in > Pb-apatite.log` mpirun is a command that signals to the system that your job should be run in parallel pursuant to the structure of the pw.x executable and any environment variables or command line options you might have set to guide MPI. pw.x is the executable. The '<' character is called a redirect, it opens the file given after it ('Pb-apatite.in' in your case) and redirects the file contents into the pw.x executable. In this way, I suspect that the Pb-apatite.in is a file containing some input parameters that guide the execution of the pw.x executable. The '>' character is another redirect, but this doesn't send the contents of Pb-apatite.log anywhere, instead it 'opens' the file Pb-apatite.log (or creates it if it doesn't already exist) and dumps all of the output of 'mpirun ./pw.x < Pb-apatite.in'. On Fri Feb 21 14:23:06 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] System: taki Request Type: General Support Hey, I just sent a support request but I have another one as well."
"3129280","67869412","2025-02-26 21:56:58","Urgent Request -- Solve Conda Issue on New Servers","Excellent. I am not the only person working on the chip cluster, so re-opening this ticket forces the issue to my inbox as opposed to the general inbox, allowing others to jump-in if they are more available than I. So I'll close this ticket out, and please open another new ticket if there is an issue on chip since I will be away. On Wed Feb 26 16:52:43 2025, [USER] wrote: Thanks a lot. I could now log in and create a new conda environment on the chip. I will do more tests and let you know if I have any problems. On Wed, Feb 26, 2025 at 4:41 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3129280> Last Update From Ticket: Hi [USER], What happens when you try to login? I've made the same symbolic links as I noted above in your home directory. Maybe this has solved your issue? On Tue Feb 25 18:49:44 2025, [USER] wrote: Hi [STAFF], I am also having the following issues on chip: 1. I'm unable to log in to the chip server. 2. Before the log in issue, I encountered the 'no disk space left' error while attempting to create a new conda environment on the chip server. Could you help me with the above issues so that I can log in again and create a new env? Thank you very much for your attention to this matter. Your help is greatly appreciated. Best regards, [USER]. On Mon Feb 24 14:25:48 2025, [STAFF] wrote: Awesome, thanks for the sanity-check. I'll close this out now. On Mon Feb 24 14:06:33 2025, [USER] wrote: Hi [STAFF], Thank you so much for helping me get acquainted on chip. I am able to submit, run jobs with newly created conda envs on chip now without adding any load on the scratch directory. If, in the future, I come across any other issues on chip I will create another ticket for help. And thank you so much once again. Regards [USER]."
"3129496","68154267","2025-03-13 12:51:00","Account Request: [USER]","Hi [STAFF], [USER] was added to Chip sometime ago. As you might be able to see from her previous message, she has login access. The difficulty she seems to be having is not understanding the new way we have organized chip. I have advised her to please read the hpc website that I linked to her. On Wed Mar 12 16:08:29 2025, [STAFF] wrote: Hi [STAFF], Please add [USER] to the Chip. Regards [STAFF]. On Sun, Mar 9, 2025 at 8:17PM [USER] via RT wrote: Ticket Last Update From Ticket: Hi [STAFF], i have tried logging in to the address provided ,failing to see the directory ,you might not have created a directory ,i tried logging in using ssh ,attaching screenshot for your reference . kindly do the needful. Thanks and regards , [USER]. On Thu, Mar 6, 2025 at 10:53AM [STAFF] via RT wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3129496&ticketowner=[EMAIL]&ticketsubject=ada Account Request: [USER] If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3129496. Thank You R e s o l u t i o n:. Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. https://doit.umbc.edu/request-tracker-rt/doit-research-computing/. On Thu Mar 06 10:40:08 2025, [USER] wrote: Hi [STAFF], I hope you are doing well ,[STAFF] has approved the request ,can you please migrate me to the chip ASAP. My work is in pending and I should complete it. On Tue, Mar 4, 2025, 9:09AM [STAFF] via RT wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3129496 Last Update From Ticket: Hi [STAFF], As you may have seen on our chip migration timeline we are redirecting all user/group creations to chip. Are you ok with us adding [USER] to your chip group instead? On Mon Mar 03 16:40:28 2025, [STAFF] wrote: Hi [STAFF], I approve [USER]'s request to use the GPU. Regards [STAFF]. On Tue, Feb 25, 2025 at 9:37AM [STAFF] via RT wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3129496 Last Update From Ticket: Hi [USER], We're just waiting on confirmation from [STAFF] before moving forward with your account creation. Once he confirms, you'll be added. On Sat Feb 22 10:19:23 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USER]. System: ada Request Type: Account Request Username: [USER] Requested Action: become a user in an existing ada PI Group Primary HPCF PI Group Owner: [STAFF]. Supplemental HPCF PI Group Owners:. Project Keywords: - Artificial Intelligence - Computer Vision - Human-Computer Interaction - Machine Learning - Natural Language Processing. Please add to discussion mailing list. Best, [STAFF] DOIT Unix Infra Student Worker"
"3130452","67819233","2025-02-24 22:23:35","Other - Need help with chip","The short answer is that you should get a small slurm allocation to build your python packages. You shouldn't use the login node to build python packages since the login node has no GPUs and is a different architecture than the compute nodes. These differences can lead to performance problems in your production-level code. On Mon Feb 24 16:46:33 2025, [USER] wrote: Hello, I am getting the following error: Regards, [USER]. On Mon, Feb 24, 2025 at 4:43PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3130452>. Last Update From Ticket: Hi [USER], Are you loading the Anaconda module? [STAFF] [EMAIL]. On Mon, Feb 24, 2025 at 4:35PM RT API via RT <[EMAIL]> wrote: Mon Feb 24 16:34:56 2025: Request 3130452 was acted upon. Transaction: Ticket created by [USER]. Queue: DoIT-Research-Computing. Subject: Other - Need help with chip. Owner: Nobody. Requestors: [EMAIL]. Status: new. Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3130452>. First Name: [USER]. Last Name: [USER]. Email: [EMAIL]. Campus ID: [USER]. System: Other. Request Type: General Support. I am unable to use conda on chip. I am getting an error '-bash: conda: command not found'. Please help."
"3131171","67910132","2025-02-28 19:22:59","ada - Using Docker and uDocker containers in HPC","Hi [USER], I would agree it seems like this version of docker is pretty much defunct. At the moment we are working on transferring all users, groups, and machines to our new one-stop-shop cluster 'Chip'. As a result, we have stopped development of the 'Ada' and 'Taki' clusters. See the link below to see more information on the timeline of this. Once everyone/everything has been moved over, please resubmit this ticket under the 'Chip' system and we'll be happy to help. https://my3.my.[DOMAIN]/groups/hpcf/posts/147513 On Tue Feb 25 15:57:16 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] System:                    ada Request Type:              General Support I want to set up docker to run a ollama model in a docker container. I see in the list of available modules that uDocker is set up so I'm trying to use that. However I think the uDocker version is outdated because it says udocker/1.1.1-foss-2017b-Python-2.7.14. Also, I don't think uDocker is set up correctly after I loaded the module. I get this error when I try to pull ollama: (test_env2) [USER@[SERVER] [USER]]$ udocker pull ollama/ollama Info: creating repo: /home/[USER]/.udocker Info: installing 1.1.1 Info: installing from: https://cernbox.cern.ch/index.php/s/VC7GuVWA7mYRAiy/download /bin/sh: line 0: cd: /home/[USER]/.udocker/bin: No such file or directory /bin/sh: line 0: cd: /home/[USER]/.udocker/lib: No such file or directory Error: setting localrepo v2 tag and version Error: no files downloaded I was wondering if there's a guide on how to use docker containers in the ADA HPC cluster."
"3131949","67874516","2025-02-27 13:49:36","Other - Unable to install git on chip","There are multiple module versions of git available. Running 'module spider git' shows the following:          git/2.33.1         git/2.38.1-GCCcore-12.2.0-nodocs         git/2.42.0-GCCcore-13.2.0         git/2.45.1-GCCcore-13.3.0 If you start an interactive job and then load one of these modules, you'll be able to do your git operations from there. Hopefully this helps.  On Wed Feb 26 16:37:49 2025, [STAFF] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [CAMPUSID] >  > System:                    Other >  > Request Type:              General Support >  > I am unable to install git on chip. I am getting no space left on the device error. Please help."
"3132002","67873560","2025-02-27 13:16:16","[USER] can't login, it slowed down before kicking [USER] out","Hi [USER], We need a little more information to understand the issue: Can you tell me what you were running, as well as the job id of the interactive session you tried to run? Are you able to login now? I currently see the following jobs running: JobID           JobName      State      User ------------ ---------- ---------- --------- [NUMBER]                  v2    RUNNING    [USER] [NUMBER].batch         batch    RUNNING [NUMBER]                bash    RUNNING  [USER] [NUMBER].[NUMBER]              bash    RUNNING On Wed Feb [NUMBER]:[NUMBER]:[NUMBER], [STAFF] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [CAMPUS_ID] >  > Request type:                 General Support >  > Hi, >  > I am [USER] ([EMAIL]), raising this ticket, supervised by [STAFF]. > We were working on chip (on gpu nodes, no mass and fuss on the login node). > It then became slow and eventually the connection timed out. Now, we cannot log back in (via vscode), says connection timed out, shows exit code 15. >  > Can you please help us resolve this issue, as we all have a deadline nearby. >  > Thanks--- [USER]"
"3132012","67878345","2025-02-27 15:22:09","ada - Ada cluster full--potential resource hoarding","Good morning [USER], I just checked the SLURM queue and it appears your jobs ([USER]'s, [STAFF]'s and [STAFF]'s) are currently running on ada's GPU nodes. Thus I will be marking this ticket as resolved, but for future reference I'm including the following to help with scheduling your jobs: Jobs that don't immediately run post-submission are put in a 'pending' or 'PD' state. Slurm determines which job from the set of PD jobs should run next based on a few factors: 1) How long the PD job has been waiting to run 2) How frequently the user's group has been running jobs 3) How large the job is (smaller jobs have slightly more priority). Item 1) means that any job you desire to run should be submitted ASAP and left for slurm to run when slurm can identify the resources. Item 2) means that users who have been 'hogging' the cluster quickly see their jobs de-prioritized in favor of users who have submitted jobs but not used the cluster as much. Item 3) doesn't factor much into the issue I believe you're communicating, but exists nonetheless. All of that said, while the usage of the cluster due to user '[USER]' was high, like I mentioned at the start of this email I can see already that jobs submitted by this user are being de-prioritized in favor of others. Slurm takes this into consideration when resources become free. It's also worth noting that we have a preemption policy in place on ada that limits jobs to no more than three days of runtime if the hardware is requested by another job. These usage rules were discussed and set by the PIs of the original NSF MRI that funded ada (along with us in DoIT) back in 2020. In the near future, faculty-led governance groups will be established and these rules stand to be revisited. I'm happy to take note of your concern and bring it up to these groups and key all PIs into the process. Any changes would be announced on the HPCF myUMBC group. I hope all of this helps, and I'd be happy to answer any additional questions via ticket or a scheduled call. [STAFF]"
"3132055","67874854","2025-02-27 14:05:05","GPU Nodes Unavailable on ADA","Disregard the 'ten minutes' ago comment. That was the time this ticket was moved into our RT queue, and I incorrectly keyed-off of that. I do see now that you submitted this ticket last night. On Thu Feb 27 08:03:42 2025, [STAFF] wrote: Hi [USER], I see no such large job on the ada cluster as I write this, ten minutes after you submitted this ticket. I see two jobs that have been running for 12 hours by [USER] and three running for 2 hours and 28 hours submitted by you. On Thu, Feb 27, 2025 at 7:50 AM The RT System itself via [EMAIL] wrote: Thu Feb 27 07:50:24 2025: Request 3132055 was acted upon. Transaction: Queue changed from DoIT-TSC-Support to DoIT-Research-Computing by RT_System Queue: DoIT-Research-Computing Subject: GPU Nodes Unavailable on ADA Owner: Nobody - Nobody in particular Requestors: [EMAIL] Status: new Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3132055> First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request type: General Support Hi, I'm unable to access GPU nodes on ADA due to a large (999-sized) array job from user '[USER]' which has been running for a number of days now. Could you please check this issue? Current-Queue-Number:33 Original-Queue-Name: DoIT-TSC-Support Original-Queue-Number:33 Response-Level: Contact-Phone-Number: HPC-Account-Sponsor-Email: HPC-Account-Sponsor-Name: HPC-Account-Sponsor-Provided: Alternate-Email: [EMAIL] RC-System: HPC-ada-PI-Emails: HPC-ada-Action: HPC-ada-MailingList: Tag: !fns=doit !ins=none"
"3132279","68170638","2025-03-13 19:03:01","Other - Unable to install libraries on chip","I see a very long and nested email thread. It appears to be a conversation between Nilanjana Das and Max Breitmeyer regarding an issue with installing libraries like Torch on a device, resulting in a 'no space left on device error on chip.'  Max Breitmeyer is responding as a student worker for the DOIT Unix Infra team at UMBC (University of Maryland, Baltimore County). He's asking Nilanjana to provide more information about the issue and offering assistance.  If you'd like, I can help summarize the conversation or try to extract any relevant details. Just let me know!"
"3132570","67897560","2025-02-28 13:42:32","ada - Need Guidance on Python 3.9+ Installation Issues","Hi [USER], If you run the command 'module spider python' you'll see there are multiple versions of python available to you. Additionally, you can also run 'module spider conda' which will output a series of modules with different versions of conda and their associated python versions preloaded. For instance, the 'Anaconda3/2023.09-0' module comes pre-loaded with python version 3.11.5. To add this to your path you can simply 'module load module_name' in your terminal, and it will be added to your environment. Hopefully, this resolves your issue. On Thu Feb [DATE] [TIME], [STAFF] wrote: First Name: [USER] Last Name: [LAST NAME] Email: [EMAIL] Campus ID: [CAMPUS ID] System: ada Request Type: General Support Hi, I hope you’re doing well. I am working on something that requires Python 3.9+ but am facing conflicts and compatibility issues with Conda. I tried installing it, but I couldn’t change the main Python version due to write permission restrictions. I then installed Python 3.9 in a different directory locally, but it didn’t resolve the issues. Thanks for your kind support in advance. Bests, [USER] -- Best, [STAFF]"
"3132604","67996852","2025-03-05 14:54:17","Other Account Request: [USER]","[STAFF], This user has been added to the project 0 account. Please share the logon portal URL with them and let me know if there are reports of problems. Have a nice day. -- [STAFF] DoIT, Windows System Administrator [EMAIL] (XXX)-XXX-XXXX"
"3132632","67901680","2025-02-28 15:50:59","Other Account Request: [USER]","Hi [USER], We don't currently have any licensing for Colab Pro or Pro+, but we're looking into this internally. There would be some additional unbudgeted cost associated with any pro license. To facilitate this conversation, would you mind roping in your research supervisor to this request? Separately, we do offer free access to our campus computing cluster from which you can launch jupyter notebooks. It's a bit more involved than gColab and cannot deal with sensitive data, but I figured I would offer that as an option as well. On Thu Feb 27 16:35:21 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] System: Other Request Type: Account Request Hi, does UMBC offer google colab pro for doctoral students working on research? Currently, I keep running out of RAM & Disk space and am unable to complete my analysis. Attachment 1: Screenshot 2025-02-27 at 2.24.39PM.png -- [STAFF] DoIT Research Computing Team"
"3132881","67968142","2025-03-04 15:33:12","ada - vs code or jupyter notebook","This appears to be a long email thread between Sara Khanjani and the HPC (High-Performance Computing) team at the University of Maryland, Baltimore County. The conversation revolves around issues with connecting to a computing node, specifically regarding access to GPUs for TensorFlow and PyTorch.  To summarize:  1. Sara initially had trouble connecting to the Jupyter notebook on the computing node. 2. She was able to connect after following some steps provided by the HPC team. 3. However, when she tried to use TensorFlow in her Jupyter notebook, it didn't recognize any available GPUs. 4. The HPC team suggested that Sara might need to install CUDA drivers or load specific modules (e.g., Horovod) to access the GPU. 5. Sara mentioned that she found a discussion on PyTorch forums indicating that NVIDIA drivers are not installed on the computing node, which is required for PyTorch to access GPUs.  The conversation ends with Max Breitmeyer from the HPC team acknowledging Sara's issue and suggesting that he will look into installing the necessary NVIDIA drivers. However, the thread doesn't provide a final resolution or confirmation of the issue being fixed.  If you're looking for specific information or guidance on resolving this type of issue, I'd be happy to try and help!"
"3132931","68655941","2025-04-10 18:40:52","ssh keys on chip","Hello [USER], Unfortunately, I'm not aware of any way to disable Duo logins from your machines which also meets our security requirements. Is there any reason you can't login to the VPN from your laptop and server? I've CC'd [STAFF] in case he can provide more insight on this matter. Thank you, [STAFF] On Fri Apr 04 18:01:46 2025, [USER] wrote: Hi [STAFF], I just tested these now. 1) I'm in the Physics building, and my laptop is connected with an ethernet cable (wifi is off). My laptop's IP is 130.85.72.231. When I try to connect to Chip, I get the DUO request. 2) If I disconnect from the wall and turn the Wi-Fi on, I get the IP 130.85.233.40. This is on Eduroam, so it's still inside the secure UMBC network, right? I tried to SSH to the chip, and I got the DUO request. 3) If I connect to the visitor Wi-Fi, I'm outside the UMBC intranet, and of course, I get the DUO request. 4) While on the visitor Wi-F, if I connect to the VPN using GlobalProtect, I get the DUO for the VPN access. Then, when I try to connect Chip, DUO is not required. 5) If I connect my cellphone's Hotspot (and make sure the phone is not connected to the UMBC's wifi), I get an IP address from my operator: 10.176.7.53 (external IP is 172.58.241.53). If I access chip, I get the DUO request. 6) While still connected to my phone's hotstop, if I connect to the VPN, then DUO is not required. *That means the VPN is working as you said: when connected to it, I can login to Chip without DUO.* However, why doesn't my wired connection in my office give me the same access? How is that not secure? The same question applies to my server, which is connected to the 10-gig network in the cluster room of the Public Policy building. Anyway, the important thing is: How can we make my wired connections for my laptop and for my server be considered secure? How do we put both behind the VPN? Thanks, [USER] On Thu, Mar 27, 2025 at 9:19 AM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Good morning [USER], I apologize for the long delay in a response to this ticket, but I do have an update for you: In regards to the Duo authentication, is there any chance you can get your group's server on the campus VPN? This would be our preferred solution for getting past Duo, as our security requirements mandate users use two-factor authentication at some point when connecting to the cluster. As for the SSH keys, were you able to get them working? Or are you still being prompted for a password alongside Duo? Thank you, [STAFF] On Thu Mar 06 12:32:04 2025, [USER] wrote: Good morning [USER], Our security guidance requires that we have Duo on all systems that are accessible publicly - i.e accessible not on the VPN - and it is meant to run in tandem with the usual SSH password/public key authentication. We have Duo configured to be bypassed when coming from the VPN since the VPN already makes you use Duo to login, a couple other smaller, trusted locations. We are currently discussing paths forward for this and I'll let you know when we have a solution. As for the SSH key, are you trying to login as [USER] or another user that the SSH key isn't working for? In my testing I was able to login successfully with an SSH key (plus Duo) from a machine off-campus, so I'm curious to see what the logs look like when you're trying to login. Also, if you don't mind could you try SSHing again with the '-vvv' flag at the end of the command and send me the output? Thank you, [STAFF] On Wed Mar 05 11:02:48 2025, [USER] wrote: Hi [STAFF], Connecting -login1 or -login2 asks for my passphrase. However, it still shows the menu for the Duo push / phone call / SMS. Requiring manual intervention to log in to an HPC environment significantly limits our use of the system. For instance, I cannot have automated scripts connecting from my group's server to Chip, copying/pasting input/output files I need for my simulations of the atmosphere. Do you mind if I ask why 2FA is being preferred over public/private ssh keys? Connecting to a remote server by exchanging public/private ssh keys requires 2 files in different machines. Breaking into such a system involves getting a copy of the private key (on the user's computer) AND figuring out the passphrase, which has 256+ bit encryption. Doing a quick search online, I could only find pages arguing that ssh-keys are more secure than 2FA. What is your evaluation? On the other hand, using 2FA with plain passwords puts all the security on the user's cellphone, which is easily stolen. How can this be safer than having two encrypted files, one in the local and one in the remote servers? Of course, having ssh-keys + 2FA is even more secure, but, as I mentioned, it limits how we can use the system. Thanks, [USER] On Tue, Mar 4, 2025 at 4:08 PM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hello [USER], With our initial implementation of Duo 2FA authentication on chip, we had to choose between disabling either password logins or public key logins, and since not everyone has public keys setup on chip we decided to disable public keys until we have a better solution. Our current security guidance requires us to have Duo enabled on systems that are publicly accessible, so disabling that wasn't an option either. We're currently working on a new implementation that will support SSH public keys, and is available on the new login nodes - chip-login1.rs.[DOMAIN] and chip-login2.rs.[DOMAIN] - if you would like to test it out and verify it's working for you. Eventually we will make these the default login nodes when you SSH to chip.rs.[DOMAIN], but that change is looking like it will happen sometime after Spring Break barring any major issues. Best, [STAFF]"
"3132989","68291069","2025-03-24 20:02:20","taki Account Request: [USER]","Hi [USER],  Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) On Mon Mar 24 15:39:46 2025, [STAFF] wrote: > Hi, > Since we are a few weeks farther, can this account be created on chip now? > I chatted with [STAFF] at the meeting today. > You were right that creating it on taki was useless already a few weeks back. I need to get my people to move to chip. > Matthias > Matthias K. [STAFF], Ph.D., Professor of Mathematics > Department of Mathematics and Statistics > Center for Interdisciplinary Research and Consulting (circ.umbc.edu) > UMBC High Performance Computing Facility (hpcf.umbc.edu) > REU Site: Online Interdisciplinary Big Data Analytics (BigDataREU.umbc.edu <http://bigdatareu.umbc.edu>) > University of Maryland, Baltimore County > 1000 Hilltop Circle, Baltimore, MD 21250 > http://www.umbc.edu/~[STAFF] On Fri, Feb 28, 2025 at 2:03 PM Max Breitmeyer via RT <UMBCHelp@rt.umbc.edu> wrote: > If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL],[EMAIL]&groupid=EIS&ticketid=3132989&ticketsubject=taki Account Request: [USER] <[USER]> > If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3132989 Good afternoon, As we prepare to make chip available to the public we have temporarily halted account creation on the Taki and Ada clusters. You can find more information on the timeline in the link below. Please feel free to put in a new ticket for the user to be added to Chip once the RT form has been made available. https://my3.my.umbc.edu/groups/hpcf/posts/147513 On Fri Feb 28 11:34:29 2025, [STAFF] wrote: > Approved. Original Request: Requestors: [STAFF], [USER] First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] System: taki Request Type: Account Request Position Title: Undergraduate Student Affiliation UMBC Department: Computer Science Role: Member of the research group Sponsor Information:    Name: [STAFF]    Department: Mathematics and Statistics    Email: [EMAIL] Research Title: Assistant during SEA Abstract: SEA in Summer 2025 People: [STAFF], [USER], [USER], [USER] Comments: Access to taki for performance studies and preparation during spring"
"3133019","67909305","2025-02-28 19:04:05","ada Account Request: [USER]","Good afternoon, As we prepare to make chip available to the public we have temporarily halted account creation on the Taki and Ada clusters. You can find more information on the timeline in the link below. Please feel free to put in a new ticket for the user to be added to Chip once the RT form has been made available. On Fri Feb 28 11:55:43 2025, [STAFF] wrote: I approve the request. Regards [STAFF]. On Fri, Feb 28, 2025 at 11:41 AM RT API via RT [EMAIL] wrote: Greetings, This message has been automatically generated in response to the creation of a ticket regarding you were Cc'd on: Subject: '[ada Account Request: [USER]]'. Message: First Name:                [USER]. Last Name:                 [USER]. Email:                     [EMAIL]. Campus ID:                 [ID]. System:                    ada. Request Type:              Account Request. Username:                     [USER]. Requested Action:             become a user in an existing ada PI Group. Primary HPCF PI Group Owner:      [EMAIL]. Supplemental HPCF PI Group Owners: - [EMAIL]. Project Keywords: - Artificial Intelligence. Please add to discussion mailing list. The ticket has been assigned an ID of [Research Computing #3133019] or you can go there directly by clicking the link below. Ticket URL: https://rt.umbc.edu/Ticket/Display.html?id=3133019. You can login with your UMBC credentials to view open tickets at any time by visiting http://my.umbc.edu and clicking on 'Help' and 'Request Help'. Thank you. Best, [STAFF] DOIT Unix Infra Student Worker"
"3133242","67929305","2025-03-03 14:18:50","ada - ADA Node 06 JobID - [USER] not pulling Deepseek Models","I'll do my best to provide a helpful response.  It appears that you're experiencing issues with pulling Deepseekr1 models using the ollama module on the ADA cluster. The error message indicates that there is no space left on the device, specifically in the `/home/gsantos2/.ollama/models/blobs` directory.  The response from Roy Prouty suggests configuring ollama to write the models elsewhere or symbolically linking the `.ollama` directory to another location with sufficient storage. This is because the default location for ollama's models is in the user's home directory, which may not have enough space.  You've also tried setting the `OLAMA_TMPDIR` environment variable to a different directory with enough space, but the error persists.  To resolve this issue, you could try the following:  1. **Configure ollama to use an alternate storage location**: You can set the `OLAMA_MODEL_DIR` environment variable to point to a directory with sufficient storage. For example: ```bash export OLAMA_MODEL_DIR=/path/to/large/storage/directory ``` Then, retry pulling the model using `ollama pull deepseek-r1:7b`.  2. **Symbolically link the `.ollama` directory**: You can create a symbolic link from the default `.ollama` directory to a directory with more storage. For example: ```bash ln -s /path/to/large/storage/directory ~/.ollama ``` Then, retry pulling the model using `ollama pull deepseek-r1:7b`.  3. **Check disk usage and available space**: Verify that the target directory has enough free space to accommodate the model files. You can use commands like `df -h` or `du -sh` to check disk usage.  If none of these solutions work, please provide more details about your environment, such as the ADA cluster's storage setup and any relevant configuration files. I'll do my best to help you troubleshoot the issue."
"3133404","68293012","2025-03-24 21:52:07","ada Account Request: [USER]","I couldn't solve the issue. Could you please arrange an online meeting to help me?  I have tried several steps as per the instructions, but I am encountering persistent errors. Steps I have attempted: 1. I successfully logged into the system using SSH and initiated an interactive session using srun --gres=gpu:1 --time=01:00:00 --mem=16G --pty bash. The GPU was visible with the command nvidia-smi, and there were no running processes. 2. I attempted to activate my Conda environment using conda activate venv, but received the error: bash: conda: command not found. 3. I ran conda init to initialize Conda, but again, I encountered the same error: bash: conda: command not found. 4. When trying to check the path to Conda with the command which conda, the output was: /usr/bin/which: no conda in (/cm/shared/apps/slurm/current/sbin:/cm/shared/apps/slurm/current/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin)   . 5. As per the steps, I verified the availability of Conda, and the error persisted as: -bash: conda: command not found. Key observations: - The error -bash: conda: command not found persists even after attempting to initialize Conda. - It appears that the Conda installation is either missing or misconfigured, causing issues with activating environments and managing packages. By default, most downloads are not available by default. You must use the 'module' system to find them, and add them to your PATH. When you start an interactive session on the GPU's run the following commands: module spider anaconda #determine which version of anaconda you want to use module load $anaconda_version Once that's done you should now be able to use the 'conda' command."
"3134350","67949041","2025-03-03 19:42:40","Other - Request to install the module git-lfs on [SERVER]","git-lfs v3.5.1 is available across [SERVER] now. -- [STAFF]"
"3135190","67982088","2025-03-04 20:16:42","ada - Migration from ada to chip","Thank you for your help. On Tue, Mar 4, 2025 at 9:38 AM [STAFF] via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3135190&ticketowner=[EMAIL]&ticketsubject=[SUBJECT] If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at Ticket https://rt.umbc.edu/Ticket/Display.html?id=3135190 Thank You Hi [USER], I've added the iharp group to chip. Please note that the location of where we store information has changed from what was on ada. Anything on ada-rstor can now be found /umbc/ada/iharp, and the normal iharp data is found in /umbc/rs/iharp/. There are aliases created for you to automatically take you to these locations under the names 'iharp_common' 'iharp_user' and 'iharp_ada'. On Tue Mar 04 09:16:11 2025, [STAFF] wrote Hi [USER], Thanks for bringing this to our attention. I'll go ahead and make sure the iharp group is added now. On Mon Mar 03 16:15:41 2025, [STAFF] wrote First Name [USER] Last Name [USER] Email [EMAIL] Campus ID [ID] System ada Request Type General Support Dear Support, I currently working in Ada user account /home/[USER]/iharp_user/[USER]/. I am able to login to chip cluster successfully. But, I couldn't locate this account in chip. I would appreciate any help and explanation. My understanding is that the chip doesn't have parallel job processing like we do in Ada? I would appreciate your response. Thank you for your time and consideration. Best [STAFF] DOIT Unix Infra Student Worker Original Request Requestors [USER] First Name [USER] Last Name [USER] Email [EMAIL] Campus ID [ID] System ada Request Type General Support Dear Support, I currently working in Ada user account /home/[USER]/iharp_user/[USER]/. I am able to login to chip cluster successfully. But, I couldn't locate this account in chip. I would appreciate any help and explanation. My understanding is that the chip doesn't have parallel job processing like we do in Ada? I would appreciate your response. Thank you for your time and consideration."
"3135489","67968159","2025-03-04 15:33:17","taki Account Request: [USER]","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu. All available modules can be viewed using the command 'module avail'. On Mon Mar 03 21:00:12 2025, [EMAIL] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] System: taki Request Type: Account Request Position Title: Undergraduate Student Affiliation UMBC Department: Biological Sciences - Bioinformatics Phone: [PHONE] Address: 402 spruce pine road abingdon, MD 21009 Role: Member of the research group Sponsor Information: Name: [STAFF] Department: Biological Sciences Email: [EMAIL] Phone: [PHONE] Research Title: Artificial Intelligence for Precision Oncology: A Multi-Omics Knowledge Network for Personalized Lung Cancer Treatment Abstract: Lung cancer, particularly non-small-cell lung cancer (NSCLC), is a significant health concern, with an estimated 238,340 new cases and 127,070 deaths expected in the United States in 2023 alone. Despite advances in targeted therapies and immune checkpoint blockade (ICB), resistance to these treatments is a common occurrence, underscoring the need for novel research approaches. This project aims to address these challenges by developing an artificial intelligence (AI) framework that integrates complex molecular data for the stratification of NSCLC patients. The proposed AI framework will enable personalized therapeutic strategies, overcoming the limitations of current precision oncology approaches. By translating knowledge from literature, functional genomics, and multi-omic patient-specific data, the framework will provide a comprehensive molecular model. People: [STAFF] Comments: n/a"
"3135704","68016766","2025-03-05 23:39:48","ada Account Request: [USER]","Ticket [NUMBER] ada Account Request: [USER] [CAMPUS ID] [OWNER CORRESPONDENCE] Comment From Ticket: Hello [STAFF], Thank you for your follow-up. Regarding the storage requirements for the VM, I anticipate needing at least 100GB of storage space. This will allow me to store datasets, models, and any necessary software for my AI research. I require Ubuntu specifically because I am using certain libraries and tools that are optimized for this operating system, particularly in the context of AI and machine learning. While RHEL could work, Ubuntu has better support for some of the frameworks I plan to use, such as TensorFlow and PyTorch, which are widely utilized in my research. I appreciate you pointing out the campus computing cluster. I will review the information provided on the HPCF website to see if it meets my needs. However, if possible, I would still prefer to have my own VM environment for flexibility in my research. Thank you for your assistance, and please let me know if you need further information. Best regards, [USER] Hi [USER], Thanks for this information. What storage requirements would this VM have? Can you speak to why Ubuntu is required over RHEL9? Are you aware of our campus computing cluster that has GPU cards and storage available? Please see https://hpcf.umbc.edu/compute/overview/ for more information. Hello [STAFF], Thank you for your response. Yes, I'm requesting an Ubuntu virtual machine (VM) for AI research purposes. I need this environment to run and test deep learning models, particularly in the areas of computer vision and natural language processing. For my project, I would need a VM with the following specifications: - Ubuntu operating system (preferably the latest LTS version) - At least 8GB RAM (more if possible) - GPU support (if available) - Sufficient storage space for datasets and models I'd be happy to provide more details about my research project if needed. Please let me know what the next steps would be to set up this VM. Thank you for your assistance! [USER] Hi [USER], You wrote requesting an account on ada, but then mention that you'd like a VM. Could you help me to understand the needs of your project? From there we can figure out how best to align you with campus resources. Also I see [STAFF] as a sponsoring PI, but [STAFF] has no account on ada. cc: [STAFF] First Name:                [USER] Last Name:                 [LAST NAME] Email:                     [EMAIL] Campus ID:                 [CAMPUS ID] System:                    ada Request Type:              Account Request Username:                     [USERNAME] Requested Action:             become a user in an existing ada PI Group Primary HPCF PI Group Owner:      [STAFF EMAIL] Supplemental HPCF PI Group Owners: Project Keywords: - Artificial Intelligence Additional Notes and Comments: Requesting virtual machine resources to support research on the training and deployment of large-scale language models in a scientific research setting."
"3135789","67978021","2025-03-04 18:46:18","taki - XMM_SAS not loading properly; permission problem with access to storage area","[STAFF]   (Note: Since the original text was quite short and only contained a name, there wasn't much to clean or anonymize. I replaced 'Roy Prouty' with '[STAFF]' as per your instructions.)"
"3135796","67998659","2025-03-05 15:37:30","conda environment issue in CHIP","It looks like you're trying to create a conda environment on the Chip cluster at UMBC and are running into issues. I'll try to provide some guidance.  **Summary of the issue:**  You're trying to create a conda environment using `conda create --prefix /umbc/ada/jianwu/users/s172 python=3.9 pytorch torchvision torchaudio matplotlib -c pytorch -y`, but you're getting an error message indicating that there's no space left on the device.  **Suggested solutions:**  1. **Check your disk quota:** Run `quota -v` to check your disk quota on the Chip cluster. If you've exceeded your quota, you'll need to clean up some files or request a quota increase. 2. **Specify a different location:** Try specifying a different location for the conda environment using the `--prefix` option. For example: `conda create --prefix /scratch/s172/conda-env python=3.9 pytorch torchvision torchaudio matplotlib -c pytorch -y` 3. **Use a smaller package set:** If you don't need all the packages specified in your command, try reducing the number of packages to see if that resolves the issue. 4. **Check for conflicts with existing environments:** Run `conda info --envs` to list all conda environments on your system. If there are conflicting environments, consider removing or renaming them.  **Additional tips:**  * Make sure you're using the correct version of conda by running `conda --version`. * If you're still having issues, try creating a minimal environment with just Python and one package to see if that works. * You can also try using `mamba` instead of `conda`, as it's often faster and more efficient.  **Example script:**  Here's an example script that creates a conda environment with the specified packages: ```bash #!/bin/bash  # Set environment variables CONDA_PREFIX=/scratch/s172/conda-env PYTHON_VERSION=3.9 PACKAGES='pytorch torchvision torchaudio matplotlib'  # Create the conda environment conda create --prefix $CONDA_PREFIX python=$PYTHON_VERSION $PACKAGES -c pytorch -y ``` **Please let me know if you have any further questions or issues!**"
"3135843","67973700","2025-03-04 17:18:33","Other - Running Jobs on Chip","Hi [USER], In terms of actually running jobs, there aren't that many differences. The hardware is slightly different, in that the new cluster now has the available constraints: L40S, and H100. The only thing you have to differently when submitting a job is add a new option for which cluster you want to use. For instance, 'srun --cluster=chip-gpu/chip-cpu --time=10:00 --mem=1000 --gres=gpu:1 some_command'. The only other major change is that we no longer allow for loading of modules on the login node. Any changes/compilations of code must be done on the compute nodes. You can access those interactively using 'srun --cluster=chip-gpu/chip-cpu --time=10:00 --mem=1000 --gres=gpu:1 --pty $SHELL'. We are working on getting more documentation out to users soon, but since you've been using the HPCf before, this should be enough to get you going. On [DATE], [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] System: Other Request Type: General Support Hi, I received an email stating that, starting March 3rd, ADA and TAKI users will be able to use CHIP. I am interested in using CHIP to run jobs and would appreciate some guidance on the process. Currently, I run jobs on ADA, and I would like to understand the specific changes and considerations when submitting jobs to CHIP, particularly for CHIP-GPU and CHIP-CPU. Could we schedule a brief meeting to go over the basics? Thank you for your help! Best, [STAFF]"
"3135982","67972943","2025-03-04 17:03:45","taki - CUDA versions","Hi [USER], We are no longer developing the taki cluster due to the imminent migration to the new chip HPC. See the myUMBC posting linked below for more information. https://my3.my.umbc.edu/groups/hpcf/posts/147513 On Tue Mar 04 11:40:51 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] System:                    taki Request Type:              General Support Hello, I need to install a specific CUDA version (either 12.4 or 12.6) in my Conda environment. However, when I check the available versions, the latest one I see is CUDA 11.4. Is there a way to install the version I need? Thank you!"
"3136199","68363023","2025-03-27 19:00:00","taki - Software needs","Hi [USER], I was curious to see if you've ever built this software before? It requires the use of another program (HEASoft), which if installing all the packages that it provides is huge. But if we can reduce the amount of packages we need, we can probably cut down on the size of the program and make it run faster. The only thing I've found so far with regards to specific packages is this (https://heasarc.gsfc.nasa.gov/docs/xmm/xmmhp_analysis.html) which mentions specifically Xspec, Xronos, and Ximage, but doesn't specifically say none of the other HEASoft packages are required. Let me know what you think. On Tue Mar 25 09:24:55 2025, [STAFF] wrote: Hi [USER], The XMM-SAS program was so big it was causing major slowdowns to users login and use of the module system. We're going to work to install it in your research volume (/umbc/rs/[USER]) so that it will be available to you, but not create issues for other users. As part of this, I would also recommend moving to Chip (chip.rs.umbc.edu). The login process is the same for chip and all your data will still be available as long as it's your research volume. We're working to move all of the nodes into Chip anyway, so your time on Taki will come to an end soon anyway. Let me know if you have questions about this, and I'll get to work on installing XMM in a place that is available for you and your users. On Fri Mar 21 13:15:46 2025, [STAFF] wrote: Hello again [USER], Actually, I just did some more testing, and while I have confirmed that: 1. the magsearch conda environment *does* have lmfit installed, and 2. after the job is submitted and I activate the environment, the node is in the magsearch environment (I ran `conda env list | grep *=` and it shows the correct one). But it is erroring out when the python script called by my test batch job script attempts to import lmfit. So there still seems to be some issue with python's ability to find that package. I also tried `python -c 'import lmfit'` and it is also unable to load the module. Additionally, I saw in the logs that the XMM-SAS/21.0.0 module has disappeared. I was able to `module load` it a few weeks ago, but not anymore. On Mar 21, 2025, at 12:58, [USER] wrote: Hello [STAFF], Apologies for the confusion. I was able to install lmfit through conda. However, I am still hitting errors when I submit my jobs that import numpy. Here is the output that I get from my submission: Traceback (most recent call last): File '/usr/cluster/contrib/Python/3.10.2-GCCcore-11.2.0/2018/lib/python3.10/site-packages/numpy/core/__init__.py', line 23, in <module> from . import multiarray File '/usr/cluster/contrib/Python/3.10.2-GCCcore-11.2.0/2018/lib/python3.10/site-packages/numpy/core/multiarray.py', line 10, in <module> from . import overrides File '/usr/cluster/contrib/Python/3.10.2-GCCcore-11.2.0/2018/lib/python3.10/site-packages/numpy/core/overrides.py', line 6, in <module> from numpy.core._multiarray_umath import ( ModuleNotFoundError: No module named 'numpy.core._multiarray_umath' During handling of the above exception, another exception occurred: Traceback (most recent call last): File 'search_pipeline.py', line 1, in <module> import numpy as np File '/usr/cluster/contrib/Python/3.10.2-GCCcore-11.2.0/2018/lib/python3.10/site-packages/numpy/__init__.py', line 144, in <module> from . import core File '/usr/cluster/contrib/Python/3.10.2-GCCcore-11.2.0/2018/lib/python3.10/site-packages/numpy/core/__init__.py', line 49, in <module> raise ImportError(msg) ImportError: IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the numpy C-extensions failed. This error can happen for many reasons, often due to issues with your setup or how NumPy was installed. We have compiled some common reasons and troubleshooting tips at: https://numpy.org/devdocs/user/troubleshooting-importerror.html Please note and check the following: * The Python version is: Python3.8 from '/usr/ebuild/software/Anaconda3/2021.05/bin/python' * The NumPy version is: '1.22.3' and make sure that they are the versions you expect. Please carefully study the documentation linked above for further help. Original error was: No module named 'numpy.core._multiarray_umath' I figure this has to do with the conda environment setup, but I have tried installing numpy there and it still crashes like this. Let me know if there is other information you need from me. Cheers, [USER]."
"3136216","68037007","2025-03-06 20:30:07","ada - Neither Pytorch nor TensorFlow can connect to GPU","It appears that the conversation is between Sara Khanjani, a researcher at the University of Maryland, Baltimore County (UMBC), and Roy Prouty, a member of the DoIT Research Computing Team. The conversation revolves around issues with running TensorFlow and PyTorch on a GPU-enabled system.  Here's a summary of the conversation:  1. Sara submitted a request for help, stating that she used `sbatch jupyter.slurm` to request a job, but none of the TensorFlow versions she tried worked, and the output showed that TensorFlow was not connected to the GPU. 2. She also mentioned that she had installed PyTorch and loaded different CUDA versions, but still faced issues. 3. Roy Prouty responded, asking Sara to check the `nvidia-smi` command to see if the NVIDIA driver is properly installed. 4. Sara attached a screenshot of the error message she received when running the `nvidia-smi` command. 5. Roy suggested that Sara might not be running within a Slurm allocation, which could cause issues with accessing the GPU.  Some key points from the conversation:  * The researcher is using a GPU-enabled system to run TensorFlow and PyTorch jobs. * There are issues with installing and running TensorFlow on the system. * The `nvidia-smi` command returns an error message, indicating potential problems with the NVIDIA driver installation. * The researcher has tried loading different CUDA versions and installing PyTorch, but still faces issues.  To better assist Sara, it would be helpful to:  1. Investigate the `nvidia-smi` error message further to determine if there is indeed a problem with the NVIDIA driver installation. 2. Verify that Sara is running her jobs within a Slurm allocation to ensure access to the GPU resources. 3. Provide guidance on troubleshooting and resolving the issues with installing and running TensorFlow on the system.  Feel free to ask me any specific questions or provide more context if needed!"
"3136321","68012240","2025-03-05 20:49:01","Other - Chip cluster conda setup","Hi, I have sent an invitation, please accept if you are available. Thank you [STAFF]. The error file contents are telling you that there are lines with malformed bash commands in the slurm submission file. Please set a meeting with me to discuss how to submit slurm jobs and run conda. My calendar can be viewed here: https://calendar.google.com/calendar/embed?src=[EMAIL]&ctz=America/New_York Plan to meet in ENGR 201A-1 or virtually. This is my batch script with all the required commands. It's not yet resolved. #!/bin/bash #SBATCH --job-name jupyter #SBATCH --gres=gpu:1 #SBATCH --output=jupyter-%j.out #SBATCH --error=jupyter-%j.err #SBATCH --time=24:00:00 #SBATCH --mem=150G module load Anaconda3/2024.02-1 conda --version python -m venv myenv conda init source myenv/bin/activate conda activate myenv TMPDIR='/umbc/rs/iharp/users/[USER]/[USER]/' pip install torchvision TMPDIR='/umbc/rs/iharp/users/[USER]/[USER]/' pip install seaborn TMPDIR='/umbc/rs/iharp/users/[USER]/[USER]/' pip install pandas TMPDIR='/umbc/rs/iharp/users/[USER]/[USER]/' pip install pyDOE TMPDIR='/umbc/rs/iharp/users/[USER]/[USER]/' pip install scikit-learn TMPDIR='/umbc/rs/iharp/users/[USER]/[USER]/' pip install matplotlib TMPDIR='/umbc/rs/iharp/users/[USER]/[USER]/' pip install nflows TMPDIR='/umbc/rs/iharp/users/[USER]/[USER]/' pip install netCDF4 TMPDIR='/umbc/rs/iharp/users/[USER]/[USER]/' pip install xarray echo 'The environment variables are:' which jupyter-lab XDG_RUNTIME_DIR='' node=$(hostname -s) user=$(whoami) cluster=ada port=$(( ( RANDOM % 60000 ) + 1024 )) echo 'Command to create a slurm allocation' Conda activate myenv -bash: conda: command not found /umbc/rs/iharp/users/[USER]/[USER] python -m venv myenv (worked) source myenv/bin/activate (worked) cat .bashrc # Source global definitions if [ -f /etc/bashrc ]; then . /etc/bashrc fi PATH=$PATH:/home/$USER export PATH module load gcc module load slurm __conda_setup='$('/usr/ebuild/installs/software/Anaconda3/2024.02-1/bin/conda' 'shell.bash' 'hook' 2> /dev/null)' if [ $? -eq 0 ]; then eval '$__conda_setup' else if [ -f '/usr/ebuild/installs/software/Anaconda3/2024.02-1/etc/profile.d/conda.sh' ]; then . '/usr/ebuild/installs/software/Anaconda3/2024.02-1/etc/profile.d/conda.sh' else export PATH='/usr/ebuild/installs/software/Anaconda3/2024.02-1/bin:$PATH' fi fi unset __conda_setup"
"3136372","67985569","2025-03-04 21:22:41","Other - Chip cluster jupyter notebook initiation","Hi [USER], I was able to make this work with almost 0 changes to this script. I've copied the whole file below. Any changes I made to the original script I put after double slashes (//). [USER@chip chipJupyterTest]$ cat jupyter.slurm  #!/bin/bash #------------------------------------------ # MAKE SURE TO RUN THIS SLURM FILE FROM # WITHIN THE FOLDER THAT CONTAIN THE OUTPUT # AND ERROR FILES #------------------------------------------ #SBATCH --cluster chip-gpu //this is a new addition. You must specify either chip-gpu or chip-cpu #SBATCH --job-name jupyter #SBATCH --gres=gpu:1 #SBATCH --output=jupyter-%j.out #SBATCH --error=jupyter-%j.err #SBATCH --time=1:00:00 //this should be however much time you want #SBATCH --mem=5000 //this should be however much memory you need  #------------------------------------------ # Uncomment the lines below in order to #   move any necessary dataset to /scratch #   Note: you will need to change the #    commands or use completely new ones #------------------------------------------ #echo 'Moving dataset to local sractch' #find /directory/to/my/csv/data -name *.csv | awk -v id=${SLURM_JOBID} '{print 'cp '$1' /scratch/'id'/.'}' | sh   #------------------------------------------ # Uncomment the following lines for to #   activate a conda environment #------------------------------------------ #echo 'Activating conda environment' #eval '$(conda shell.bash hook)' #conda activate <CONDA ENV NAME>   #------------------------------------------ # Get tunneling info #------------------------------------------ module load Anaconda3 echo 'The environment variables are:' which jupyter-lab XDG_RUNTIME_DIR='' node=$(hostname -s) user=[USER] cluster=chip //change this from ada to chip port=$(( ( RANDOM % 60000 )  + 1024 )) #------------------------------------------ # Print tunneling instructions to *.out file #------------------------------------------ echo '========================================' echo $PATH echo -e ' Command to create ssh tunnel below. Run this on your local machine. ssh -N -f -L ${port}:${node}:${port} [USER]@${cluster}.rs.[DOMAIN]  Then go to the .err file associated with this SLURM job and copy the line starting with \'http://127.0.0.1\' into your browser. '  #------------------------------------------ # Make sure you're using the version of #   jupyter-lab that you want. #------------------------------------------ jupyter-lab --no-browser --port=${port} --ip=${node}   # Submit an RT ticket to [SUPPORT_LINK] with any questions about this script  Otherwise just follow the instructions that are output in the .err and .out files after running 'sbatch jupyter.slurm' On Tue Mar [DATE], [USER] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [CAMPUS_ID] >  > System:                    Other >  > Request Type:              General Support >  > Hi, Thanks. I am trying to run jupyter.slurm. I added the commands here. will i be able to use the jupyter.slurm here? I would appreciate any help make jupyter.slurm to work? (myenv) [USER@chip USER]$ cat jupyter.slurm #!/bin/bash #------------------------------------------ # MAKE SURE TO RUN THIS SLURM FILE FROM # WITHIN THE FOLDER THAT CONTAIN THE OUTPUT # AND ERROR FILES #------------------------------------------ #SBATCH --job-name jupyter #SBATCH --gres=gpu:1 #SBATCH --output=jupyter-%j.out #SBATCH --error=jupyter-%j.err #SBATCH --time=24:00:00 #SBATCH --mem=150G  #------------------------------------------ # Uncomment the lines below in order to #   move any necessary dataset to /scratch #   Note: you will need to change the #    commands or use completely new ones #------------------------------------------ #echo 'Moving dataset to local sractch' #find /directory/to/my/csv/data -name *.csv | awk -v id=${SLURM_JOBID} '{print 'cp '$1' /scratch/'id'/.'}' | sh   #------------------------------------------ # Uncomment the following lines for to #   activate a conda environment #------------------------------------------ #echo 'Activating conda environment' #eval '$(conda shell.bash hook)'  #conda activate   #------------------------------------------ # Get tunneling info #------------------------------------------ module load Anaconda3/2024.02-1 python -m venv myenv source myenv/bin/activate conda activate myenv echo 'The environment variables are:' which jupyter-lab XDG_RUNTIME_DIR='' node=$(hostname -s) user=[USER] cluster=ada port=$(( ( RANDOM % 60000 )  + 1024 )) #------------------------------------------ # Print tunneling instructions to *.out file #------------------------------------------ echo '========================================' echo $PATH echo -e ' Command to create ssh tunnel below. Run this on your local machine. ssh -N -f -L ${port}:${node}:${port} [USER]@${cluster}.rs.[DOMAIN]  Then go to the .err file associated with this SLURM job and copy the line starting with \'http://127.0.0.1\' into your browser. '"
"3136901","68002566","2025-03-05 17:00:19","ada - How to pip install in manas ada folder","So you are currently trying to uninstall the base versions included in the anaconda module, which is what is available to all users. By default you don't have the permissions to do this. What you can do instead is create a conda environment with the versions of the libraries you do want, and import those kernels into jupyter. Start by creating the environment like you would normally. After you've installed the libraries you want, run the following command: ipython kernel install --user --name=${environmentName} Then run the slurm job to open the new jupyterhub, and click on the kernal named after your environment. If you want to check to make sure the version of the package is what you expect you can do run the following in jupyterhub: from importlib.metadata import version import ${package} version('${package}') Let me know if you have further questions regarding this. On Wed Mar 05, [USER] wrote: So the notebook that I am running is value_prism_short_data.ipynb On Wed, Mar 5, [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Can you give me the job number you are running? On Wed Mar 05, [USER] wrote: I am using normal pip install and not any conda environment. I am installing the libraries from inside the notebook only while running it to the jupyter.slurm file On Wed, Mar 5, [STAFF] <[EMAIL]> wrote: I am uninstalling and putting the latest version of these libraries. As without latest version is not able to run sentence_transformers and hdbscan. These are the libraries that I am trying to install import os import pandas as pd import numpy as np import torch from datasets import load_dataset, Dataset from sentence_transformers import SentenceTransformer import faiss import hdbscan from transformers import AutoModelForCausalLM, AutoTokenizer from tqdm import tqdm On Wed, Mar 5, [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hi [USER], In the original ticket, it shows you are trying to *uninstall* numpy and scipy. Why? Also what modules do you have loaded? Are you in a conda environment when you try to run this command? On Wed Mar 05, [USER] wrote: The commands were executed in the slurm task. The commands were executed in the ada server which I run in my laptop using ssh command On Wed, Mar 5, [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hi [USER], Our first step in any of these tickets is to try to replicate the issue. I don't have enough information to do that based on your original message. What machine are you running these commands on? Are you running the commands within a python virtual environment? Were the commands executed as a part of slurm task? On Wed Mar 05, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USER] System: ada Request Type: General Support Hi Team Can you please let me know how can I pip install in manas ada folder. I am facing this permission denied error. Code: !pip uninstall -y numpy scipy Error: Found existing installation: numpy 1.18.5 Uninstalling numpy-1.18.5: ERROR: Exception: Traceback (most recent call last): File '/usr/ebuild/software/Anaconda3/2020.07/lib/python3.8/shutil.py', line 788, in move os.rename(src, real_dst) OSError: [Errno 18] Invalid cross-device link: '/umbc/ebuild-soft/cascade-lake/software/Anaconda3/2020.07/bin/f2py' -> '/tmp/pip-uninstall-k1ac4x5w/f2py' During handling of the above exception, another exception occurred: Traceback (most recent call last): File '/usr/ebuild/software/Anaconda3/2020.07/lib/python3.8/site-packages/pip/_internal/cli/base_command.py', line 188, in _main status = self.run(options, args) File '/usr/ebuild/software/Anaconda3/2020.07/lib/python3.8/site-packages/pip/_internal/commands/uninstall.py', line 85, in run uninstall_pathset = req.uninstall() File '/usr/ebuild/software/Anaconda3/2020.07/lib/python3.8/site-packages/pip/_internal/req/req_install.py', line 676, in uninstall uninstalled_pathset.remove(auto_confirm, verbose) File '/usr/ebuild/software/Anaconda3/2020.07/lib/python3.8/site-packages/pip/_internal/req/req_uninstall.py', line 394, in remove moved.stash(path) File '/usr/ebuild/software/Anaconda3/2020.07/lib/python3.8/site-packages/pip/_internal/req/req_uninstall.py', line 283, in stash renames(path, new_path) File '/usr/ebuild/software/Anaconda3/2020.07/lib/python3.8/site-packages/pip/_internal/utils/misc.py', line 349, in renames shutil.move(old, new) File '/usr/ebuild/software/Anaconda3/2020.07/lib/python3.8/shutil.py', line 803, in move os.unlink(src) PermissionError: [Errno 13] Permission denied: '/umbc/ebuild-soft/cascade-lake/software/Anaconda3/2020.07/bin/f2py'"
"3137717","68016268","2025-03-05 22:53:38","Other - Volume not available in CHIP","Yes, it worked 10 mins after I opened the ticket. I couldn't find any option to close the ticket, but thanks. On Wed, Mar 5, 2025 at 5:52 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3137717> Last Update From Ticket: Hi [USER], I went in as your user and was able to confirm that all of the mounts available and the aliases worked. Can you show me what you were running that was failing? [USER@chip ferraro]$ ferraro_ada [USER@chip ferraro]$ pwd /umbc/ada/ferraro [USER@chip common]$ ferraro_common [USER@chip common]$ pwd /umbc/rs/ferraro/common [USER@chip common]$ ferraro_user [USER@chip sroydip1]$ pwd /umbc/rs/ferraro/users/[USER] On Wed Mar 05 16:50:36 2025, [USER] wrote: > First Name: [USER] > Last Name: [USER] > Email: [EMAIL] > Campus ID: [ID] > System: Other > Request Type: General Support > In the CHIP server, the following aliases are not working: > alias ferraro_ada='cd /umbc/ada/ferraro' > alias ferraro_common='cd /umbc/rs/ferraro/common' > alias ferraro_user='cd /umbc/rs/ferraro/users/[USER]' > I think because the specific volumes are not mounted yet. Best, [STAFF] DOIT Unix Infra Student Worker"
"3138212","68036827","2025-03-06 20:23:07","taki Account Request: [USER]","Hi [STAFF], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu. All available modules can be viewed using the command 'module avail'. On Thu Mar 06 15:13:34 2025, [USER] wrote: We'll certainly also be happy with an account on Chip. Best, [STAFF]. On 3/6/25 15:12, [STAFF] via RT wrote: Ticket Last Update From Ticket: Hello [STAFF], Per our recent HPCF timeline announcement (https://my3.my.umbc.edu/groups/hpcf/posts/147513), we will no longer be creating users for Taki, however, if you would like us to make the user for Chip, our new cluster, that can be done. Please let me know if I should proceed with this action. On Thu Mar 06 11:21:29 2025, [USER] wrote: Dear HPC staff, Dr. [STAFF] is a postdoc in my group, and I acknowledge and approve this request. Kindest regards, [STAFF]."
"3138870","68046407","2025-03-07 13:37:49","taki Account Request: [USER]","Hi [USER],  Your account ([USERNAME]) has been created on [SERVER]. Your primary group is [GROUPNAME]. Your home directory has 500M of storage. Please read through the documentation found at [WEBSITE]. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://[LINK]) On Fri Mar 07 05:36:47 2025, [STAFF] wrote: > Approve, if [USER] is not available then chip >  M. > Sent from my iPhone  On Mar 6, 2025, at 11:44 PM, RT API via RT <[EMAIL]> wrote: Dear [STAFF], This e-mail is a notification that [USERNAME] Account Request: [USER] has requested an account for the UMBC HPCF in your user group. As the PI we request that you acknowledge and approve this account creation by replying to this message. Alternatively, you can go to this link and review the ticket and indicate your decision here - Ticket Once we have your approval and the account request is reviewed we will create the account and you and the new user will receive another e-mail notifying you that the account has been created. If you have any other questions or concerns please contact us. See [WEBSITE] or point of contact [STAFF]. Thanks, HPCF support staff -- Best, [STAFF]"
"3139130","68063585","2025-03-07 22:07:29","Other - chip cluster - Fail to use the Anaconda module after loading it","Problem resolved by '[STAFF]'. Thank you."
"3139221","68073377","2025-03-10 13:01:21","taki Account Request: [USER]","Hi [STAFF], Per our HPC Timeline announcement (https://my3.my.umbc.edu/groups/hpcf/posts/147513), we are no longer accepting account requests for taki. That being said, we have gone ahead and created a group for you on our new cluster, chip.rs.umbc.edu. In addition we have added the users we requested. If you have any issues with login, please open a new ticket.  On Fri Mar 07 12:28:56 2025, [STAFF] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [CAMPUSID] >  > System:                    taki >  > Request Type:              Account Request >  > Position Title:            Faculty >  > Affiliation                UMBC > Department:                Mechanical Engineering > Phone:                     [PHONE] > Address:                   1000 Hiltop Rd, ENG216 >                            Baltimore, MD 21250 >  > Role:                      UMBC Faculty/PI >  > Research Title:            Data-driven, Learning-based, Adaptive Control of Solid Fuel Ramjet > Abstract:                  The project's aim is develop an online, data-driven, learning-based adaptive control system to modulate the thrust generated by solid fuel ramjets in uncertain operating conditions. The proposed project will primarily rely on computational modeling and numerical simulations of the solid fuel ramjet and will include extensive software development and numerical experiments to demonstrate the reliable operation of the control system in realistic conditions. > People:                    [USER]  Campus ID - [CAMPUSID] > [USER]  Campus ID - [CAMPUSID] > Comments:                  I would like to request an HPC account for my students [USER]  Campus ID - [CAMPUSID] > [USER]  Campus ID - [CAMPUSID] both of whom are assisting in the project on data driven control of solid fuel ramjet."
"3139628","68066382","2025-03-08 17:15:58","ada - Can't access directories on Ada","Hi [USER], This directory should be available to you now. It was migrated, but the directory needed to be re-mounted. I'll mark this as resolved since I've checked that your account can access reu2024 from ada. On Sat Mar 08 11:04:15 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] System: ada Request Type: General Support Good morning, I am unable to access directories on Ada: /umbc/rs/cybertrn/reu2024. I went to this location and found that the cybertrn folder is no longer there. I know that the HPCF is migrating hardware and I wonder if this folder was moved to another location or another system? Do you know why I cannot access this directory anymore? Do you know where the new location for this directory is? Thank you very much!"
"3139640","68072836","2025-03-10 12:47:18","HPC Account/Permission access to lab drive for [USER]","Hi [STAFF], Please submit a new rt ticket here with your lab coordinator cc'ed. Once they approve it, we can add you to the cluster. On Sat Mar 08 11:59:17 2025, [USER] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [ID] >  > Request type:                 General Support >  > Hello, I am a student working in [STAFF]'s lab and I need access to the lab drive located at: >  > /umbc/rs/[STAFF] >  > and would like to be added to the group pi_[STAFF]. >  > Thank you, > [USER]"
"3139651","68286338","2025-03-24 18:22:18","ada - error when [USER] wants to use gpu for operations","Hi guys, thanks a lot for all your help! Now, I am able to extract vggish features using gpus with no problem. Thanks again, and we can close this ticket. Best, -[USER] On Thu, Mar 13, 2025 at 11:18 AM [STAFF] via RT wrote: Ticket Last Update From Ticket: Just added! [STAFF] Appointment Calendar https://calendar.google.com/calendar/u/0/appointments/[APPOINTMENT_LINK] The most dangerous phrase in the language is, 'We've always done it this way.' - Adm Grace Hopper On Thu, Mar 13, 2025 at 11:15 AM [USER] via RT wrote: Ticket Last Update From Ticket: Roy, I cannot see the meeting link On Wed, Mar 12, 2025 at 5:25 PM [USER] wrote: Thanks [STAFF]! just booked for tomorrow 11:15 am On Wed, Mar 12, 2025 at 4:07 PM [STAFF] via RT wrote: Ticket Last Update From Ticket: Since I have no way of replicating that, let's find a time to meet in person again. It's most convenient for me if you use my appointment calendar linked below. [STAFF] Appointment Calendar https://calendar.google.com/calendar/u/0/appointments/[APPOINTMENT_LINK] The most dangerous phrase in the language is, 'We've always done it this way.' - Adm Grace Hopper On Wed, Mar 12, 2025 at 3:59 PM [USER] via RT wrote: Ticket Last Update From Ticket: When connected to jupyter notebook I choose it there [USER], Department of Information Systems University of Maryland, Baltimore County On Wed, 12 Mar 2025 at 3:55 PM [STAFF] via RT wrote: Ticket Last Update From Ticket: How do you normally load 'my_env'? I don't see it in your ada account. [STAFF] Appointment Calendar https://calendar.google.com/calendar/u/0/appointments/[APPOINTMENT_LINK] The most dangerous phrase in the language is, 'We've always done it this way.' - Adm Grace Hopper On Wed, Mar 12, 2025 at 3:34 PM [USER] via RT wrote: Ticket Last Update From Ticket: Thanks [STAFF] for the response. The my_env environment is used as we utilized it in our previous meeting to install tensorflow [USER], Department of Information Systems University of Maryland, Baltimore County On Wed, 12 Mar 2025 at 1:53 PM [STAFF] via RT wrote: Ticket Last Update From Ticket: Hi [USER], Apologies for the delay, some of my team are out sick this week. I'm taking a look at this now, could you tell us what conda environment you're building tensor flow within? We've looked around your account and only see a definition for the 'base' environment. On Tue Mar 11 10:38:24 2025, [USER] wrote: Any updates on this? Thanks [USER], Department of Information Systems University of Maryland, Baltimore County On Sat, 8 Mar 2025 at 1:41 PM via RT wrote: Greetings, This message has been automatically generated in response to the creation of a ticket regarding: Subject: 'ada - error when wants to use gpu for operations' Message: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] System: ada Request Type: General Support Hi, now I can see tensorflow can recognize the gpu by this: print('Num GPUs Available:', len(tf.config.list_physical_devices('GPU'))) output: Num GPUs Available: 1 also this code shows the same thing: print(tf.config.list_physical_devices('GPU')) output:[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')] !nvidia-smi output: screenshot of it is attached However, when running an operation with forcing tensorflow to use gpu (see the code attached in the screenshot called exp_gpu) the output is an error: output : --> 721 self._session = tf_session.TF_NewSessionRef(c_graph, opts) 722 # pylint: enable=protected-access 723 finally: 724 tf_session.TF_DeleteSessionOptions(opts) InternalError: cudaSetDevice() on GPU:0 failed. Status: CUDA-capable device(s) is/are busy or unavailable Not sure what is going on! I checked the version alignments from here, cudnn needs to be upgraded to 9.3 (current version is 9), however, I do not think that could cause the issue as even without using dnns, and with a simple matrix multiplication operation the gpu is not used again! JobID: [JOB_ID] path to slurm file: cd /nfs/rs/vjaneja/users/[USER]/jupyter.slurm Attachment 1: nvidia-smi.png (https://umbc.box.com/s/[ATTACHMENT_LINK]) Attachment 2: exp_gpu.png (https://umbc.box.com/s/[ATTACHMENT_LINK]) There is no need to reply to this message right now. Your ticket has been assigned an ID of [TICKET_ID] or you can go there directly by clicking the link below. Ticket https://rt.umbc.edu/Ticket/Display.html?id=[TICKET_ID] You can login to view your open tickets at any time by visiting http://my.umbc.edu and clicking on 'Help' and 'Request Help'. Alternately you can click on http://my.umbc.edu/help Thank you -- [STAFF] DoIT Research Computing Team"
"3139673","68303738","2025-03-25 15:10:12","Other - Query regarding storage solutions","Hi, Thanks for the information. We found an alternative solution. Thanks again, [STAFF]  Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=[NUMBER]> Last Update From Ticket: Hi [USER], UMBC does not administer Dropbox accounts. We don't have any way to extend its storage. A listing of what we do administer is listed here: https://doit.[DOMAIN]/eis/storage/ On Tue Mar 25 10:04:56 2025, [USER] wrote: Dear office, The issue has not been resolved. Is it possible to temporarily extend the Dropbox file storage capacity for [USER] until the end of this semester? Best,[STAFF] On Mon, Mar 24, 2025 at 8:32 AM [STAFF] via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://[DOMAIN].us2.qualtrics.com/SE/?SID=[STRING]&customeremail=[EMAIL]&groupid=[GROUPID]&ticketid=[NUMBER]&ticketowner=[OWNER]&ticketsubject=[SUBJECT] If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=[NUMBER]> Thank You _______________________________________ R e s o l u t i o n: = = = = = = = = = = = = = Hi [USER], Sorry for the delay here. We do not offer support for DropBox Pro through the university. However, I think box.[DOMAIN] would be a good solution for your lab. 30GB is well within the normal allocation for normal Box accounts. You can read more about Box services here: https://[DOMAIN].atlassian.net/wiki/spaces/faq/pages/[NUMBER]/Box Let me know if you have further questions, but I'll mark this as resolved for now. On Sat Mar 08 17:47:39 2025, [USER] wrote: First Name: [USER] Last Name: [LAST NAME] Email: [EMAIL] Campus ID: [CAMPUS ID] System: Other Request Type: General Support DoIT Support Team, I hope you are doing well. My name is [USER], and I am a Research Assistant working with Prof. [STAFF]. We are currently working on the '[PROJECT]' project and have been using Dropbox for file storage. However, the dataset provided by Prof. [STAFF] is 21GB in size, and my current Dropbox Basic Plan account only offers 2GB of available storage. Could you kindly advise on options to extend the storage on Dropbox or recommend alternative solutions for handling large files effectively? I look forward to your suggestions. Best regards, [USER] [CAMPUS ID] Research Assistant Prof. [STAFF]'s Team -- [STAFF] DoIT Research Computing Team Original Request: Requestors: [USER] First Name: [USER] Last Name: [LAST NAME] Email: [EMAIL] Campus ID: [CAMPUS ID] System: Other Request Type: General Support DoIT Support Team, I hope you are doing well. My name is [USER], and I am a Research Assistant working with Prof. [STAFF]. We are currently working on the '[PROJECT]' project and have been using Dropbox for file storage. However, the dataset provided by Prof. [STAFF] is 21GB in size, and my current Dropbox Basic Plan account only offers 2GB of available storage. Could you kindly advise on options to extend the storage on Dropbox or recommend alternative solutions for handling large files effectively? I look forward to your suggestions. Best regards, [USER] [CAMPUS ID] Research Assistant Prof. [STAFF]'s Team"
"3139864","68073417","2025-03-10 13:02:59","taki Account Request: [USER]","Hi [USER], It appears you already exist in [STAFF]'s group. You should be able to access chip.rs.umbc.edu with no issues. On Sun Mar 09 19:00:40 2025, [EMAIL] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] System: taki Request Type: Account Request Position Title: Undergraduate Student Affiliation UMBC Department: Bioinformatics Phone: [PHONE] Address: [ADDRESS] Role: Member of the research group Sponsor Information: Name: [STAFF] Department: Biological Sciences Email: [EMAIL] Phone: [PHONE] Research Title: Artificial Intelligence for Precision Oncology: A Multi-Omics Knowledge Network for Personalized Lung Cancer Treatment Abstract: Lung cancer, particularly non-small-cell lung cancer (NSCLC), is a significant health concern, with an estimated 238,340 new cases and 127,070 deaths expected in the United States in 2023 alone. Despite advances in targeted therapies and immune checkpoint blockade (ICB), resistance to these treatments is a common occurrence, underscoring the need for novel research approaches. This project aims to address these challenges by developing an artificial intelligence (AI) framework that integrates complex molecular data for the stratification of NSCLC patients. The proposed AI framework will enable personalized therapeutic strategies, overcoming the limitations of current precision oncology approaches. By translating knowledge from literature, functional genomics, and multi-omic patient-specific data, the framework will provide a comprehensive molecular model. People: [STAFF] Comments: n/a"
"3139866","68071706","2025-03-10 11:58:05","Other - Link for [USER] from support ticket resolution email did not work","Hi [USER], Please review the overview page that discusses access to the system: https://hpcf.umbc.edu/compute/overview/. On Sun Mar 09 20:05:01 2025, [USER] wrote: When I try to click on the link that’s provided to me in the response email from the ticket [NUMBER], the page gives me an error that says “this site can’t be reached”. Thank you for working with me on this, [STAFF]. On Sun, Mar 9, 2025 at 7:59 PM [EMAIL] via RT wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3139866 Last Update From Ticket: Hi [USER], What isn’t working? What are you trying to do? Please give a list of commands that allow us to replicate your problem. Roy Prouty (he/him/his) On Sun, Mar 9, 2025 at 19:10 RT API via RT wrote: Transaction: Ticket created by [USER] Queue: DoIT-Research-Computing Subject: Other - Link for Chip from support ticket resolution email did not work Owner: Nobody Requestors: [EMAIL] Status: new First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] System: Other Request Type: General Support tried to access the link for the chip account that was set up from the email sent from a ticket i submitted, but the link does not work. this was the link given: chip.rs.umbc.edu. The ticket number was: Research Computing #[NUMBER]."
"3139867","68073525","2025-03-10 13:05:08","taki Account Request: [USER]","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/)  On [DATE], [STAFF] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [CAMPUSID] >  > System:                    taki >  > Request Type:              Account Request >  > Position Title:            Undergraduate Student >  > Affiliation                UMBC > Department:                Biological Sciences - Bioinformatics > Phone:                     [PHONE] > Alt E-Mail:                [EMAIL] > Address:                   [ADDRESS] >  > Role:                      Member of the research group >  > Sponsor Information: >    Name:                       [STAFF] >    Department:                 Biological Sciences >    Email:                      [EMAIL] >    Phone:                      [PHONE] >  > Research Title:            Artificial Intelligence for Precision Oncology: A Multi-Omics Knowledge Network for Personalized Lung Cancer Treatment > Abstract:                  Lung cancer, particularly non-small-cell lung cancer (NSCLC), is a significant health concern, with an estimated 238,340 new cases and 127,070 deaths expected in the United States in 2023 alone. Despite advances in targeted therapies and immune checkpoint blockade (ICB), resistance to these treatments is a common occurrence, underscoring the need for novel research approaches. This project aims to address these challenges by developing an artificial intelligence (AI) framework that integrates complex molecular data for the stratification of NSCLC patients. The proposed AI framework will enable personalized therapeutic strategies, overcoming the limitations of current precision oncology approaches. By translating knowledge from literature, functional genomics, and multi-omic patient-specific data, the framework will provide a comprehensive molecular model. > People:                    [STAFF] > Comments:                  n/a"
"3140030","68072997","2025-03-10 12:50:35","HPC Account/Permission access to lab drive","First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request type: General Support Hello I am a student working in [STAFF]'s lab and I need access to the lab drive located at /umbc/rs/[STAFF] and would like to be added to the group pi_[STAFF]. Thank you [USER]"
"3140854","68114338","2025-03-11 17:05:33","Other - Draining for days","g24-09 is out of a draining state and is working. g20-02 will be up in a little bit On Tue Mar 11 09:45:48 2025, [STAFF] wrote: Hi We are working on identifying the issue with g24-09 and g20-02. I will update you once it is resolved. On Mon Mar 10 18:49:29 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] System:                    Other Request Type:              General Support g24-09 and g20-02 are on draining stage for the last 1 week. Is it normal?"
"3140882","68238783","2025-03-20 20:39:34","taki - Maximum Array size","Hi [USER], Sorry for the delay here. We've increased the Maximum Job count. Please try this and see if you can run more array jobs. On Thu Mar 13 11:20:55 2025, [STAFF] wrote: Good morning [USER], I apologize for the delay in responding to your ticket. We are currently looking into this issue, and will respond with some guidance on how to move forward as soon as possible. Best, [STAFF] On Mon Mar 10 19:50:12 2025, [EMAIL] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] System: taki Request Type: General Support I was trying to run the slurm job. I got this error. File LUT_computation_Libradtrain_input.txt has 80000 line but here when uploading the file I removed few lines to keep maximum upload size less than 7MB I was discussing this with [STAFF] and he asked me to submit a ticket. Attachment 1: error.png (https://umbc.box.com/s/[LINK]) Attachment 2: run_libradtran_test.slurm (https://umbc.box.com/s/[LINK]) Attachment 3: LUT_computation_Libradtrain_input.txt (https://umbc.box.com/s/[LINK])"
"3141185","68159691","2025-03-13 14:38:28","taki Account Request: [USER]","The accounts are both on taki and chip. On Thu Mar 13 10:13:23 2025, [STAFF] wrote: Just to clarify. These accounts are in Taki, right? On Thu, Mar 13, 2025 at 10:10 AM [STAFF] via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3141185&ticketowner=[STAFF]&ticketsubject=taki Account Request: [USER] <[EMAIL]> If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3141185 Thank You _________________________________________ R e s o l u t i o n: Hi [USER], It looks like [USER] has been in your group for some time, so nothing to be done there. I just added [USER] to your group, so please give that a moment to propagate. On Thu Mar 13 09:41:34 2025, [STAFF] wrote: Have you created the two accounts we requested? Thanks. Joshua Richards [EMAIL] Amanda Vieira dos Santos [EMAIL] On Tue, Mar 11, 2025 at 10:18 AM [STAFF] via RT <[EMAIL]> wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3141185 Last Update From Ticket: I just check the CHIP-CPU cluster. It seems that all my data disks are not mounted to it yet. At the moment, can you create accounts for students in the taki cluster so they can use the machine immediately? Thanks. And Yes, you can put them in my user group. pi_[USER] On Tue, Mar 11, 2025 at 10:03 AM [STAFF] via RT <[EMAIL]> wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3141185 Last Update From Ticket: Yes, You have access to chip cluster. We have migrated your group and the group members to the cluster. The login node address is chip.rs.umbc.edu. You can see more info about chip and how to use it here : https://hpcf.umbc.edu/compute/overview/ Also, do you want the students to be added to pi_[USER] or students group? On Tue Mar 11 09:58:46 2025, [STAFF] wrote: Do I have access to CHIP-CPU? username: [USER] What is the login node address of the new CHIP-CPU cluster? On Tue, Mar 11, 2025 at 9:54 AM [STAFF] via RT <[EMAIL]> wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3141185 Last Update From Ticket: Hello Is it alright to create this account on chip? We are no longer provisioning accounts on taki since taki will not be available after a month. On Tue Mar 11 09:42:15 2025, [USER] wrote: First Name: Zhibo Last Name: Zhang Email: zzbatmos@umbc.edu Campus ID: OX20655 On Behalf Of: Joshua Richards (jrichar2@umbc.edu, WO44695) System: taki Request Type: Account Request Position Title: Faculty Affiliation UMBC Department: Physics Phone: 19799976515 Alt E-Mail: zzbatmos@umbc.edu Address: 1000 Hilltop Circle 1000 Hilltop Circle Baltimore, MD 21250 Role: UMBC Faculty/PI Research Title: PHYS721 Radaitive Transfer Abstract: PHYS721 Radaitive Transfer People: Zhibo Zhang Comments: please create a student account for the follow two students Joshua Richards jrichar2@umbc.edu Amanda Vieira dos Santos avieira2@umbc.edu"
"3141537","68159385","2025-03-13 14:32:29","taki - Inquiry About Using Chip","Hi [STAFF], Yes! All users from Taki and Ada have been added to chip. You can login using 'ssh [USER]@[SERVER].rs.[DOMAIN]'. Please let us know if you have any issues logging in.  On Tue Mar 11 13:47:49 2025, [EMAIL] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [ID] >  > System:                    taki >  > Request Type:              General Support >  > Hello, > I have an account on Taki and was wondering if I can start using the > chip yet. If so, could you kindly guide me on how to proceed? Thank > you!"
"3142382","68159758","2025-03-13 14:40:50","ada Account Request: [USER]","Hi [USER]. We are no longer creating accounts for users on taki or ada, but I've gone ahead and added them to your group in chip. Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) On Wed Mar 12 14:17:30 2025, [STAFF] wrote: Approved. Many thanks. Best regards, [STAFF]. On Mar 12, 2025, at 1:57 PM, RT API via RT <[EMAIL]> wrote: This e-mail is a notification that ada Account Request: [USER] has requested an account for the ada cluster environment in your research group. As the PI we request that you acknowledge and approve this account creation by replying to this message. Alternatively you can go to this link and review the ticket and indicate your decision here - Ticket https://rt.umbc.edu/Ticket/Display.html?id=3142382 Once we have your approval and the account request is reviewed we will create the account and you and the new user will receive another e-mail notifying you that the account has been created. If you have any other questions or concerns please contact us. Thanks, HPCF support staff -- Best, [STAFF]"
"3142566","68159577","2025-03-13 14:36:55","taki Account Request: [USER]","Hi [STAFF], we are no longer creating accounts for users on Taki, but I've gone ahead and created his account on chip. Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu. All available modules can be viewed using the command 'module avail'. On Wed Mar 12 16:21:45 2025, [USER] wrote: Yes, I approve creation of the account for [USER]. On Wed, Mar 12, 2025 at 4:12 PM The RT System itself via RT <[EMAIL]> wrote: Dear [STAFF], This e-mail is a notification that taki Account Request: [USER] has requested an account for the UMBC HPCF in your user group. As the PI we request that you acknowledge and approve this account creation by replying to this message. Alternatively you can go to this link and review the ticket and indicate your decision here - Ticket URL: https://rt.umbc.edu/Ticket/Display.html?id=3142566 Once we have your approval and the account request is reviewed we will create the account and you and the new user will receive another e-mail notifying you that the account has been created. If you have any other questions or concerns please contact us. See link: http://hpcf.umbc.edu/contact/ or point of contact [STAFF] <[EMAIL]>. Thanks, HPCF support staff"
"3142750","68159951","2025-03-13 14:43:19","Other - CHIP: SSH Issue","Hi [STAFF], Thanks for the quick catch, this issue has been resolved. Please put in a new ticket if you have any other issues. On Thu Mar 13 08:07:14 2025, [USER] wrote: While I can login now, the 'squeue' command is not working. Following are the outputs: [USER@chip ~]$ squeue squeue: error: slurm_persist_conn_open_without_init: failed to open persistent connection to host:master:6819: Connection refused squeue: error: Sending PersistInit msg: Connection refused squeue: error: Sending PersistInit msg: Connection refused squeue: error: DBD_GET_CLUSTERS failure: Connection refused squeue: error: Problem talking to database squeue: error: There is a problem talking to the database: Connection refused. Only local cluster communication is available, remove --cluster from your command line or contact your admin to resolve the problem. If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3142750&ticketowner=[STAFF]&ticketsubject=Other - CHIP: SSH Issue If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3142750 Thank You Login node was in an odd state, rebooted it. Original Request: Requestors: [USER] First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] System: Other Request Type: General Support SSH access to chip.rs.umbc.edu closes immediately after 2FA success despite valid credentials. Both from terminal and vscode"
"3143119","68184578","2025-03-14 15:33:02","GPUs drained on chip","Hi [USER], The issue should be resolved. Let us know if you have any issues. On Thu Mar 13 12:38:25 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request type: General Support Hi, A number of the new (g24-**) gpus on chip are drained and my job request therefore is awaiting resources despite there is no job traffic. Can you please resolve the issue? Thanks [USER] ([EMAIL])"
"3143468","68234163","2025-03-20 18:09:10","taki - 5+ minutes to log into taki (and still not complete)","Hi [STAFF], I just tried it, it's much faster than what it was a few days ago. I'll keep an eye on it! Thanks! [USER] On Thu, Mar 20, 2025 at 11:11 AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3143468 > Last Update From Ticket: Dear [USER], We apologize for the inconvenience caused by the slow loading of modules. This was due to an issue with certain modules that should be fixed now. Would you be able to check and see if you still experience these issues? Thanks for understanding, have a great day! -- Kind regards, [STAFF] DOIT Unix Infra Student Worker On Thu Mar 13 20:42:31 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] System: taki Request Type: General Support those module loads are getting slower and slower and slower ...."
"3143547","68184447","2025-03-14 15:30:46","Other - CHIP: draining","Hi [STAFF], Nope, nothing you guys are doing wrong, an error on our end that we believe that we have patched. Go ahead and run some things and let us know if it works for you this go around. On Thu Mar 13 23:38:55 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] System: Other Request Type: General Support Most of the L40s are in the draining state. Is there anything we are doing wrong? CLUSTER: chip-gpu PARTITION AVAIL TIMELIMIT NODES STATE NODELIST gpu* up infinite 1 down* g20-02 gpu* up infinite 1 drng g24-01 gpu* up infinite 4 drain g24-[02-03,05-06]"
"3143846","68185351","2025-03-14 15:55:03","Other - Loading Modules on Chip","This isn't an error, it was a decision we put in place to prevent users from loading modules, attempting to develop, and running projects on the login node. If you would like to run things, please request a slurm allocation as you normally would and run things from there. If you have further questions, please let me know. On Fri Mar 14 11:47:43 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] System:                    Other Request Type:              General Support Hello, I recently connected to Chip, and when I attempt to load a module (e.g., Anaconda), I receive an error stating that modules cannot be loaded on the login node. Could you kindly assist me with resolving this issue? Thank you in advance for your help. Best, [STAFF]"
"3144336","68227860","2025-03-20 15:27:53","chip - reservation request for H100 & L40S machines","Thank you [STAFF] and [STAFF]. I appreciate your quick action. Regards [USER]. If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3144336&ticketowner=[STAFF]%40umbc.edu&ticketsubject=chip%20-%20reservation%20request%20for%20H100%26%20L40S%20machines. If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3144336. Hi [USER], I've created this reservation for g24-07 (L40S machine) and g24-10 (H100 machine). Only the users [USER],[USER],[USER],[USER],[USER] can access this reservation. To use the reservation, include the following slurm directives: --cluster=chip-gpu --reservation=neurips25. Let me know if there are any questions! More information on the reservation below... scontrol show reservation neurips25 ReservationName=neurips25 StartTime=2025-03-19T17:17:00 EndTime=2025-05-01T00:00:00 Duration=42-06:43:00 Nodes=g24-[07,10] NodeCnt=2 CoreCnt=64 Features=(null) PartitionName=(null) Flags=SPEC_NODES TRES=cpu=64 Users=[USER],[USER],[USER],[USER],[USER] Groups=(null) Accounts=(null) Licenses=(null) State=ACTIVE BurstBuffer=(null) Watts=n/a MaxStartDelay=(null). On Fri Mar 14 21:10:33 2025, [STAFF] wrote: Hi [USER] and [STAFF], You each purchased 1/2 of an H100 machine. [STAFF]: are you alright with the entire H100 machine being allocated to [USER] for this period starting ASAP and running through May 1, 2025? I'm happy to reserve half of the machine's resources, but that would be more cumbersome to write slurm allocations for. I'll follow-up after spring break to schedule future reservations and look forward to your input to the GPU Committee meetings [STAFF] will schedule in early April. My lab is planning to submit four papers to NeurIPS 2025, which you all know is a very competitive conference. There is a requirement for a significant amount of experimentation. I request increased storage (10 TB) and access to L40S and H100 for the following students: (a) [USER] ([USER]) (b) [USER] ([USER]) (c) [USER] ([USER]) (d) [USER] ([USER]). Looking forward to your immediate attention. I request access till April 30, 2025. -- Roy Prouty DoIT Research Computing Team Original Request: Requestors: [USER]."
"3144338","68197513","2025-03-15 01:42:38","rrstor - Temporary Storage Increase of 10TB","Sure thing. The storage that's available on ada is mounted on chip as '/umbc/ada/manas'. We'll have this better documented in the coming days, sorry for any confusion and thanks for the quick response. [ndas2@chip ~]$ df -h /umbc/ada/manas Filesystem Size Used Avail Use% Mounted on 10.2.42.254:/export/manas 40T 15T 26T 36% /umbc/ada/manas [ndas2@chip ~]$ ls /umbc/ada/manas users [ndas2@chip ~]$. On Fri Mar 14 21:32:40 2025, [STAFF] wrote: Hi [STAFF], I met my students today. They told me that the storage on my part of the server is 500GB. Can you tell me where I should ask them to look for 26TB? I requested 10TB because they told me 500GB was the remaining storage. Please ignore my request if I already have 26TB left. I am CCing my students so that they get to know where to look for the storage. Regards [STAFF]. On Fri, Mar 14, 2025 at 9:19 PM via RT [EMAIL] wrote: Greetings, This message has been automatically generated in response to the creation of a ticket regarding: Subject: 'rrstor - Temporary Storage Increase of 10TB'. Message: Hi [STAFF], Your allocation within UMBC's research storage is 40TB, which is a temporary 20TB increase from 20TB set to expire April 1. The current usage leaves 26TB free. I'm happy to extend the 20TB lease until May, but I wanted to get clarity on whether or not the request for 10TB was a part of this 20TB increase or meant to be another 10TB on top of the 20TB increase (leaving your group with 50TB volume that would shrink to 20TB sometime after May 1). '''' My lab is planning to submit four papers to NeurIPS 2025, which you all know is a very competitive conference. There is a requirement for a significant amount of experimentation. I request increased storage (10 TB) and access to L40S and H100 for the following students: (a) [USER] (b) [USER] (c) [USER] (d) [USER]. Looking forward to your immediate attention. I request access till April 30, 2025. -- [STAFF] DoIT Research Computing Team. There is no need to reply to this message right now. Your ticket has been assigned an ID of [Research Computing #3144338] or you can go there directly by clicking the link below. Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3144338>. You can login to view your open tickets at any time by visiting http://my.umbc.edu and clicking on 'Help' and 'Request Help'. Alternately you can click on http://my.umbc.edu/help. Thank you -- [STAFF] DoIT Research Computing Team"
"3144451","68205138","2025-03-17 14:04:51","taki - TAKI commands not recognized","Hey [USER], Thank you very much! I just logged in and it looks like everything is working again. Best, [STAFF] On Mon, Mar 17, 2025 at 10:01 AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3144451 > Last Update From Ticket: Hi [USER], This was a symptom of a fix put into place around the module system to resolve the long login times for taki. I've put these modules back into place, so this should be fixed now. Sorry for the inconvenience. [STAFF] On Sat, Mar 15, 2025 at 10:09 AM RT API via RT <[EMAIL]> wrote: Sat Mar 15 10:09:34 2025: Request 3144451 was acted upon. Transaction: Ticket created by [USER] Queue: DoIT-Research-Computing Subject: taki - TAKI commands not recognized Owner: Nobody Status: new Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3144451 > First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] System: taki Request Type: General Support Hello, I logged into TAKI this morning to check on a run I have been working on only to see that my run was cancelled at some point. I attempted to check if the job was in fact still running or not by using the squeue command (squeue -u [USER]) only for the system to spit out 'command not found'. I similarly checked the sbatch command and got a similar message. I've included screen shots of my window showing the system messages and the output from my error file saying that the run had been cancelled at some point. Is this a temporary issue or something that can be fixed?"
"3144471","68230795","2025-03-20 16:25:15","taki Account Request: [USER]","New project added to https://hpcf.[DOMAIN]/research-projects-hpcf/ On Thu Mar 20 12:24:47 2025, [STAFF] wrote: > Hi [USER], >  > We are no longer creating accounts on taki. As such, your account > ([USER]) has been created on chip.rs.[DOMAIN]. > Your primary group is pi_[STAFF]. > Your home directory has 500M of storage. > Please read through the documentation found at hpcf.[DOMAIN]. > All available modules can be viewed using the command 'module avail'. > Please submit additional questions or issues as separate tickets via > the following link. > (https://doit.[DOMAIN]/request-tracker-rt/doit-research-computing/) > On Sat Mar 15 12:00:09 2025, [STAFF] wrote: > > First Name:                [USER] > > Last Name:                 [USER] > > Email:                     [EMAIL] > > Campus ID:                 [ID] > > > > System:                    taki > > > > Request Type:              Account Request > > > > Position Title:            Graduate Student > > > > Affiliation                University of Maryland Baltimore County > > Department:                [DEPARTMENT] > > Phone:                     [PHONE] > > Address:                   [ADDRESS] > > > > Role:                      Member of the research group > > > > Sponsor Information: > >    Name:                       [STAFF] > >    Department:                 [DEPARTMENT] > >    Email:                      [EMAIL] > >    Phone:                      [PHONE] > > > > Research Title:            First-principles informed supervised > > machine learning models for ferroic materials discovery. > > Abstract:                  The search for new ferroic materials to > > advance tomorrow's generation of materials that are capable of > > storing > > energy in a very efficient way is more profound now than ever before. > > Experimental and computational approaches have helped in accelerating > > the discovery of these materials, but they have not come far enough. > > In this work, we plan to incorporate first principle calculations > > with > > supervised machine learning approaches to speed up the discovery of > > these materials. The study will further highlights the power of data- > > driven material exploration in uncovering the wealth of ferroic > > materials that lies within the periodic table. > > People:                    [STAFF]. > > Comments:                  No comment as of now"
"3144658","68210290","2025-03-18 15:21:31","taki - [USER] Unable to log on to taki today using same approach as 5 days ago","Thanks for the quick fix! I was working yesterday and I was able to make progress. Yes, I figured it was something due to the migration. I anticipate using taki just about every day for the next few weeks so I'll let you know if anything else seems amiss. Good luck with the transition. Thanks! [USER] Hi [USER], This is a symptom of a workaround we put into place in the module system to reduce the login time for taki. I've put some of the modules back in place, so you should be able to login as normal now. Sorry for the random login failure. The most dangerous phrase in the language is, 'We've always done it this way.' - Adm Grace Hopper Sun Mar 16 11:40:40 2025: Request [NUMBER] was acted upon. Transaction: Ticket created by [STAFF] Queue: DoIT-Research-Computing Subject: taki - Unable to log on to taki today using same approach as 5 days ago Owner: Nobody - - Nobody in particular Requestors: [EMAIL] Status: new First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] System: taki Request Type: General Support Hello, I tried logging onto taki using the same approach I've been using for years and it gave me a new error, and will not run sbatch commands. Does this have something to do with the upgrade to CHIP? I am giving a seminar at another university in 10 days and need to be able to run my files to get my results for the talk. ERROR MESSAGES: Lmod has detected the following error: The following module(s) are unknown: 'hpc_toolkit' Please check the spelling or version number. Also try 'module spider ..' It is also possible your cache file is out-of-date; it may help to try: $ module --ignore-cache load 'hpc_toolkit' Also make sure that all modulefiles written in TCL start with the string #%Module (storm_venv) [USER]@taki-usr1 [USER]$ sbatch era.slurm -bash: sbatch: command not found"
"3144691","68238655","2025-03-20 20:31:15","taki - Request for [SOFTWARE] Installation on HPC Account","Hi [USER], Have you tried to install this code yourself in your research directory? Nothing about this install should require super user/administrator privileges. On Sun Mar 16 15:43:47 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] System:                    [SERVER] Request Type:              General Support Dear HPC Support Team, I recently created my CHIP account and would like to use it for running CFD simulations as part of my research. For this, I need access to the commercial software SU2 (or SU2code). I would appreciate it if you could install SU2 on my account, preferably version 8.0.0 'Harrier.' All SU2 versions are freely available on GitHub: - Repository: https://github.com/su2code - Releases: https://github.com/su2code/SU2/releases?after=v7.0.2 Please let me know if you need any additional information. Best Regards, [USER]"
"3144907","68237101","2025-03-20 19:32:45","[USER] - Updating Stata license","Yes it's working now. Thanks so much for the quick fix! On Thu, Mar 20, 2025 at 2:57 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3144907 > Last Update From Ticket: Dear [USER], I have gone ahead and updated the Stata license on [SERVER] for the versions installed (15, 17, and 18). Would you be able to test and verify that the license was installed properly on your end? Thanks, have a great day! On Mon Mar 17 11:43:00 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] System: [SERVER] Request Type: General Support Hello, It is the time of year when UMBC's Stata license expires. All users need to enter the new license information posted here https://download.umbc.edu/Stata/ I think am unable to do this on [SERVER] since I don't have admin privileges so could someone please update this for me for Stata on [SERVER]? Thanks! [USER]"
"3146242","68250036","2025-03-21 14:21:27","ada - Symbolic Link for .local broken in home folder","Dear [USER], I have gone ahead and recreated the .local symbolic link in your home folder. It appears that the old link was mapped to '/nfs/rs/[STAFF]....' but, there is no [STAFF] folder under /nfs/rs. Perhaps the folder mounts changed for pi_[STAFF]. Either way, the .local folder currently exists along with .conda and .cache in /nfs/ada/[STAFF]/users/[USER]/ If you experience any further issues, please let us know and we would be happy to assist you. Have a great day! -- Kind regards, [STAFF] On Fri Mar 21 00:18:37 2025, [EMAIL] wrote: > First Name: [USER] > Last Name: [USER] > Email: [EMAIL] > Campus ID: [CAMPUSID] >  > System: ada >  > Request Type: General Support >  > The symbolic link for the .local folder is broken, owing to which I am unable to update python library installations. Could you please fix it as soon as possible?"
"3146383","68250607","2025-03-21 14:38:11","Other Account Request: [USER]","Dear [USER], We apologize for the inconvenience. It seems that our script to port the taki users over to chip had a couple errors and missed a couple accounts. I have gone ahead and manually created your account on chip. You should now be able to log in at chip.rs.[DOMAIN]! If you encounter any further issues or have any questions, feel free to reach out! Have a great day! -- Kind regards, [STAFF] On Fri Mar 21 09:16:04 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] System: Other Request Type: Account Request Hello, I am unable to ssh into the new Chip cluster. When I enter my password, it acts as if it is incorrect. I am using the same password I use to ssh into Taki."
"3146397","68252701","2025-03-21 15:47:37","Problems in logging into chip","Hi [STAFF],  Thanks for the link. I am able to log into the chip now. Thank you!  Best, [USER] On Fri, Mar 21, 2025 at 11:13 AM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hi [USER], Are you able to follow the steps listed on this wiki page? https://umbc.atlassian.net/wiki/spaces/faq/pages/[PAGEID]/How+do+I+opt+in+to+Duo+multi-factor+authentication+for+my+[ORG] account On Fri, Mar 21, 2025 at 10:01 AM The RT System itself via RT <[EMAIL]> wrote: Fri Mar 21 10:01:21 2025 Request [REQUESTID] was acted upon Transaction Queue changed from [QUEUE1] to [QUEUE2] by RT_System Queue [QUEUE2] Subject Problems in logging into chip Owner Nobody Requestors [USER] Status new Ticket First Name [USER] Last Name [USER] Email [EMAIL] Campus ID [CAMPUSID] Request Type Other Hello I was trying to log into chip cluster but I got an error message as follows 'Access is not allowed because you are not enrolled in Duo Please contact your organization s IT help desk' Additionally just in case it s helpful I have no problems in logging into taki and myumbc I think I had never been asked to use Duo to log into those Could you please help me to solve this problem? Thanks! Best [USER]"
"3147920","68542064","2025-04-04 21:32:56","can't write on /scratch of [USER]'s computing nodes","Hi [STAFF], I confirm that c24-29 scratch area is now working. I logged into the node, and I can write in the /scratch/$SLURM_JOBID folder. Thanks, [USER] On Thu, Mar 27, 2025 at 9:15 AM [STAFF] via RT wrote: Ticket Last Update From Ticket: Good morning [USER], You should be able to, but to setup the scratch directories we needed to reboot all of the compute nodes and c24-29 was one of the handful of nodes that was in use and we weren't able to reboot. I was able to reboot c24-29 this morning - are you able to try running your job again to see if it works now? Thank you, [STAFF] On Wed Mar 26 09:53:37 2025, [USER] wrote: Hi [STAFF], Unfortunately, this doesn't work for me. When I log into a node, there is only 1 sub-folder inside /scratch called 'ebuild'. I tried to 'cd' into my personal JOBID folder, hoping the system would create the folder when I tried to access it, but it also didn't work. See below: This is the command I used to start a 'bash' job on a computing node: srun -N1 -n4 --qos=shared --cluster=chip-cpu --time=480 --mem=200G --pty /bin/bash In the example above, the job started on 'c24-29' (that's the output of 'hostname'). Shouldn't I be able to access /scratch/$SLURM_JOBID as you said? [USER] On Mon, Mar 24, 2025 at 5:43 PM [STAFF] via RT wrote: Ticket Last Update From Ticket: Hello [USER], The top-level /scratch directory is only writable by root, as it is accessible to anyone running jobs on that node. In most cases this isn't really an issue, but in the event multiple jobs are running on a node this is to prevent one job from deleting data from another job. As such, every job that gets run has a separate directory created under /scratch named with its SLURM job ID, e.g. '/scratch/2303'. When running a job, there is an environment variable SLURM_JOBID that stores this value, and can be used in Bash like '$SLURM_JOBID' and thus your scratch directory can be accessed like '/scratch/$SLURM_JOBID'. I hope this information helps! Best, [STAFF] On Mon Mar 24 15:57:39 2025, [USER] wrote: Request type: General Support Each computing node of the new HPC system chip has a /scratch folder that we could use for temporary writing (e.g., when running an IO-intensive program). These are fast 2Tb NVME drives. This is not working, at least for me. I do not have permission to write in the /scratch folder (see the attached screenshot). Could you please fix the permissions? [USER]"
"3148004","68390331","2025-03-29 11:26:09","Other Account Request: [USER]","Roy Prouty suggested submitting a new ticket for this issue as it's not an account request On Sat Mar 29 2025 at 01:24 [STAFF] via RT wrote Comment From Ticket do you have any update On Thu Mar 27 2025 at 8:57 PM [USER] wrote Dear Support Team I hope you are doing well Now I am experiencing an issue with my storage on the network system My home directory /home/[USER] has become completely full and I am unable to manage or delete any files due to the lack of available space Could you please assist me with clearing some space or provide guidance on how I can resolve this If it's necessary for me to take specific actions or contact another team for support I would appreciate any direction Thank you for your assistance and I look forward to your guidance on resolving this issue Best regards [USER] On Tue Mar 25 2025 at 6:08 AM [STAFF] via RT wrote Ticket Last Update From Ticket Hi [USER] You'll need to load the conda module before attempting to make use of it You can view available modules on the login node chip rs umbc edu but you'll need to be running within a slurm allocation e g srun --gres=gpu:1 --time=01:00:00 --mem=16G ... to load and use the module Something like module load Anaconda3 should work once within a slurm allocation I'll stall this for a day or so in case you have questions but this seems to be the issue at hand On Mon Mar 24 18:06:41 2025 [USER] wrote First Name [USER] Last Name [USER] Email [EMAIL] Campus ID [CAMPUSID] System Other Request Type Account Request 1 I successfully logged into the system using SSH and initiated an interactive session using srun --gres=gpu:1 --time=01:00:00 --mem=16G pty bash The GPU was visible with the command nvidia-smi and there were no running processes 2 I attempted to activate my Conda environment using conda activate venv but received the error bash conda command not found 3 I ran conda init to initialize Conda but again I encountered the same error bash conda command not found 4 When trying to check the path to Conda with the command which conda the output was /usr/bin/which no conda in(/cm/shared/apps/slurm/current/sbin:/cm/shared/apps/slurm/current/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin) 5 As per the steps I verified the availability of Conda and the error persisted as -bash conda command not found Key observations The error -bash conda command not found persists even after attempting to initialize Conda It appears that the Conda installation is either missing or"
"3148022","68298111","2025-03-25 13:11:25","Other - conda issue on chip","Hi [USER], A couple of things here. As the prompt says in the picture, we don't allow for the modules to be loaded on the login node. This is to prevent people from attempting to develop on login nodes, and causing slowdown for other users. To load the module, you'll need to create an interactive session on the node that you want, and then you can load them normally.  As for your other problem with your bashrc, currently your home directory is full: [root@chip-mgt1 [USER]]# df -h ./ Filesystem                            Size  Used Avail Use% Mounted on nfs.iss:/ifs/data/chip/home/[USER]  500M  500M     0 100% /home/[USER]. DoIT is not in the business of deleting data, so I've gone ahead and made a copy of the default .bashrc and placed it in your user directory under the following path: /umbc/rs/[STAFF]/users/[USER]/bash_files Delete some of the data in your home directory and then go ahead move the .bashrc file to your home directory. As a side note, it is highly recommended that you set your vscode server to be somewhere else on the cluster (like your research volume), as it tends to take up a lot of space.  Let me know if you have other issues. [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID]. System: Other Request Type: General Support Hi, I am unable to load the conda module from the module list of chip (attached screenshot of the error for ref). Also I accidentally deleted the ./baschrc file. thats why I see [bash-5.1$] whenever I enter the GPU node. Requesting help to resolve these issues"
"3148177","68298177","2025-03-25 13:12:10","Other - general questions : mostly chip related","Hi [USER], a) Yep! Duo is now a 'feature' of all logins to our infrastructure. It's now required by a mixture of state and federal security guidance. b) Your home directory is empty (save for the standard hidden files). Any of the groups you have access to will have unix aliases auto-generated for you. Run `alias` to see which are available to you. We removed the symbolic links from the default home directory deployment since the linked path was generating confusion among new users. We did goof and not have the other hpcnfs boxes mounted on chip. I'll get that done now. However, the isilon disk is available, you just need to indicate to the system that it's needed by navigating to that directory. `cd /umbc/rs/strow` c) Only the contributors to the past purchase cycle have access to the 2024 partition. We'll be bringing over the strow-interact machine to chip though and you'll maintain access to that as normal. d) You'll need to tell sbatch/srun/salloc what cluster you intend to run on. To get to the CPU machines, use either '-M chip-cpu' or '--cluster=chip-cpu'. e) We did resolve the login issues with taki. Glad it's working better all around :) f) chip is mentioned under 'compute'. the taki and ada menu items will be leaving April 10 :) Sorry for the quick/terse replies. Happy to chat more if you have questions! I'll follow-up separately about lustre. On Tue Mar 25 06:27:51 2025, [USER] wrote: First Name:                [USER] Last Name:                 [STAFF] Email:                     [EMAIL] Campus ID:                 [ID] System:                    Other Request Type:              General Support Hi [STAFF], I listened in to your/[STAFF] presentation yesterday, cool! So I immediately tried to log into chip.rs.umbc.edu, and now have a longish general email :   a) trying to log in, I am immediately asked for a duo push authentication to my iphone. Is that going to be a recurrent feature?  b) even now, when I log in my homespace is blank. 'ls' produces nothing. None of [STAFF]'s disks are mounted. 'df | grep strow' comes up blank also. I assume you are still migrating disks?  c) I think I heard you say now there will be cpu2024, cpu2021, cpu2018 (my understanding being 2021 are the fast ones we are used to, i assume 2018 is the current high-mem). Will we have access to any of the new cpu2024 nodes eg is strowinteract1 one of those nodes?  d) further going on the sbatch options (--time, --qos), did you say now there will be a new option we need to exercise namely '--cpucluster chip' so that our jobs go to the compute nodes? Or will that be easily covered under --partition=cpu2024 etc  e) everything else should be mostly transparent and/or as before. BTW logging into taki now is very fast, I assume because now it is under your new management system? I assume that will go away in a few week (will have to get into chip), but we'll still be able to get into strowinteract  f) you'll probably have to update your umbc hpcf page .. no mention of chip there that I can find with a quick browse! And finally I'll be sending a general account request on our machines for a student who will be here for 3 months, starting Monday. Cheers [USER]"
"3148178","68459334","2025-04-01 20:54:55","Account Request: [USER]","Hi [STAFF], Could you submit a new ticket on this asl issue? On Tue Apr 01 16:32:45 2025, [USER] wrote: Thanks, I sent this on to [STAFF] BTW when I log onto taki (now defunct) or strowinterach (still alive), most of my home is symbolic links to /asl/s1/[USER] eg [USER@strow-interact ~]$ pwd /home/[USER] [USER@strow-interact ~]$ ls -lt lrwxrwxrwx 1 [USER] pi_strow   40 Mar  6 20:10 IR_NIR_VIS_UV_RTcodes -> /asl/s1/[USER]/git/IR_NIR_VIS_UV_RTcodes drwxrwxr-x 2 [USER] pi_strow  119 Feb 22 00:02 bin lrwxrwxrwx 1 [USER] pi_strow   34 Feb 18 14:38 PYTHONCODE_Git -> /asl/s1/[USER]/home/PYTHONCODE_Git drwxrwxr-x 2 [USER] pi_strow    0 Feb  7 17:57 JUNK lrwxrwxrwx 1 [USER] pi_strow   18 Apr 25  2024 git -> /asl/s1/[USER]/git lrwxrwxrwx 1 [USER] pi_strow   29 May 19  2023 JULIA_Git -> /asl/s1/[USER]/home/JULIA_Git lrwxrwxrwx 1 [USER] pi_strow   52 Apr 16  2023 SARTA_CLOUDY_RTP_KLAYERS_NLEVELS -> /asl/s1/[USER]/home/SARTA_CLOUDY_RTP_KLAYERS_NLEVELS But when I log onto chip, I still cannot see /asl/s1? I guess it still is not mounted? -[USER] On Tue, Apr 1, 2025 at 3:08PM [STAFF] via RT wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3148178&ticketowner=[STAFF]&ticketsubject=taki Account Request: [USER] <[EMAIL]> If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3148178 Thank You _________________________________________ Resolution: Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_strow. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) On Tue Apr 01 11:43:25 2025, [USER] wrote: Hi [STAFF], Lorenzo now has his official umbc email (cc'd on this email), and ID number. Is this enough for you to give him an HPC account, and let him have access to our directories? Thanks -[USER] On Tue, Mar 25, 2025 at 10:58AM [STAFF] via RT wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3148178 Last Update From Ticket: We'll need his UMBC username or UMBC ID to get his account created. So I'll stall this until we can get that. On Tue Mar 25 09:44:11 2025, [USER] wrote: Hello [STAFF], This e-mail is a notification that taki Account Request: [USER] <[EMAIL]> has requested an account for the UMBC HPCF in your user group. As the PI we request that you acknowledge and approve this account creation by replying to this message. Alternatively, you can go to this link and review the ticket and indicate your decision here - Ticket https://rt.umbc.edu/Ticket/Display.html?id=3148178 Once we have your approval and the account request is reviewed we will create the account and you and the new user will receive another e-mail notifying you that the account has been created. If you have any other questions or concerns please contact us. See link:http://hpcf.umbc.edu/contact/ or point of contact Matthias K. Gobbert <[EMAIL]>. Thanks, HPCF support staff -- [STAFF] DoIT Research Computing Team"
"3148457","68327981","2025-03-26 14:34:25","Other - Loading Modules on Chip","Hi [USER], It is possible to create the environments using a batch script submitted through slurm. I understand that can be a little inconvenient if you want to test things, so you can also use an interactive job. That can be done using the following command on chip-cpu: $ srun --cluster=chip-cpu --account=pi_[STAFF] --partition=general --qos=normal --time=1:00:00 --mem=5000 --pty $SHELL or the following command on chip-gpu $ srun --cluster=chip-gpu --account=pi_[STAFF] --mem=5000 --time=1:00:00 --gres=gpu:1 --pty $SHELL Let me know if you have any trouble with this.  On Tue Mar 25 11:50:42 2025, [EMAIL] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [ID] >  > System:                    Other >  > Request Type:              General Support >  > Hello, >  > I have a question regarding loading modules on chip. When I was using Taki previously, I had to create a virtual environment to install the necessary libraries for my Python code. Since it seems we can't load modules onto the login node now, could you let me know how we should go about installing the required libraries? >  > Thanks again!"
"3149193","68343108","2025-03-26 20:08:13","Other - Research storage","Thanks a lot for the quick response Best [USER] On Wed Mar 26 2025 at 11 04 AM [STAFF] via RT wrote If you agree your issue is resolved please give us feedback on your experience by completing a brief satisfaction survey https //umbc.us2.qualtrics.com/SE /SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3149193&ticketowner=[EMAIL]&ticketsubject=Other - Reasearch storage If you believe your issue has not been resolved please respond to this message which will reopen your ticket Note A full record of your request can be found at Ticket https //rt.umbc.edu/Ticket/Display.html id=3149193 Hi [USER] We made the decision when we moved to Chip that we would no longer use symbolic links to people's research directories since it was causing confusion among users Instead you cd directly there under /umbc/rs/oates/... and we've also applied an alias or shortcut using the same name as what was on taki/ada ie oates_user oates_common etc See below [USER]@chip ~$ alias alias egrep='egrep --color=auto' alias ferraro_ada='cd /umbc/ada/ferraro' alias ferraro_common='cd /umbc/rs/ferraro/common' alias ferraro_user='cd /umbc/rs/ferraro/users/[USER]' alias fgrep='fgrep --color=auto' alias grep='grep --color=auto' alias l.='ls -d .* --color=auto' alias ll='ls -l --color=auto' alias ls='ls --color=auto' alias oates_ada='cd /umbc/ada/oates' alias oates_common='cd /umbc/rs/oates/common' alias oates_user='cd /umbc/rs/oates/users/[USER]' alias sinfo='sinfo -M chip-cpu chip-gpu -p 2024 2021 2018 general gpu' alias squeue='squeue -M chip-cpu chip-gpu' alias xzegrep='xzegrep --color=auto' alias xzfgrep='xzfgrep --color=auto' alias xzgrep='xzgrep --color=auto' alias zegrep='zegrep --color=auto' alias zfgrep='zfgrep --color=auto' alias zgrep='zgrep --color=auto' [USER]@chip ~$ oates_user [USER]@chip [USER]$ pwd /umbc/rs/oates/users/[USER] Please let us know if you have any further questions about this"
"3149226","68454135","2025-04-01 19:03:32","GESDISC ftp push to /umbc/xfs2/[ID]/asl/ftp/incoming/L1c","ftp.rs.umbc.edu If there's no more issues I'll go ahead an close this. On Tue Apr 01 13:56:36 2025 [STAFF] wrote: Thank you [USER] looks like we're back to normal with the transfers - which machine was it that needed rebooting? cheers [USER] On Mon Mar 31 10:04 Max Breitmeyer via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3149226> Last Update From Ticket: Hi [USER], We've rebooted the machine it seemed to have gone into a bad state when we were doing an upgrade and now looks nicer on our end. Could you give this another try? On Mon Mar 31 10:50:10 2025 [STAFF] wrote: Hi [STAFF] not quite - there is a service set up at NASA GESDISC that automatically pushes (I presume by FTP - see log previously attached) files every few hours to the UMBC ftp server that is attached (in whatever method the attachment is implemented) and we receive them at a mounted volume linked by this path: /asl/ftp/incoming/L1c/ (abs path /umbc/xfs2/strow/asl/ftp/incoming/L1c) so I can't say which UMBC server is handling the comms let alone where the firewall is implemented. plz advise and keep working it thnx [USER] On Mon Mar 31 09:11 [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3149226> Last Update From Ticket: Hi [USER], To confirm you're ftp'ing some files from some local machine to which server? strow-interact? Or some other server? On Thu Mar 27 08:29:55 2025 [STAFF] wrote: [STAFF] - plz see attached from the sender (In the past the problem has often been related to new firewall/changes to firewall at our end) . 2025-03-25 18:47:19 127051 s4paops INFO s4pa_file_pusher.pl: Local directory is /vol1/AirsL1/OPS/s4pa/airsl1v6_7/postoffice/RUNNING.130_85_28_205.PUMBC_L1CT20250325184713 2025-03-25 18:47:19 127051 s4paops INFO s4pa_file_pusher.pl: Using local address gs6102dsc-airsl1.gesdisc.eosdis.nasa.gov blocksize 10240 ftplog 2025-03-25 18:47:19 127051 s4paops ERROR s4pa_file_pusher.pl: Failed to login to 130.85.28.205: OOPS: cannot change directory:/umbc/xfs2/strow/asl/ftp 2025-03-25 18:47:19 127051 s4paops INFO s4pa_file_pusher.pl: Directory /incoming/L1c doesn't exist 2025-03-25 18:47:19 127051 s4paops ERROR s4pa_file_pusher.pl: Failed to create directory /incoming/L1c: [Net::FTP] Connection closed 2025-03-25 18:47:19 127051 s4paops ERROR s4pa_file_pusher.pl: Failed to push /ftp/data/s4pa/.5kNTX5B9SOGXxsFi/Aqua_AIRS_Level1/AIRICRAD.6.7//2025/081/AIRS.2025.03.22.111.L1C.AIRS_Rad.v6.7.5.0.G25084144515.hdf to 130.85.28.205:/incoming/L1c by ftp 2025-03-25 18:47:19 127051 s4paops INFO s4pa_file_pusher.pl: Using local address gs6102dsc-airsl1.gesdisc.eosdis.nasa.gov blocksize 10240 ftplog 2025-03-25 18:47:19 127051 s4paops ERROR s4pa_file_pusher.pl: Failed to login to 130.85.28.205: OOPS: cannot change directory:/umbc/xfs2/strow/asl/ftp 2025-03-25 18:47:19 127051 s4paops INFO s4pa_file_pusher.pl: Directory /incoming/L1c doesn't exist 2025-03-25 18:47:19 127051 s4paops ERROR s4pa_file_pusher.pl: Failed to create directory /incoming/L1c: [Net::FTP] Connection closed 2025-03-25 18:47:19 127051 s4paops ERROR s4pa_file_pusher.pl: Failed to push /var/tmp/AIRS.2025.03.22.111.L1C.AIRS_Rad.v6.7.5.0.G25084144515.hdf.met to 130.85.28.205:/incoming/L1c by ftp On Thu Mar 27 06:09 [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3149226> Last Update From Ticket: Hi [USER] I'm seeing that the ownership of the 'ftp' directory at the level (/umbc/xfs2/strow/asl/ftp) seems to be owned by root as opposed to pi_strow which makes me think that's probably the issue but as I'm unsure of how this was initially set up do you think you could provide me with a little more information with regards to the actual error message you receive when you attempt to push ie what is the actual error message? On Wed Mar 26 11:02:05 2025 [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USER] Request Type: Other Please could you advise if there is a change our end causing NASA GESDISC to be unable to push to our server since yesterday to: /asl/ftp/incoming/L1c/ (abs path /umbc/xfs2/strow/asl/ftp/incoming/L1c) If we need to open up the rules again please do so and let me know thank you [USER]"
"3149322","68344582","2025-03-26 20:59:03","ada - [USER] cannot access the kekechen_common directory","Dear [USER], It appears the permissions for the [USER]_common were changed to remove read access for the owner, which is you. The permissions were set to 'd-wxrws---', when they should have been 'drwxrws---'. I have gone ahead and changed the permissions to allow the owner to read the directory. Please let me know if you still have trouble accessing the directory. Have a great day! -- Kind regards, [STAFF] On Wed Mar 26 11:54:57 2025, [USER] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [CAMPUS_ID] > > System:                    ada > > Request Type:              General Support > > Hello, I noticed today somehow I cannot access the [USER]_common directory mounted to my home directory. However, my students were able to. Can you please check? Thank you! [USER]"
"3149459","68340682","2025-03-26 19:18:16","Other Account Request: [USER]","Dear [USER], It appears your user account [USER] already exists on chip. Have you attempted to log in yet? You should be able to login with 'ssh [USER]@chip.rs.[DOMAIN]' with your my[DOMAIN] password. Please let me know if you have access. If you experience further issues logging in, we would be happy to assist you! -- Kind regards, [STAFF]"
"3149486","68347826","2025-03-27 11:15:14","ada - Not being able to get a job on ada!","Hi [USER], It looks like it went through. Are you still seeing it in the queue on your end? As a reminder, we are slowly ingesting the machines on ada into chip, so as the weeks go on there will be less devices available, and you'll likely have to wait in a the queue longer. I would highly recommend moving your work to chip at your earliest convenience. On Wed Mar 26 13:38:20 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] System: ada Request Type: General Support Hello, I have been attempting to run a job using srun since yesterday, but it remains in the queue. Could you please update me on the status? Thanks"
"3149671","68342709","2025-03-26 19:57:26","Other - CHIP scancel not working","Hi [STAFF], You'll need to specify the cluster in the scancel command. You can do this by providing the -M or --cluster flag and specifying the chip-cpu/chip-gpu cluster that the job is running on. -- [STAFF] DoIT Research Computing Team"
"3149801","68401292","2025-03-31 13:51:50","Other - Discrepancy Between 'module avail' and Software Directories","Hi [USER], Apologies for the late reply, I was out on Friday. I'll try to address your issues in order: After I add the module 'iimpi/2023a' using 'module add iimpi/2023a', I can see that several packages are loaded. However, neither the c compiler 'icc' or the fortran compiler 'ifort' are working. I also tried the command 'icx', but it does not work either. What is the problem here? As I mentioned earlier, we don't allow for loading modules on the head-node. The fact that you were even able to use the 'module add' command was an oversight on our part, and has now been disabled. When using the head node, the module spider command can find many more packages than what the same command can give if I use a computation node. This is a problem, but not really a bug. In general, we want users to be able to view all modules available on the system. As a result, running any of the module commands, 'spider', 'avail', 'keyword', etc. will return ALL modules. For a more accurate listing of all the modules available on the computation node that you intend on using, you should run the module commands on the node you plan on developing/running on. Alternatively on the head-node you can do something like the following: [STAFF@chip ~]$ module spider iimpi #displays all version of iimpi available on chip  ---------------------------------------------------------------------------  iimpi: ---------------------------------------------------------------------------   Description:       Intel C/C++ and Fortran compilers, alongside Intel MPI.       Versions:         iimpi/2021a         iimpi/2023a         iimpi/2023b         iimpi/2024a  ---------------------------------------------------------------------------   For detailed information about a specific 'iimpi' package (including how to load the modules) use the module's full name.   Note that names that have a trailing (E) are extensions provided by other modules.   For example:       $ module spider iimpi/2024a ---------------------------------------------------------------------------  #now run module show on the module that you would like more information about [STAFF@chip ~]$ module show iimpi/2024a ---------------------------------------------------------------------------    /usr/ebuild/software/emerald/modules/all/iimpi/2024a.lua: --------------------------------------------------------------------------- help([[ Description = Intel C/C++ and Fortran compilers, alongside Intel MPI.   More information  - Homepage: https://software.intel.com/parallel-studio-xe ]]) whatis('Description: Intel C/C++ and Fortran compilers, alongside Intel MPI.') whatis('Homepage: https://software.intel.com/parallel-studio-xe') whatis('URL: https://software.intel.com/parallel-studio-xe') conflict('iimpi') load('intel-compilers/2023.1.0') load('impi/2021.9.0-intel-compilers-2023.1.0') setenv('EBROOTIIMPI','/usr/ebuild/installs/software/iimpi/2023a') setenv('EBVERSIONIIMPI','2023a') setenv('EBDEVELIIMPI','/usr/ebuild/installs/software/iimpi/2023a/easybuild/iimpi- 2023a-easybuild-devel') Please carefully check and make sure that those modules in the 'module avail' list actually exist and work."
"3149803","68505310","2025-04-03 15:11:25","Other - install packages in CHIP","Hello GSL/2.7-intel-compilers-2021.2.0 and GSL/2.7-intel-compilers-2022.1.0 are available as modules. The latest version I found of GSL compiled with intel was with the 2022 version and [STAFF] has GSL-2.7-intel-compilers-2021. On Wed Mar 26 18:36:41 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] System: Other Request Type: General Support Some of the modules available in taki are missing in CHIP. Please install them. 1. GNU Scientific Library (GSL) compiled using both GCC and intel (iimpi-2023a) 2. netcdf4 fortran library compiled using both GCC and intel (iimpi-2023a)"
"3150518","68371809","2025-03-28 12:52:31","Other - Scancel does not work on CHIP","You'll add either the '-M chip-cpu' or '--cluster=chip-cpu' flags if you're using the chip-cpu cluster. I'm hoping this works, so I'll mark this as resolved. Feel free to reopen if it doesn't work. On Thu Mar 27 18:09:26 2025, [EMAIL] wrote: Hi [STAFF], Thank you for your response. I did not specify the cluster, could you guide me on how to use scancel with the cluster specified? Thanks Best, [USER] On Thu, Mar 27, 2025 at 5:32 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3150518> Last Update From Ticket: Are you specifying the cluster in the scancel command? Roy Prouty (he/him/his) Sent from mobile device On Thu, Mar 27, 2025 at 16:57 RT API via RT <[EMAIL]> wrote: > Thu Mar 27 16:57:32 2025: Request 3150518 was acted upon. Transaction: Ticket created by [USER] Queue: DoIT-Research-Computing Subject: Other - Scancel does not work on CHIP Owner: Nobody Status: new Requestors: [EMAIL] Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3150518> First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USER] System: Other Request Type: General Support Hello, I am migrating from taki to chip by submitting rsync slurm job. I submit the same job twice by mistake, but I am unable to scancel either one of them, as scancel jobID does not seem to work on CHIP. Could you please help me to solve this issue? Thanks Best, [USER] -- Roy Prouty DoIT Research Computing Team"
"3150813","68377687","2025-03-28 15:36:22","ada Account Request: [USER]","Hi [USER], Chip is a good fit for your use case. Your account ([USER]) has been added to the pi_ndwalker group on chip.rs.umbc.edu. Please read through the documentation found at https://hpcf.umbc.edu/compute/overview/. All available modules can be viewed using the command 'module avail'. On Fri Mar 28 11:14:14 2025, [USER] wrote: Hi [STAFF], If that's the case, then it would be for chip. Currently, I am using my personal laptop for our labs pipeline and we would like to transfer some of the imaging data we have to the cluster as well as the script- and would like to be able to use some python packages with GPU support. Would chip be the best use case for this then if ada is migrating? Thanks, [USER]. On Fri, Mar 28, 2025 at 10:36 AM [STAFF] via RT wrote: Ticket . Last Update From Ticket: Hi [USER], Is this for ada or for chip? ada is actively being migrated into chip. [STAFF]. On Fri, Mar 28, 2025 at 10:29 AM RT API via RT wrote: Fri Mar 28 10:29:06 2025: Request was acted upon. Transaction: Ticket created by . Queue: DoIT-Research-Computing. Subject: ada Account Request: [USER] ([USER]). Owner: Nobody - - Nobody in particular. Requestors: [EMAIL]. Status: new. Ticket . First Name: [USER]. Last Name: [USER]. Email: [EMAIL]. Campus ID: [USER]. On Behalf Of: [USER] ([EMAIL], [USER]). System: ada. Request Type: Account Request. Username: [USER]. Requested Action: become a user in an existing ada PI Group. Primary HPCF PI Group Owner: . Supplemental HPCF PI Group Owners:. Project Keywords: - Artificial Intelligence - Biology - Computer Vision - Machine Learning - Math. Additional Notes and Comments: Hello, I would like to gain access to our shared lab drive. Thank you, [USER]."
"3151549","68403983","2025-03-31 14:41:17","Other - Hung up on resource allocation request","Hi [USER], The problem was just that there were no available machines. You'll know when the job runs because it will say that the job has executed (but not if you cancel it using cntrl + c). I'm not sure what you mean by 'do I need to submit the batch job following that?' For future reference, you can always view the availability of machines by running 'sinfo'. On Sun Mar 30 08:37:27 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [LAST NAME] Email:                     [EMAIL] Campus ID:                 [CAMPUS ID] System:                    Other Request Type:              General Support Dear support, The below command is not responding at all. This is my working location: /umbc/rs/iharp/users/[USER]/[USER] How will I know the resource allocation is executed, and do I need to submit the batch job following that? I would really appreciate your help and support. [EMAIL@chip [USER]]$ srun --cluster=chip-gpu --account=[ACCOUNT] --gres=gpu:1 --mem=1000 --time=10:00:00 --pty $SHELL srun: job 1498 queued and waiting for resources ^Csrun: Force Terminated JobId=1498 srun: Job allocation 1498 has been revoked [EMAIL@chip [USER]]$ srun --cluster=chip-gpu  --gres=gpu:1 --mem=1000 --time=10:00:00 --pty $SHELL srun: job 1499 queued and waiting for resources"
"3151672","68398816","2025-03-31 13:09:48","GPUs are being drained, submitted jobs are awaiting resources in CHIP","Hi [USER], This has been resolved, sorry for the inconvenience. On Sun Mar 30 21:58:14 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request type: General Support Hi, the non-reserved gpus in chip are being drained currently (see attached for reference) and the submitted jobs -- therefore are awaiting resources. Can you please resolve this issue? Thanks [USER] ([EMAIL]) Attachment 1: Screenshot 2025-03-30 at 9.54.01 PM.png"
"3152137","68449719","2025-04-01 17:58:59","taki - ftp site not working","Great, seems to be working today (on two different computers/networks!) [USER] On Tue, Apr 1, 2025 at 11:13 AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3152137 > Last Update From Ticket: Good morning [USER], It appears that the server hosting asl.umbc.edu was being patched yesterday when you were trying to access it. After patching finished, I was able to connect to asl.umbc.edu and download the file that you gave as an example - could you try accessing it again to verify it works for you now? Thank you, [STAFF] On Mon Mar 31 13:32:50 2025, [USER] wrote: System: taki Request Type: General Support Hi, I asked a colleague to pick up a file from https://asl.umbc.edu/pub/[USER]/RDelgado/2025/profiles_for_stm_april_2025.mat but he told me he can't access it, and neither could I when I tried it. I tried using http instead of https but that did not work either. Could you give me a few suggestions? I know we had this problem couple months earlier, it seemed to get resolved but now we're stuck again Thanks [USER]"
"3152152","68478551","2025-04-02 16:20:29","Other - Need help regarding chip GPU storage","According to this ticket https://rt.umbc.edu/Ticket/Display.html?id=3133 you are a grad student working under [STAFF] that is who your PI is Their UMBC ID is [STAFF] which is the name of the research directory under /umbc/rs/[STAFF] Kind regards [STAFF] On Mon Mar 31 23:49:20 2025 [USER] wrote Dear [SUPPORT TEAM] I hope you are doing well I am currently working on setting up my environment on the CHIP system and need to store Conda packages in the research directory However I am unsure of the exact name of my PI that should be used for accessing the directory Could you please clarify what my PI's name is or guide me on how to find it so I can proceed with accessing the appropriate research directory e g /umbc/rs/[STAFF]/users/[USER] Thank you for your help Best regards [USER] On Mon Mar 31 2025 at 2:09 PM [STAFF] via RT wrote If you agree your issue is resolved please give us feedback on your experience by completing a brief satisfaction survey https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3152152&ticketowner=[STAFF]&ticketsubject=Other - Need help regarding chip GPU storage If you believe your issue has not been resolved please respond to this message which will reopen your ticket Note A full record of your request can be found at Ticket https://rt.umbc.edu/Ticket/Display.html?id=3152152 Thank You Hi [USER] I'm looking at your home directory and it looks like you may have resolved this already Filesystem Size Used Avail Use Mounted on nfs.iss:/ifs/data/chip/home/[USER] 500M 223M 278M 45% /home/[USER] As you may have learned your home directory is limited to 500M of space Do NOT store large datasets in your home directory put them into your research directory which can be found at /umbc/rs/[STAFF]/common or /umbc/rs/[STAFF]/users/[USER]"
"3152217","68416586","2025-03-31 18:43:24","CHIP connection issues persist","Hi [USER], I need some more clarifying information. Is the vscode GUI disconnecting? Or the terminal? When you say that it was fine until yesterday, what does that mean exactly? Just that you've never experienced these issues before yesterday? Have you been running longer sessions than normal? We haven't made any changes where I would expect something like this.  On Mon Mar 31 14:25:33 2025, [STAFF] wrote: > Request type: General Support > Hi, CHIP login connection (via VS-Code) keeps getting interrupted and logs me out in like every few hours. This happens even when my laptop is awake (i.e. not an issue of server getting disconnected when my machine goes to sleep mode). I have been experiencing this issue since this morning, things were fine until yesterday. Can you please help us resolve this issue? Thanks [USER]"
"3152449","68428459","2025-04-01 13:15:19","Request for access into ada cluster","Navigate to [SERVER] > Request Help. Then select 'HPC' and 'User Account Creation/Modification'.  The most dangerous phrase in the language is, 'We've always done it this way.'  - Grace Hopper    On Tue, Apr 1, 2025 at 9:03 AM The RT System itself via RT < [EMAIL]> wrote:  > Request 3152449 was acted upon. Transaction: Queue changed from DoIT-TSC-Support to DoIT-Research-Computing by RT_System        Queue: DoIT-Research-Computing      Subject: Request for access into [SERVER] cluster        Owner: Nobody - Nobody in particular   Requestors: [USER]       Status: new  Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=[ID] > First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] Request Type:                 2. How do I create my account? Hello, I am conducting research under Dr. [STAFF], and my work requires GPU-based computation. I would like to request access to the [SERVER] cluster and need guidance on how to create an account to obtain the necessary permissions. Thank you in advance for your assistance, and I look forward to hearing from you soon."
"3152716","68428471","2025-04-01 13:15:42","High Performance Computing - Account request for [USER]","First Name: [USER] Last Name: [STAFF] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Computing Create/Modify account in existing PI group Existing PI Email: [EMAIL] Project Title: totally cool thing Project Abstract: ** descriptions ** YEP"
"3153348","68446529","2025-04-01 17:11:35","High Performance Computing - Installing HDF library","Hi [STAFF],  Thank you for the help. The HDF with different GCC versions should work, as long as it is consistent with other modules that have the same GCC versions, like I am using CMake/3.27.6-GCCcore-13.2.0 and OpenMPI/4.1.6-GCC-13.2.0. So the HDF with GCC-13.2.0 should work for me.  Thank you so much.  -[USER]   Ticket Last Update From Ticket:  Hello [USER],  Do you need HDF/4.2.14-GCCcore-7.3.0 specifically, or will another version work for you? I was able to successfully build HDF/4.2.15 and HDF/4.2.16 with a couple different GCC versions each, but the toolchains used in HDF/4.2.14 are too old and won't build on current versions of Red Hat Enterprise Linux 9. Thank you,  [STAFF]  On Tue Apr 01 11:22:13 2025, [STAFF] wrote:  Good morning [USER],  Yes, HDF/4.2.14-GCCcore-7.3.0 can be installed! I'll work on installing that and a few other versions of HDF with different compiler chains, and will send you an email when this is done. Best,  [STAFF]  On Tue Apr 01 10:53:21 2025, [USER] wrote:  First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] Request Type:              High Performance Computing Dear support team,  I am writing to request installation of HDF modules to Chip. Taki has the HDF modules like HDF/4.2.14-GCCcore-7.3.0, while Chip does not. I need the HDF module for running my Fortran codes. Please let me know if it is possible to install one. Thanks! -[USER]"
"3153629","68445916","2025-04-01 17:02:25","High Performance Computing - Urgent Assistance Needed with Ada & Chips","Thanks it worked Kindest regards [USER] On Tue Apr 1 2025 at 12 50 PM [STAFF] via RT <[EMAIL]> wrote Ticket Last Update From Ticket Hello [USER] Ah I see the problem now We were making some changes to the modulepath on Chip last week and forgot to link modules to the 2020 GPU nodes It is now fixed - can you try again to verify you can see Anaconda now You might need to logout and back in for the changes to take effect Thank you [STAFF] On Tue Apr 01 12 25 21 2025 [USER] wrote Hello [STAFF] On my end on the GPU nodes on chip g20-07 I do not see any anaconda to load Can you please check it out On Tue Apr 1 2025 at 12 08 PM [STAFF] via RT <[EMAIL]> wrote Ticket Last Update From Ticket Hello [USER] When running module avail on one of the GPU nodes on Chip specifically g24-03 I see Anaconda3 version 2024 02-1 and Anaconda2 2019 10 available to load Is there a specific version of Conda that youre looking for or are you having trouble loading the module Thank you [STAFF] On Tue Apr 01 11 48 51 2025 [USER] wrote Request Type High Performance Computing I hope this email finds you well We are close to a critical deadline and we are facing urgent issues with our computing resources We are unable to run our codes on the ada node and we also face an issue where Conda is not installed on the chips which prevents us from building our virtual environments Your prompt assistance in resolving these issues would be greatly appreciated Best regards [USER]"
"3153793","68571344","2025-04-07 17:37:46","High Performance Computing - Request to add imkl to chip","Hi [USER],  It works now! Thank you!  [STAFF] On Thu, Apr 3, 2025 at 12:02 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3153793> Last Update From Ticket: Hello [USER], I've installed a few different versions of the imkl module on Chip. Could you load one and verify that it's working properly for you? Thank you, [STAFF] On Tue Apr 01 12:35:48 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Computing A fortran software I use for my research (located here: /umbc/rs/[USER]/users/[USER]/II-T-Matrix/iitm_arbitrary_shape) does not run properly without the imkl module present on taki prior to the migration. It uses version 2021.4.0, though I don't think it needs a specific version of the module. Attachment 1: cube_test(1).err (https://umbc.box.com/s/[HASH])"
"3154172","68454269","2025-04-01 19:05:34","High Performance Computing - Account Request","Shouldn't [STAFF] be the existing PI email since it's for his group, even though [USER] is requesting? On Tue Apr 01 15:04:35 2025, [EMAIL] wrote: > On Tue Apr 01 14:23:53 2025, [EMAIL] wrote: > > First Name:                [USER] > > Last Name:                 [USER] > > Email:                     [EMAIL] > > Campus ID:                 [ID] > > Request Type:              High Performance Computing > Create/Modify account in existing PI group > Existing PI Email:    [EMAIL] > Project Title:        N/A > Project Abstract:     N/A > Please add [USER] to pi_[STAFF] on chip."
"3154250","68483533","2025-04-02 17:59:21","High Performance Computing - GitHub not installed on Chip environment","Hi [STAFF], Git has been added to the system. Sorry for the inconvenience! On Tue Apr 01 14:51:55 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Computing Github is not installed on the chip environment, though it is available on ada. Having it on chip would be helpful, especially in moving existing software systems. Can it be installed on the chip environment?"
"3154270","68479284","2025-04-02 16:34:07","High Performance Computing - Request for access into ada cluster","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) On Tue Apr 01 15:31:36 2025, [STAFF] wrote: Hello , I approve [USER]'s request/ Regards [STAFF] On Tue, Apr 1, 2025 at 3:18 PM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hi [USER], As nodes get integrated from ada into our new system, Chip, we are no longer creating accounts for Ada. We can make an account for you on Chip, with [STAFF]'s approval. I've CC'ed him now. Once he says he approves, we'll be able to get you on right away. On Tue Apr 01 14:56:49 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Computing Create/Modify account in Student group Hello, I am conducting research under [STAFF], and my work requires GPU-based computation. I would like to request access to the Ada cluster. Best, [STAFF] DOIT Unix Infra Student Worker"
"3154306","68479484","2025-04-02 16:39:14","Create a Taki account","Hi [USER], Here is the link to the account request form. Please fill it out, and CC the PI that you're working with. https://rtforms.[DOMAIN]/rt_authenticated/doit/DoIT-support.php?auto=Research%20Computing On Tue Apr 01 15:06:47 2025, [STAFF] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [CAMPUSID] > > Request Type:                 2. How do I create my account? > > Dear Sir > > I need to create a Taki account for my RA project. Thank you!"
"3154570","68511721","2025-04-03 18:07:11","High Performance Computing - symbolic links to /asl/s1 (and others!!!)","Hi [STAFF], Great thanks. I'll wait for [USER] to reply about lustre, and if he has any other comments/questions, I'll be sure to contact you. Sincerely [USER] On Thu, Apr 3, 2025 at 1:53 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=[NUMBER] > Last Update From Ticket: Hello [USER], I've mounted the /umbc/xfs2/strow and /umbc/xfs3/strow volumes, and the /umbc/isilon/rs/strow volume is already available under /umbc/rs/strow. Though for the lustre volume, do you still need access to that? It is my understanding that it is going to be decommissioned on June 1st, and we'd rather not mount that unless it is still needed. In regards to the link request: we used to create symbolic links for users that point to their respective research volumes, but that created confusion for a lot of users where they didn't know where things were located and what storage was available. You can create these links yourself though, with the command 'ln', for example 'ln -s /umbc/xfs2/strow /home/[USER]/strow'. In regards to [USER]'s access: they should already have access to /umbc/xfs2/strow/asl/s1/, seeing as it is owned by the group pi_strow, and running 'getent group pi_strow' shows that [USER]'s user account is in that group. Based on the output you sent, it seems like you might have been looking at the directories inside /umbc/xfs2/strow/asl/s1, and if so you can create one by running the command 'mkdir /umbc/xfs2/strow/asl/s1/[USER]'. Thank you, [STAFF] On Wed Apr 02 11:35:09 2025, [USER] wrote: [STAFF], Oops yet another request (from [USER]) : he is asking if all of our old files/disks can be mounted From strowinteract.rs.[DOMAIN]: [sergio@strow-interact PBL_Apr2025]$ df | grep strow 10.2.47.2:/mnt/xfs2/strow 371512584192 322693549792 48819034400 87% /umbc/xfs2/strow 10.2.47.3:/mnt/xfs3/strow 374517966848 296977786560 77540180288 80% /umbc/xfs3/strow nfs.[DOMAIN]/ifs/data/rs/strow 563714457600 468457479552 95256978048 84% /umbc/isilon/rs/strow 10.2.44.1@o2ib:/strow 167705793664 149835431040 17870358528 90% /umbc/lustre/strow Thanks [USER] On Wed, Apr 2, 2025 at 11:32 AM [USER] <[EMAIL]> wrote: Also could you add [USER] ([DOMAIN] email : [EMAIL]) to /umbc/xfs2/strow/asl/s1/ which currently has many users eg chepplew emaddy imbiriba jshaw5 motteler rkramer robinso2 sbuczko1 sergio strow tangborn tilak yurganov Thanks [USER] On Wed, Apr 2, 2025 at 11:28 AM [USER] <[EMAIL]> wrote: If I looked for 'strow' disks, I can see ls /umbc/xfs2/strow/asl/s1/ Is there a better way to do this? Perhaps I should make a symbolic link from /home/[USER] to /umbc/xfs2/strow/asl/s1/"
"3155414","68478328","2025-04-02 16:13:50","High Performance Computing - 2 factor authorization","Dear [USER] and [USER], You should be able to enable Duo 2FA by following the steps outlined here: https://umbc.atlassian.net/wiki/spaces/faq/pages/30743276/How+do+I+opt+in+to+Duo+multi-factor+authentication+for+my+UMBC+account. After that, you should have your account successfully enrolled in Duo 2 Factor Authentication. If you have issues with these steps please feel free to let us know. Kind regards, [STAFF] On Wed Apr 02 11:55:33 2025, [EMAIL] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Computing Apparently [USER]'s UMBC account does not have 2FA. Apparently, he was told to contact the administrator of UMBC google account to have the two factor authentication unlocked. Do you know who he can contact? Thanks [USER]"
"3155508","68484746","2025-04-02 18:28:24","High Performance Computing - Research Group Storage","Hi [STAFF], Please read the overview of the HPC as it explains some of the basics on how to navigate Chip. https://hpcf.umbc.edu/compute/overview/ On Wed Apr 02 12:43:31 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [ID] Request Type:              High Performance Computing I recently started using Chip and was trying to create a virtual environment to run my Python code. However, when I create it in my home folder, it takes up all my available space. I am also part of the research group pi_[USER], but I can’t seem to find it anywhere. I would really appreciate your help. Thank you!"
"3155550","68565686","2025-04-07 15:48:50","High Performance Computing - fMRI data","Hi [USER],  Your account ([USERNAME]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) -- Kind regards, [STAFF] DOIT Unix Infra Student Worker  On Mon Apr 07 10:00:29 2025, [USER] wrote: > Approved! > Best, > [USER] > > On Apr 7, 2025, at 6:55 PM, [STAFF] via RT <[EMAIL]> wrote: > > Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3155550> > Last Update From Ticket: > Hi [USER], Once we get confirmation from [USER], we can add you to the account. > On Wed Apr 02 13:08:38 2025, [USER] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [CAMPUSID] > Request Type:              High Performance Computing > Create/Modify account in existing PI group > Existing PI Email:    [STAFF EMAIL] > Project Title:        site effect for fMRI data analysis > Project Abstract:     study the different FNC structure for different sites in BSNIP dataset, and compare the site difference > NA > Best, > [STAFF] DOIT Unix Infra Student Worker"
"3155622","68483719","2025-04-02 18:06:30","High Performance Computing - Question about canceling a running job","Dear [USER], To cancel jobs on chip, you need to specify the specific cluster which the job resides. This can be done with: 'scancel -M chip-cpu *job-id*' for jobs using chip-cpu And: 'scancel -M chip-gpu *job-id*' for jobs on chip-gpu. On [DATE], [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Computing My name is [USER], and I am a PhD student in the ME department. I have a question about canceling a running job. The command 'scancel job_id' does not work after updating the system. Could you please tell me the new commands? Looking forward to your reply."
"3155739","68501034","2025-04-03 13:35:20","High Performance Computing - Macroeconomics",""
"3155743","68486551","2025-04-02 18:57:54","High Performance Computing - Research Group Folder","Hi [USER], For future reference, any ticket can be reopened if it's been closed by just responding to the same ticket as before. No need to open a new ticket. Now for your main issue: Although the directory isn't appearing, it still exists. As seen below: `[USER]@chip ~]$ cd /umbc/rs/[STAFF] [USER]@chip [STAFF]]$ pwd /umbc/rs/[STAFF] [USER]@chip [STAFF]]$ cd /umbc/ada/[STAFF] [USER]@chip [STAFF]]$ pwd /umbc/ada/[STAFF]` You not seeing it is a result of no one having accessed it recently (on chip). The same locations can be reached without the direct path using the aliases defined in your bashrc (as mentioned in the chip overview, and seen below: `[USER]@[STAFF]]$ [STAFF]_common [USER]@chip common]$ pwd /umbc/rs/[STAFF]/common [USER]@[STAFF]]$ cd [USER]@[STAFF]]$ [STAFF]_user [USER]@[STAFF]]$ pwd /umbc/rs/[STAFF]/users/[USER] [USER]@[STAFF]]$ cd [USER]@[STAFF]]$ [STAFF]_ada [USER]@[STAFF]]$ pwd /umbc/ada/[STAFF]` You can always view what storage directories you have access to via the 'alias' command. If you have further questions, reopen this ticket by responding. On Wed Apr 02 14:44:38 2025, [EMAIL] wrote: > Request Type: High Performance Computing > Hello, > Following up on ticket #3155508, I have already reviewed the documentation on navigating Chip before, and I still can't locate the storage. I remember accessing it before, but it no longer appears. > I’ve attached a screenshot of the available pi storages for reference. Thank you. Best, [STAFF]"
"3155946","68864706","2025-04-22 14:52:46","High Performance Computing - pseudo permissions","I am closing this ticket. Please do not respond to it. New RT tickets are an important part of our workflow, and having them randomly be re-opened with issues unrelated to the original ticket can be detrimental to us. Hi [STAFF], I hope this message finds you well. I=E2=80=99ve recently migrated my project files and environments to the research directory (/umbc/rs/manas/users/[CAMPUSID]) to support my current work involving large language models. After carefully cleaning up unnecessary files and dependencies, I=E2=80=99ve discovered that the remaining space is still insufficient to complete my model runs. The majority of the storage is now occupied by required packages, pre-trained model weights, and essential runtime dependencies. I would greatly appreciate it if you could either: - Increase the storage quota for my RS directory, or - Extend my home directory quota to accommodate the resources needed for my active GPU jobs. This will enable me to run the models and complete my scheduled tasks in time for an upcoming deadline. Please let me know if any additional details are needed from my end. Thank you for your support! Best regards, [USER] UMBC Username: [CAMPUSID] Group: manas Hi [USER], Thanks for the information. It appears your home directory is full. If you run 'df -h ./' from your home directory you'll see that you only have 500MB of space as described here https://hpcf.umbc.edu/compute/overview/. I would recommend moving any of your larger datasets/files to your research directory. The directory name can also be found in the start-up page. Hi [STAFF], I tried logging in ,it seems there is no space left .can you please solve this problem?  On Fri, Apr 4, 2025 at 3:52=E2=80=AFPM [USER] <[EMAIL]> wrote: Ok, I will do that.  On Fri, Apr 4, 2025, 11:18=E2=80=AFAM [STAFF] via RT <UMBCHelp@rt.umbc.edu> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3D3155946> Last Update From Ticket: Hi [USER], Please ssh into chip, and type 'mkdir test_folder', and send me what the response is. On Thu Apr 03 14:40:05 2025, [CAMPUSID] wrote: Iam trying to login using ssh [CAMPUSID]@chip Rs.umbc.edu I logged in and when iam trying to make a directory using mkdir ,iam not able to do so,while I have checked if I have any directory in the chip it's not available. On Thu, Apr 3, 2025, 11:28=E2=80=AFAM [STAFF] via RT <UMBCHelp@rt.umbc.edu> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3D3155946> Last Update From Ticket: Hi [USER], When you try to make a directory can you tell me the exact error you are receiving, and the path in which you are trying create it? On Thu Apr 03 09:44:21 2025, [CAMPUSID] wrote: Hi [STAFF], While iam trying to create a directory for myself in the given chip ,iam not able to make one ,so I contacted you to give me the solution also moving forward I might need a link which I can access all my files ,I want to create a folder so that my files will not scatter here and there. Can you please look into this and help me . Regards, [USER] On Thu, 3 Apr, 2025, 9:27 am [STAFF] via RT, <UMBCHelp@rt.umbc.edu> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3D3155946> Last Update From Ticket: Hi [USER], This is not nearly information to help. Where are you trying to create a folder that you need *sudo* permissions? Sudo permissions are restricted to administrators, so we can't give you that, but you shouldn't need sudo permissions to create a folder anywhere that you would regularly be able to view. On Wed Apr 02 17:37:08 2025, [USER] wrote: First Name:                [USER] Last Name:                 [LAST NAME] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Computing Iam not able to create a folder, i don't have the pseudo permissions."
"3156339","68541811","2025-04-04 20:51:00","High Performance Computing - LaTeX on knacc1","Hi [STAFF], It is resolved. On Fri Apr 04 16:46:59 2025, [USER] wrote: I managed to figure out an interactive node. But the module load gives an error: [gobbert@c18-01 ver0.3chip]$ module load texLive/2025 Lmod has detected the following error: /cm/shared/modulefiles/texLive/2025: (texLive/2025): extra characters after close-quote While processing the following module(s): Module fullname  Module Filename ---------------  --------------- texLive/2025     /cm/shared/modulefiles/texLive/2025 On Fri, Apr 4, 2025 at 3:45 PM [STAFF] via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3156339&ticketowner=[STAFF]&ticketsubject=High Performance Computing - LaTeX on chip If you believe your issue is not resolved, please respond to this email or call the DOIT Help Desk at 410-455-3838. On Thu, Apr 3, 2025 at 12:27 PM [STAFF] via RT <[EMAIL]> wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3156339 Hi [USER], LaTeX hasn't been installed on Chip yet (no one has requested it so it hasn't been at the forefront of our minds right now), but I can get this done for you in a timely manner. As for your other question, yes modules are no longer loadable on the login node. This is for a few reasons, but the main one being the following: On taki and ada we saw a significant number of users who used the login node as a compute node, which caused major slowdown for all other users. Now, we've virtualized the login nodes for easier management on our end, but as a result the login nodes are even less powerful than they were before. To preemptively combat the flood of new users who might be tempted to run computationally heavy jobs on the login node, we've disabled loading modules on the login node. However, modules can still be loaded and tested from an interactive session on any of the compute nodes. Hopefully this clears up some of the questions you had, and I'll work to get the LaTeX installed on chip. On Thu Apr 03 09:46:09 2025, [USER] wrote: Requestors: [USER] First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [USER] Request Type:              High Performance Computing Hi, How can I use LaTeX on chip? On taki, it used to be 'module load texLive2018', but I cannot find an equivalent on chip. In fact, module seems to behave differently, like not wanting to load on the user node. Can you explain this, please? [USER]"
"3156483","68627207","2025-04-09 17:29:19","High Performance Computing - Installing Modules for Selenium and Playwright on the ADA HPC Cluster","Yes, for Selenium, you are able to install the WebDriver with pip or any similar methods. You can find more information on that here: https://www.selenium.dev/documentation/webdriver/getting_started/install_library/ For playwright, this is something that can be installed and used through nodejs/npm. I have installed NodeJs on chip, and you should be able to load it by running 'module load nodejs', then you should be able to follow the instructions outlined here: https://playwright.dev/docs/intro#installing-playwright You should be able to use PlayWright that way. Hope this helps! On Wed Apr 09 07:28:02 2025, [USER] wrote: For selenium just the webdriver. I’ll go ahead and install that. As for Playwright the latest version is fine. On Tue, Apr 8, 2025 at 5:04 PM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hi [USER], I had some questions about your request. Could you provide more information on what version of Selenium you want installed? Are you looking for Selinium Grid? Or just Selenium WebDriver? If you are looking for WebDriver, that is something that has to be installed yourself, usually in a conda environment. Additionally, is there a specific version of PlayWright you need installed? Or is the latest version okay. Thanks, -- Kind regards, [STAFF] DOIT Unix Infra Student Worker On Thu Apr 03 12:32:54 2025, [USER] wrote: Hi [STAFF], Yes, please look into installing selenium and playwright on Chip. Thank you! Best, On Thu, Apr 3, 2025 at 12:18 PM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hi [USER], Due to the imminent shutdown of Ada (April 10th), we stopped all development on ada. That being said, we highly recommend moving to our new cluster 'Chip' (chip.rs.umbc.edu). All the storage and the machines from Ada are being moved into the one location with an additional 10 brand new nodes. We can look into getting selenium and playwright installed there, if that's ok? On Thu Apr 03 11:30:56 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Computing Can we install Selenium and Playwright on the ADA cluster? Best, [STAFF] DOIT Unix Infra Student Worker"
"3156669","68608650","2025-04-08 19:52:26","High Performance Computing - Job killed","(base) [USER@chip ~]$ cat /umbc/rs/zzbatmos/users/[USER]/tamu/TAMUdust2020-v1.0/make_netcdf.err Traceback (most recent call last):   File '/umbc/rs/zzbatmos/users/[USER]/tamu/TAMUdust2020-v1.0/small_netcd fs.py', line 58, in <module>     scat_df[f'P{s}{s}'] = pii     ~~~~~~~^^^^^^^^^^^^   File '/umbc/rs/zzbatmos/users/[USER]/pyenv/lib/python3.12/site-packages= /dask_expr/_collection.py', line 3037, in __setitem__     out = self.assign(**{key: value})           ^^^^^^^^^^^^^^^^^^^^^^^^^^^   File '/umbc/rs/zzbatmos/users/[USER]/pyenv/lib/python3.12/site-packages= /dask_expr/_collection.py', line 2815, in assign     raise TypeError(f'Column assignment doesn't support type {type(v)}') TypeError: Column assignment doesn't support type <class 'numpy.ndarray'> /cm/local/apps/slurm/var/spool/job02609/slurm_script: line 12: 138346 Killed                  python3 full_netcdf.py  Can you verify that you have made this code work on non-hpc machines? On Mon Apr 07 13:46:52 2025, [STAFF] wrote: > Hi Max, > Sure! The file paths are as follows: > /umbc/rs/zzbatmos/users/[USER]/tamu/TAMUdust2020-v1.0/make_netcdf.out > /umbc/rs/zzbatmos/users/[USER]/tamu/TAMUdust2020-v1.0/make_netcdf.err > /umbc/rs/zzbatmos/users/[USER]/tamu/TAMUdust2020-v1.0/full_netcdf.py > /umbc/rs/zzbatmos/users/[USER]/tamu/TAMUdust2020-v1.0/netcdf.sh > I think it is possible I used too much memory depending on the maximum allowed. I was attempting to load in an assortment of files adding up to over 100GB of data and export it to a different file structure; .txt to netCDF, after a small bit of calculations to reformat some values. It dies before it finishes loading in all the .txt files. For now I am working to split up into smaller files. Thank you, [USER] On Fri, Apr 4, 2025 at 3:07 PM Max Breitmeyer via RT <[EMAIL]> wrote: > Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3156669 > Last Update From Ticket: Hi [USER], First, I want to say thank you for providing as much information as you did. Python exit code 9 usually implies that it was killed due to out-of-memory, but I would be surprised if that was actually the issue. Chip-cpu allows for you to request all the memory on the node, and I see that you set '--mem' to 0 which should in theory get all the memory. Can you give us the path to the slurm file as well? There might be more information the slurm .out and .err file's associated with it. On Thu Apr 03 13:40:24 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Computing I received the error message: /cm/local/apps/slurm/var/spool/job02576/slurm_script: line 12: 1150203 Killed python3 full_netcdf.py today, for job 2576 on chip-cpu. I was using the 2021 partition with maximum memory. Is this a ran out of memory error? How much memory does this type of job get?"
"3157262","68537420","2025-04-04 18:42:37","Help with something else - unable to ssh on taki/[ID]","Hi [STAFF], UMBC doesn't allow access to UMBC IP's from overseas without using the UMBC VPN. Instructions for installing the VPN can be found here. https://umbc.atlassian.net/wiki/spaces/faq/pages/30754220/Getting+Connected+with+the+UMBC+GlobalProtect+VPN Let me know if you have any issues with this.  On Fri Apr 04 06:57:42 2025, [USER] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [USER] >  > Request Type:              Help with something else >  > I am unable to ssh to my account on taki/strowinteract. The SSH session times out. I am on overseas travel at the moment. I can ping umbc.edu and packets appear to reach umbc campus 136.160.255.182 but no further, could you please advise and remedy if possible thank you [USER] -- Best, [STAFF]"
"3157419","68530534","2025-04-04 15:21:07","create new account on cluster","Hi [STAFF], Please submit a ticket here https://rtforms.umbc.edu/rt_authenticated/doit/DoIT-support.php?auto=Research%20Computing. This will help us track the request better as well as get a sense of the project you're working on. On Fri Apr 04 10:39:31 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:                 2. How do I create my account? Hi there, I am a new post doctoral researcher at the physics department under Dr. [STAFF]. I am looking forward to create an account to access the HPC cluster. I already have an UMBC account and UMBC badge. Please let me know what should I do next. Best, [STAFF]"
"3157541","68562283","2025-04-07 14:47:14","High Performance Computing - how can we develop Matlab code on chip","Hi [STAFF], That's correct. Strowinteract is still currently set-up in Taki which [USER] doesn't have access to, but once it gets moved to Chip (at the latest April 10th, possibly earlier), he'll have access to it. On Mon Apr 07 09:43:39 2025, [EMAIL] wrote: Hi [STAFF], OK so basically once strowinteract is moved to chip, then both [USER] and I will be able to log into it and use it as I have been doing all these years (matlab/slurm etc)? BTW [USER] can get into chip but I don't think he can log into strowinteract. In the meantime we'll go through the documentation. Thanks -[STAFF]. On Mon, Apr 7, 2025 at 9:23 AM [STAFF] via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3157541&ticketowner=[STAFF]&ticketsubject=High Performance Computing - how can we develop matlab code on chip. If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3157541. Hi [USER], The new cluster works slightly different than how [STAFF] is used to. We no longer allow for the loading of modules on the login node. You can start an interactive session and use the modules from there. More information on how to do this can be found here https://umbc.atlassian.net/wiki/spaces/faq/pages/1033142321/Using+slurm. Once we move the strow-interact node that's on taki to chip, you'll be able to use that node as [STAFF] expects. On Fri Apr 04 12:23:41 2025, [EMAIL] wrote: Request Type: High Performance Computing. Hi, I am new to the chip cluster. I was wondering how develop matlab code and develop fortran code on chip. [STAFF] told me to try module load matlab but i got this error message: Modules do not function on the login nodes. I was not able to find the documentation on Hpcf website. Thank you."
"3157840","68834959","2025-04-21 13:30:52","High Performance Computing - Request to install ifort (intel fortran)","Apologies for the delay, we've installed the module 'intel/2024a' which includes ifort built using gcccore 13.3.0. Hopefully that works. First Name: [USER] Last Name: [STAFF] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Computing Dear DoIT team, I am writing to request the installation of ifort with compatible GCCcore version (e.g., GCCcore-13.2.0) to Chip. The ifort is installed on Taki but is missing in Chip. My current fortran code need ifort as the compiler to work. The default gfortran cannot read the .mod files in my code. Feel free to let me know if the ifort compiler is installed or if you have other concerns. Thank you for your help. -- Best, [STAFF]"
"3158282","68557390","2025-04-07 13:34:10","High Performance Computing - Request to Increase Job Time Limit on [CLUSTER]","Hi [USER], Please review this site here for more information on our QOS policies (https://hpcf.umbc.edu/compute/chip-cpu/). As a non-contributing user, the longest running job you can have is 5 days, and up to 256 cores using the 'long' QOS. Let me know if you have further questions about this. On Sat Apr 05 23:02:21 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Computing Hi, I’m trying to submit a job on the chip-cpu cluster, but I’m encountering an issue with the time limit. The job I’m running requires several days or potentially weeks to complete. However, even after adjusting the time limit in my .sh submission script, I receive the following error: 'sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)' Could you please check the current time limit associated with my account, and let me know if it would be possible to increase it? [USER] Best, [STAFF]"
"3158287","68562834","2025-04-07 14:54:43","High Performance Computing - [USER] nodes status: Drain","The gpu node won't be transitioning to Chip. There are a few reasons for this: 1. It's 7 years old and we have significantly newer/stronger hardware available 2. It's the only node of its kind 3. It hasn't been widely used over the last few months. The effort to create a new image and maintain it just isn't worth it with that in mind. We can certainly create modules for Tensorflow and Keras on chip-gpu though (I would kindly ask that you put in a ticket for this so that we can track it though). On Mon Apr 07, [STAFF] wrote: Hi Max, He is trying to use the gpu2018 node. What will this be called on Chip? The other problem is that we were not able to assess yet if Tensorflow works on chip-gpu. Is it possible to have the Tensorflow/Keras as they are on taki ported to chip-gpu? [USER] On Mon Apr 07, [STAFF] via RT wrote: Hi [USER], We have set all Taki nodes to drain in preparation for the final move to Chip on April 10th. Please switch to Chip at this point. Documentation can be found here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1082589207/UMBC+HPCF On Sat Apr 05, [USER] wrote: The status for all the nodes on taki has been drain and my job is paused. The status has not changed for hours. Best, Max Breitmeyer"
"3158341","68555434","2025-04-07 12:57:03","High Performance Computing - Running jobs on chip","Hi [USER], Seems you somehow slipped through the cracks as we moved over, but you should be good to access the chip-gpu cluster! Let me know if you have any other issues! On Sun Apr 06 11:12:43 2025, [STAFF] wrote: > First Name: [USER] > Last Name: [USER] > Email: [EMAIL] > Campus ID: [ID] >  > Request Type: High Performance Computing >  > I was wondering how to run jobs on chip. I keep getting an error that says 'Invalid account or account/partition combination specified' as shown in one of the screenshots I've provided. I have also included my slurm submission script that is leading to this error message. Is it correct to use the --account flag in this way, or do I need to do something else?  Best, [STAFF]"
"3158687","68561997","2025-04-07 14:43:16","High Performance Computing - Not enough space","Hi [STAFF], Information on storage can be found here: https://hpcf.umbc.edu/compute/overview/ Information on how to use jupyter on our cluster can be found here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1104805915/Jupyter+Notebooks On Mon Apr 07 01:30:48 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] Request Type:              High Performance Computing Hello, I was added to the 'chip' cluster, But I had two questions regarding that: 1. It said that my home directory only had 500Mb storage, but the whole purpose of requiring the chip cluster was that I could process large datasets in jupyter notebooks. So, could you tell me how I could access more space? 2. I am not really familiar with running jupyter notebooks on remote servers, could you tell me if there is any documentation regarding that? Or if you just give me a way to get extra space in my home directory, I guess I could figure out all that stuff on my own. Thank you and regards, --  Best, [STAFF]"
"3158772","68556362","2025-04-07 13:12:51","High Performance Computing - [USER] account and btw slurm not working all weekend","Hi [STAFF], Re: Adding [USER]/Matlab: We won't be adding anyone new to Taki since Taki will be gone in three days (see below for more information), but you can use an interactive session to open matlab. More information on that can be found in the user documentation here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1033142321/Using+slurm Re: Jobs on Taki: All nodes on taki have been set to drain in preparation for the final move happening on April 10th (per the timeline set out here: https://my3.my.umbc.edu/groups/hpcf/posts/147513), meaning no new jobs can be submitted. As part of that move, we'll also be moving strow-interact where you'll have free reign to do use the machines as you like in the same way that you have been using it.  On Mon Apr 07 08:59:40 2025, [USER] wrote: > First Name:                [STAFF] > Last Name:                 [LAST NAME] > Email:                     [EMAIL] > Campus ID:                 [CAMPUS_ID] >  > Request Type:              High Performance Computing >  > Hi [STAFF] >  > Can you add [USER] ([EMAIL]) to strowinteract, so he has ready access to Matlab and/or slurm? He and I have not yet figured out how to do that with chip >  > BT my job has been frozen all weekend, does that mean soon we will no longer be able to submit jobs from strowinteract? >  > JOBID PARTI:QOS         USER:ACCOUNT   NAME         ST        TIME / TIME_LIMIT  NODEn:CPUS MIN_MEM NODELIST(REASON) PRIORI PRIORITY > 21491183_[18 cpu20:short+    [STAFF]:[ACCOUNT]  RUN_CLD_RETR PD > 0:00 / 59:00          1n:1     12000M (Nodes required  87149 > 0.00002029 >  > Thanks >  > [USER]"
"3158926","68628697","2025-04-09 18:03:17","High Performance Computing - Unable to submit job in chip","It appears that you have posted a large amount of text, which is actually an email thread between Sai Vikas Amaraneni and the University of Maryland Baltimore County (UMBC) IT department.  To answer your question, it seems like Sai Vikas Amaraneni is having trouble submitting a job to the CHIP (Computational High-performance Infrastructure for Physics) cluster and is seeking help from the IT department. He is also asking about how GPU constraints correspond to nodes in the CHIP cluster.  The response from Danielle provides information on how to map GPU constraints to specific nodes in the CHIP cluster, but it does not explicitly answer Sai's question about whether he needs to start over with setting up his environment and submitting jobs.  To provide a more direct answer:  No, you do not need to start over from scratch. Based on the response from Danielle, it seems like you can modify your job submission script to use the correct GPU constraints for the nodes in the CHIP cluster. You can try updating your script with the correct constraints and resubmitting the job.  If you are still having trouble, I recommend reaching out to the UMBC IT department or a system administrator for further assistance. They can provide more specific guidance on how to troubleshoot and resolve any issues with your job submission."
"3158992","68716454","2025-04-14 18:06:33","Research Computing & Data Consultation - Install Tensorflow/Keras on chip-gpu","Hi [STAFF], After some internal discussion, we would prefer to not create new modules for people that could otherwise be set up in a python virtual environment. All you'll need to install this on your end is to load an appropriate version of python and cuda, and then you'll be able to install and manage the versions of tensorflow and Keras you specifically want. Let me know if you have further questions about how to do this, but I'll close this ticket out for now. On Thu Apr 10 09:27:32 2025, [STAFF] wrote:  Hi [USER], Sorry for the long wait on this, but we've been having trouble installing the GCCcore-8.2.0 on the new system (which is a required dependent for the version of module that you all were using) , as it turns out RHEL 9 doesn't play well with versions of GCC older than 10.X. I'm still going to work to get a module made with as similar a version of Keras as possible, and will keep you updated. On Wed Apr 09 10:22:05 2025, [STAFF] wrote:  Hi [USER], Yep this is the info I needed! Thanks! On Tue Apr 08 18:12:21 2025, [USER] wrote:  Hi, We use the Keras version that comes with the module Python/3.7.6-intel-2019a. This can be found here: TensorFlow/Keras – High Performance Computing Facility – UMBC <https://hpcf.umbc.edu/gpu/keras/>. I hope this answers the question as to what we used to do. On Tue, Apr 8, 2025 at 3:49 PM [STAFF] via RT <[EMAIL]> wrote:  Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3158992> Last Update From Ticket: Hi all, The directory '/umbc/xfs1/cybertrn/common/PGML_Example' still had a bunch of stuff underneath it. I was able to find the tensorflow version, which is installing now, but I can't find the Keras version. Could you specify the module of Keras you use? On Mon Apr 07 11:42:17 2025, [STAFF] wrote:  Hi, The directory where we were working in is: /umbc/xfs1/cybertrn/common/PGML_Example. On Mon, Apr 7, 2025 at 11:15 AM RT API via RT <[EMAIL]> wrote:  Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3158992> Last Update From Ticket: First Name:                [USER] Last Name:                 [STAFF] Email:                     [EMAIL] Campus ID:                 [USER]. Request Type:              Research Computing & Data Consultation Hi, Please install Tensorflow and Keras on chip-gpu. I am copying Hussam Fateen and Dan Kelly, who used these on gpu2018. They are the ones who can test after installation or provide more detail on what is needed, if it is not clear. Hussam, please reply to this ticket and give a directory ('pwd -P') where you have run successfully on gpu2018, so that the sys admin could look up what version was used, if that helps them. Specify the sbatch script that you used and where the output is. (A shorter run is better, like with 512 epochs.)"
"3159094","68568634","2025-04-07 16:50:17","High Performance Computing - Migration to the Chip Cluster","Hi [USER], According to our migration timeline posted here: [LINK], ada is being fully shutdown and migrated into chip this week. Your user account should be migrated to chip, and you should have log in access. If you stored your jobs on Ada in your PI's research volume, you should be able to access them under /umbc/rs/pi_name/users/*username*. Please review all documentation available on using Chip here: [LINK]. Please be aware, that you will likely have to modify your code to adjust it to run properly on Chip. If you have any issues, please feel free to reach out. -- Kind regards, [STAFF]. On Mon Apr 07 12:41:14 2025, [USER] wrote: Request Type: High Performance Computing. I've noticed the ADA cluster is not running any more jobs, and my batch is on hold. I just want to confirm if we've fully migrated to the Chip cluster, and if so, how can I transfer my jobs on the ADA cluster into the Chip cluster."
"3159484","68591837","2025-04-08 14:22:54","High Performance Computing - [USER] account password","Your account is created on chip. You should log in to [SERVER]. Your password is similar to your myumbc password. Please read through the documentation for additional information https://[DOMAIN]/wiki/spaces/faq/pages/[PAGEID]/START+HERE On Mon Apr 07 15:46:00 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Computing Hi sir I just created my taki account today but when I want to log into it I'm unable to log into my taki account since I don't know what is my password. Could you tell me where I can find my account's password? Thank you a lot! Attachment 1: Screenshot [DATE] at [TIME].png (https://[DOMAIN]/s/[ATTACHMENTID])"
"3159542","68629813","2025-04-09 18:30:49","Research Computing & Data Consultation - which storage areas exist?","There was a mounting problem with [SERVER] and [SERVER]. We have mounted them properly correctly now. The research volume for group [GROUP], [SERVER], [SERVER], and [SERVER] can be accessed using the alias like other pi groups. They all are located at /umbc/rs/$groupname  Let me know, if you still have similar issue. On Mon Apr 07 16:23:20 2025, [USER] wrote: First Name:                [STAFF] Last Name:                 [STAFF] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              Research Computing & Data Consultation Hi, On [SERVER], we had [GROUP], [SERVER], [SERVER], [SERVER], and some more. How can I determine, where / if such areas still exist on [SERVER]? Or can you maybe advise me where each is located? I trust that no data is lost, so it is a matter of finding the data. Or am I wrong on this? I looked at the list 'alias' on [SERVER], and the following is in there. However, when I try the alias or cd to that, it says this: [USER@SERVER ~]$ [COMMAND] -bash: cd: /umbc/rs/[SERVER]/common: No such file or directory"
"3159710","68595589","2025-04-08 15:36:18","High Performance Computing - ada becoming unavailable?","You can find a guide user guide here: https://umbc.atlassian.net/wiki/space=s/faq/pages/972750849/Research+Computing. This will help you start using chip  This link is a light overview on chip https://hpcf.umbc.edu/compute/chip-gpu/=20 On Tue Apr 08 11:21:29 2025, [USER] wrote: > Thank you! Could you please guide me how to be connected to chip? any instructions? =20 =20 > On Tue, Apr 8, 2025 at 11:19AM [STAFF] via RT <[EMAIL]> wrote: =20 > If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3159710&ticketowner=[STAFF]&ticketsubject=High+Performance+Computing+-+ada+broadcasts+unavailable%3F =20 If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3159710 =20 Thank You =20 _________________________________________ R e s o l u t i o n:=20 Chip is now available, for everyone who had an account on taki or ada, according  to the timeline announced. You can read more info about our migration to chip on this link https://my3.my.umbc.edu/groups/hpcf/posts/147513 =20 On Tue Apr 08 11:14:05 2025, [USER] wrote: > Hi, Thank you for your response. When Can I start working with chip and run the experiments? =20 On Tue, Apr 8, 2025 at 11:11AM [STAFF] via RT <[EMAIL]> wrote: > If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3159710&ticketowner=[STAFF]&ticketsubject=High+Performance+Computing+-+ada+broadcasts+unavailable%3F =20 If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3159710 =20 Thank You =20 _________________________________________ R e s o l u t i o n:=20 Hello [USER] All your data in research storage (vjaneja_common, vjaneja_user,..) are mounted on chip so there will not be any data lost. The only data you have to backup/ save are the files in your home directory  /home/[EMAIL]/ that didn't come when the account was created. (subset_file_list.txt , test.sh  and subset_flacs ) Let me know if you have more questions."
"3159760","68608953","2025-04-08 19:58:53","Research Computing & Data Consultation - storage areas cd not working","Hi [STAFF], /umbc/rs/vitals should now be mounted.  hpcreu has not been mounted yet as we still need to complete a sync of that data to the isilon. Once we've done that, it will be mounted to /umbc/rs/hpcreu (/umbc/xfs1 is going away), and we will let you know. On Mon Apr 07 20:40:03 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: Research Computing & Data Consultation Hi, On chip, we cannot find some of our storage areas. The following exist on taki: /umbc/xfs1/hpcreu /umbc/rs/vitals There are Unix groups associated with them, and the membership is listed on chip, when I say 'groups'. Can you point me to where these data are? [USER] -- Best, [STAFF]"
"3159814","68732259","2025-04-15 13:50:46","High Performance Computing - Cannot pip install torch on [SERVER]","I was able to login as [USER] and activate a conda environment. Please try using conda again, it should work as expected. You don't need to run 'conda init' anymore, you only have to do it the once. Once you submit an interactive job, you will be able to create and activate a conda environment. In addition, please don't forget to follow the last step, about moving your .local, in my previous response. On Mon Apr 14 11:33:45 2025, [USER] wrote: Hi [STAFF], when I use srun --cluster=chip-gpu --account=pi_[STAFF] --mem=48GB --time=4:00:00 --gres=gpu:2 --pty $SHELL to create an interactive job. And I can run module spider anaconda and module load Anaconda3/2024.02-1. After that, I run conda init, it shows the following error. How can I fix it? It seems I don't have a sudo password. active environment : None user config file : /home/[USER]/.condarc populated config files : conda version : 24.1.2 conda-build version : 24.1.2 python version : 3.11.7.final.0 solver : libmamba (default) virtual packages : __archspec=1=icelake __conda=24.1.2=0 __cuda=12.8=0 __glibc=2.34=0 __linux=5.14.0=0 __unix=0=0 base environment : /usr/ebuild/installs/software/Anaconda3/2024.02-1 (read only) conda av data dir : /usr/ebuild/installs/software/Anaconda3/2024.02-1/etc/conda conda av metadata url : None channel URLs : https://repo.anaconda.com/pkgs/main/linux-64 https://repo.anaconda.com/pkgs/main/noarch https://repo.anaconda.com/pkgs/r/linux-64 https://repo.anaconda.com/pkgs/r/noarch package cache : /umbc/rs/[STAFF]/users/[USER]/conda_pkgs envs directories : /umbc/rs/[STAFF]/users/[USER]/conda_envs /home/[USER]/.local/lib/python3.9/site-packages/nvidia Can you tell me what should I do? Thanks!"
"3159860","68609296","2025-04-08 20:07:33","High Performance Computing - Unable to install a code repo in ADA Cluster, need working directories in CHIP Cluster","Hi [STAFF], First, as you mentioned, you should not be using Ada anymore, as it is being decommissioned on April 10th (two days). You mentioned implementing a 'paper'? I'm not sure what that means. Second, for chip, I would highly recommend reading through this page https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/START+HERE as it explains how to use the new Chip cluster. Once you've understood the basics of the cluster, I think we can circle back to some of your more complicated issues. Let me know if you would like to discuss more once you read the article. On Mon Apr 07 23:48:20 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Computing Hi, I have been trying to implement a paper (containing Python code) by installing it on a worker node on the ADA cluster. Some the challenges I've faced include (1) not being able to install the correct version of each library that is compatible with the other ones (the implementation imports 100+ libraries/modules, all in Python), (2) getting caught up in circular dependencies for the modules, (3) observing that manually installed libraries/modules (on a cluster node) are not retained after I log out and log back into the cluster (not necessarily the same node). I was recommended to migrate the workflow to the CHIP Cluster, but when I SSHed into the CHIP Cluster using my [EMAIL], I could not find any working directories or symbolic links. Additionally, if I need to migrate the workflow to the CHIP Cluster, I need to transfer my files from the ADA cluster to the CHIP cluster. Could someone please help me with this? Thank you. Regards, [USER]."
"3160203","68642008","2025-04-10 13:20:28","High Performance Computing - Unable to use Conda, older GPUs","Hi [USER], Yes this is by design. We want to encourage users to either develop code on their personal machines and then port it over to Chip, or develop in an interactive session (more information about this can be found here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1033142321/Using+slurm On [DATE], [USER] wrote: Thanks a lot about the constraints issue About conda - I am still unable to use conda from the login node. Is that the case by design? I used to be able to use conda at the login node itself when on ADA. I will change the settings for conda to look at the right directory for the environments, thanks. On [DATE], [STAFF] wrote: Hi [USER], The constraints issue has been fixed. As for your other question, the only thing that has not been transferred from Ada to Chip is your home directory. It looks like your .conda folder on ada was linked to '/nfs/ada/oates/users/[USER]/.conda'. The same thing can be found on chip under a slightly different path name: '/umbc/ada/oates/users/[USER]/.conda'. You can either tell anaconda to look there for your environments using the '--prefix' flag, or link .conda in your home directory the same way that it was on ada. Let me know if you have any trouble with this! On [DATE], [USER] wrote: Hi [STAFF], Thank you for the response. Please let me know when the constraints issue is fixed; my workload is such that I need a higher number of GPUs, not faster GPUs - using L40s for my work would be an unnecessary overkill. Also, was there supposed to be link to the FAQ you said? Can you send me a link? Can we expect that conda virtual environments that existed on ADA will be transferred to CHIP eventually? (As in, a conda env called myenv that was created months ago on ADA, will that also be migrated to CHIP?) Thank you On [DATE], [STAFF] wrote: Hi [USER], The issue with constraints is a bug that we are working on fixing. We'll let you know when we have a fix for it. As for your issue with conda, please check out this FAQ. It explains some of the differences that we have between chip and ada, and how to appropriately use conda on chip. On [DATE], [USER] wrote: I am currently unable to use Anaconda (it is listed when I run module list) to work on virtual environments. Also, I am unsure how to use older ADA GPUs (RTX 6000, 8000) on CHIP. When I set --constraint=rtx_6000 I get an error 'Invalid feature specification'. I am able to use the L40S though. When I run an interactive job with 'srun' and get a compute node, I am able to run conda as well; however none of my previous environments are available now. 'conda env list' returns only the base environment."
"3160541","68611838","2025-04-08 23:02:27","High Performance Computing - Main research storage","Okay, just checked. It works now. Many thanks!  Best, [USER] On 4/8/2025 3:45 PM, [STAFF] via RT wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3160541&ticketowner=[STAFF]&ticketsubject=High%20Performance%20Computing%20-%20Main%20research%20storage If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3160541 Thank You R e s o l u t i o n Hi [USER], We use a program called autofs, which unmounts the storage device after it has not been used for some amount of time. If you `cd` to the directory (even though you can't see it), it will reappear since the program recognizes that someone is requesting a resource and remount it. Please try just running `cd /umbc/rs/[USER]` and you'll see that you (and your student) do still have access to your storage. Please let me know if you have any other issues On Tue Apr 08 14:39:24 2025, [USER] wrote Hi [STAFF], Here is what I see As you can see in the last line, there is no folder with my username Does this help Thanks [USER] On 4/8/2025 2:17 PM, [STAFF] via RT wrote Ticket https://rt.umbc.edu/Ticket/Display.html?id=3160541 Last Update From Ticket Hi [USER], Could you give a little more information here 1 What happens when you navigate to that directory 2 What machine are you on when you attempt this 3 Is there any error message reported [STAFF] On Tue, Apr 8, 2025 at 2 08 PM RT API via RT wrote Tue Apr 08 14 08 00 2025 Request 3160541 was acted upon Transaction Ticket created by [USER] Queue DoIT-Research-Computing Subject High Performance Computing - Main research storage Owner Nobody - Nobody in particular Requestors[EMAIL] Status new Ticket https://rt.umbc.edu/Ticket/Display.html?id=3160541 First Name [USER] Last Name [USER] Email[EMAIL] Campus ID [USER] Request Type High Performance Computing Hi My group's storage folder on CHIP has disappeared We used to have a folder /umbc/rs/[USER]/ and my student ([USER]) used to have access to it Can you please help us restore the folder Thanks [USER]"
"3160573","68606099","2025-04-08 19:02:30","Help with something else - Access on chip","Problem solved [STAFF]. :) Thanks a ton.  Just finished Duo things and I entered chip now.  On Tue, 8 Apr 2025 at 14:41, [STAFF] <[EMAIL]> wrote:  > [USER], > > Ah, that message says it. See in my e-mail to [STAFF], [STAFF], etc., the remark > that chip is behind the UMBC firewall. > You need either (i) the Duo app on your phone or (ii) use the VPN. > I hope DoIT can confirm this statement and provide a link to > documentation. Maybe, this is the right thing for Duo: > https://umbc.atlassian.net/wiki/spaces/faq/pages/30743265/Multi-Factor+Authentication+with+DUO > [STAFF] > On Tue, Apr 8, 2025 at 2:26 PM RT API via RT <[EMAIL]> wrote: >> Greetings, >> This message has been automatically generated in response to the creation of a ticket regarding you were Cc'd on: >> ------------------------------------------------------------------------- >> Subject: 'Help with something else - Access on chip' >> Message: >> First Name:                [USER] >> Last Name:                 [USER] >> Email:                     [EMAIL] >> Campus ID:                 [ID] >> Request Type:              Help with something else >> Hi There, >> I am student of [STAFF] and I have no access to enter on chip.rs.umbc.edu, though i have access to go on ADA and TAKI cluster. >> my username is [USER] >> When i signin using ssh [USER]@chip.rs.umbc.edu >> I get an error message 'Access is not allowed because you are not enrolled in Duo. Please contact your organization's IT help desk.' >> Could you please help me to signin in chip for my simulation studies. >> My operating system is UBUNTU 20.04 LTS >> Regards >> [USER]"
"3160611","68605732","2025-04-08 18:56:02","High Performance Computing - Can Anaconda be installed on chip?","Hi [USER], Anconda2 and Anaconda3 (with some sub versions) are all installed on chip via the module system. You can view the modules with `module avail`, but you'll need a slurm allocation to load modules and build environments. Here's an FAQ page that discusses the use of conda on chip: https://[DOMAIN]/wiki/spaces/faq/pages/[PAGEID]/conda+virtual+environments On Tue Apr [DATE] [TIME], [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Computing For a project that we'd like to do on chip.rs.[DOMAIN] we need Anaconda. Can that be installed for all users? I think many others will want it as well."
"3160632","68641886","2025-04-10 13:17:56","High Performance Computing - chip jupyter","Hi [STAFF], Please open a new ticket, as this is a separate issue from what was originally the problem. On Wed Apr 09 12:54:32 2025, [USER] wrote: thanks I opened the jupyter notebook; however, unfortunately, again the same problems occurred in ada I can see here, regarding tensorflow installation I see the error below: ERROR: Could not install packages due to an OSError: [Errno 28] No space left on device: '/home/[USER]/.local/lib' My code in jupyter lab console1: TMPDIR='/umbc/rs/vjaneja/users/[USER]/' python3 -m pip install 'tensorflow[and-cuda]==2.16.1' The ssh tunnel you got from your jupyter.slurm file is for ada. This is set on line 42 of your file. Please change ada to chip, and it should work. Let me know if you have any other issues. Hi [USER], I am using chip now. I requested a gpu using this: sbatch jupyter.slurm The job id is: 3912. I used cat *912.out and got the ssh for the tunnel and pasted it in another terminal. Then, I came back to the chip terminal and typed cat *912.err . The err file contains what I pasted below (partially pasted due to space issue): To access the server, open this file in a browser: file:///home/[USER]/.local/share/jupyter/runtime/jpserver-2561277-open.html Or copy and paste one of these URLs: http://g24-05:15114/lab?token=778479e5af372b09daee10ea83d69e3114697171ecd852d9 http://127.0.0.1:15114/lab?token=778479e5af372b09daee10ea83d69e3114697171ecd852d9[I 2025-04-08 14:04:33.558 ServerApp] Skipped non-installed server(s): bash-language-server, dockerfile-language-server-nodejs, javascript-typescript-langserver, jedi-language-server, julia-language-server, pyright, python-language-server, r-languageserver, sql-language-server, texlab, typescript-language-server, unified-language-server, vscode-css-languageserver-bin, vscode-html-languageserver-bin, vscode-json-languageserver-bin, yaml-language-server However, the provided urls do not open anything when pasted in my browser. Any other things that I need to do so my jupyter will be connected to gpus?The path to my jupyter.slurm is: /nfs/rs/vjaneja/users/[USER]/"
"3160634","68669865","2025-04-11 15:20:48","High Performance Computing - Getting error on creating anaconda environment","Hi [USER], Please give it a try now. We've established a change to people's environments that should allow them to create new conda environments without it saving their environments to their home directories and filling up. Let me know if you have any problems. On Wed Apr 09 09:35:08 2025, [STAFF] wrote: Sure, here it is. Best [USER] On Tue, Apr 8, 2025 at 4:43 PM [EMAIL] via RT wrote: Ticket Last Update From Ticket: Hi again, Could you share the entire error message produced by conda? Just paste it into the ticket. On Tue Apr 08 15:20:02 2025, [STAFF] wrote: Thank you for your quick response. I tried your solution but still getting the same error. '''conda create --prefix /umbc/rs/[USER]/users/[USER]/conda_envs/test-env python=3.10 Channels: - defaults Platform: linux-64 Collecting package metadata (repodata.json): failed NoSpaceLeftError: No space left on devices.''' What can I do? Thanks again. Best [USER] On Tue, Apr 8, 2025 at 3:07 PM [EMAIL] via RT wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey. If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3160634 Thank You _________________________________________ Resolution: Hi [USER], By default, conda will attempt to write to your home directory. You can specify '--prefix' and then give a file path to instruct conda to write the conda environment elsewhere. I.e., `conda create --prefix /umbc/rs/[PI UMBC Username] /users/[USER]/test-env` On Tue Apr 08 14:54:02 2025, [STAFF] wrote: Request Type: High Performance Computing Hi, I am trying to create anaconda environment on my account but getting an error. '''conda create -n tushar python=3.10 Channels: - defaults Platform: linux-64 Collecting package metadata (repodata.json): failed NoSpaceLeftError: No space left on devices.''' I understand that this is because there is limited space on my account. Priorly I used my PI's directory to store files and install environment packages. For the chip system, how can I do that? Thanks."
"3160722","68611033","2025-04-08 21:31:39","High Performance Computing - Slurm issue [ Chips /  ]","Hi [USER], Please arrange video session. I really need help for my data collection. My paper is under way for only graph. Your help will be appreciated. Regards [USER] On Tue, Apr 8, 2025 at 5:27 PM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: [USER] and [USER], [USER], I think you need to be a little more specific in your questions. That said, in my opinion, emailing back and forth through an RT ticket is not the best experience. I would encourage you two to set up a short video conference in google meet or webex. [USER] can share his screen and show the slurm files and ask questions why certain things might not be working. Taking 15 minutes to talk will likely be quicker and less stressful than going back and forth with email/tickets. Thanks On Tue Apr 08 15:36:40 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Computing Hi There, Thankyou for your prompt help. I further need assistance to update my slurm file according to chips. Previously i was using taki without any problem. This is the same slurm as was on TAKI. Accout is pi_gobbert. I added my advisor Dr. [USER] with this message. Please help. Attachment 1: slurm-screenshotScreenshot from 2025-04-08 15-32-51.png Attachment 2: item_13.spot38.slurm"
"3160731","68625511","2025-04-09 16:45:55","High Performance Computing - Batch Script for running on Chip Cluster","Ollama version 0.6.5 has been installed on chip, you can load it using 'module load ollama' -- Kind regards, [STAFF] On Tue Apr 08 19:36:13 2025, [USER] wrote: Hello, I'm actually running on chip-gpu, but I used sinfo to find the right partition and it worked! I also wanted to ask if the ollama module has been set up on chip. I'm checking the list of modules and I don't see it. On Tue, Apr 8, 2025 at 4:49PM [STAFF] via RT UMBCHelp@rt.umbc.edu wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3160731&ticketsubject=High%20Performance%20Computing%20-%20Batch%20Script%20for%20running%20on%20Chip%20Cluster If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3160731 Thank You R e s o l u t i o n: Hello [USER], In your script, you are attempting to request a GPU with the type of rtx_8000. The nodes from Ada with rtx_8000 GPUs are not yet fully integrated into Chip, so requesting one will fail, as they do not exist at the moment. They will shortly, however, in the mean time you can specify one of the other cards available. If you run the command 'scontrol show nodes', you can see a list of all available GPU nodes, and what GPU constraint options are present. Under the 'AvailableFeatures' option, you can see the different options for requesting GPUs. Currently, we have nodes with Nvidia RTX 2080's, Nvidia L40S's, and Nvidia H100's. Before requesting a specific GPU, make sure the nodes with those GPU's are available for jobs. -- Kind regards, [STAFF] DOIT Unix Infra Student Worker On Tue Apr 08 15:42:20 2025, [USER] wrote: First Name: [FIRST NAME] Last Name: [LAST NAME] Email: [EMAIL] Campus ID: [CAMPUS ID] Request Type: High Performance Computing Before the Chip migration, I was on ADA would compile a batch script that would specify the job requirements and submit a job for me. When I try compiling it in the Chip cluster, I get the error message: sbatch: error: Batch job submission failed: Invalid feature specification I'm wondering what the correct specifications are to submit a batch of jobs. I'll also provide the batch script I'm using Attachment 1: llm-scraper-batch.sh (https://umbc.box.com/s/hurdduw11u1banwwd0kika0wmbvxex6u) Original Request: Requestors: [USER] First Name: [FIRST NAME] Last Name: [LAST NAME] Email: [EMAIL] Campus ID: [CAMPUS ID] Request Type: High Performance Computing Before the Chip migration, I was on ADA would compile a batch script that would specify the job requirements and submit a job for me. When I try compiling it in the Chip cluster, I get the error message: sbatch: error: Batch job submission failed: Invalid feature specification I'm wondering what the correct specifications are to submit a batch of jobs. I'll also provide the batch script I'm using Attachment 1: llm-scraper-batch.sh (https://umbc.box.com/s/hurdduw11u1banwwd0kika0wmbvxex6u)"
"3160842","69028220","2025-04-30 11:25:36","High Performance Computing - Submitted batch job 2893 on cluster chip-cpu","The provided text appears to be a series of email exchanges between Roy Prouty and others, discussing various topics related to research computing. The emails are formatted in a nested style, with each response indented and separated by a line of dashes.  After reformatting the text for better readability, I noticed that there is no specific question or problem statement presented. The emails seem to be discussing the installation of software packages, including Geant4 and ROOT, on a computing cluster. There are also mentions of scheduling meetings and sharing Slurm files.  If you could provide more context or clarify what specific issue or question you would like help with, I'll do my best to assist you."
"3161248","68708721","2025-04-14 15:31:15","Any file transfer 3rd party software that supports CHiP on UBUNTU","Hi [USER], Here are the instructions for the linux VPN client: https://docs.paloaltonetworks.com/globalprotect/6-2/globalprotect-app-user-guide/globalprotect-app-for-linux/use-the-globalprotect-app-for-linux You should be able to download the zipped tar file here: https://drive.google.com/file/d/1cKFRjv8bt0JQ0h_eS2kXLQhtQbbDfZs7/view?usp=sharing Let me know if this client works better for you on a linux machine. You are also free to use any VPN client software, but it might take more configuration on your end. Either way, point the client to gpvpn.[USER.DOMAIN] On Wed Apr 09 17:20:57 2025, [STAFF] wrote: Dear [STAFF], this doesn't helped me. For linux none method worked. Do you have any other alternate. Regards On Wed, Apr 9, 2025 at 3:06 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.[USER.DOMAIN]/Ticket/Display.html?id=3161248 > Last Update From Ticket: Hi, [USER], I rarely use VPN. But WinSCP works -- with a Duo push. That is from Windows, of course. To be sure, I only started really using chip last week, so my experience is pretty thin, as well. Are you trying to connect from a Linux machine or Windows? [STAFF] On Wed, Apr 9, 2025 at 2:07 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.[USER.DOMAIN]/Ticket/Display.html?id=3161248 > Last Update From Ticket: Hi [USER], If you sign-in to the campus VPN, these issues should be resolved. Under immense pressure from state and federal security guidelines, we've had to move the campus HPC resources to a networking setup that requires either campus VPN or Duo 2FA. Duo 2FA is likely what's causing the file transfer programs to hang and fail. You skirt the 2FA by being on the VPN. Let me know if this helps or if there are related issues. On Wed Apr 09 10:35:52 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: Help with something else OS: UBUNTU 20.04 Previously I was using nautilus cmd to fasten my work and to manage folders systematically. Since with this chip update, i find it hard to have interactive way to file transport or download rather to open new terminals every time which seems to be cumbersome. Any suggestions available to follow on web link to install any 3rd party firewall to transfer files easily. Example : filezilla ? screenshot attached. Thankyou Attachment 1: Screenshot from 2025-04-09 10-35-11.png -- [STAFF] DoIT Research Computing Team"
"3161525","68880844","2025-04-22 22:07:56","HPC Other Issue: tensorflow installation","The error message indicates that there is no space left on the device '/home/zkhanja1/.local/lib'. This is likely because the .local directory is located in your home directory, which has limited storage space.  To resolve this issue, you can try the following:  1. Remove any unnecessary files or directories from your home directory to free up space. 2. Consider moving your .local directory to a different location with more available storage space.  Here is an example of how to move the .local directory: ``` mkdir -p /umbc/rs/vjaneja/users/zkhanja1/.local mv /home/zkhanja1/.local/* /umbc/rs/vjaneja/users/zkhanja1/.local/ rm -rf /home/zkhanja1/.local ln -s /umbc/rs/vjaneja/users/zkhanja1/.local /home/zkhanja1/.local ``` This will move the contents of your .local directory to a new location and create a symbolic link to that location from your home directory.  Alternatively, you can also try installing tensorflow in a different location using the `--prefix` option with pip. For example: ``` pip install --prefix=/umbc/rs/vjaneja/users/zkhanja1/.local tensorflow[and-cuda]==2.16.1 ``` This will install tensorflow to the specified prefix location instead of the default .local directory.  Let me know if you have any further questions or concerns!"
"3161549","68629821","2025-04-09 18:31:03","HPC Other Issue:  Urgent: No Space Left on Chip Cluster - Need Assistance Accessing Ada Storage","Please review all documentation available on our website (hpcf.umbc.edu) for information about chip. You will see that all home directories are limited to 500MB of storage. Your PI has a research volume for storage of large amounts of data, which is mounted to /umbc/rs/pi_group/. Under this directory, there is a directory for your user (located at /umbc/rs/pi_group/users/[USER]). Under this directory, you can store all data you are working on. In your home directory, there are hidden folders for conda, pip, and other programs. When installing packages, these can get filled quickly. To mitigate this, we recommend you move these folders to your directory at /umbc/rs/pi_group/users/[USER], and create a symbolic link to them. Here are the instructions on how to do that: # move ~/.local directory to /umbc/rs/pi_group/users/[USER]/ mkdir /umbc/rs/pi_group/users/[USER]/.local mv -R ~/.local/* /umbc/rs/pi_group/users/[USER]/.local # remove old .local directory rm -rf ~/.local #symbolic link the new .local to users home folder ln -s /umbc/rs/pi_group/users/[USER]/.local/ ~/.local After looking at your home directory, it seems to be mostly .cursor-server and .vscode-server. You can use the same steps above for these folders as well. I recommend also moving the .conda folder too. Moving these folders to your research volume will prevent your home directory from being filled.   I am writing to you because I am encountering an issue with storage space on the Chip computing cluster. Whenever I attempt to install any software or create a new environment, I receive an error message indicating that there is no space left on the device. I understand that there are two computing clusters, Chip and Ada. I currently only have an account on the Chip cluster. However, I was advised to utilize the storage available on the Ada cluster. Could you please assist me with accessing and utilizing the storage on the Ada cluster from my Chip account?"
"3161587","68819233","2025-04-18 18:56:57","HPC Other Issue: CHIP JOB NOT ABLE TO SUBMIT","It seems like you've provided a large amount of text that appears to be an email thread or a conversation about a technical issue with running a job on a high-performance cluster. However, I'll try to summarize the key points and provide some guidance.  **Summary:**  * The user, Saksham Kumar Sharma, is having trouble running a job on a high-performance cluster using the `sbatch` command. * They have created a file called `ihmi_memorizing_five_tokens.py` in their home directory (`home/ssharma8/`) and want to submit a job using a script called `job2.ssh`. * The user has reached out to Max Breitmeyer, a Unix Infra Student Worker, for assistance.  **Potential Issues:**  1. **File permissions:** Make sure that the file `ihmi_memorizing_five_tokens.py` has the correct permissions and is executable. 2. **Script formatting:** Verify that the script `job2.ssh` is properly formatted and contains the necessary commands to run the job. 3. **Cluster configuration:** Check if there are any issues with the cluster configuration or resource availability that might be preventing the job from running.  **Next Steps:**  1. Provide more information about the error message or output you receive when trying to run the job. 2. Share the contents of the `job2.ssh` script and the `ihmi_memorizing_five_tokens.py` file. 3. Check with Max Breitmeyer or other cluster administrators for guidance on troubleshooting and resolving the issue.  If you have any further questions or would like more specific assistance, please feel free to ask!"
"3161588","68650047","2025-04-10 16:12:45","HPC Slurm/Software Issue: Requesting more space","Hi [USER], From the screenshots you provided I see you are getting an error when installing packages to your virtual environment. The error you encountered indicates that there is no space left in your home directory, specifically when conda is trying to write to the .local directory (/home/[CAMPUS_ID]/.local). This is happening because your home directory has a 500MB storage limit, and .local, located in your home directory, is exceeding that. To identify what's taking up space, you can run the following command: du -sh ~/* .[^.]* | sort -h In your case, .local will likely be the issue. To resolve this: 1. Move your .local directory to research storage: mv .local /umbc/rs/$groupname/users/[USER]/ 2. Create a symbolic link to the new location: ln -s /umbc/rs/$groupname/users/[USER]/.local .local After making these changes, you should be able to install packages without encountering the 'no space left' error. Since your .local is in your research volume that has more storage compared to your home directory. Let me know if you are still getting no space left error. On Wed Apr 09 14:48:40 2025, [STAFF] wrote: First Name: [USER] Last Name: [LAST_NAME] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Cluster I request to allow me to have some more space in the GPU iam left with 82 GB which I haven't used. Attached are the images please do the needful Best, [STAFF]"
"3161625","68649764","2025-04-10 16:05:17","HPC Other Issue: Conda installation on CHIP help","Hello [USER]  First, please make sure to start an interactive job before loading Conda and running commands.  To set up your Conda environment and install packages, follow the instructions provided here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1032814637/conda+virtual+environments  However, before installing packages, there's an additional step required. You're encountering a 'no space left' error in your home directory—specifically when Conda tries to write to .local or .cache (e.g., /home/[USER]/.local). This is because your home directory has a 500MB storage limit, and virtual environments often write to these hidden folders during package installation and setup. As a result, these hidden files can exceed the storage limit of your home directory. To avoid this error: 1. Move your .local and .cache directories to your research storage: mv .local /umbc/rs/[GROUPNAME]/users/[USERNAME]/ mv .cache /umbc/rs/[GROUPNAME]/users/[USERNAME]/ 2.Create symbolic links to the new locations: ln -s /umbc/rs/[GROUPNAME]/users/[USERNAME]/.local .local ln -s /umbc/rs/[GROUPNAME]/users/[USERNAME]/.cache .cache After making these changes, you should be able to install packages without encountering the 'no space left' error.  In the future, if you want to identify what’s taking up space in your home directory, you can run the following command: du -sh ~/* .[^.]* | sort -h Let me know if you are still getting no space left error. On Wed Apr 09 15:20:37 2025, [STAFF] wrote: > Request Type:              High Performance Cluster >=20 > Hello, I was wondering if anyone could help me install Conda on CHIP. I have been trying but keep getting an error about memory space, and it's time-consuming. Thank you. Best, [STAFF]"
"3161716","68771285","2025-04-16 18:15:05","Common Name:  *.rs.umbc.edu - Expires :  04/22/2025","[STAFF] Seven day notice. -- [USER], [EMAIL]"
"3161947","68657486","2025-04-10 19:18:25","HPC Slurm/Software Issue: Problems with submitting jobs on CHIP general partition","Having tickets that track different workflows is crucial for internal documentation and tracking changes to the cluster. When putting in a new ticket please provide as much information as possible such as specific modules used on the old cluster login node and exact error messages seen. Is mpi (mpi4py) still downloaded on the cluster? Getting 'Command not found' errors when trying to run the mpiexec function. If agree issue is resolved please give feedback by completing a satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=3DSV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=3DEIS&ticketid=3D3161947&ticketowner=[STAFF]&ticketsubject=3DHPC%20Slurm%2FSoftware%20Issue%3A%20Problems%20with%20submitting%20jobs%20on%20CHIP%20general%20partition For most things on Chip now specify the cluster when using slurm. Used command 'sacct -j 3336 --cluster=chip-cpu' and got output: JobID           JobName  Partition    Account  AllocCPUS      State ExitCode ------------ ---------- ---------- ---------- ---------- ---------- -------- 3336          ITTF_test    general   pi_erill          5     FAILED 127:0 3336.batch        batch              pi_erill          5     FAILED 127:0 Similarly with command 'sacct -u [USER] --cluster=chip-cpu': JobID           JobName  Partition    Account  AllocCPUS      State ExitCode ------------ ---------- ---------- ---------- ---------- ---------- -------- 3328         ITTF_test+    general   pi_erill          5     FAILED 127:0 3328.batch        batch              pi_erill          5     FAILED 127:0 ...  Request Type: High Performance Cluster. Experiencing problem submitting jobs using CHIP on general partition. Submit slurm script as job using sbatch in chip-cpu cluster with general partition receive message that job has been submitted with certain job ID but does not actually submit."
"3162286","68683906","2025-04-11 21:08:16","Storage: create pi directory on the chip cluster","I'm still not seeing the same thing you are. As your user I was able to make a directory and edit a file using vim: [USER@chip USER]$ mkdir doit_test [USER@chip USER]$ ls doit_test finetuning_sets finetuning_sets_small obs obs_small second_models second_obs test test.txt third_models third_obs [USER@chip USER]$ pwd /umbc/ada/[STAFF]/users/[USER] [USER@chip USER]$ cat test.txt testing [USER@chip USER]$ vim test.txt [USER@chip USER]$ cat test.txt testing this is a test done by your sys admin [USER@chip USER]$ I may be able to help more if you could either copy the output of your terminal or paste a picture, but certainly from my end I'm seeing no reason you shouldn't be able to run these commands. On Fri Apr 11 15:37:25 2025, [STAFF] wrote: > I cannot create folders (permission denied) at that directory. > I cannot save modified files using nano or via. > Thanks, [USER] >=20 > [STAFF] <[EMAIL]> 2025=04=11 = 15:42: > [USER], > Please describe the problem you have. Thanks > [STAFF] > On Apr 11, 2025 at 13:30, [STAFF] via RT <umbchelp@rt.umbc.edu> wrote: > Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3162286> > Last Update From Ticket: > Hi [STAFF], I was able to get to the users directory as their user: [USER@chip USER]$ pwd /umbc/ada/[STAFF]/users/[USER] Can you expound a little bit on what the error they are see is? On Fri Apr 11 13:17:15 2025, [USER] wrote: > Hello, Thanks for the information. I was able to fully access the directory, e.g., /umbc/ada/[STAFF]/users/[STAFF] However, my student, [USER], reported he could not access his /umbc/ada/[STAFF]/users/[USER] Is there any permission problem that needs to be corrected? This may also affect other student directories under /umbc/ada/[STAFF]/users/ Thank you! [STAFF] On Thu, Apr 10, 2025 at 3:23 PM [STAFF] via RT <UMBCHelp@rt.umbc.edu> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customemail=[EMAIL]&groupid=EIS&ticketid=3162286&ticketowner=mb17%40umbc.edu&ticketsubject=Storage:%20create%20pi%20directory%20on%20the%20chip%20cluster If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3162286> Thank You R e s o l u t i o n: Hi [STAFF], All data that was on Ada and Taki have been mounted to chip. I would highly recommend reading through this document (https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/START+HERE). Some of this may be familiar to you, but there are many changes to Chip from Taki/Ada, and reading this may save you some time! In the meantime, you can access all your storage from /umbc/rs/[STAFF] or /umbc/ada/[STAFF] (depending on where you stored your data previously. Hopefully this helps! On Thu Apr 10 12:50:02 2025, [USER] wrote: First Name: Keke Last Name: Chen Email: [EMAIL] Campus ID: [USER] Request Type: Research Storage Research Storage action: Request new allocation Hello, Since we are moving to the chip cluster, I will need to have the pi directories to store large datasets. Could you please help create them? Thank you -- Best, [STAFF] DOIT Unix Infra Student Worker"
"3162567","68671970","2025-04-11 16:00:15","HPC Slurm/Software Issue: Unexpected 'unknown command mpiexec'","I realized you replied to this ticket. Are you still unable to run your slurm script? On Fri Apr 11 11:53:00 2025, [STAFF] wrote: Changes from taki to CHIP. El vie, 11 abr 2025 a la(s) 11:07?a.m., [STAFF] via RT (UMBCHelp@rt.umbc.edu) escribi?: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3162567&ticketowner=[STAFF]&ticketsubject=HPC Slurm/Software Issue: Unexpected 'unknown command mpiexec'. If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3162567 Thank You. _______________________________________. R e s o l u t i o n: Hello In order to run the command mpiexec, you will need to load the module mpich. There are couple of things that have changed when transitioning to chip. One of the changes is on loading modules. It is not possible to load a module in the login node instead you will need to load a module during an interactive job or in your slurm file. If you ran the command `module keyword MPICH`, you will be able to see what is available. In your case, you can add the command `module load mpich/ge/gcc/64` in your slurm script before executing mpiexec . That should resolve your error. Let us know if you still have the command not found error. On Thu Apr 10 17:48:10 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID]. Request Type: High Performance Cluster Hello, I hope you've been well. In the transition from taki to chip, I've now become unable to use mpi to run my python scripts in parallel. With taki, I recall being able to use the mpiexec command to run scripts in a batch job (mpiexec would be in the slurm script). In chip, when I attempt to do the same thing, an error message is returned (/cm/local/apps/slurm/var/spool/job03418/slurm_script: line 14: mpiexec: command not found ). An example of the situation which leads to this error message is in job 3418. Help would be greatly appreciated, so that I may run my workflow. A picture of my slurm script is shared. Thank you Attachment 1: mpierror.png (https://umbc.box.com/s/3kzmdxusdvet1dv5e9appu0gxaxy3rd1)."
"3163299","68756809","2025-04-16 12:56:07","HPC Other Issue: Is MATLAB available?","Looks like we need to get X11 configured for the cluster to get this working. In the meantime, you can pull the files to your local machine using scp and view them from there. Let me know if you have questions about this. On Mon Apr 14 10:55:51 2025, [USER] wrote: Hi [STAFF], Ok cool! The basic doodads work. Then the not so good news Here's the first issue, I can't get any plots showing up!! It says all the right things but nothing shows up plot(1:10) Fontconfig warning: '/usr/share/fontconfig/conf.avail/05-reset-dirs-sample.conf', line 6: unknown element 'reset-dirs' Warning: MATLAB has disabled some advanced graphics rendering features by switching to software OpenGL. For more information, click here. My usual test for this is to run 'xeyes' but that does not work, both on the cluster, or on chip headnode itself. Is there an alternative? This is how I get onto the machines ssh -X -Y -l [USER] strowinteract.rs.[DOMAIN] ssh -X -Y -l [USER] chip.rs.[DOMAIN] and I don't (usually) have problems with graphs in strowinteract coming over to my desktop at home or at [ORGANIZATION]. Secondly, just a gut feeling, but matlab seemed a bit slow to load up. Not sure about that, maybe comparing to strowinteract. Even getting it to accept takes a while ... -[USER] On Mon, Apr 14, 2025 at 10:28 AM [STAFF] via RT <[EMAIL]> wrote: Hi [USER], The matlab version you requested has successfully installed on c18/c21. Try it out and let me know if there are any issues! I'll go ahead and close this ticket out for now. Please feel free to put in new ones when issues arise. On Mon Apr 14 10:24:11 2025, [USER] wrote: HI [STAFF], OK here are my answers for now a) oops, ok I'll let Larrabee know about the limitation onto which partition we can submit our jobs b) yep c) It's just that some of the libs we used last year on taki are not on chip .. don't worry about it for now, as I said for one of my codes I linked to the newer libs. d) ok, I'll look into this git issue e) that is something I need to get correct/discuss with Larrabee so it may take a few iterations to get everyone happy f) I guess we can see each other's stuff through /asl/s1 so I'll live with that. Cheers [USER] On Mon, Apr 14, 2025 at 9:48 AM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: No worries! It's not that he doesn't see them, he's not on the frontlines of these tickets anymore! Our team is expanding so you'll likely see more names appear in the next few weeks! In the meantime, I'll work to get that version installed. I sent you a message re:symbolic links in the other ticket you sent. I'll let you know once the version of matlab you need installed. On Mon Apr 14 09:30:04 2025, [USER] wrote: Hi [STAFF], Oh, I didn't realize Roy was not seeing these emails.! Anyway, I just checked and I am using 23.2.0.2365128 (R2023b) on strowinteract, so could you also install that one? And please can you get those symbolic links fixed, since without them my code(s) cannot run on the chip compute nodes. Thanks [USER] On Mon, Apr 14, 2025 at 9:15 AM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hi [USER], Just as a reminder, Roy is not the frontline for tickets anymore (though he still pops in to check every so often). I'm working on getting matlab 2019b installed for you on the c18/c21 nodes. Is there a specific version/year you would also like installed? On Fri Apr 11 15:55:29 2025, [USER] wrote: First Name: [USER] Last Name: [LAST NAME] Email: [EMAIL] Campus ID: [CAMPUS ID] Request Type: High Performance Cluster Hi Roy, I'm 'learning' chip .. managed to get onto a compute node using srun --cluster=chip-cpu --account=pi_strow --partition=general --time=1:00:00 --cpus-per-task 2 -N 1 --pty /bin/bash But when I try to load matlab, nada, zillch nothing, If I do module spider or module avail, nothing about Matlab Is it not yet available? Thanks [USER]"
"3163966","68708240","2025-04-14 15:23:55","HPC Other Issue: No rxt_8000","The issue has now been resolved. Please try it out and let us know if you have any issues with it. Thanks for the note. We see the issue, and are working on a fix. We'll let you know when this is resolved. First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Cluster During my last job, I was able to use the rxt_8000. When I try to run another job with rxt_8000 it failed and I checked the availability of the nodes and its not there anymore (base) [USER@chip scripts]$ scontrol show nodes NodeName=g20-01 Arch=x86_64 CoresPerSocket=24 CPUAlloc=0 CPUEfctv=96 CPUTot=96 CPULoad=0.00 AvailableFeatures=location=local ActiveFeatures=location=local Gres=gpu:8 NodeAddr=g20-01 NodeHostName=g20-01 Version=23.11.4 OS=Linux 5.14.0-427.42.1.el9_4.x86_64 RealMemory=385581 AllocMem=0 FreeMem=328870 Sockets=2 Boards=1 MemSpecLimit=5722 State=IDLE ThreadsPerCore=2 TmpDisk=0 Weight=1 Owner=N/A MCS_label=N/A Partitions=gpu BootTime=2025-03-27T12:48:44 SlurmdStartTime=2025-04-11T14:12:47 LastBusyTime=2025-04-12T23:21:33 ResumeAfterTime=None CfgTRES=cpu=96,mem=385581M,billing=96,gres/gpu=8 AllocTRES= CapWatts=n/a CurrentWatts=0 AveWatts=0 ExtSensorsJoules=n/a ExtSensorsWatts=0 ExtSensorsTemp=n/a NodeName=g20-02 Arch=x86_64 CoresPerSocket=24 CPUAlloc=0 CPUEfctv=96 CPUTot=96 CPULoad=0.00 AvailableFeatures=location=local ActiveFeatures=location=local Gres=gpu:6 NodeAddr=g20-02 NodeHostName=g20-02 Version=23.11.4 OS=Linux 5.14.0-427.42.1.el9_4.x86_64 RealMemory=385581 AllocMem=0 FreeMem=377430 Sockets=2 Boards=1 MemSpecLimit=5722 State=IDLE ThreadsPerCore=2 TmpDisk=0 Weight=1 Owner=N/A MCS_label=N/A Partitions=gpu BootTime=2025-03-27T12:48:37 SlurmdStartTime=2025-04-11T14:12:47 LastBusyTime=2025-04-11T21:16:30 ResumeAfterTime=None CfgTRES=cpu=96,mem=385581M,billing=96,gres/gpu=6 AllocTRES= CapWatts=n/a CurrentWatts=0 AveWatts=0 ExtSensorsJoules=n/a ExtSensorsWatts=0 ExtSensorsTemp=n/a NodeName=g20-03 Arch=x86_64 CoresPerSocket=24 CPUAlloc=0 CPUEfctv=96 CPUTot=96 CPULoad=0.36 AvailableFeatures=location=local ActiveFeatures=location=local Gres=gpu:8 NodeAddr=g20-03 NodeHostName=g20-03 Version=23.11.4 OS=Linux 5.14.0-427 RealMemory=385581 AllocMem=0 FreeMem=328870 Sockets=2 Boards=1 MemSpecLimit=5722 State=IDLE ThreadsPerCore=2 TmpDisk=0 Weight=1 Owner=N/A MCS_label=N/A Partitions=gpu BootTime=2025-03-27T12:48:44 SlurmdStartTime=2025-04-11T14:12:47 LastBusyTime=2025-04-12T23:21:33 ResumeAfterTime=None CfgTRES=cpu=96,mem=385581M,billing=96,gres/gpu=8 AllocTRES= CapWatts=n/a CurrentWatts=0 AveWatts=0 ExtSensorsJoules=n/a ExtSensorsWatts=0 ExtSensorsTemp=n/a -- Best [STAFF]"
"3164085","68731105","2025-04-15 13:30:34","HPC Other Issue: Storage setup on Chip cluster","Hi [STAFF], I'll go ahead and give you ownership of his files. You can decide if you want to delete it then. On Mon Apr 14 17:38:45 2025, [STAFF] wrote: > Thanks. One more thing: Could you delete all files under /umbc/ada/[STAFF]/[USER] > The student graduated but I don't have permission to delete the files. > Thank you. > Regards, > [STAFF] --- On Mon, Apr 14, 2025 at 9:18 AM [STAFF] via RT <[EMAIL]> wrote: > If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_[ID]&customeremail=[EMAIL]&groupid=EIS&ticketid=3164085&ticketowner=[STAFF]&ticketsubject=HPC Other Issue: Storage setup on Chip cluster > If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3164085 > Thank You _________________________________________ R e s o l u t i o n: =========== Hi [STAFF], All of your storage from is mounted on chip as seen below: [STAFF]@chip ~]$ [COMMAND] [STAFF]@chip common]$ df -h ./ Filesystem Size Used Avail Use% Mounted on nfs.iss.rs.umbc.edu:/ifs/data/rs/[STAFF] 500G 33G 468G 7% /umbc/rs/[STAFF] [STAFF]@chip common]$ pwd /umbc/rs/[STAFF]/common [STAFF]@chip sjkim]$ pwd /umbc/ada/[STAFF] [STAFF]@chip sjkim]$ df -h ./ Filesystem Size Used Avail Use% Mounted on 10.2.42.254:/export/[STAFF] 1.0T 984G 40G 97% /umbc/ada/[STAFF] There are many changes to chip from ada/taki. I would highly advise that your students read through our quick start guide: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip On Sun Apr 13 14:21:15 2025, [USER] wrote: > First Name: [USER] > Last Name: [STAFF] > Email: [EMAIL] > Campus ID: [ID] > Request Type: High Performance Cluster The Chip cluster is operational and Ada is shutting down. But my students are reporting that the storage space is not available (They say other research groups have their storage available already.) We need the following mounts from Ada moved to Chip: ada-rstor:/export/[STAFF] 1.0T 984G 40G 97% /nfs/ada/[STAFF] nfs.iss:/ifs/data/rs/[STAFF] 500G 33G 468G 7% /umbc/rs/[STAFF] Could you help with this so that the students can run their tasks? They are racing against the clock to submit their papers by May 1st deadline. Thank you. -- Best, [STAFF] DOIT Unix Infra Student Worker Original Request: Requestors: [STAFF] First Name: [USER] Last Name: [STAFF] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster The Chip cluster is operational and Ada is shutting down. But my students are reporting that the storage space is not available (They say other research groups have their storage available already.) We need the following mounts from Ada moved to Chip: ada-rstor:/export/[STAFF] 1.0T 984G 40G 97% /nfs/ada/[STAFF] nfs.iss:/ifs/data/rs/[STAFF] 500G 33G 468G 7% /umbc/rs/[STAFF] Could you help with this so that the students can run their tasks? They are racing against the clock to submit their papers by May 1st deadline. Thank you."
"3164327","68702926","2025-04-14 13:43:43","HPC Other Issue: some 'issues' [USER] has noticed on chip","Hi [USER], Correction to a., just let us know if you're having any issues with the current privileges you're having, and we can go from there. On Mon Apr 14 09:41:36 2025, [STAFF] wrote: Hi [USER], a.) This is correct. Without being a contributor to the new cluster, we cannot give anymore privilages. b.) Yep, see previous ticket, we are working on getting that installed. c.) Can you provide us with some workflows that require what you're talking about? I've doubled checked that hdf5 is certainly available. d.) This seems like an issue where you have not setup your git account on the new cluster. Remember that this is a new account/system. All your data has been transferred over, but any changes you made to your account on taki would need to be re-applied to your user on chip. Let me know if you have issues with this. e.) Looking at your directory, I do receive the same error as you, but I also see the following: ls -la lrwxrwxrwx 1 [USER] pi_[USER] 13 Jul 23 2020 rta -> /asl/xfs3/rta lrwxrwxrwx 1 [USER] pi_[USER] 20 Jul 23 2020 xfs3 -> /umbc/xfs3/[USER]/asl Is there a reason your linking things in this way? Here's a good answer on why this is happening, but I think the only thing I can suggest is to just work on cleaning your datasets so they aren't as intertwined. Happy to help more if need on this issue though. f.) This is by design. No user should (by default) have access to another's home directory. Of course, you and your users can change this with some chmod/chown commands if you feel that's it's necessary to your workflow. [USER]@chip ~]$ ls -la total 792 drwx------ 4 [USER] pi_[USER] 678 Apr 12 14:36 . This line of the 'ls' command says that only you have read/write/execute to your home directory. Hopefully all this helps! On Sun Apr 13 20:49:07 2025, [USER] wrote: First Name: [USER] Last Name: [LAST NAME] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Cluster Hi [STAFF], I tried to do some work on the chip cluster over the weekend, and solved some/ran into issues a) is this what I should always be doing to get a compute node? srun --partition=general --cpus-per-task 1 --cluster=chip-cpu --account=pi_[USER] --time=1-00:00:00 --qos=medium -N1 --pty /bin/bash (ie other than changing the queue to short/medium/long as needed, should I always be on general partition .. or can I get more privileges?) b) Matlab is unavailable on the chip cluster (headnote and compute nodes) c) ifort : for some reason with newer ifort, I also had to module load imkl/2023.1.0 Pretty sure I did not have to do this earlier on taki, Plus quite a few of the lib (hdf,nc etc) available on taki are unavailable on chip, but so far I was able to compile (one) code .. few more to go d) git issues : from above, I had to monkey around with my makefile, and forgetting I was on a compute node, was able to do git add, git commit. When I tried to push, it told me my username is different Committer: [USER] So then I exited the node, to push from chip .. and could not. So had to go back to strowinteract and git push from there. Could these issues be fixed? e) running the compiled code .. it immediately fell flat on its face on the compute node. The reason, after looking into it, was that chip can see /asl/rta But as soon as I am on a compute node, I get the following error [USER]@c18-05 WORK]$ ls /asl/rta ls: cannot access '/asl/rta': Too many levels of symbolic links [USER]@c18-05 WORK]$ ls /asl airs asl cris data ftp iasi iasi2 iasi3 isilon leroy leroy_downloads matlab2012 matlib models n20 n21 oco2 packages rta rtp s1 s2 stats users val www xfs3 Actually its more obvious in color, you will see unavailable links (see attachments) f) from chip, I cannot see /home/[USER] or /home/[USER] but I can see /asl/s1/[USER] etc (see screenshot, I can see the users but coan't look at their dirs) That's it for now, [USER]."
"3164611","68713177","2025-04-14 16:57:37","HPC Other Issue: change directory ownership in [ID]'s home directory","Hi, I have fixed all the permission issues in /umbc/rs/[USER]/common/Data. Let me know if you run into any problems when accessing the data! Have a good day!  --  Kind regards, [STAFF] On Mon Apr 14 08:52:03 2025, [USER] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [ID] >  > Request Type:              High Performance Cluster >  > There are several directories in the directory > /umbc/rs/[USER]/common/Data owned by 'root'. Can you change the > ownership to '[USER]'? Thanks. >  >  >  > ./Polarization_Cloud_Aerosol_Remote_Sensing > ./GEO_AERONET > ./Scanza_Dust_CRI > ./ML_DUST_input_data > ./LES_cases > ./meng_database > ./Subgrid_cloud_var > ./TAMUdust2020 > ./VIIRS > ./MAIAC > ./ryder_2019_fig9_data > ./PACE > ./NIST_FiB_dust_database > ./LUT_Smoke_NA > ./Global_dust_from_HongbinYu > ./RSP"
"3165012","68731183","2025-04-15 13:33:00","HPC Other Issue: module load Anaconda3/2024.02-1 doesn't work","Hi [USER], Note the file location of your TMPDIR variable. That doesn't exist on chip, and was the old location used on ada. Please read through our startup guide (found here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip) on the new locations of things. On Mon Apr 14 14:28:55 2025, [STAFF] wrote: > Hi, > I just cleaned up my home directory. Can you make sure my cleaning is successful? And now, I create an interactive job on node g20-02 with conda environment. I want to install a torch library but it seems that space is limited. When I use TMPDIR='/nfs/ada/[STAFF]/users/[USER]' pip install torch, it still shows no space limit. What can I do to install torch library? Thanks! > Best, [USER] On Mon, Apr 14, 2025 at 1:28 PM [STAFF] via RT wrote: > If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3165012&ticketowner=[STAFF]&ticketsubject=HPC Other Issue: module load Anaconda3/2024.02-1 doesn't work > If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3165012 > Thank You > _________________________________________ R e s o l u t i o n: = = = = = = = = = = = = = = = = = Hi [USER], The first thing I'm noticing is that your home directory is full: (base) bash-5.1$ du -h | sort -h ... 693M ./.cache/pip/http/3/2/5/3/9 764M ./.cache/pip 764M ./.cache/pip/http 769M ./.cache 793M . (base) bash-5.1$ I would start by cleaning up your home directory as being this full (you only have 500MB of space on in your home directory) can have major consequences on how the nodes interact with you. I've also verified that other users are able to access the anaconda module on the compute nodes, and the only difference between you and them is their home directories. Let me know if you have questions about how to do this. On Mon Apr 14 12:37:43 2025, [USER] wrote: > First Name: [USER] > Last Name: [USER] > Email: [EMAIL] > Campus ID: [CAMPUSID] > Request Type: High Performance Cluster Hi officer, I follow the steps in https://umbc.atlassian.net/wiki/spaces/faq/pages/1032814637/conda+virtual+environments. I firstly create a interactive job srun --cluster=chip-gpu --account=pi_[STAFF] --mem=48GB --time=2:00:00 --gres=gpu:2 --pty $SHELL And then I command module spider anaconda and when I module load Anaconda3/2024.02-1 it shows Note: Modules do not function on the login nodes. After that I use hostname, the system shows g24-05. It looks like I am not on the login nodes. Can you help me fix this problem? Thanks! Attachment 1: Screenshot 2025-04-14 at 12.37.10PM.png (https://umbc.box.com/s/eug10wosaubsvt10k1nkt26qwenqs07n) Best, [USER]"
"3165138","69138511","2025-05-05 13:41:33","Failure of the NASA ftp service","Since there's been no updates and the test works for me now I'm marking this RT as resolved."
"3165186","68723772","2025-04-14 20:51:52","Error with starting run on CHIP","To kill/cancel jobs on the chip cluster, you now need to specify the -M flag with the scancel command. For example, to cancel job id 3515 running on chip-cpu, you would run 'scancel -M chip-cpu 3515'. You need to specify the cluster that the job resides on. If running a gpu based job, you would specify chip-gpu instead. I have looked at your job, and cannot see any reasons popping out immediately on why it would not properly run. If you still continue to experience issues when running that job, I would recommend attempting to create an interactive job in slurm, with the same specifications as the SBATCH file, and manually run the commands. You might be able to narrow down the specific item causing issues better that way. You can find some information about running interactive slurm jobs here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1033142321/Using+slurm#How-do-I-run-an-interactive-job? Let me know if you continue experiencing issues with running your jobs! My apologies about that. I've attached the screenshots to this email. The job in question is #3515. The code I have been using in the slurm script works, I have started other runs with it, but I can't seem to kill job 3515 despite multiple attempts. It is the job with the error 'Launch Failed Requeued Held'. In general, does the command scancel not work in chip to cancel jobs? Best, [USER] On Mon, Apr 14, 2025 at 2:58 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3165186> Last Update From Ticket: Hi [USER], There is no screenshot attached. Could you provide the path to the script and the commands you are attempting to run? -- Kind regards, [STAFF] DOIT Unix Infra Student Worker On Mon Apr 14 14:35:22 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Hello, I have been working on getting runs started on CHIP since the transition from TAKI and I have encountered an issue. I submitted a job on Friday and it has been in the pending stage since then. The accompanying message is 'launch failed requeued held', but there are no error messages in my error output folder. I have similarly been unable to kill the job in order to attempt a new run. I have included a screenshot of the accompanying slurm script. Thank you! Best, [USER]"
"3165242","68730004","2025-04-15 13:01:34","HPC Other Issue: [USER] cannot get X plots from chip to show up on home/office desktop","Hi [USER] I always use these to get onto taki or chip from home/office desktop ssh -X -Y -l [STAFF] strowinteract.rs.umbc.edu ssh -X -Y -l [STAFF] chip.rs.umbc.edu [USER] asked me to see if I could open xterm on the machines. And yes I can open xterm on chip and see it from my home computer. But then when I get a compute node and start matlab, first no matlab logo splash shows up, then there are errors, and then no plot shows Conversely if I log into chip, then go into a compute node and try to start xterm, there are errors Can you help resolve these errors? Thanks [STAFF] On Mon, Apr 14, 2025 at 3:14 PM via RT <[EMAIL]> wrote: Greetings This message has been automatically generated in response to the creation of a ticket regarding Subject 'HPC Other Issue cannot get X plots from chip to show up on home/office desktop' Message First Name [USER] Last Name [USER] Email [EMAIL] Campus ID [CAMPUSID] Request Type High Performance Cluster Hi [STAFF] I still cannot get plots from Matlab to display on my desktop (home of office) I've tried to duplicate the essentials of my .bashrc and .ssh/config on chip, to look like the ones on strowinteract, but no luck Could you look at my .bashrc and .ssh on chip and fix them/tell me what to do? Thanks [STAFF] Your ticket has been assigned an ID of [RESEARCH COMPUTING #3165242] or you can go there directly by clicking the link below Ticket <URL https://rt.umbc.edu/Ticket/Display.html?id=3165242> You can login to view your open tickets at any time by visiting http://my.umbc.edu and clicking on 'Help' and 'Request Help' Alternately you can click on http://my.umbc.edu/help Thank you"
"3165265","68826041","2025-04-19 16:18:25","HPC Slurm/Software Issue: Accessing Chip cluster","Yes you can mark this as resolved Thank you  Hi [USER] Taki is for all intents and purposes chip I saw that you had a ticket open with [STAFF] that has resolved Does that mean this can be closed as well On Wed Apr [NUMBER] [NUMBER]:[NUMBER]:[NUMBER] [NUMBER] wrote: Is it possible to access taki for a couple of weeks in the meantime while I figure out how to set my projects up in chip It wasn't clear from the emails that nothing was going to work when I switched over and it's going to take a while to figure it out I have an upcoming deadline and literally can't make any progress on my work without access to the HPCF Thanks [USER] On Mon Apr [NUMBER] at [TIME]=E2=80=AFPM [STAFF] via RT wrote: If you agree your issue is resolved please give us feedback on your experience by completing a brief satisfaction survey https://umbc.us[NUMBER].qualtrics.com/SE/?SID=SV_etfDUq[NUMBER]MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=[NUMBER]&ticketowner=[STAFF]&ticketsubject=HPC Slurm/Software Issue Accessing Chip cluster If you believe your issue has not been resolved please respond to this message which will reopen your ticket Note A full record of your request can be found at Ticket https://rt.umbc.edu/Ticket/Display.html?id=[NUMBER] Thank You -- Kind regards [STAFF] DOIT Unix Infra Student Worker On Mon Apr [NUMBER] [TIME]:[NUMBER] [USER] wrote: First Name [USER] Last Name [USER] Email [EMAIL] Campus ID [CAMPUSID] Request Type High Performance Cluster Hello I have an upcoming deadline and need to run jobs on the HPCF to prepare for it I'm no longer able to run jobs on taki error message Job's account not permitted to use this partition high_mem allows is[NUMBER]sp[NUMBER] not pi_[USER]) And there isn't documentation online to explain how to run jobs on Chip I can log on to chip and cd to '/home/[USER]' but it doesn't look like my research files have been migrated to Chip nfs.iss:/ifs/data/chip/home/[USER] [NUMBER]M [NUMBER] [NUMBER]% /home/[USER] And when I try to run any of these commands I get an error since my workspace is not set up on chip cd '/umbc/xfs[NUMBER]/[USER]/users/[USER]' module load Stata/[NUMBER] sbatch dhsregs.slurm Can you please tell me how I can run my code Thanks [USER] Original Request Requestors [USER] First Name [USER] Last Name [USER] Email [EMAIL] Campus ID [CAMPUSID] Request Type High Performance Cluster Hello I have an upcoming deadline and need to run jobs on the HPCF to prepare for it I'm no longer able to run jobs on taki error message Job's account not permitted to use this partition high_mem allows is[NUMBER]sp[NUMBER] not pi_[USER]) And there isn't documentation online to explain how to run jobs on Chip I can log on to chip and cd to '/home/[USER]' but it doesn't look like my research files have been migrated to Chip nfs.iss:/ifs/data/chip/home/[USER] [NUMBER]M [NUMBER] [NUMBER]% /home/[USER] And when I try to run any of these commands I get an error since my workspace is not set up on chip cd '/umbc/xfs[NUMBER]/[USER]/users/[USER]' module load Stata/[NUMBER] sbatch dhsregs.slurm Can you please tell me how I can run my code Thanks [USER]"
"3165877","68740503","2025-04-15 17:03:33","iHARP: AWS User [ID] Login Issue","resolved at user request."
"3166124","68800817","2025-04-17 19:52:23","HPC User Account: [USER] in pi_[ID]","I mean that /umbc/ada/[STAFF] was not a directory I could browse to. I confirmed it was not mounted using “df -h | grep [STAFF]”, which only showed our storage at /umbc/rs/[STAFF]. The ada mount has reappeared again though, so we are all good. Thanks for your help.  On Apr 17, 2025, at 3:30 PM, [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hello What do you mean the mount has disappeared? Are you unable to access /umbc/ada/[STAFF]/users ? You can also be redirected to /umbc/ada/[STAFF]/users, using the alias [STAFF]_ada. On Thu Apr 17 13:50:58 2025, [USER] wrote: This mount has now disappeared from Chip and is inaccessible On Wed, Apr 16, 2025 at 2:58 PM [STAFF] via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey. https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3166124&ticketowner=[STAFF]&ticketsubject=HPC User Account: [USER] in pi_[STAFF]. If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3166124. Thank You R e s o l u t i o n: Hello [USER] You can create the directory /umbc/ada/[STAFF]/users/[USER]. now, we have changed the permissions. On Tue Apr 15 12:56:53 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [USER] Request Type:              High Performance Cluster Create/Modify account in existing PI group Existing PI Email:    [STAFF]@umbc.edu Existing Group:       pi_[STAFF] Project Title:        N/A Project Abstract:     N/A Our group has some storage that was recently migrated from Ada to Chip. This is mounted at /umbc/ada/[STAFF] on Chip. I need a folder created for my own storage on this mount, at /umbc/ada/[STAFF]/users/[USER]. I don't have permission to create this folder myself. Are you able to create one for me?"
"3166252","68757828","2025-04-16 13:16:20","HPC Other Issue: [STAFF] PI Group Missing from Chip","Hi [USER], Looking it over, I can confirm that your lab was not missed and that Freeland research volume was mounted successfully: [root@chip-mgt1 chip-gpu]# id [USER] uid=[NUMBER]([USER]) gid=[NUMBER](pi_freeland) groups=[NUMBER](pi_freeland) [root@chip-mgt1 chip-gpu]# cd /umbc/rs/freeland [root@chip-mgt1 freeland]# pwd /umbc/rs/freeland We have made a multitude of changes to chip from taki/ada, and I would highly advise reading our startup guide which can be found here: https://[DOMAIN]/wiki/spaces/faq/pages/[NUMBER]/Getting+Started+on+chip Please put in a new ticket if you feel the documentation doesn't cover something in particular! On [DATE], [STAFF] wrote:  First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Good afternoon! Congratulations in successfully deploying the Chip Cluster! Unfortunately when porting over, it appears the PI group for Dr. Freeland's lab is absent. My ([USER], [EMAIL], [CAMPUSID]) user folder is present and I can log into Chip no problem but I cannot find either of the Freeland Lab spaces (freeland_user & freeland_common). Please advise, and thank you so very much! Best, [USER] Ph.D. Candidate Biological Sciences"
"3166387","68757418","2025-04-16 13:08:57","HPC Slurm/Software Issue: Jupyter Notebook Error","Hi [USER], A few things to note: 1.) You're missing some of the slurm directives such as '#SBATCH --cluster=chip-gpu' in your jupyter.slurm 2.) The ssh command you use to connect the node you've allocated still uses 'ada.rs.umbc.edu' which no longer exists. Those are the main two reasons your jupyter notebook might not be working. Additionally, you should verify the paths and names of the modules you want to use are the same on chip as they were on ada. You can find a working example of a jupyter notebook at /cm/shared/sampleScripts/chip-gpu/jupyter.slurm. Feel free to copy and paste it to your research vols. On Tue Apr 15 16:05:19 2025, [USER] wrote: > Apologies for the incomplete message. > The url generated to connect to jupyter notebook is not working http://localhost:7010/lab?token=298be4521af53bc7038c9ba802c96e1e63f907a429db3467 > Regards, [USER] On Tue, Apr 15, 2025 at 3:50 PM [STAFF] via RT <[EMAIL]> wrote: > Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3166387> Last Update From Ticket: Hi [USER], It looks like you maybe sent the ticket without finishing the error? I'm not sure what the problem is. On Tue Apr 15 15:31:33 2025, [STAFF] wrote: > First Name: [USER] > Last Name: [USER] > Email: [EMAIL] > Campus ID: [USER] Request Type: High Performance Cluster Slurm Job ID 5240 File_path: /umbc/rs/iharp/users/[USER]/ Message [I 2025-04-15 14:47:17.208 ServerApp] Skipped non-installed server(s): bash-language-server, dockerfile-language-server-nodejs, javascript-typescript-langserver, jedi-language-server, julia-language-server, pyright, python-language-server, r-languageserver, sql-language-server, texlab, typescript-language-server, unified-language-server, vscode-css-languageserver-bin, vscode-html-languageserver-bin, vscode-json-languageserver-bin, yaml-language-server -- Best, [STAFF] DOIT Unix Infra Student Worker"
"3166395","68820410","2025-04-18 19:32:56","HPC Other Issue: symbolic links for [ID]","Hi [USER], From the virtual session I attended with the others on Th, I figured out the partition option, I didn't realize nodelist also did that. I do think that Matlab is pretty 'slow' to load or exit on chip, compared to taki ... I haven't done any serious computation because of my ongoing disk access issues. BTW for srun do we always need two dashes --? I remember being confused if I thought one dash worked occasionally? As you can tell, [STAFF] has been looking at the disks more closely. On Fri, Apr 18, 2025 at 2:54 PM [EMAIL] via RT wrote: Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=[NUMBER]> Last Update From Ticket: Hi [USER], I'm not sure I see the problem? You cd to `asl`, and your pwd shows that (/home/[USER]/asl). It might be best if you schedule an office hours appointment since I think wires are getting crossed. As for how to get onto a 2021 node, you have two options. You can either: - change the partition to '2021' instead of 'general', or - specify a 2021 node using the '--nodelist' option. Either should let you onto a 2021 node. I'll leave this ticket open so that we can look back on it if you end up doing an office hour. On Wed Apr 16 13:13:17 2025, [USER] wrote: Hi [STAFF], While it works on chip, I'm still getting an infinite loop of links on a compute node See for example /home/[USER]/asl on chip and on c18-01 By the way, I assume c18 means the high-mem cpu2018 nodes, how do I get onto a cpu2021 node? Thanks Sergio On Wed, Apr 16, 2025 at 9:58 AM [STAFF] via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://[DOMAIN].us2.qualtrics.com/SE/?SID=SV_[STRING]&customeremail=[EMAIL]&groupid=EIS&ticketid=[NUMBER]&ticketowner=[STAFF]&ticketsubject=HPC Other Issue: symbolic links for asl If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=[NUMBER]> Thank You ______________________________________ R e s o l u t i o n: Done! On Tue Apr 15 15:35:14 2025, [USER] wrote: First Name: [USER] Last Name: [LAST NAME] Email: [EMAIL] Campus ID: [CAMPUS ID] Request Type: High Performance Cluster Hi [STAFF], Larrabee looked at /asl from strowinteract. He basically sees these links made by root, that are causing 'Too many levels of symbolic links' on chip [USER]@strow-interact ~]$ ls -lt /asl lrwxrwxrwx 1 root root 20 Feb 12 2019 /asl -> /umbc/xfs2/strow/asl [USER]@strow-interact ~]$ ls -lt /asl/ total 28 lrwxrwxrwx 1 root root 20 Apr 2 10:32 asl -> /umbc/xfs3/strow/asl but root made these links, so can you remove them? And please cc [STAFF] on the replies Thanks [USER] -- Best, [STAFF] DOIT Unix Infra Student Worker Original Request: Requestors: [USER] First Name: [USER] Last Name: [LAST NAME] Email: [EMAIL] Campus ID: [CAMPUS ID] Request Type: High Performance Cluster Hi [STAFF], Larrabee looked at /asl from strowinteract. He basically sees these links made by root, that are causing 'Too many levels of symbolic links' on chip [USER]@strow-interact ~]$ ls -lt /asl lrwxrwxrwx 1 root root 20 Feb 12 2019 /asl -> /umbc/xfs2/strow/asl [USER]@strow-interact ~]$ ls -lt /asl/ total 28 lrwxrwxrwx 1 root root 20 Apr 2 10:32 asl -> /umbc/xfs3/strow/asl but root made these links, so can you remove them? And please cc [STAFF] on the replies Thanks [USER]."
"3166470","68769778","2025-04-16 17:46:30","HPC Other Issue: Request for Additional Storage Account on /umbc/ada","I understand now. You don't have a directory in the /umbc/ada/manas/users space. I've created this directory for you. It is named '[USER]'. This directory shares that 26TB of space mentioned in my last reply. On Wed Apr 16 12:41:20 2025, [STAFF] wrote: Hi [STAFF], I cannot access that 26TB because I do not have an account there? I never had an account on ada before. when my HPC account was created it was created only for chip so i only have an account on /umbc/rs/manas/ I do not have an account on /umbc/ada/manas On Wed, Apr 16, 2025 at 12:38PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=[NUMBER]> Last Update From Ticket: Hi [USER], Is there a reason the 26TB currently available to you via /umbc/ada/manas isn't enough? On Tue Apr 15 16:52:45 2025, [STAFF] wrote: > First Name: [USER] > Last Name: [USER] > Email: [EMAIL] > Campus ID: [ID] > Request Type: High Performance Cluster > Dear Support team, I am writing to request the creation of an additional storage account for my user, [USER]. Currently, I only have a storage account located at /umbc/rs/manas/users with a 500GB limit. I am finding that I am reaching this limit and require more storage space for my research data. I would like to request a new storage account on /umbc/ada/manas/users to supplement my current storage capacity. This additional space will be very helpful for my project. Thank you for your time and consideration of this request. Sincerely, [USER]"
"3166506","68758875","2025-04-16 13:37:10","HPC Other Issue: File transfer permissions","Makes sense, thanks [STAFF]. If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://www.google.com/url?q=https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3166506&ticketowner=[STAFF]&ticketsubject=HPC Other Issue: File transfer permissions. If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at Ticket https://rt.umbc.edu/Ticket/Display.html?id=3166506. Thank You. Resolution: 2-Factor authentication is required for all access. If you connect to the UMBC VPN you will complete the DUO 2-factor authentication process one time on the initial connection then can access resources without further DUO prompts. The authentication stack on Linux does not maintain any state information from one connection to another, so each time you connect its an independent operation and you must satisfy all the required modules in the stack. This is why you get prompted for each file copy. If you are using the UMBC VPN and also establish a Kerberos ticket then your file copies will complete without any password requirement at all. Other options include using zip or tar to send multiple files at one time. It is also possible (but somewhat more complex) to configure the ssh client in master mode (version and implementation dependent) so that one connection is used to spawn additional children. Original Request: Requestors: [USER]. First Name: [USER]. Last Name: [USER]. Email: [EMAIL]. Campus ID: [ID]. Request Type: High Performance Cluster. Hi there, If I modify scripts locally and then try to transfer them to the research storage partition on the HPCF before running them on chip, I am being asked for a password and DUO confirmation *for every file* on chip in a way that I never had to do with taki. This means a pretty substantial change to our work flow. Is there a workaround that someone can suggest?"
"3166519","69046947","2025-04-30 17:09:52","HPC Slurm/Software Issue: facing issue on chip with node 20","Hi [USER], I missed this the first time you submitted a ticket, but in general anytime you run a slurm command (any of the commands that start with 's' such as 'srun', 'squeue', 'sinfo') you should assume you need to add a 'cluster' flag. So for instance the srun you ran:  srun --mem=200000 --time=48:00:00 --gres=gpu:1 --pty --nodelist=g20-01 bash should be:  srun --cluster=chip-gpu --mem=200000 --time=48:00:00 --gres=gpu:1 --pty --nodelist=g20-01 bash I was able to verify this works as your user. Please let me know if you have any more issues with it. On Wed Apr 30 12:01:24 2025, [USER] wrote: > Hello, > I am still facing the issue. > As you can see, when I do sinfo, I can see there are three ideal nodes on g20. > But even if I give a very low memory requirement, I am not getting any space assigned. It's been the same since last night at least. > It's been pretty difficult to get space on g20 at any point. Could you please help! > Thank you, [USER] [EMAIL] On Wed, Apr 16, 2025 at 10:25 AM [STAFF] via RT wrote: > If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3166519&ticketowner=mb17%40umbc.edu&ticketsubject=HPC Slurm/Software Issue: facing issue on chip with node 20 > If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3166519 > Hi [USER], Nope, you did nothing wrong. There are a few nodes that have been giving us this issue. We are working to get it resolved. In the meantime, we've taken them out of rotation. Please let us know if you find this happening again. On Tue Apr 15 17:51:59 2025, [STAFF] wrote: > Request Type: High Performance Cluster > Hello, Every time I try getting space on the chip, I face the issue. Attached screenshots. Please let me know if I am doing anything wrong or missing anything!"
"3166520","68766582","2025-04-16 16:33:27","New Publication","Hello I have added your paper to our list of publication page. You can find it here https://hpcf.[DOMAIN]/publications/ On Tue Apr 15 17:52:24 2025, [STAFF] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [CID] >  > Request type:                 Request new article >  > Hi, our recent work got accepted for presentation at 2025 IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2025). We used HPCF's ada cluster to conduct a part of the computation. Here is the bibliography. >  > [USER], [USER], [USER], [USER], [USER], and [USER]. 'Joint Retrieval of Cloud properties using Attention-based Deep Learning Models.' arXiv preprint arXiv:2504.03133 (2025). >  > Thanks. -- Best, [STAFF]"
"3166646","68763502","2025-04-16 15:21:12","waiting for more than 48 hours to allocate a single node with 4 GPUs!","Thank you for your quick response. Thank you - [USER] ______________________ [USER] PhD Candidate, Big Data Analytics Lab, Department of Information Systems, University of Maryland, Baltimore County   On Wed, Apr 16, 2025 at 11:17 AM [STAFF] via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3166646&ticketowner=[EMAIL]&ticketsubject=waiting+for+more+than+48+hours+to+allocate+a+single+node+with+4+GPUs. If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3166646 Thank You _________________________________________ R e s o l u t i o n: Hi [USER], In your slurm file: [root@chip-mgt1 ~]# cat /umbc/ada/jianwu/users/[USER]/25RL/dc/rl/chipscript.sh #!/bin/bash #SBATCH --job-name=rL Job name #SBATCH --mem=20480 Job memory request #SBATCH --gres=gpu:3 Number of requested GPUs #SBATCH --time=24:00:00 Time limit days-hrs:min:sec #SBATCH --constraint=L40S #H100 Specific hardware constraint #SBATCH --error=err.err Error file name #SBATCH --output=out.out Output file name module load Anaconda3/2024.02-1 conda activate /umbc/rs/nasa-access/[USER]env python mainx.py --training_file train3.py --baseline_samples 3 Just take out the line that says '#SBATCH --constraint=L40S #H100' On Wed Apr 16 11:01:39 2025, [USER] wrote: Hi Max, Thank you for the clarification. I tried to use H100, but it gives me an error saying, cannot be allotted (or something like it). So I am using only L40s and keep waiting. Can you please let me know how do I not constrain my training to the L40S nodes?? How to define that? Is it mentioned in the website? regarding my 2nd question: ignore it for now please. Again, I am looking for a solution to run my tests. How can I do so? Do you have any suggestions/advice? Thank you again. /Seraj On Wed, Apr 16, 2025 at 10:32 AM [STAFF] via RT <[EMAIL]> wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3166646 Last Update From Ticket: Hi [USER], The rule has never been that you can only have a job running for 3 days, but that your job may be cancelled if it is running longer than 3 days AND another user requires it. Looking at the job you submitted, you requested 4 gpus with the constraint L40s. The job you pointed out that has been running for nine days is on a node that uses h100's, so you were never in line to preempt that job anyway. All the jobs running on the L40s nodes have been running for less than 3 days, therefore they can't be preempted either. Your job is more likely to run if you don't constrain it to the L40S nodes. As for your second question, I'm not 100% sure I understand what you're asking. Could you clarify? On Tue Apr 15 21:34:50 2025, [USER] wrote: Request type: General Support Hi, Thank you for brining the new CHIP system, it is faster! However, I am waiting for more than 48 hours to allocate a single node with 4 GPUs, which I need to test for my project. I saw there are some processes running for more than 9 days/3 days (please see attached, during the time of my screenshot they were still running). Could you please help me, as I need to access to GPU nodes (min 4 nodes) on an urgent basis. Is there any way to get help or I have to wait untill I get my queue? I am also curious about 2 things as follows: 1. whether still the 3 days rule apply for all users to run a test? previously in ADA we have seen, a user can run their tests for 3 days (72 hours) max in a row, is it the same for chip or we can run tests for an unlimited time if we are alloted? 2. when we use SRUN, we can run interactive jobs, however, we can do SBATCH as well. What I have seen is the occupied GPU for SBATCH(g24-06) is different than the SRUN (g24-02). So in such case, am I using 2 nodes simultaneously? Thank you for your cooperation. /[USER] Attachment 1: chip.png (https://umbc.box.com/s/f82hz83akde5z6xp335u0xthrjwo7a7o)"
"3166651","68759603","2025-04-16 13:47:35","HPC Slurm/Software Issue: Cannot [ID] identify their ID after requesting resource","Hi [USER], Thanks, we identified two more nodes in this state and have set them to drain. Please reach out if you have any more issues. On Wed Apr 16 09:29:28 2025, [STAFF] wrote: Hi, I requested resources twice. In the screenshot, the g20-09 node has the same problem but the g20-12 is okay. On Wed, Apr 16, 2025 at 9:10 AM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hi [USER], This seems to be an issue with this specific node. We've taken it out of rotation while we work to resolve the issue. Can you confirm this is not a problem with any of the other nodes? On Tue Apr 15 21:40:16 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USER] Request Type: High Performance Cluster Hello, I have issue today. when I am on the login node, the system is able to identify me as '[USER]' but after I request the resource. The system said 'no such user' and it is not able to identify me. I attached the screenshot. Thanks Attachment 1: Screenshot 2025-04-15 213517.png (https://umbc.box.com/s/[URL]) Best, [STAFF]"
"3166938","68763337","2025-04-16 15:17:00","HPC Other Issue: GPUs Unavailable on 2020 Nodes","Working now, thanks! On Apr 16, 2025, at 11:13 AM, [STAFF] via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3166938&ticketowner=[STAFF]&ticketsubject=HPC Other Issue: GPUs Unavailable on 2020 Nodes. If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3166938. Thank You. Hi [USER], No this was a bug. It should be resolved. On Wed Apr 16 10:55:40 2025, [USER] wrote: First Name: [USER]. Last Name: [USER]. Email: [EMAIL]. Campus ID: [ID]. Request Type: High Performance Cluster. For all of the 2020 nodes, the available features shown when running scontrol show node -a g20-XX are blank. Are these nodes unavailable for use right now? -- Best, [STAFF] DOIT Unix Infra Student Worker. Original Request: Requestors: [USER]. First Name: [USER]. Last Name: [USER]. Email: [EMAIL]. Campus ID: [ID]. Request Type: High Performance Cluster. For all of the 2020 nodes, the available features shown when running scontrol show node -a g20-XX are blank. Are these nodes unavailable for use right now?"
"3167123","68815927","2025-04-18 17:24:10","Other","AWS services require a faculty member to sponsor configuration with a p-card to fund costs. To configure a [ORGANIZATION] based AWS environment, we must apply [ORGANIZATION] security profiles and settings, set up auditing and alerts, perform periodic audits. We can configure a project in Google Cloud using your [ORGANIZATION] credentials. This is easier as we don't have [ORGANIZATION] production/business services in GCP, avoiding audit/security requirements. Google's offerings are similar to AWS but with differences. A student project in GCP gets a small amount of free credit (about $100), after which you'd need to provide a credit card or services would shut down until new credits are available."
"3167124","68772800","2025-04-16 18:49:29","HPC Slurm/Software Issue: Couldn't open Jupyter Notebook","Hello Your home directory was full that was why you are getting an no space left error. I have moved .conda and created a symbolic link, clearing some space in your home directory. You should be able to open notebook. In the future, if you encounter storage issue follow the steps in this page to clear you home directory: https://umbc.atlassian.net/wiki/spaces/faq/pages/1118765095/What+to+do+if+I+run+out+of+space+in+my+chip+home+directory#2.-Use-Symbolic-Links-to-redirect-data-to-your-research-volume On Wed Apr 16 13:12:47 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Here are the issues I am having 1. I could not open a jupyter notebook. 2. I created a conda environment using the terminal and wanted to create an ipykernel to connect to the environment, but I got a message that said there was no space. Slurm script path: /umbc/rs/iharp/users/[USER]/jupytersbatch.slurm Slurm Job ID: 5401 Attachment 1: Screenshot 2025-04-16 130915.png (https://umbc.box.com/s/7i9w2wvh8qwjgn6xl1ivl68px8ajp9zc) Attachment 2: Screenshot 2025-04-16 131153.png (https://umbc.box.com/s/biws3rh8x6t201s0m7jx4bibk100pyrg)"
"3167167","70490693","2025-07-22 22:20:40","HPC Other Issue: Requesting additional storage","Hi [USER], My colleague, [STAFF], should be reaching out to you before the end of the week to schedule a migration to the larger 25TiB volume. I'll mark this ticket as resolved. [STAFF] will open another to capture the details of the migration. Sorry for the wait. This process is well understood now. On Wed Apr 16 13:38:16 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Cluster My NASA project is ending this summer and we ran out of storage space. Could we have additional 10 TB space at /umbc/rs/nasa-access/? Without the space, we won't be able to complete the work properly. Thanks!"
"3167177","68770622","2025-04-16 17:58:16","HPC User Account: [USER] in Complex Quantum Systems","Hi everyone, I approve. Cheers [STAFF] ----------------------------------------- [STAFF], Ph.D. Assistant Professor Complex Quantum Systems Group https://[DOMAIN] Department of Physics Cybersecurity Institute Quantum Science Institute University of Maryland, Baltimore County"
"3167418","68801947","2025-04-17 20:22:18","HPC Slurm/Software Issue: The [DISK NAME] is missing in Chip","Hello I have mounted /umbc/rs/nasa-camro on chip. You should be able to access it. On Wed Apr 16 15:42:15 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CID] Request Type:              High Performance Cluster Dear DoIT team, I am writing to report that '/umbc/rs/nasa-camro' is currently not on Chip but only on Taki. Could you help mount the disk of '/umbc/rs/nasa-camro' to Chip? so that we could continue using the data on this disk. But if the '/umbc/rs/nasa-camro' is no longer being used in Chip, please let me know so that we can be aware of moving data out of it. Thanks! -- Best, [STAFF]"
"3167431","69121306","2025-05-02 18:03:34","HPC Slurm/Software Issue: OpenMPI not implemented?","A very long email thread!  It appears to be a discussion between Daniel J. Kelly and Beamlak Bekele (and possibly Max Breitmeyer) about an issue with installing MPI (Message Passing Interface) on a Linux system.  Here's a brief summary:  * Daniel J. Kelly is trying to install MPI on his system, but is encountering issues. * Beamlak Bekele responds with some suggestions and troubleshooting steps. * Max Breitmeyer chimes in with additional advice. * The conversation goes back and forth, with each person providing more information and suggestions.  If you'd like me to extract specific details or quotes from the email thread, feel free to ask!"
"3167538","68809843","2025-04-18 14:21:34","HPC Slurm/Software Issue: Cannot run slurm files on chip","Hi [STAFF],  I'm able to run my files on slurm again -- thank you!!  I still have some debugging to do since the files are not all running all the way through due to chip-related issues, not my Stata code.  For example, I got this error when running a file: /cm/local/apps/slurm/var/spool/job05275/slurm_script: line 17: 1838602 Killed                  stata-mp dhsclean.do  When it was in the process of running a merge command with a large data set, so I will try increasing memory and seeing what I can accomplish.  It will take me some time to work through all my code on this project to make sure it's all running properly, but at least I can access the server now so I'm a huge leap closer to getting my project output.  Thanks! [USER] On Thu, Apr 17, 2025 at 5:30 PM [STAFF] via RT <[EMAIL]> wrote:  Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=3167538 > Last Update From Ticket: The 'rp_test.slurm' file is in your home directory (/home/[USER]). Also, we've added a series of 'office hours' that can be in-person or virtual. If you'd like a bit of live troubleshooting, you can schedule a time on the webpage located at [DOMAIN] User Support Office Hours . On Thu Apr 17 17:03:15 2025, [USER] wrote: Hi [STAFF], Thanks for helping with this. Stata 19 should be fine - I think the license transfers over. You said that you added 'rp_test.slurm' but I don't know where to access that. Can you send it or send me the file path. The 'can't find dhsregs.do' error is likely because I usually have to cd to my 'home' directory where the slurm files are stored before I run the slurm file as follows:'cd '/umbc/rs/[USER]/users/[USER]'(I think that's the correct file path, but I can double check when I run it.) But I'll have to double check that the file you ran can run from my end. Thank you for your help with this. When the migration was announced I didn't realize it was going to require new code or else I would have been working on this ahead of time while still accessing taki. Thanks! [USER] On Thu, Apr 17, 2025 at 4:42 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=3167538 > Last Update From Ticket: Hi [USER], I ran into some issues installing Stata/18, but I was able to get Stata/19 installed on chip-cpu. I tested the run with a slurm filed based on what I saw in your home directory. I've added this slurm file alongside this file and named it 'rp_test.slurm'. Please take a look, I didn't change very much, just the qos and the specific module name. This job did run, but it failed to find the file 'dhsregs.do'. I hope this is expected. I'll leave this ticket open for a few days unless I hear back about related issues. Hope this works well for you -- eager to hear back. On Wed Apr 16 17:33:52 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Cluster I am trying to run a file using slurm. I log in and run this command: srun --cluster=chip-gpu --account=pi_[USER] --mem=80G --time=10:00:00 --gres=gpu:1 sbatch dhsregs.slurm which gives me error message srun: job 27377 queued and waiting for resources srun: job 27377 has been allocated resources sbatch: error: Missing: '--gres' sbatch: error: You must specify a Generic RESource to use in your job. sbatch: error: See this webpage for more details: https://[DOMAIN]/ada/slurm/overview/. sbatch: error: Batch job submission failed: Unspecified error srun: error: g20-05: task 0: Exited with exit code 1 This is the content of the slurm file that used to run fine on taki: #!/bin/bash #SBATCH --job-name=dhsregs #SBATCH --output=slurmdhsregs.out #SBATCH --error=slurmdhsregs.err #SBATCH --cluster=chip-gpu #SBATCH --partition=general #SBATCH --account=pi_[USER] #SBATCH --qos=medium #SBATCH --time=10:00:00 #SBATCH --nodes=1 #SBATCH --tasks-per-node=1 #SBATCH --mem=80G #SBATCH --gres=gpu:1 export STATATMP=/scratch/${SLURM_JOB_ID} export TEMP=/scratch/${SLURM_JOB_ID} export TMP=/scratch/${SLURM_JOB_ID} export TMPDIR=/scratch/${SLURM_JOB_ID} module load Stata/18 stata-mp dhsregs.do"
"3167686","68802906","2025-04-17 21:03:33","HPC Other Issue: Duo access","Hello Please follow the instruction here to opt in to duo https://umbc.atlassian.net/wiki/spaces/faq/pages/30743276/How+do+I+opt+in+to+Duo+multi-factor+authentication+for+my+UMBC+account On Wed Apr 16 22:04:37 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster Hi, I want to set up Duo to access the new HPC facility. Could you please help me or direct me to the instructions for creating a Duo key? Thank you, [USER]"
"3167732","68802725","2025-04-17 20:50:57","HPC User Account: [ID] in Student Group","Hello Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/)  If there are more users from your group who don't have access to chip, let me know. On Thu Apr [DATE] [TIME], [STAFF] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [ID] > Request Type:              High Performance Cluster > Create/Modify account in Student group > Hi, I’m reaching out regarding access to the CHIP cluster following the migration from ADA. Our research group, under Dr. [STAFF] ([EMAIL]), previously had access to ADA, but we’re currently unable to access CHIP. Could you kindly clarify whether we need to create new accounts for our group members to regain access? If there are any additional steps we should follow, please let us know. Thank you for your time and support. Best regards, [USER]"
"3168161","68799544","2025-04-17 19:28:55","HPC Other Issue: Chip authentication issues","Hi [STAFF], Between when I sent you the message and when you checked we saw another massive load spike. We increased the amount of memory and cpus available on the login node to account for the increased user load, and things look much happier. Let me know if you end up having more issues. On Thu Apr 17 15:26:15 2025, [USER] wrote: Just updating, whatever the issue was, it seems to be resolved. I can now log into chip again. Thank you! [STAFF] On Thu, Apr 17, 2025 at 3:03 PM [STAFF] <[EMAIL]> wrote: Hi [USER], Yes, I still cannot connect. Unfortunately it seems the login node is now actively refusing connections. That might be why the high loads were mitigated. I get a connection timeout error trying to connect directly to the jupyter session I have running. Thanks, [STAFF] On Thu, Apr 17, 2025 at 2:50 PM Max Breitmeyer via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hi [STAFF], Thanks for the detailed message. We were seeing some high loads on the login node from users. Those seemed to have calmed down now. Are you still having this issue? On Thu Apr 17 13:25:53 2025, [USER] wrote: First Name: [STAFF] Last Name: [STAFF] Email: [EMAIL] Campus ID: [USER] Request Type: High Performance Cluster There seems to be an issue logging into chip. It is effecting the PI_[USER] group largely, and appears to be on the login password step of authentication, before Duo. I attached my SSH client's logs. This occurs with or without the UMBC VPN, and I cannot log in to jupyterlab from a job i currently have running (jobid 5010 on chip-cpu) either, so it seems not unique to the login node, though this attempt was made on powershell, so theres no logs or feedback, just asks for the password again. Attachment 1: chip_error_logs.txt"
"3168260","68809157","2025-04-18 13:53:30","HPC Other Issue: [USER] reports login taking too long","Hello There was a high load on chip.rs that was hindering the password authentication process . We were able to fix that you should be able to log in now On Thu Apr 17 14:47:45 2025 [USER] wrote First Name [STAFF] Last Name [STAFF] Email [EMAIL] Campus ID [ID] Request Type High Performance Cluster Hi I type the ssh...chip.rs.umbc.edu and it takes a fair amount of time to ask for my password After it requests my password I type and it asks again I type and it asks again I type and it asks again After the 3rd time or this message appears Connection closed by 130.85.28.213 port 22 or permission denied (publickey gssapi-with-mic keyboard-interactive) Once in between if I get lucky I am able to login to my chip account Iam trying from the [DEPARTMENT] department Thank you Best [STAFF]"
"3168266","68809140","2025-04-18 13:52:56","HPC Other Issue: Access Denied","There was a high load on chip.rs, that was hindering the password authentication process. We were able to fix that, you should be able to log in now On Thu Apr 17 14:50:55 2025, [STAFF] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [CAMPUSID] >  > Request Type:              High Performance Cluster >  > I couldn't log into my account >  > root@DESKTOP-BGH2N5Q:~# ssh [USER]@chip.rs.umbc.edu > ([USER]@chip.rs.umbc.edu) Password: > ([USER]@chip.rs.umbc.edu) Password: > ([USER]@chip.rs.umbc.edu) Password: > ([USER]@chip.rs.umbc.edu) Password: > Connection closed by 130.85.28.213 port 22 > root@DESKTOP-BGH2N5Q:~# ssh [USER]@chip.rs.umbc.edu > ([USER]@chip.rs.umbc.edu) Password: > ([USER]@chip.rs.umbc.edu) Password: > ([USER]@chip.rs.umbc.edu) Password"
"3168383","68803019","2025-04-17 21:12:05","RCD Consult: [USER] has no access to research volume","Hello  I have fixed the directory permission. You should be able to access /umbc/rs/fanza .  On Thu Apr 17 16:13:53 2025, [STAFF] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [CAMPUS_ID] >  > Request Type:              Research Computing & Data Consultation >  > Hello there, >  > I recently got an account on the cluster. I can access my home directory but can't enter the research directories. It seems like I don't have permission to access the research volume. I get error like ' '-bash: cd: /umbc/rs/fanza: Permission denied'."
"3169288","68826926","2025-04-19 22:57:05","HPC Other Issue: Slurm Database Connection Issue","Looks to be working now, thanks! Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=3D[NUMBER] > Last Update From Ticket: Hello [USER], We had an issue on the head node where the /var partition filled up which caused the slurmdb service to crash. We've corrected this issue and restarted slurmdb. Could you try running squeue again or submitting a job to verify it's working for you? I apologize for any inconvenience this may have caused. Thank you, [STAFF] On Sat Apr 19 13:56:52 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster When attempting to submit a Slurm job, or use any slurm commands, I receive the following error: [johnv3@chip rf-dvae]$ squeue squeue: error: slurm_persist_conn_open_without_init: failed to open persistent connection to host:master:6819: Connection refused squeue: error: Sending PersistInit msg: Connection refused squeue: error: Sending PersistInit msg: Connection refused squeue: error: DBD_GET_CLUSTERS failure: Connection refused squeue: error: Problem talking to database squeue: error: There is a problem talking to the database: Connection refused. Only local cluster communication is available, remove --cluster from your command line or contact your admin to resolve the problem."
"3169316","68826817","2025-04-19 22:29:54","HPC Slurm/Software Issue: Unable to use squeue and sinfo commands","Hello [USER], We had an issue on the head node where the /var partition filled up which caused the slurmdb service to crash. We've corrected this issue and restarted slurmdb. Could you try submitting a job again to verify it's working for you? I apologize for any inconvenience this may have caused. Thank you, [STAFF] On Sat Apr 19 16:07:35 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster I am getting errors when trying to run squeue and srun commands. Some connection refused, and unable to talk to the database. Attachment 1: slurm_error.png"
"3169665","68834039","2025-04-21 13:02:04","HPC Slurm/Software Issue: Help with slurm syntax","Hi [USER], I would recommend working from the UMBC wiki (a getting started page can be found here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip). We also have a series of 'new to chip' presentations happening over the next few weeks (links can be found here: https://my3.my.umbc.edu/groups/hpcf/events). For the particular problem you're having, it seems you're trying to run on the 'GPU' cluster, which is also why it's requiring a generic resource (gres) to be specified. Putting '--cluster=chip-cpu' should solve most of your problems. As for your other questions: > do users have to be logged in via a VPN in order to run programs on chip? No! They need to be duo authenticated though, and the easiest way to do this is through the vpn. > is there some other formatting change on chips from taki of which I should be aware? See above. We'll be removing the page you've been working from shortly since it's out of date, and we're moving all documentation to the wiki going forward. The wiki can also be found on the hpcf website under 'User Support' > 'User Documentation' Hopefully that helps. Please let me know if you have more issues. On [DATE], [STAFF] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [CAMPUSID] > Request Type:              High Performance Cluster > Hello, We recently tried to run code on chip that we had been running on taki and received an error. Here is the submission text: we are submitting the MPI_control_1.slurm for HUC02060003_GunpowderPatapsco ['sbatch', '--job-name=p1HUC02060003_GunpowderPatapsco', '--nodes=8', '--ntasks-per-node=8', '--output=/umbc/rs/[USER]/common/huc_test/Essential_Scripts/HydrographyWorkflow/Cang/HUC02060003_GunpowderPatapsco_2025_test_flat0p1/HUC02060003_GunpowderPatapsco_1.out', '--error=/umbc/rs/[USER]/common/huc_test/Essential_Scripts/HydrographyWorkflow/Cang/HUC02060003_GunpowderPatapsco_2025_test_flat0p1/HUC02060003_GunpowderPatapsco_1.err', '--qos=medium', '--mail-user=[EMAIL]', '--mem=320G', '--gres=gpu:0', '--export=ALL,work_place=/umbc/rs/[USER]/common/huc_test/Essential_Scripts/HydrographyWorkflow/Cang/HUC02060003_GunpowderPatapsco_2025_test_flat0p1,HUC_name=HUC02060003_GunpowderPatapsco,googleDrvieVar=gdrive', 'MPI_control_1.slurm'] sbatch: error: invalid partition specified: 2018 sbatch: error: Batch job submission failed: Invalid partition name specified I think one reason this may have failed was perhaps the specification of the '2018' partition, but we have also tried 'general' as well. A few questions here: 1) do users have to be logged in via a VPN in order to run programs on chip? 2) is there some other formatting change on chips from taki of which I should be aware? We are working from this web page: https://hpcf.umbc.edu/compute/chip-cpu/ Thank you, [USER]"
"3169667","68833768","2025-04-21 12:50:06","HPC Slurm/Software Issue: /tmp out of space","Hi [USER], When you say your application uses /tmp, do you mean this is something you programmed? Or another application that you've pulled in for your workflow? We don't recommend using /tmp for any data to be used in jobs since that space is mostly meant to be used for system actions. Instead we give users temporary 'scratch space' when a job is started. Please check out [LINK] for more information! On Sun Apr 20 19:24:04 2025, [STAFF] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [ID] > Request Type:              High Performance Cluster > Job ID: 50740 > During this job, /tmp filled up, which my application uses for temporary storage during execution. Can we ensure that there is sufficient space available? -- Best, [STAFF]"
"3170031","68843164","2025-04-21 16:27:53","HPC Slurm/Software Issue: Cancel works on cluster","Hi [USER], Just like when using srun or sbatch, you must specify the 'cluster' when using scancel. So the command would look something like 'scancel -u [USER] --cluster=chip-cpu'. Replace 'cpu' with 'gpu' as needed! On Mon Apr 21 11:43:19 2025, [STAFF] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [ID] >  > Request Type:              High Performance Cluster >  >  > Hi, > I am trying to cancel the jobs associated with my account (-u [USER]) on the cluster. But, even after trying several codes, my jobs are still running or pending. > Is it possible to remove them from your side, or is there some procedure I can follow to force cancel them. Best, [STAFF]"
"3170039","68868086","2025-04-22 16:12:10","HPC User Account: [ID] in LEARN","The group [GROUP] now exists on the chip cluster. Members of this group can therefore access and contribute to the research storage space allocated to the group. This storage is located at /umbc/rs/[GROUP] and currently has a quota of 500G. Please review documentation on the hpcf.[DOMAIN].website. Submit any questions or issues as separate RT Tickets at the following URL: https://[DOMAIN]/request-tracker-rt/[DEPARTMENT]-research-computing/. Additionally, your accounts ([USER] and [USER]) have been created on chip.rs.[DOMAIN] and Your primary group is [GROUP]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.[DOMAIN] > User Support. All available modules can be viewed using the command 'module avail'. On Mon Apr 21 12:35:29 2025, [STAFF] wrote: Hi [STAFF]: I haven't used the cluster before. Could you help me set up the account? On Mon, Apr 21, 2025 at 12:32 PM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hi [USER], I'm not seeing your group or user on the cluster. Have you ever used the cluster before? If not, we'll have to create a group for you first and then add your student to it. On Mon Apr 21 12:01:23 2025, [STAFF] wrote: I approve. Thanks. On Mon, Apr 21, 2025 at 11:46 AM RT API via RT <[EMAIL]> wrote: This e-mail is a notification that a [DOMAIN] user: [USER] has requested an account within [DOMAIN]'s HPC environment in your group. As the PI, we request that you acknowledge and approve this account creation by replying to this message. Alternatively you can go to this link and review the ticket and indicate your decision here: Ticket Once we have your approval, we will create the account and you and the new user will receive another e-mail notifying you that the account has been created."
"3170219","68891062","2025-04-23 14:49:55","HPC Other Issue: Request to Transfer [USER]'s Account to New Lab and Clarification on Data Migration","Hi [USER], Your account ([USER]) has been added to the pi_leizhang group on chip.rs.umbc.edu .  Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) On Wed Apr 23 10:22:05 2025, [STAFF] wrote: > Hi [STAFF], >=20 > Approve on my side. Please let me know if there are any further steps > that I should proceed with. Thanks, and have a good day. >=20 > Best regards, > [STAFF] >=20 > =E2=80=94=E2=80=94=E2=80=94 > [STAFF], Ph.D. >  Assistant Professor > Department of Information Systems > University of Maryland, Baltimore County > Lab website: https://est.umbc.edu <https://est.umbc.edu/> > Schedule a meeting with me: https://app.reclaim.ai/m/[STAFF] > Office: ITE 444 >=20 >=20 > > On Apr 23, 2025, at 10:06=E2=80=AFAM, [STAFF] via RT > > <[EMAIL]> wrote: > > > > Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=[ID] > > > Last Update From Ticket: > > Hi [USER], > The transition between ada and chip has been completed for some time now. Any files that were in your research volume with your old lab is still there, however anything in your home directory is not. However, the ada login node is still available and you can easily access it to get your files and move them to chip. Once [STAFF] has approved your request, will get you added to the his lab's research volume. On Mon Apr 21 13:32:23 2025, [USER] wrote: >> First Name:                [USER] >> Last Name:                 [USER] >> Email:                     [EMAIL] >> Campus ID:                 [ID] >> Request Type:              High Performance Cluster >> Hello, I hope this message finds you well. I wanted to inform you that I have transitioned to Professor [STAFF]'s lab. I would greatly appreciate it if my account could be transferred under his group. Additionally, I was previously an 'ada' user, and I understand that there is an ongoing migration to the CHIP cluster. I wanted to confirm whether my files and environments will be automatically transferred to CHIP or if any action is needed on my part. Thank you for your attention to this matter. Username: [USER] Best regards, [USER]."
"3170249","68867734","2025-04-22 16:02:09","HPC Slurm/Software Issue: Launch failed requeued held","Hi [STAFF], It looks like the job ran. Are you still having an issue?  On Mon Apr 21 13:46:01 2025, [USER] wrote: > First Name: [USER] > Last Name: [USER] > Email: [EMAIL] > Campus ID: [CAMPUSID] >  > Request Type: High Performance Cluster >  >  > Hi, I have submitted a job. Job ID: 51210. Before this, I ran the same > job for > fewer iteration. It went well without any errors. But when I submitted > the job > for more number of iteration, I started getting the following error. >  > Launch failed requeued held. >  > I have added the screenshot for your reference. >"
"3170435","68886479","2025-04-23 13:01:48","HPC Other Issue: Python Virtual Environment mpi4py error","Hi [STAFF], Please try this page and see if it solves your issue: https://umbc.atlassian.net/wiki/spaces/faq/pages/1150156801/mpi4py+Installation On Mon Apr 21 15:49:00 2025, [USER] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [CAMPUS_ID] >  > Request Type:              High Performance Cluster >  > I am trying to set up Python virtual environment for my project, but I > am running into an issue when I tried to install mpi4py, with: >  > python3 -m venv p-env > source p-env/bin/activate > python3 -m pip install --upgrade pip > pip3 install --upgrade scikit-learn > pip3 install --upgrade tensorflow==2.11.0 > pip3 install --upgrade numpy==1.26.4 > pip3 install --upgrade mpi4py >  > Which yielded the following error: > * On Fedora/RHEL systems, run: $ sudo dnf install mpich-devel     # for MPICH $ sudo dnf install openmpi-devel   # for Open MPI * On Debian/Ubuntu systems, run: $ sudo apt install libmpich-dev    # for MPICH $ sudo apt install libopenmpi-dev  # for Open MPI [end of output] > note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for mpi4py Failed to build mpi4py ERROR: Failed to build installable wheels for some pyproject.toml based projects (mpi4py)"
"3170587","68905963","2025-04-23 22:52:58","HPC Other Issue: CPU cluster: Cannot port forwarding from resource node to login node","Yes, that is exactly what I did. Today and Yesterday, I got assigned to node c18-01 and c18-12. It worked normally. I am able to work now! Maybe,it only happens with node c18-30? Thank you so much for helping. This is the detail command I put: session 1: login into to the login node `ssh [EMAIL] -p 22` I requested resource `srun --cluster=chip-cpu --account=[ACCOUNT] --partition=general --qos=medium --time=24:00:00 --mem=300G --pty $SHELL` open jupyter notebook: `jupyter notebook --no-browser --port=8895` session 2: login into the login node: `ssh [EMAIL] -p 22` do port forwarding: `ssh -NL 8895:localhost:8895 [USER]@[NODE]`. On Wed, Apr 23, 2025 at 9:16 AM [STAFF] via RT wrote: Ticket <https://rt.umbc.edu/Ticket/Display.html?id=3170587> Last Update From Ticket: Hi [USER], I need a little more information about how you're trying to accomplish this. It looks like you're trying to start an interactive session and then opening port forwarding that way? A step by step of the commands you ran would be helpful for me to attempt to replicate (to answer you question though, no port forwarding is not turned off on the cpu cluster). On Mon Apr 21 17:42:09 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID]. Request Type: High Performance Cluster. Hello, This is the first time I tried the CPU clusters because the GPU clusters got very crowded. I tried port forwarding from CPU node to the login node but It keep getting abort. It is worked on GPU clusters. Is it because the CPU clusters is not allow port forwarding?. Thanks, [USER]."
"3170598","68944777","2025-04-25 18:12:31","HPC Other Issue: [STAFF] - AI for Automated Radiology Report Generation","Hi [USER],  Your account ([USER]) has been created on chip.rs.umbc.edu. Your research storage is located at /umbc/rs/student/users/[USER]/ Your primary group is student. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/)  On Wed Apr 23 14:16:21 2025, [STAFF] wrote: > Hi, I support the student's request to access the clusters. Let me know if I need to do anything else. Thanks, [STAFF] Adjunct Instructor, DATA 606 Capstone in Data Science On Wed, Apr 23, 2025 at 11:21 AM Beamlak Bekele via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3170598&ticketowner=[EMAIL]&ticketsubject=HPC Other Issue: AI for Automated Radiology Report Generation If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3170598 Thank You Hello We have integrated ADA into our new system chip, which includes additional new GPUs. You can access the GPUs through chip.rs.umbc.edu To request an account, go to https://rtforms.umbc.edu/rt_authenticated/doit/DoIT-support.php?auto=Research Computing and create a new ticket. You can place a user account request ticket by selecting: *Research Computing Action: High Performance Cluster HPC Action: User Account Creation/Modification I'd like to: Create/Modify account in existing PI group Since you are a grad student, you will need to enter your PI email and PI group name. On Mon Apr 21 18:07:04 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster AI for Automated Radiology Report Generation – Request for GPU Access on ADA Cluster Hello Research Computing Team, I am a graduate student at UMBC working on my Capstone project titled 'AI for Automated Radiology Report Generation' under the guidance of Dr. [STAFF]. I am requesting GPU access on the ADA cluster to train deep learning models (CNNs and transformers) on large-scale medical imaging datasets such as NIH ChestX-ray14 and CheXpert. I plan to use Python with PyTorch/TensorFlow for multi-label classification and report generation tasks. Please let me know the necessary steps to: Enable GPU access on my ADA cluster account Set up the environment for deep learning model training Submit jobs using SLURM for H100 or A100 nodes (if available) Let me know if any additional documents or steps are required. Thank you for your support. Best regards, [USER] Campus ID: [CAMPUSID] UMBC Email: [EMAIL]"
"3170608","68888699","2025-04-23 13:51:57","HPC Other Issue: Nodes are drained for some reasons.","Hi [USER], These resources have returned to normal. We appreciate your patience. On Mon Apr 21 18:24:43 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Hi, I'm running some jobs that may use around 10 GPUs. Since they are not large-scale, I want to use RTX 2080. However, I found these nodes (g20-01, 02, 03, 04) are draining due to the prolog error. I also found that some nodes are drained due to the SSSD being dead. Are these normal? Shall I just wait for these resources? Thanks, [USER] Attached: GPU Nodes Status [EMAIL@chip Code]$ sinfo -p gpu -Nel Mon Apr 21 18:06:17 2025 CLUSTER: chip-cpu NODELIST NODES PARTITION STATE CPUS S:C:T MEMORY TMP_DISK WEIGHT AVAIL_FE REASON CLUSTER: chip-gpu NODELIST NODES PARTITION STATE CPUS S:C:T MEMORY TMP_DISK WEIGHT AVAIL_FE REASON g20-01 1 gpu* draining 96 2:24:2 385581 0 1 RTX_2080 Prolog error g20-02 1 gpu* draining 96 2:24:2 385581 0 1 RTX_2080 Prolog error g20-03 1 gpu* draining 96 2:24:2 385581 0 1 RTX_2080 Prolog error g20-04 1 gpu* draining 96 2:24:2 385581 0 1 RTX_2080 Prolog error g20-05 1 gpu* mixed 96 2:24:2 385581 0 1 RTX_6000 none g20-06 1 gpu* drained 96 2:24:2 385581 0 1 RTX_6000 MaxB - SSSD dead on g20-07 1 gpu* drained 96 2:24:2 385581 0 1 RTX_6000 Prolog error g20-08 1 gpu* drained 96 2:24:2 385581 0 1 RTX_6000 Prolog error g20-09 1 gpu* drained 96 2:24:2 385581 0 1 RTX_6000 MaxB - SSSD dead on g20-10 1 gpu* drained 96 2:24:2 385581 0 1 RTX_6000 MaxB - SSSD dead on"
"3170652","68922491","2025-04-24 18:16:30","HPC Other Issue: Conda Not Working - Assistance Needed","Thanks for your response, I got it resolved. Regards, [USER] On Thu, 24 Apr 2025, 1:43 pm [STAFF] via RT, <[EMAIL]> wrote: Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=3170652> Last Update From Ticket: Hi [USER], It would be very helpful if you could show us an example of the commands you are running, what you are expecting, and what is actually happening. We can't help with the limited information provided. On Wed Apr 23 15:06:26 2025, [USER] wrote: Hii team, Thanks for your reply. I am unable to create conda in my home directory, after loading and running anaconda. I don't see it in my home directory so that I can copy that to my working directory. Thanks and Regards, [USER] On Wed, 23 Apr 2025, 9:59 am [STAFF] via RT, <[EMAIL]> wrote: Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=3170652> Last Update From Ticket: Hi [USER], This isn't enough information. What commands are you running? Are you running them on the login node? Have you loaded the anaconda module? There's a lot of helpful information in our wiki https://[DOMAIN].atlassian.net/wiki/spaces/faq/pages/1032814637/Conda+Virtual+Environments On Mon Apr 21 19:34:05 2025, [USER] wrote: Request Type: High Performance Cluster I’m experiencing issues with Conda on my system. When I try to run any Conda-related command, it either doesn't respond or throws an error. I’ve tried basic troubleshooting steps like restarting the terminal and checking the environment paths, but the issue still persists."
"3170685","68867580","2025-04-22 15:59:06","HPC Other Issue: Issue with data transferred from [SERVER] to [SERVER]","Hello [USER], your group's data can be accessed through chip and it is located at /umbc/rs/[STAFF]. In Taki, the research volumes could be accessed through symbolic link however on chip we have moved to using alias to get to your research volume. You can find a detailed description on how to access your research storage here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip#Accessing-Research-Volumes. If you want additional resource on using chip, you can join one of our Getting started with chip meetings list in our groups events https://my3.my.umbc.edu/groups/hpcf/events. On Mon Apr 21 20:26:36 2025, [USER] wrote: > First Name: [USER] > Last Name: [USER] > Email: [EMAIL] > Campus ID: [CAMPUSID] > > Request Type: High Performance Cluster > > Hi, my HPC user ID is '[USER]' and my group's ID is '[STAFF]'. I'm raising the issue on behalf of my group. Dr. [STAFF] is our advisor. We were notified a few weeks earlier that all the data from Taki would be transferred to Chip, but as it stands, although we can log in to Chip, the directories that we had in Taki are still not visible in Chip. All our Chip user directories are empty. However, the files are still accessible via Taki. Given the shutdown of Taki, we would have to start using the chip, and we have been unable to do so for the last two weeks. Given this, we are very confused regarding what is going on. Any form of help would be great. Thank you."
"3170752","68909296","2025-04-24 12:19:41","HPC Other Issue: Reserve [USER]'s access to knacc1 for 3 weeks","Whoops. I'll move those jobs off now. Sorry about that.  [STAFF] (he/him/his) [EMAIL] Appointment Calendar https://calendar.google.com/calendar/u/0/appointments/AcZssZ2_GGzCOMI6OlOc= p-k_iSO6Zl_71GsAOqgoyA4= The most dangerous phrase in the language is, 'We've always done it this way.'  - Adm [STAFF]    On Thu, Apr 24, 2025 at 8:17 AM [USER] via RT <[EMAIL]> wrote:  > Ticket https://rt.[DOMAIN]/Ticket/Display.html?id=3170752 > Last Update From Ticket: Thanks [STAFF]! Students confirmed they are able to run jobs.  But they also observed: *2 of the 8 gpus allocated to us are running jobs from non-[USER] users, my hunch is that these jobs were already running before the reservation happened and once those jobs are done, no non-[USER] users can run jobs on g24-05 and g24-06.* Best, [USER] On Wed, Apr 23, 2025 at 7:54 PM [STAFF] via RT <[EMAIL]> wrote: > Ticket https://rt.[DOMAIN]/Ticket/Display.html?id=3170752 Last Update From Ticket: Sure thing. I've reserved nodes g24-05 and g24-06 for your group (pi_[USER]). In order to access this reservation, members of your group must specify the flag '--account=pi_[USER]' and the flag '--reservation=[USER]'. Please let me know if there are any questions. I'll leave this ticket open for a few days just in case. Find below some sample output using or attempting to make use of the reservation. ''' As [USER]: srun -M chip-gpu --time=1 --mem=1 --gres=gpu:0 --account=pi_[USER] --reservation=[USER] hostname g24-05 scontrol -M chip-gpu show reservation [USER] ReservationName=[USER] StartTime=2025-04-23T19:49:00 EndTime=2025-05-14T19:48:00 Duration=20-23:59:00 Nodes=g24-[05-06] NodeCnt=2 CoreCnt=64 Features=(null) PartitionName=(null) Flags=IGNORE_JOBS,SPEC_NODES TRES=cpu=64 Users=(null) Groups=(null) Accounts=pi_[USER] Licenses=(null) State=ACTIVE BurstBuffer=(null) Watts=n/a MaxStartDelay=(null) ... As my user (not in pi_[USER]): srun -M chip-gpu --time=1 --mem=1 --gres=gpu:0 --account=pi_[USER] --reservation=[USER] hostname srun: error: Unable to allocate resources: Invalid account or account/partition combination specified srun -M chip-gpu --time=1 --mem=1 --gres=gpu:0 --account=pi_doit --reservation=[USER] hostname srun: error: Unable to allocate resources: Access denied to requested reservation ''' On Mon Apr 21 22:32:05 2025, [USER] wrote: First Name:                Tejas Last Name:                 Gokhale Email:                     gokhale@[DOMAIN] Campus ID:                 [CAMPUS_ID] Request Type:              High Performance Cluster Hi, My group has reported being unable to run jobs on chip-gpu because of long waiting periods and this is a recurring issue.   I don't want to get into the details as to why it's happening, but my research group is unable to use the machines that I contributed.  As I communicated in the SIG-GPU meeting, I am opposed to the current usage model for exactly situations like these, where the only people upset are the contributors.  The meeting was quite productive and I am thankful to [STAFF] for taking the lead in drafting a new policy for review. But while we work out the policy, our research cannot suffer any additional delays.  Since I contributed two L40S nodes, I am requesting a reservation on these machines for the next three weeks. Thanks! Tejas"
"3170781","68987767","2025-04-29 04:23:18","HPC Other Issue: 'No space left on device' error","Hi [STAFF], Thank you for your response. I will create a new ticket for this. Thank you. Regards, [USER] On Mon, Apr 22, [STAFF] suggested moving everything from .cache in my home directory to /umbc/ada/donengel/users/[USER]/.cache and then running 'ln -s /umbc/ada/donengel/users/[USER]/.cache .cache'. I am trying to run a project (Python based) from the /umbc/ada/donengel/users/[USER]/3D-CODED directory on the CHIP cluster. Initially, this was on the ADA cluster, and I was able to locate the same folder on the CHIP cluster. Before running the code, I loaded the Anaconda3/2024.02-1 module using the 'module load Anaconda3/2024.02-1' command, and installed the required libraries (such as PyTorch, torchvision, and many others) into a conda environment. Currently, I am running into the 'OSError: [Errno 28] No space left on device: '/home/[USER]/.cache/matplotlib/fontlist-v330.json.matplotlib-lock'' when I try to run the code (screenshot attached). When I checked for available disk space, I found that there is 22% space left (screenshot attached). Could you please help me with this issue? Thank you. Regards, [USER]"
"3170789","69057971","2025-04-30 19:43:18","HPC User Account: [ID] in pi_[USER]","This is an email thread discussing a user's issue with accessing the contributor partition on the CHIP (High-Performance Computing) system at UMBC. The user, Maryam Rishehri, had previously had access to the contributor partition on the TAKI system but found that her account was now under the general partition after migrating to CHIP.  Here is a summary of the thread:  1. Maryam Rishehri emails the DOIT Unix Infra Student Worker (Max Breitmeyer) explaining her issue and requesting help. 2. Max responds, stating that he has checked Maryam's account and found that it was indeed under the general partition on CHIP. 3. Roy Prouty from the DoIT Research Computing Team takes over the conversation, explaining that contributor partitions were removed during the migration from TAKI to CHIP. 4. Maryam explains her project requirements and requests access to a contributor partition or a suitable alternative to run her simulations. 5. Roy offers alternative solutions, such as using the medium or large partitions, but also mentions that these may not provide the same level of priority as the contributor partition. 6. The conversation ends with Beamlak Bekele, another DOIT Unix Infra Student Worker, acknowledging Maryam's issue and likely taking over to assist her further.  The email thread highlights the complexity of managing user accounts and access control on high-performance computing systems, especially during migrations or upgrades. It also shows the importance of clear communication between users, administrators, and support staff in resolving technical issues."
"3170838","68894834","2025-04-23 16:19:06","HPC Other Issue: fixing the symbolic links on our disks","Just tell [STAFF] let's forget this approach. I doubt he would do it anyway. We will just change our software instead.  [USER]   On Wed, Apr 23, 2025 at 8:36 AM [EMAIL] via RT wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3170838> Last Update From Ticket: Hi [USER], Sorry for the delayed response. I passed your request up the chain to [STAFF] since making a new directory would require mounting this directory on all of the nodes, and would be another thing we would need to manage. I'll poke him and see if he's come back with anything for you though. On Tue Apr 22 08:50:07 2025, [USER] wrote: Request Type: High Performance Cluster Hi [STAFF], We were wondering if you saw [USER]'s response to ticket #3166395, about the symbolic links? I have cut and paste it below (btw I have changed permissions so [USER] can see /home/[USER]) Thanks -[USER] -------------------- [STAFF], I think something subtle has happened, but we do have a bit of a symbolic link mess in our directory structures, although they have been stable for 10+ years. I'd like to clean up our symbolic links but not sure you can do what I'd like to do. So, are you able/willing to make a REAL directory on 'chip' named /asl that we own? If you could do that I could then just put one layer of symbolic links under that, and we are done. Thanks, [USER]"
"3170954","69092796","2025-05-01 19:08:16","HPC Slurm/Software Issue: g20-12 Node In Error State","Flipped the card locations from bus 41 to 40. waiting to see if it fails again. On Tue Apr 29 09:18:06 2025, [STAFF] wrote: Hi [USER], Yea, it appears to be the same card. We're looking into getting that removed today. This should hopefully fix the problem. In the meantime, you can run on g20-13 which has the same card types. You can specify this using the --nodelist=g20-13 flag in either srun or sbatch. On Mon Apr 28 17:20:54 2025, [USER] wrote: Checking in on this again. I'm hesitant to start another job unless this is fixed as they take a few days to run. Are you able to see if there is one specific offending GPU causing this issue that can be removed from the list of available resources? On Thu, Apr 24, 2025 at 12:02 John [USER] wrote: Looks like this node is having the same issue again. Job ID is 53883. Here's the error I see on my end: RuntimeError: CUDA error: unspecified launch failure CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect. For debugging consider passing CUDA_LAUNCH_BLOCKING=1. Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions. It's soon followed by this error message the next time Ray Tune tries to schedule a trial on the errored GPU: ray.exceptions.ActorUnavailableError: The actor [ACTOR_ID] is unavailable: The actor is temporarily unavailable: RpcError: RPC Error message: ping timeout; RPC Error details:. The task may or not have been executed on the actor. Trial [TRIAL_ID] errored after 0 iterations at 2025-04-23 23:57:15. Total running time: 13min 42s Error file: /scratch/53883/session_2025-04-23_23-43-21_332837_100599/artifacts/2025-04-23_23-43-31/2025-04-23_23-43-21/driver_artifacts/[TRIAL_ID]/error.txt On Wed, Apr 23, 2025 at 10:02 [STAFF] via RT wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey. On Mon Apr 22 16:50:18 2025, [USER] wrote: Great, thanks Greg. Am I using too many resources on the node? I have been slowly scaling up my jobs to see where I hit a wall and this is my first time with any issues like this. On Apr 22, 2025, at 4:26 Greg Ballantine via RT wrote: Last Update From Ticket: Hello [USER], We started looking into your issue with g20-12 and were able to replicate your issue with nvidia-smi hanging. On Tue Apr 22 10:27:38 2025, [USER] wrote: Job ID: 51772 I started a job on this node last night. It seems that no progress is being made on my job - no computations are occurring but my application is not returning any errors. When I try to log into the node and run 'nvidia-smi' or 'top', the shell freezes up and I do not get a response. Is there a hardware issue with this node?"
"3171028","68986197","2025-04-29 01:05:45","HPC Other Issue: Request for SU2 Installation on [USER]'s CHIP Account","Hi [STAFF], Thank you so much for your help. It seems to be working now. I will create a new ticket if I run into issues later. Best Regards, [USER] On Fri, Apr 25, 2025 at 10:26 AM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hello I have successfully installed SU2. I am assuming the missing component was loading OpenMPI/4.1.6-GCC-13.2.0 before build and setting the prefix to the research volume. These are the commands I used to install it. git clone https://github.com/su2code/SU2.git module load OpenMPI/4.1.6-GCC-13.2.0 ./meson.py build --prefix=/umbc/rs/[STAFF]/common/SU2 ./ninja -C build install I have also added the environment variables to your .bashrc. Please run a test code and let us know if it is working as intended.  I will keep the ticket stalled to see if any issues arise. On Thu Apr 24 13:15:37 2025, [USER] wrote: Hi [STAFF], Yes, I think it's best to remove all previous instances and start from scratch. Please go ahead and delete all SU2-related folders—or let me know if you’d prefer I take care of it. None of the previous setups worked out. Best Regards, [USER] On Thu, Apr 24, 2025 at 11:36 AM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hello I was going through your directories and noticed there are two instances of SU2 — one located at /umbc/rs/[STAFF]/common/su2 and another at /umbc/rs/[STAFF]/common/SU2. Could you let me know which one is the most recent or currently in use? Also, would it be okay if I delete both instances and try cloning the directory again? I’m suggesting this because I encountered an error during installation related to MPI not being found. I was hoping to build SU2 with OpenMPI loaded and see if we get a different error or resolve it. On Wed Apr 23 15:52:57 2025, [USER] wrote: Hi Max, Thank you for getting back to me. When I initially submitted the ticket for the SU2 installation, Roy also mentioned that admin access shouldn’t be necessary and that I could handle it myself. Unfortunately, despite many attempts, I’ve been unable to complete the installation. I also discussed this with Roy during the 'User Support: Getting Started with CHIP' session, he even tried a quick installation using my account, but we encountered the same issues. He suggested I either submit a new ticket or set up a meeting to resolve the problem. And regarding your questions, yes I just want to use it (no development) and yes, I’d really appreciate it if you could install SU2 as a module. It’s an open-source software package used for CFD simulations. I’m currently working on a project funded by ONR under Dr. [STAFF]’s supervision, where we’re testing control techniques on various solid fuel ramjet CFD models, so having SU2 set up is essential. Best Regards, [USER] On Wed, Apr 23, 2025 at 9:56 AM Max Breitmeyer via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hi [USER], Are you looking to develop this code? Or just use it? I'm looking through the documentation and I'm not seeing anything that requires sudo access to have it installed. Were you looking to have it installed as a module? If so, why? On Tue Apr 22 11:28:22 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster Dear Roy, As we discussed after the 'User Support: Getting Started with CHIP' session, I’ve been unable to install SU2 on my CHIP account. You kindly suggested that I submit another RT ticket and reach out for assistance. I would really appreciate it if you could help install SU2 (or SU2code) on my account—preferably version 8.0.0 'Harrier.' All SU2 versions are freely available on GitHub: - Repository: https://github.com/su2code - Releases: https://github.com/su2code/SU2/releases?after=v7.0.2 Please let me know if you need any additional information from my side. Best Regards, [USER]"
"3171115","68895466","2025-04-23 16:35:57","HPC Other Issue: Space issue","This appears to be an email conversation between Uma Gayatri Kothuri and Max Breitmeyer, a Unix Infra Student Worker at the University of Maryland, Baltimore County (UMBC). The conversation is about Uma's request for additional storage space on the university's research directory (/umbc/rs/manas/users/oy83492) to support her work on large language models.  Here's a summary of the conversation:  Uma initially emails Max explaining that she has migrated her project files and environments to the research directory, but after cleaning up unnecessary files and dependencies, she still needs more storage space to complete her model runs. She requests either an increase in storage quota for her RS directory or an extension of her home directory quota to accommodate the resources needed for her active GPU jobs.  Max responds by informing Uma that he has created a new directory for her on the ADA cluster (/umbc/ada/users/oy83492) with a 500 GB quota. He also mentions that he can increase this quota if needed. Max also explains that the research directory (/umbc/rs/manas/users/oy83492) is not suitable for large language models and recommends using the ADA cluster instead.  Uma responds by thanking Max for creating the new directory, but expresses concern about the quota size being too small. She requests an increase in the quota to at least 1 TB.  Max responds again, explaining that he has increased the quota on the ADA cluster to 2 TB. He also provides instructions on how to access and use the new directory.  The conversation ends with Max providing additional information about the university's storage policies and resources available for researchers.  Overall, the conversation is about Uma's request for additional storage space to support her research work on large language models, and Max's efforts to accommodate her needs by creating a new directory and increasing the quota size."
"3171316","69315189","2025-05-14 15:29:32","QuantumEspresso run on chip-cpu 2021 partition","After isolating the problem to the last two lines of the script I investigated several solutions The root cause turned out to be related to how the job steps were launched and how MPI processes were managed by the scheduler In the original script the script was using mpirun for all steps including post-processing tools like bands.x and plotband.x These particular tools are not designed to run in parallel with MPI and forcing them to do so led to conflicts and the MPI_Abort errors we observed Additionally using mpirun in a SLURM batch environment can sometimes interfere with proper process cleanup and job termination You have mentioned the script doesn't have an error when submitting a job to the [SERVER] node My understanding is that on those nodes the system is able to handle the process management internally so the conflict does not manifest in the same way To resolve this I updated the script to use srun-SLURM's recommended launcher-for all steps For the post-processing tools that should run serially I specified srun -n 1 to ensure they only use a single process I also set a couple of Intel MPI environment variables I_MPI_HYDRA_BRANCH_COUNT=0 and I_MPI_JOB_FAST_STARTUP=0 to improve the stability of MPI process initialization and finalization With these changes the script now runs to completion without error and the job terminates cleanly This is what the new slurm file will look like #!/bin/bash #SBATCH --job-name=[JOBNAME] #SBATCH --account=[ACCOUNT] #SBATCH --output=slurm2.%jout #SBATCH --error=slurm2.%jerr #SBATCH --partition=[PARTITION] #SBATCH --qos=[QOS] #SBATCH --time=[TIME] #SBATCH --nodes=[NODES] #SBATCH --exclusive #SBATCH --cluster=[CLUSTER] module load QuantumESPRESSO/[VERSION]-intel-[YEAR] export I_MPI_HYDRA_BRANCH_COUNT=0 export I_MPI_JOB_FAST_STARTUP=0 srun pw.x < [INPUTFILE] > [OUTPUTFILE] srun pw.x < [INPUTFILE] > [OUTPUTFILE] srun pw.x < [INPUTFILE] > [OUTPUTFILE] srun projwfc.x < [INPUTFILE] > [OUTPUTFILE] srun dos.x < [INPUTFILE] > [OUTPUTFILE] srun -n 1 bands.x < [INPUTFILE] > [OUTPUTFILE] srun -n 1 plotband.x < [INPUTFILE] > [OUTPUTFILE]"
"3171521","69021460","2025-04-29 21:59:57","HPC Slurm/Software Issue: Issue Accessing JupyterLab on Compute Node via SLURM Tunnel","Hi [USER],  The issue just resolved itself; My jobs are running now, and I can access the jupyterlab.  Thanks so much!  Best, [STAFF]"
"3171819","68887939","2025-04-23 13:35:22","HPC Slurm/Software Issue: Stuck SLURM Job - Request for Manual Removal","Thank you so much I wasn't specifying the cluster Adding the flag --cluster=chip-cpu worked Issue solved Thank you so much for your quick response Best [USER] On Wed Apr 23 2025 at 9 26 AM [STAFF] via RT [EMAIL] wrote Ticket URL https rt umbc edu/Ticket/Display html?id=3171819 Last Update From Ticket Hi [USER] Can you give us the command for cancelling the job that you ran Typically with almost all slurm commands you need to specify the cluster So scancel 5534 --cluster=chip-cpu should do the trick Let me know if that still doesn't work On Wed Apr 23 09 11 22 2025 [USER] wrote First Name [USER] Last Name [USER] Email [EMAIL] Campus ID [CAMPUSID] Request Type High Performance Cluster Hi I submitted a job 5534 to the Chip cluster which is now stuck in a pending state with the reason launch failed requeued held I've attempted to cancel it using scancel and scontrol but I keep getting the error slurm_suspend error Invalid job id specified The job still appears in squeue but it seems to be in a broken or zombie state that I can't remove on my end Would you mind manually purging it from the system Job ID 5534 User [USER] Thanks so much for your help Best [USER]"
"3171981","68893510","2025-04-23 15:45:40","HPC User Account: [USER] in Student Group","It seems like some pubkey problems. I’ve resolved it. Thanks! [STAFF] From: via RT [EMAIL] Date: Wednesday, April 23, 2025 at 10:39 To: [EMAIL] Subject: [Research Computing #3171981] HPC User Account: [USER] in Student Group Greetings, This message has been automatically generated in response to the creation of a ticket regarding: Subject: 'HPC User Account: [USER] in Student Group' Message: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster Create/Modify account in Student group Hi, My account is [USER]. I can log in the chip with my password this morning. But now the password does not work. Thanks, [STAFF] Your ticket has been assigned an ID of [Research Computing #3171981] or you can go there directly by clicking the link below. Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3171981> You can login to view your open tickets at any time by visiting http://my.umbc.edu and clicking on 'Help' and 'Request Help'. Alternately you can click on http://my.umbc.edu/help"
"3171982","68893293","2025-04-23 15:40:03","HPC Slurm/Software Issue: Request for reserving a node from [ID] constraint for 5 days","First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Cluster Hello Team, I'm [USER], a graduate research assistant working at iHARP, UMBC. I'm writing to request a node from L40S constraint for 5 days for our research purposes, we also anticipate that the job won't take whole 5 days but just to be safe we're requesting more time. Can you please advise us through this."
"3171985","68896035","2025-04-23 16:55:15","HPC Slurm/Software Issue: slurm commands are not working","We apologize for the inconvenience, we needed to perform maintenance on the primary head node that would require it to be offline, but the failover to the secondary head node did not work as we had anticipated. We've reverted the changes we made and things appear to be working as normal. Please let us know if you are still having issues, and again, sorry for the inconvenience! On Wed Apr 23 11:42:44 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster This is the output of `sinfo` from login node (Q2E-dynamic-chip) [USER@login Q2E-dynamic]$ sinfo sinfo: error: slurm_persist_conn_open_without_init: failed to open persistent connection to host:master:6819: Connection refused sinfo: error: Sending PersistInit msg: Connection refused sinfo: error: Sending PersistInit msg: Connection refused sinfo: error: DBD_GET_CLUSTERS failure: Connection refused sinfo: error: Problem talking to database sinfo: error: There is a problem talking to the database: Connection refused. Only local cluster communication is available, remove --cluster from your command line or contact your admin to resolve the problem."
"3171993","68894753","2025-04-23 16:16:18","HPC Other Issue: chip unavailable?","No problem it works now thanks Ticket  Last Update From Ticket Hi [USER] We apologize for the inconvenience we needed to perform maintenance on the primary head node that would require it to be offline but the failover to the secondary head node did not work as we had anticipated Weve reverted the changes we made and things appear to be working as normal Please let us know if you are still having issues and again sorry for the inconvenience On [DATE] [USER] wrote First Name [USER] Last Name [USER] Email [EMAIL] Campus ID [CAMPUS_ID] Request Type High Performance Cluster Hi This morning I logged in [SERVER] but when I used this command cd /umbc/rs/[DIRECTORY]/[USER]/ to see my files it said No such file or directory This is regular directory that I always put my files in I logged out and tried to log in again it did not accept my password that I always use and the permission was declined Since morning I have not been able to log in Best [STAFF]"
"3171998","69037171","2025-04-30 14:41:04","HPC Slurm/Software Issue: Request for reserving a node from [ID] constraint for 5 days","Sounds good. I'll mark this as resolved, but please reopen if there are issues. -- [STAFF]"
"3172071","69456824","2025-05-22 16:02:20","iHARP AWS New Shell Creation","The requested accounts have been created and users have been assigned based off of the Google sheet. If we have verified that credits have been applied then you should be able to turn over the accounts to the users. I have added the accounts in Kion if you would like to setup a budget. If you run into problems please let me know. Have a nice day. -- [STAFF] DoIT, Windows System Administrator [EMAIL] (XXX)-XXX-XXXX"
"3172078","68939588","2025-04-25 15:34:43","iHARP: AWS Add [USER] to project 8 AWS Account# 050451374969","The requested users should see the account now for the AWS logon portal. Please let me know if there are reports of problems, have a nice weekend. -- [STAFF] DoIT, Windows System Administrator [EMAIL]"
"3172086","69456804","2025-05-22 16:00:21","iHARP: Add [USER] to project XI (New Shell)","The user has been created and added to project 13 administrator group. -- [STAFF] [EMAIL] (xxx)xxx-xxxx"
"3172148","68965638","2025-04-28 13:46:08","HPC Slurm/Software Issue: Docker Installation","Hi [USER], We probably won't install docker since it doesn't work super well with clusters. We have another containerized service that's specifically meant to work with clusters: apptainer/1.4.0-rc.2. Let me know if this works. There are other options we can look at if this doesn't work for you. On Wed Apr 23 13:50:29 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Hello Team, I would like to install Docker in my account for some of my current research work and was wondering if you could guide me through the installation process. Please let me know if you need any further information."
"3172155","68901770","2025-04-23 19:13:40","HPC User Account: [USER] in  pi_ndwalker","Hello [USER], I have changed the permission to pi_ndwalker research storage. You should be able to transfer your pipeline without an error.  On Wed Apr 23 13:54:28 2025, [STAFF] wrote: > First Name: [USER] > Last Name: [USER] > Email: [EMAIL] > Campus ID: [CAMPUSID] > Request Type: High Performance Cluster > Create/Modify account in existing PI group > Existing PI Email: [EMAIL] > Existing Group: pi_ndwalker > Project Title: Deep Learning-Assisted Histopathological Analysis Of Adipose Tissue Remodeling In Breast Cancer > Project Abstract: Breast cancer is one of the most commonly diagnosed cancers in women and a leading cause of cancer-related deaths worldwide. While tumor cells drive disease progression, the surrounding stromal microenvironment—particularly changes in adipose tissue—plays a crucial role in tumor growth and metastasis. Emerging evidence suggests cancer-associated adipose tissue undergoes structural remodeling, potentially serving as an early indicator of tumor presence. However, current assessment methods are subjective and lack scalable computational tools. To address this gap, we developed a deep-learning-based computational framework to analyze histopathological images of mammary adipose tissue and identify tumor-induced changes. Our approach applies automated image segmentation and machine learning models to quantify key morphological features—such as adipocyte size, shape irregularity, and spatial distribution—distinguishing normal adipocytes from cancer-associated adipocytes. We trained this model on tissue samples from breast cancer patients, comparing tumor microenvironment and distal (healthy) regions to capture distinct adipose remodeling patterns. By applying artificial intelligence to breast cancer pathology, our framework enables objective, scalable detection of cancer-associated stromal remodeling. We have identified statistically significant differences in adipocyte morphology, aligning with previous manual analyses. This tool has potential clinical applications for improving risk assessment, prognosis, and treatment planning in breast cancer management. > Hello! I was trying to log into the lab space to transfer the pipeline I have running on my personal laptop to the lab group storage—with all of our imaging data as well; but it appears that I do not have access to the folder to upload anything. I'd like to request access to the lab group: pi_ndwalker until May 2026. I have CC'd my lab PI, let me know if you have any questions."
"3172202","68935134","2025-04-25 13:30:32","HPC Other Issue: Issue updating version of program on CHIP","You cannot add software to system locations (/usr/local) in this manner. All of the nodes in the cluster are managed in order to keep them in an identical state since you don't know what node you are going to get when your job runs. Anything that did get added would be removed the next time the node reboots and its rebuilt from the baseline. The software will need to be added as part of the baseline by [STAFF] or you can relocate the software to a user location like inside your PI storage or if its very small your $home. The most common approach to this is the '--prefix' option to the configure script."
"3172573","68935046","2025-04-25 13:29:36","HPC Slurm/Software Issue: No Permission to Scratch Directory","Hi [USER], That's on us. It looks like we never put the changes in place for the g24-* machines. We'll get those rebooted so they have the appropriate scratch perms. In the meantime, it looks like all the g20-* machines seem to be working as intended. Please let us know if you notice any that are not so we can get those rebooted as well. On Wed Apr 23 23:53:16 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster Job ID: 52626 Following previous advice to avoid using /tmp for any temporary storage, I am instead using /scratch/$JOBID for storage. When running this job, my application encountered a permission error when writing to this directory. When I run the same application on g20-12, I do not encounter this permission error. Best, [STAFF]"
"3172713","68937825","2025-04-25 14:48:23","HPC Slurm/Software Issue: Module installation","Hi [STAFF], So I've gone ahead and installed ParMETIS/4.0.3-iimpi-2021a, and METIS/5.1.0-GCCcore-11.3.0. These should be compatible with the versions we currently have installed. Would you mind trying them out with intel 2021a compilers/iimpi, etc? If they don't work for you I'll see about getting all the previous versions of things installed as well. On Fri Apr 25 10:25:25 2025, [USER] wrote: Hi [STAFF], Sorry for the mess. NEED to install: - METIS/5.1.0-GCCcore-11.3.0 - ParMETIS/4.0.3-iimpi-2021b Below are the ones I don't know which version available on Chip is compatible: previous version:iimpi/2021b current versions: -iimpi/2021a -iimpi/2023a -iimpi/2024a previous version: impi/2021.4.0-intel-compilers-2021.4.0 current versions: -impi/2021.2.0-intel-compilers-2021.2.0 -impi/2021.9.0-intel-compilers-2023.1.0 -impi/2021.13.0-intel-compilers-2024.2.0 previous version: imkl-FFTW/2021.4.0-iimpi-2021b current versions: -imkl-FFTW/2023.1.0-iimpi-2023a -imkl-FFTW/2024.2.0-iimpi-2024a previous version: intel/2021b current versions: -intel/2021a -intel/2023a -intel/2024a Thank you for your help and patience. On Fri, Apr 25, 2025 at 9:58 AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3172713> Last Update From Ticket: Hi [STAFF], Happy to help, but the PDF you send is a little hard to parse. Could you send us a list of just the modules you need added? On Thu Apr 24 10:11:35 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USER] Request Type: High Performance Cluster Hi, I'm trying to load the modules I need to run simulations. On the PDF attached, there is a list of what I currently have on Chip, what I had on Taki, and a list of the modules I tried, but I don't know which version is compatible, or some modules that Chip does not have at all. I'm requesting help to know which software version is closer/compatible to what I had, and for the HPC personnel to install the modules that are not available at all. Thank you for your help."
"3172783","68920309","2025-04-24 17:28:27","RCD Consult: Requesting help for GPU memory issues","Hi [USER], I need more information, what are you confused about exactly? The error message seems to indicate your GPU ran out of memory. On Thu Apr 24 11:05:07 2025, [STAFF] wrote: First Name: [USER] Last Name: [LAST NAME] Email: [EMAIL] Campus ID: [CAMPUS ID] Request Type: Research Computing & Data Consultation I hope you are doing well. Can you please let me know while my program was working fine in the starting, why it is showing memory error in the middle of the progress? This is my ssh file attached Getting errors like these File '/umbc/ada/manas/users/[USER]/with_tokens_imhi/tokensimhi/lib64/python3.9/site-packages/torch/nn/modules/module.py', line 1750, in _call_impl return forward_call(*args, **kwargs) File '/umbc/ada/manas/users/[USER]/with_tokens_imhi/tokensimhi/lib64/python3.9/site-packages/transformers/models/llama/modeling_llama.py', line 262, in forward key_states, value_states = past_key_value.update(key_states, value_states, self.layer_idx, cache_kwargs) File '/umbc/ada/manas/users/[USER]/with_tokens_imhi/tokensimhi/lib64/python3.9/site-packages/transformers/cache_utils.py', line 446, in update self.key_cache[layer_idx] = torch.cat([self.key_cache[layer_idx], key_states], dim=-2) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacity of 44.40 GiB of which 162.12 MiB is free. Including non-PyTorch memory, this process has 44.24 GiB memory in use. Of the allocated memory 38.69 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation. See documentation for Memory Management."
"3172921","68934496","2025-04-25 13:15:31","Adding a [USER] to HPC","Your account ([USER]) has been created on [SERVER]. Your primary group is [GROUP]. Your home directory has 500M of storage. Please read through the documentation found at [SERVER] > User Support. All available modules can be viewed using the command 'module avail'. On Thu Apr 24 12:50:13 2025, [USER] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [ID] >  > On Behalf Of:             [USER] ([EMAIL], [ID]) >  > Request Type:              Help with something else >  > Please Add the student to Chip."
"3173099","69093229","2025-05-01 19:14:20","HPC User Account: [ID] in IHarp","It appears that this is a lengthy email thread between Al Amin and the UMBC Department of Information Technology (DOIT) regarding access to high-performance computing resources for research purposes. Here's a summary:  * Al Amin initially requested access to high-performance computing resources, providing context about his research project on quantum-enhanced hybrid deep learning for robust audio deepfake detection. * Beamlak Bekele, a DOIT Unix infra student worker, responded with instructions on how to access the resources and provided a ticket number (#3173099) for reference. * Al Amin replied, mentioning that he had tried to access the resources but was unable to do so. He attached an image (not visible in this text format) showing the error message he received. * Max Breitmeyer, another DOIT Unix infra student worker, responded, acknowledging Al Amin's issue and stating that he would look into it.  The conversation seems to be ongoing, with the IT team attempting to troubleshoot and resolve the access issue for Al Amin."
"3173492","69221966","2025-05-08 18:09:48","HPC Slurm/Software Issue: Help porting software from taki to chips","I'd be happy to help you with your query. However, I must point out that the text you provided appears to be a lengthy email conversation between multiple parties discussing issues with a high-performance cluster at UMBC.  To better assist you, could you please clarify what specific question or issue you would like me to address? Are you looking for information on how to resolve the problems mentioned in the email conversation, or is there something else I can help you with?"
"3173592","68962749","2025-04-28 12:44:44","Storage: [USER] Researcher needs storage space","Hi [STAFF], Please have [USER] fill out the request form on the hpcf website under 'User Support' -> 'Request Help' and fill out the section titled 'High Performance Cluster' and then 'Group Creation' On Fri Apr 25 10:37:58 2025, [EMAIL] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [CAMPUS_ID] >  > Request Type:              Research Storage >  > Research Storage action:      Request new allocation >  > Hi, >  > [USER] needs space for storing large amount of research data. How can we access HPCF for this purpose? >  > Thanks >  > [USER]"
"3173818","69440530","2025-05-21 18:01:02","iHARP: AWS Add users to project 4","[STAFF],  This has been updated.  Please let me know if there are problems.   -- [STAFF]"
"3173822","68945139","2025-04-25 18:24:15","HPC Other Issue: Getting error on ada","Hi [USER], You=E2=80=99re trying to run on Ada. All compute nodes on ada have been taken offline as of April 10th and migrated to chip.rs.[DOMAIN] (see: https://my3.my.[DOMAIN]/groups/hpcf/posts/147513) V/R, [STAFF] Graduate Student Computer Science [DOMAIN] GA HPCF System Administrator [DOMAIN] Observatory IT Manager [PHONE] On Fri, Apr 25, 2025 at 2:20=E2=80=AFPM RT API via RT <[EMAIL]> wrote: Fri Apr 25 14:20:13 2025: Request [NUMBER] was acted upon. Transaction: Ticket created by [USER] Queue: DoIT-Research-Computing Subject: HPC Other Issue: Getting error on ada Owner: Nobody - Nobody in particular Requestors: [EMAIL] Status: new Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=[NUMBER]> First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster Hello, when I run the squeue command, I get an error. I have attached a screenshot. Please help."
"3174044","69283952","2025-05-13 13:47:38","RCD Consult: how to display PDF files from chip","Glad that it was an easy fix! On Tue May 13 09:46:33 2025, [STAFF] wrote: Stupid me. Happens when I do not write down things immediately. Yes, that's it of course. Matthias K. Gobbert, Ph.D., Professor of Mathematics Department of Mathematics and Statistics Center for Interdisciplinary Research and Consulting (circ.umbc.edu) UMBC High Performance Computing Facility (hpcf.umbc.edu) REU Site: Online Interdisciplinary Big Data Analytics (BigDataREU.umbc.edu) University of Maryland, Baltimore County 1000 Hilltop Circle, Baltimore, MD 21250 http://www.umbc.edu/~[USER] On Tue, May 13, 2025 at 9:20 AM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hi [USER], Did you use salloc to get this interactive session? Or srun? If you used srun, by default it won't connect you to the new session with X11 forwarding enabled. This new page may help https://umbc.atlassian.net/wiki/spaces/faq/pages/1202749443/Accessing+GUI+Applications+on+Chip+Using+X11+Forwarding Let me know if anything is unclear in that page. On Mon May 12 16:19:55 2025, [USER] wrote: Dear [STAFF], I am so sorry to re-open this ticket and sorry I did not try it the other day. But at least I am getting an error message. Maybe I am doing something wrong (like not the same environment as you). I got interactive session. I used module spider xpdf to find what to load. Then these commands: module load texLive/2025 module load xpdf/4.04-GCCcore-12.3.0 seemed to work fine. I have XLaunch running on my Windows 10 laptop, so the issue is on chip. Namely, xpdf gave this error (I do not know what a Qt platform plugin is): [gobbert@c24-29 PsiMcCarthy]$ xpdf PsiMcCarthy_byGobbert250512.pdf & [1] 1737573 [gobbert@c24-29 PsiMcCarthy]$ qt.qpa.xcb: could not connect to display localhost:13.0 qt.qpa.plugin: Could not load the Qt platform plugin 'xcb' in '' even though it was found. This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem. Available platform plugins are: eglfs, linuxfb, minimal, minimalegl, offscreen, vnc, webgl, xcb. [1]+ Aborted (core dumped) xpdf PsiMcCarthy_byGobbert250512.pdf Can you see what the issue is? Matthias On Thu, May 1, 2025 at 3:06 PM [STAFF] via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3174044&ticketowner=mb17%40umbc.edu&ticketsubject=RCD Consult: how to display PDF files from chip If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3174044 Thank You _______________________________________ R e s o l u t i o n: Hi [USER], I've gone ahead and installed xpdf on both sets of architecture, and confirmed the modules work using a test of my own. If you have any questions please let me know. On Mon Apr 28 09:29:15 2025, [STAFF] wrote: Hi [USER], All the compute nodes (and the login node) have been configured with X11 forwarding. Using salloc, you should be able to run a series of -X ssh commands to get to a compute node and then have it display to your desktop. I can also start an install of 'evince' built on GCC-12.3.0 as well. On Fri Apr 25 20:47:11 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USER] Request Type: Research Computing & Data Consultation Hi, On taki, we had evince to display PDF files. (Under Windows on my laptop, I needed XLaunch for instance.) On chip, what do we have? The context is LaTeX. I can produce the PDF using pdflatex on a compute node (interactive session and after loading a module). I figure I might not be able to display the PDF from the session on that compute node. But how about from the user node? Similarly, how to display PNG or JPEG files? [USER]"
"3174047","68965266","2025-04-28 13:39:07","RCD Consult: [USER] Account Creation/Modification","Hi [USER], This it looks like you put in the wrong ticket type. Please fill out the account request using the following link as a guide: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip#Putting-in-a-Request-to-Access-Chip On Fri Apr 25 21:00:07 2025, [USER] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [ID] >  > Request Type:              Research Computing & Data Consultation >  > Create/Modify account in existing PI group > PI email: [STAFF] > PI group name:  [PROJECT NAME]"
"3174431","68963666","2025-04-28 13:07:26","HPC Other Issue: G24 nodes down","Hi [STAFF], Thanks for the heads up, we're working on it now. Many of them are back up! On Sun Apr 27 07:45:22 2025, [USER] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [ID] >  > Request Type:              High Performance Cluster >  > Do you know when some of the G24 nodes will be back up and running? > Half of them seem to be unavailable. > CLUSTER: chip-gpu > PARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST > gpu*         up   infinite      1  inval g24-11 > gpu*         up   infinite      3  down* g24-[01,03,08] > gpu*         up   infinite      6   drng g20-12,g24-[02,04-06,09] > gpu*         up   infinite      3  drain g20-[03,08-09] > gpu*         up   infinite      6    mix g20-[01-02,10,13],g24-[07,10] > gpu*         up   infinite      5   idle g20-[04-07,11] -- Best, [STAFF]"
"3174453","69076571","2025-05-01 13:58:22","HPC Software Issue: Installing ROOT across chip","Perfect, thanks for the update. I will leave this open until the build of the same version completes on the [SERVER] machines. Was there any other issue we should address in the scope of this ticket? On Thu May 01 09:54:18 2025, [STAFF] wrote:"
"3174507","69060639","2025-04-30 20:35:20","HPC Slurm/Software Issue: jupyter.slurm not working","Hi [USER], You are right, the vjaneja folder is 100% full. This will cause slurm jobs to fail. By moving your working directories over to the iharp volume, you should be able to resume your work. Sorry for the confusion. I'll mark this as resolved since you have a good plan, but feel free to reopen if there is some related issue. On Wed Apr 30 16:31:30 2025, [STAFF] wrote: Yes. You are a part of the iharp group and the pi_vjanega group. You can move files to /umbc/rs/iharp. On Wed Apr 30 14:33:42 2025, [USER] wrote: Roy, another update is I can use iharp resources, should I move all my files there? On Wed, Apr 30, 2025 at 2:32 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3174507 > Last Update From Ticket: Roy, Did you read the ticket from its start? As I mentioned, I have *NOT* changed the jupyter.slurm file, and it *used to work *before Friday!  As you can see in the slurm file, the cluster is defined! I have 'cluster=chip' ... Do you think that's the problem? The research storage of vjaneja is full! You have allocated 300G and it is all used. I am not sure if this is the reason, but the jupyter.slurm does not work as before, as explained with the details in the ticket. 300G is not as much as needed when we use large deep learning models. Also, could I request a much shorter waiting time for you to answer? Thanks! On Sun, Apr 27, 2025 at 12:54 PM via RT <[EMAIL]> wrote: Greetings, This message has been automatically generated in response to the creation of a ticket regarding: Subject: 'HPC Slurm/Software Issue: jupyter.slurm not working' Message: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Cluster hello, same sbatch jupyter.slurm command that I used to use, and it could give me jupyter connected to gpu, does not work since Friday. When I request it, without any notice, it only does not show up the assigned job id in squeue -u [USER]. It even does not show it as a pending job. The last job id is Submitted batch job 56604. The path to my jupyter.slurm is: /umbc/rs/vjaneja/users/[USER]/jupyter.slurm. I have not changed the jupyter.slurm file! Please let me know if you need any more information. thanks! module list Currently Loaded Modules: 1) slurm/chip-gpu/23.11.4 2) git/2.33.1 3) shared 4) DefaultModules -- [STAFF] DoIT Research Computing Team"
"3174863","68990912","2025-04-29 12:58:48","RCD Consult: requesting GPU access for experiments related to use of LLMs in solving advanced math problems","Hi [USER], Go to User Support and from drop down click Request help on this webpage: https://hpcf.umbc.edu On Tue, Apr 29, 2025 at 2:55 AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3174863> Last Update From Ticket: Can you share the link for the account request form ? Went to User Support --> Request help and ended up at the 'Contact DoIT Support' page (https://rtforms.umbc.edu/rt_authenticated/doit/DoIT-support.php?auto=Re%20Search%20Computing) as before Regards, [USER] On Mon, Apr 28, 2025 at 6:39 PM [STAFF] via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3174863&ticketowner=[EMAIL]&ticketsubject=RCD%20Consult:%20requesting%20GPU%20access%20for%20experiments%20related%20to%20use%20of%20LLMs%20in%20solving%20advanced%20math%20problems If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket Note: A full record of your request can be found at: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3174863> Thank You _________________________________________ Resolution: Hi [USER], Please fill out an account request form on our website under 'User Support' -> 'Request Help' On Mon Apr 28 01:52:47 2025, ZZ99999 wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USERID] Request Type: Research Computing & Data Consultation We are interested in the following experiments: 1 Take an opensource LLM and prompt it to 'behave like a mathematician' and note the performance on the MATH/MATHSQUARED dataset from Sanjeev Arora and co 2 Note the training freeze date of the opensource LLM and ask it to be an expert in highschool/undergraduate/graduate level math respectively We assume it has access to all data prior to the freeze date during pretraining, including previous Putnam exams and other undergrad math books from AMS/MAA or Springer's UTM etc The test will be on recent year's Putnam which we are sure happened after the training freeze Best, [STAFF] DOIT Unix Infra Student Worker"
"3175088","69043957","2025-04-30 16:20:44","HPC Other Issue: circular symbolic links","Further, it seems you and [STAFF] are working on this in the background. I'll resolve this ticket for now, given that we're talking about it in the other ticket [STAFF] and I have been going back and forth on. On Mon Apr 28 11:09:24 2025, [USER] wrote: Hi [USER], Please feel free to schedule something at this link: https://hpcf.umbc.edu/help/office-hours/. On Mon Apr 28 10:43:23 2025, [USER] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [ID] >  > Request Type:              High Performance Cluster >  > Could we all sit down sometime (virtually) to figure out the circular symbolic links. I'm mostly dead in the water for the last few days (can do limited matlab runs on strowinteract, but cannot submit to cluster ... conversely I can submit jobs to chip but they immediately crash since the disks/data cannot be accessed). >  > [STAFF] I'd really need you to be on th call since I have no clue what to do here. >  > Thanks >  > [USER]"
"3175346","68979099","2025-04-28 19:07:58","HPC Slurm/Software Issue: slurm error while requesting for GPU resources on CHIP","Hi [STAFF], Thank you for all the information. I was able to confirm the issue, and resolve it. We recently did a reboot on some machines when no jobs were running (including g24-05) and one of the system service that mounts the directories didn't come back up correctly. I was able to bring it back up, and confirm that the issue has been resolved. On Mon Apr 28 13:33:16 2025, [USER] wrote: > First Name: [USER] > Last Name: [USER] > Email: [EMAIL] > Campus ID: [CAMPUS_ID] >  > Request Type: High Performance Cluster >  > Hi, I and my labmate [USER] (cc'ed) [advisor: [STAFF] (cc'ed)] have been using reserved GPU on chip (g24-05 and g24-06). We have been facing a Slurm error while allocating the GPU on g24-05; though the resources get allocated, the bash gets redirected to the default state while raising a couldn't redirect to pi_location error. I have attached the detailed screenshot of the error; please refer to the screenshot and help us resolve the issue ASAP. Thanks, [USER]"
"3175364","70126032","2025-07-02 13:53:17","Storage: Data Storage","Hi [STAFF], There hasn't been any activity on this ticket since late April, so I'll mark this as resolved. Feel free to reopen if you have questions about our research storage offerings. On Wed Apr 30 08:46:10 2025, [STAFF] wrote: Hi [STAFF], These storage policies are constructed by DoIT in concert with various faculty governance groups. If you or your department would like to buy some storage that DoIT will maintain for the lifetime of the hardware, we're happy to discuss and guide the process. I'll also point out that archiving published datasets is generally handled differently than datasets used for active iteration in research workflows. Archived datasets can be stored relatively cheaply in various cloud platforms we provide. More 'active' datasets that are recalled more often are a different matter. To help me understand this, could you share a bit more about the provenance of the data (microscopy/simulated/etc)? And how long it might need to be stored? On Mon Apr 28 16:05:07 2025, [USER] wrote: Thanks for the reply! Most universities provide the infrastructure for data storage. This is a norm to maintain the research results obtained from important experiments. When I was at different institutes, I remember we had this cloud space for big data storage at no additional cost. Hopefully, the University Administration can provide a solution to this issue. Perhaps the University can pay this cost on behalf of the laboratories. Best, [USER] On Mon, Apr 28, 2025 at 3:36 PM Roy Prouty via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3175364> Last Update From Ticket: Hi [STAFF], Our default storage allocation within our enterprise storage systems is 10TB / lab. At the rate of 800GB/wk, it seems you would fill this in a matter of 3-4 months. Storage allocations beyond this 10TB must necessarily come with some cost. We can promise an additional 125TB within our storage systems for a time span of 3 years for a one-time cost of about $25K. We can also discuss ways to ramp-up storage usage to achieve a better cost:TB ratio over time. Dr. [STAFF] and I have been working together to better understand the needs of faculty around research data storage and how best to align our DoIT systems to those needs. Would you be willing to meet with Dr. [STAFF] and I sometime in the next week or so to discuss your needs? On Mon Apr 28 13:48:46 2025, [USER] wrote: > First Name: [USER] > Last Name: [USER] > Email: [EMAIL] > Campus ID: [CAMPUSID] > Request Type: Research Storage > Research Storage action: Request new allocation > Hi, We would like to request a space for storing the generated big data from my laboratory. The approximate file sizes are 800 GB per week. Thanks!"
"3175405","69001278","2025-04-29 15:50:01","HPC User Account: [ID] in Pi_[ID]","added to the list of projects -- Best, [STAFF]"
"3175477","68983938","2025-04-28 21:35:14","HPC Other Issue: Chip Issue","I visited one of the team members in person and the issue is resolved. Thank you! Regards  On Mon Apr 28 2025 at 4:53 PM [STAFF] via RT <[EMAIL]> wrote:  Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3175477 > Last Update From Ticket: Hi [USER] You can get in-person or virtual help by scheduling in our office hours here: https://hpcf.umbc.edu/help/office-hours/ In the meantime if you could provide us the exact set of commands that may help us more. On Mon Apr 28 15:25:15 2025 [USER] wrote: Are you available on campus? On Mon Apr 28 2025 at 3:22 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3175477 > Last Update From Ticket: Hi [USER] Could you please provide the exact set of commands and errors you are seeing? This will help us identify the issue faster. On Mon Apr 28 15:00:47 2025 [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [USER] Request Type:              High Performance Cluster To whom it may concern Hope you are doing well. I am trying to use a library called SAE-Lens which requires Python 3.10.x or higher. However when I attempted to install it I encountered a 'no space memory' error. Could you please help me resolve this issue? I need to fix it as soon as possible due to an upcoming deadline. Thank you. Best [USER]"
"3175485","69003754","2025-04-29 16:22:02","HPC User Account: [ID] in Quantum Thermodynamics","Hi [STAFF], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_deffner. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) On Mon Apr 28 15:04:05 2025, [USER] wrote: > First Name: [USER] > Last Name: [USER] > Email: [EMAIL] > Campus ID: [ID] > Request Type: High Performance Cluster > Create/Modify account in existing PI group > Existing PI Email: [EMAIL] > Existing Group: Quantum Thermodynamics > Project Title: Quantum Speed Limit for Scrambling > Project Abstract: This work presents a comprehensive study of quantum speed limits for information scrambling in many-body complex quantum systems. We have shown how a four point correlation function which is a diagnostic of quantum chaos is bounded by a two point correlation function. this is shown for many body quantum systems Future work will focus on refining bounds for many-body systems and experimental verification of the derived speed limits. I have been trying to create an account by filling up the form and I was received with the response that I will be contacted by someone but that never happened. I would like some assistance for creating an account in the HPC. I work with Dr. [STAFF] in the Department of Physics and other student/postdoctoral members in our group have been using the HPC. If you could help me create an account ASAP, it'd be really helpful as I'm approaching my project deadlines."
"3176038","69173523","2025-05-06 16:27:04","HPC Other Issue: ImportError: libcudart.so.10.0","The issue was your python and pytorch version weren't compatible so it wasn't able to find the gpu. I have created a new environment named [ENVIRONMENT] with python version 3.9, installed pytorch and run python setup.py install . This process has made it possible to import chamfer. These are the commands I used: conda create [ENVIRONMENT] python=3.9 conda activate [ENVIRONMENT] pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128 python setup.py install . In python when testing, you have to import torch then import chamfer. If you don't import torch before importing chamfer you will get this error below so be advised. Traceback (most recent call last): File '<stdin>', line 1, in <module> ImportError: libc10.so: cannot open shared object file: No such file or directory"
"3176611","69054473","2025-04-30 18:52:31","HPC User Account: [USER] in pi_[ID]","Hello Your path to access data has changed to /umbc/rs/[STAFF]. We have stopped using xfs. You can learn more on accessing your research volume at the link here https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip#Accessing-Research-Volumes On Tue Apr 29 11:49:39 2025, [USER] wrote: My data were under my advisor. I used to access it using cd /umbc/xfs1/[STAFF]/users/[USER]/ in taki. How to access that in Chip? Thank you, [USER] On Tue, Apr 29, 2025 at 11:42 AM [USER] <[EMAIL]> wrote: Hi [STAFF], I see, I can login but couldn't access research storage. There's nothing in my directory. On Tue, Apr 29, 2025 at 11:33 AM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hi [USER], You already have an account on chip. Did you have an issue logging in? On Tue Apr 29 11:31:52 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USER] Request Type: High Performance Cluster Create/Modify account in existing PI group Existing PI Email: [STAFF]@umbc.edu Existing Group: pi_[STAFF] Project Title: Regular research computing Project Abstract: Accessing chip in regular research computing. Hello, I want to create account in chip. My taki account: [EMAIL] Thank you, [USER] -- Best, [STAFF]"
"3176923","69074854","2025-05-01 13:23:32","HPC Other Issue: directory permissions","The text appears to be a email conversation between Roy Prouty, Sergio De Souza-Machado, and L. Larrabee Strow regarding access to directories on a high-performance cluster at UMBC (University of Maryland, Baltimore County).   Sergio requests that Roy give him and his team privileges to go through directories owned by former group members who have left the university, as they do not have permission to look through them.   Roy responds asking for clarification on the location of these home directories, as he does not see anything at the root level of /umbc/xfs2/strow or /umbc/xfs3/strow.  Larrabee Strow explains that many directories owned by members who have recently left the group did not give him permission to look through them. He also mentions that he intends to move the links from the shared disk space to their home directories instead."
"3176954","69028129","2025-04-30 11:18:17","RCD Consult: request for an account","Hi [USER], Please take a look at this page: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip#Requesting-a-User-Account-on-chip and resubmit a ticket. This ticket, as it stands doesn't have enough information for us to proceed and is not formatted properly. That page should step you through the process. On Tue Apr 29 13:01:13 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USER_ID] Request Type: Research Computing & Data Consultation need an account to access gpus for experiments"
"3177449","69028170","2025-04-30 11:21:48","HPC Slurm/Software Issue: Nodes down","Hi [USER], We are seeing heavy use of the cluster. g24-09 is back online, but it is now in use. There is one g24-* machine that is offline. We'll be working on this today. Thanks for the note and I hope you don't have difficulty running your workflows. On Tue Apr 29 15:18:39 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [ID] Request Type:              High Performance Cluster g24-09 with many other nodes are down. We have a conference deadline soon. So if you could fix it soon, that would be great. Thanks"
"3177613","69029683","2025-04-30 12:39:11","HPC Slurm/Software Issue: Cancel commands not cancelling slurm jobs","Glad it's working. We'll sort out the other issues via email. I'll close this ticket. -- [STAFF]"
"3177923","69036670","2025-04-30 14:35:18","HPC Slurm/Software Issue: scancel is not working","Thanks for the quick review. I'll mark this ticket as resolved. Take care. On Wed Apr 30 10:14:37 2025, [USER] wrote: Hello Roy, I think those are going to be useful for new & old users both. Thanks. [USER] On Tue, Apr 29, 2025 at 7:59 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3177923 > Last Update From Ticket: Hi again [USER], Could you let me know if the ideas presented toward the top of this page might be helpful to you or other users? https://umbc.atlassian.net/wiki/spaces/faq/pages/1033142321/Using+slurm+on+chip#Cancelling-Jobs On Tue Apr 29 19:08:59 2025, [EMAIL] wrote: This specific issue is not addressed within our user documentation. We'll work to get a page up within this space in the near future: https://umbc.atlassian.net/wiki/spaces/faq/pages/1082589207/UMBC+HPCF+-+chip FYI: You can get to this space via hpcf.umbc.edu > User Support > User Documentation [STAFF] (he/him/his) [EMAIL] Appointment Calendar The most dangerous phrase in the language is, 'We've always done it this way.' - Adm Grace Hopper On Tue, Apr 29, 2025 at 7:06 PM [USER] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3177923 > Comment From Ticket: Hello Roy, Thanks for your response. It worked, so the issue is fixed. I did not find the details about scancel on the wiki page. Can you point to me where I can get these details if I face similar issues in the future? [USER] On Tue, Apr 29, 2025 at 6:58 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3177923 > Last Update From Ticket: Hi [USER], Since there are two slurm clusters, you need to specify which you are trying to cancel a job on. In this way, you'll need to provide `scancel` with an additional flag: '-M <cluster>' or '--cluster=<cluster>'. You should set '<cluster>' to either 'chip-cpu' or 'chip-gpu' depending on which cluster you mean to operate on. A complete command for you might be: 'scancel --cluster=chip-cpu 14824' or 'scancel -M chip-cpu 14824' Let me know if this helps, I'll leave the ticket open for a few days to see. On Tue Apr 29 18:55:10 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster I have tried to cancel the submitted job using scancel {JOBID}. It did not work. [mdbadrh1@chip badrul]$ scancel 14824 [mdbadrh1@chip badrul]$ squeue -u mdbadrh1 CLUSTER: chip-cpu JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 14826 2018 wrf_test mdbadrh1 PD 0:00 1 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions) 14824 general wrf_test mdbadrh1 PD 0:00 1 (Priority) 14297 general bash mdbadrh1 R 41:18 1 c18-01 CLUSTER: chip-gpu JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) [mdbadrh1@chip badrul]$ Thanks. [USER] -- [STAFF] DoIT Research Computing Team"
"3178056","69030225","2025-04-30 12:52:48","RCD Consult: add [USER] to my Unix group on chip","Hi [USER], Your account ([USER]) has been added to the pi_[STAFF] group on chip.rs.umbc.edu. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/). You now have access to [STAFF]'s partition and the match partition. To access [STAFF]'s partition which will run jobs and has no chance of being preempted, use the following flags: --cluster=chip-cpu --account=pi_[STAFF] --partition=pi_[STAFF] --qos=pi_[STAFF]. To access the 'Match' partition which will run jobs and has no chance of being preempted, but still has a core/time limit, use the following flags: --cluster=chip-cpu --account=pi_[STAFF] --partition=match --qos=shared. For more information on the QOS', see the following: https://umbc.atlassian.net/wiki/spaces/faq/pages/1173389327/chip-cpu+QOS+Restrictions. On [DATE], [STAFF] wrote: > First Name: [STAFF] > Last Name: [STAFF] > Email: [EMAIL] > Campus ID: [CAMPUSID]. Request Type: Research Computing & Data Consultation. Hi, Please add user [USER] ([USER]) to my Unix group (as secondary group for her) on chip. Best, [STAFF]."
"3178059","69027593","2025-04-30 10:12:19","RCD Consult: [USER] use of scontrol for array jobs","Since there are two slurm clusters, you need to specify which you are trying to operate on. In this way, you'll need to provide `scontrol` with an additional flag: '-M <cluster>' or '--cluster=<cluster>'. You should set '<cluster>' to either 'chip-cpu' or 'chip-gpu' depending on which cluster you mean to operate on. A complete command for you might be: 'scontrol --cluster=chip-cpu show job [JOBID]' or 'scontrol -M chip-cpu show job [JOBID]'. Let me know if this helps, I'll leave the ticket open for a few days to see. On Tue Apr 29 20:36:26 2025, [USER] wrote: First Name:                [USER] Last Name:                 [STAFF] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              Research Computing & Data Consultation Hi, I am looking at an array job which has many lines of output in squeue, including for example           [JOBID]   general nsga_par bhargvb1  R    2:08:39      1 c18-30          [JOBID]   general nsga_par bhargvb1  R    2:08:39      1 c18-30          [JOBID]   general nsga_par bhargvb1  R    2:08:39      1 c18-30          [JOBID]   general nsga_par bhargvb1  R    2:08:39      1 c18-30 I am trying to use scontrol show job but when I use either [JOBID] or [JOBID], it says [gobbert@chip ~]$ scontrol show job [JOBID] slurm_load_jobs error: Invalid job id specified How do I use this correctly to get scontrol output???"
"3179255","69220739","2025-05-08 17:37:10","HPC Other Issue: run matlab on chip","On Thu May 08 11:27:33 2025, [USER] wrote: Hi [STAFF] Today I got the results from chip successfully, your suggestion is very helpful to me. It is the reason that I put the wrong path. Thank you again! Best [USER] > Hello > We met yesterday to discuss error you were having when submitting a MATLAB jobs. I suggested changing the path, because one of the errors was saying matlab can not find a directory. Did you submit a new job and was it able to output expected results? > I also suggested running an interactive job, editing your slurm script to have .out and .err file and running your friends code from your account.  I just wanted to write it here so you remember :) > On Tue May 06 07:41:41 2025, [STAFF] wrote: > Hi [USER], > These screenshots are cut off, so I can't tell if the commands are correct. It's best practice to simply copy and paste the commands and any output or errors into the body of the ticket. > I'd really like to get your workflow working, perhaps it would be easiest for us to meet briefly to see the issues 'live'. If you'd like please navigate to [URL] User Support Office Hours to schedule a time to meet either in-person or virtually. Either me or one of my colleagues would be happy to sit with you to get this figured out. > On Fri May 02 17:40:37 2025, [USER] wrote: > Hi [STAFF], > Yesterday I resubmit the job on chip, but I still get errors. My job ids are 59703 59702 59701 59700 and the details of my code and steps are attached. > Best [USER] > On Thu May 01 09:33:14 2025, [STAFF] wrote: > Hi [USER], > This job ID is for chip-gpu. Your screenshot shows chip-cpu. Please confirm that the issue exists and provide the accurate slurm script, steps taken, and reported error. Please just copy and paste these into the body of the ticket. > On Wed Apr 30 14:02:49 2025, [USER] wrote: > Hi the job id is  57777 thank you > On Wed Apr 30 12:16:52 2025, [STAFF] wrote: > Hi [USER], > I don't see this failed job in the slurm logs for chip-cpu. Could you tell me the job ID of the failed job? > I also see that the updated version of this slurm script uses a GPU and calls chip-gpu. Was that job run successful? > On Wed Apr 30 12:03:48 2025, [USER] wrote: > Request Type: High Performance Cluster > I hope this email finds you well. Right now I have a very urgent task to run on chip, but unfortunately I was unable to get any results from chip since it keeps give me errors. Since everyone in the lab is using the same code but I’m the only one have errors. I asked lots of people around me but none of them were able to solve the problem for me. Therefore, I’m wondering if you could help me to find our the errors. I’m very appreciated if you are willing to help."
"3180131","69060945","2025-04-30 20:43:20","HPC Other Issue: Adding a Coding Language","Hi [USER], I've installed Julia with versions 1.9.3 and 1.10.4 across the cluster. I tested with a tiny command line script: julia -e 'println(PROGRAM_FILE); for x in ARGS; println(x); end' foo bar and saw success [ebuild@c18-01 ~]$ module load Julia/1.9.3; julia -e 'println(PROGRAM_FILE); for x in ARGS; println(x); end' foo bar foo bar ... [ebuild@c21-01 ~]$ module load Julia/1.9.3; julia -e 'println(PROGRAM_FILE); for x in ARGS; println(x); end' foo bar The following have been reloaded with a version change: 1) Julia/1.9.3-linux-x86_64 => Julia/1.10.4-linux-x86_64 foo bar On Wed Apr 30 15:34:40 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster I previously used the Taki cluster and used the programming language Julia. I don't currently see Julia as an option for a language to use, so is it possible to download that language onto Chip so I can use it there as well? The version doesn't matter too much, 1.9.3 is what I use on my own laptop for example."
"3180245","69121929","2025-05-02 18:20:53","Slurm issue","Outstanding. It worked for me as well. Thank you so much [STAFF]. You can turn off this ticket. However, plz do not close software ebuild one, geant4 etc. Regards On Fri, May 2, 2025 at 1:53 PM [EMAIL] via RT <[EMAIL]> wrote: Ticket [URL] Last Update From Ticket: Hi [USER], Can you some clarification on the slurm file you were having an issue with? I was able to create a little dummy script. I tested it with and without the exclusive option. Without the exclusive, all jobs ran at the same time in the general partition. With the exclusive flag, it could only run 8 jobs at a time with the rest being held due to 'resources' (this of course meaning that the resources I requested weren't available (ie, an entire node to myself). #!/bin/bash #SBATCH --cluster=chip-cpu #SBATCH --time=10 #SBATCH --mem=500 #SBATCH --account=pi_doit #SBATCH --partition=general #SBATCH --qos=short #SBATCH --array=1-36%36 #SBATCH --job-name=array_test #SBATCH --exclusive #SBATCH --output=array_test-%j_%a.out echo '$(hostname):$(date)' sleep 10 echo '$(hostname):$(date)' Here's the script in question. Let me know if you have more questions. On Thu May 01 15:11:59 2025, [USER] wrote: Hi [USER], This ticket is becoming very confusing. Please keep the ticket topic to one idea. Installation of Geant4 is different from debugging a slurm file. I will leave this ticket focused on debugging a slurm file and leave that to [STAFF]. I will work on Geant4 on another ticket [USER] opened (I'll CC you). On Thu May 01 15:04:47 2025, [USER] wrote: Dear [STAFF], I humbly requested you to plz use Geant4 version geant4-v10.7.3I have the tar file, and plz you ebuild this version only. else our code will pass through some major changes and this will be time consuming. This version was on taki, module load Geant4/10.07.03-GCCcore-11.2.0 Please we do not need this one module load Geant4/10.7.1-GCC-11.2.0 Best Regards [USER] On Thu, May 1, 2025 at 12:09 PM [USER] <[EMAIL]> wrote: Hi [STAFF], Ehsan made a discovery in the slurm file.Now i am able to submit the jobs on an exclusive partition 2018 But the problem is with this slurm file though the array is define to be 36,I can see only one file output, not 36 outputs.#SBATCH --array=1-36 So I have done a slight change to #SBATCH --array=1-36%36 and this generates 18 files started at the same time. GOOD.However, I was expecting 36 files to start at the same time. As from previous experience working on exclusive. Does it mean that the 2018 exclusive has 18 nodes. if so, I need to redesign the data time. Any ideas ? Regards [USER] On Thu, May 1, 2025 at 10:22 AM [STAFF] via RT <[EMAIL]> wrote: Ticket [URL] Last Update From Ticket: I can only blindly comment on which of those directives you should use... Remove the line: '#SBATCH --cpus-per-task=1' and rerun. On Thu May 01 09:53:48 2025, [USER] wrote: I got thissrun: fatal: SLURM_MEM_PER_CPU, SLURM_MEM_PER_GPU, and SLURM_MEM_PER_NODE are mutually exclusive. this is the slurm file i usd #!/bin/bash #SBATCH --cluster=chip-cpu #SBATCH --job-name=GEANT4 #SBATCH --output=chip_test/slurm_op/slurm%a.out #SBATCH --error=chip_test/slurm_err/slurm%a.err #SBATCH --account=pi_gobbert #SBATCH --partition=2018 #SBATCH --qos=medium #SBATCH --time=15:00:00 #SBATCH --cpus-per-task=1 #SBATCH --mem-per-cpu=8G #SBATCH --array=1%36 #SBATCH --exclusive hostname srun POLARIS3 poin_experimental_energy_data.mac chip_test/data_geneChip On Thu, May 1, 2025 at 9:52 AM [USER] <[EMAIL]> wrote: I got thissrun: fatal: SLURM_MEM_PER_CPU, SLURM_MEM_PER_GPU, and SLURM_MEM_PER_NODE are mutually exclusive. On Thu, May 1, 2025 at 9:48 AM [STAFF] via RT <[EMAIL]> wrote: Ticket [URL] Last Update From Ticket: This job failed after one second of runtime. sacct -M chip-cpu -Xj 16810 --format='jobid,user,account,cluster,elapsedraw' JobID User Account Cluster ElapsedRaw ------------ --------- ---------- ---------- ---------- 16810_1 [USER] pi_gobbert chip-cpu 1 Could you provide any output and error file contents in the body of this ticket? On Thu May 01 09:29:23 2025, [USER] wrote: 16810 -- [STAFF] DoIT Research Computing Team -- [STAFF] DoIT Research Computing Team -- Best, [STAFF] DOIT Unix Infra Student Worker"
"3180466","69072991","2025-05-01 12:44:40","HPC Slurm/Software Issue: Error Message","Hi [STAFF], We need more information before we can help with this. What's the slurm job number you tried to run? What modules are you using? Sending us a generic error message 'Aborted (Core Dumped)' with almost no context doesn't provide us enough information to be able to look into this. On Wed Apr 30 17:53:30 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USER] Request Type: High Performance Cluster I was running some input file in my radiative transfer model. I got the attached error. Is it because of any memory issue? RTM says we need high memory to run this particular setup Attachment 1: Error.png"
"3181846","69164008","2025-05-06 13:03:59","RCD Consult: small issues with groups and related","Hi [STAFF], sorry for the long delay. I've reinstated that directory on taki, but to be clear, you're ls'ing the same directory on both systems. I'll close this for now. Let me know if you have other issues. On Fri May 02 11:20:34 2025, [USER] wrote: Hi [STAFF], Thank you! I thought that the files on taki and chip are really the same, so I am accessing both ways right now. But otherwise, the reason for accessing from taki right now is that I would like to systematically list 'ls -l' the contents of all my top-level areas and see the same subdirectories/files on both to check that I can see them correctly on both systems. Does that make sense? [USER] On Fri, May 2, 2025 at 11:00 AM [STAFF] via RT wrote: Ticket Last Update From Ticket: Hi [USER], I've changed the group number to be in line with it's LDAP number, let me know if there are more issues with this. I've verified that [USER] is part of the hpcreu group. hpcreu on chip seems to be working successfully, and all data should be the same from taki, why are you still trying to access it? We're not supporting/making changes to taki anymore. On Thu May 01 12:24:34 2025, [USER] wrote: Request Type: Research Computing & Data Consultation Hi, Group 'vitals': On chip, the output of 'ls -l' shows a number 1186 instead of the group 'vitals'. This makes it inaccessible to other group members than myself. Group 'hpcreu': Please check that [USER] is a member of the 'hpcreu' group. Maybe that's the problem. Now, on taki, I get a 'stale file handle' for the hpcreu area, like [USER@taki-usr1 ~]$ ll /umbc/xfs1/ [...] drwxrwx--- 4 [USER] pi_[USER] 47 Feb 28 2022 [USER]/ d????????? ? ? ? ? ? hpcreu/ dr-xr-xr-x 2 root root 0 Jan 8 12:53 [USER]/ dr-xr-xr-x 2 root root 0 Nov 22 09:40 [USER]/ [...] Can you check this? [USER]"
"3182432","69168562","2025-05-06 14:42:46","Geant 4 Install","Excellent! Glad you've got it working. I'll mark this as resolved. Please consider filling out the survey if you have time. Take care On Tue May 06 10:41:56 2025, [USER] wrote: Dear [STAFF], I confirm that the code works very well and data collection is going so fine. Million thanks for the support and action. Best Regards [USER] On Tue, May 6, 2025 at 8:49 AM [USER] <[EMAIL]> wrote: Thank you [STAFF], I'll give it a try this afternoon. On Tue, May 6, 2025 at 7:38 AM [STAFF] via RT <[EMAIL]> wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3182432 Hi [USER], I've installed the same versions of ROOT and DCMTK across the 2024 hardware. The CMake version is 3.18.4. Please try with this version and let me know if you find success. I'll leave this ticket open for a few more days before resolving if I hear no issues. -- [STAFF] DoIT Research Computing Team"
"3182474","69109540","2025-05-02 13:12:44","HPC Slurm/Software Issue: Sbatch Error","Hi [USER], There was a temporary slurm issue, it should have been resolved minutes after this ticket was submitted. Sorry for the lag here, and thank you for sending us a note on it. Let me know if you run into similar issues. On Thu May 01 16:55:07 2025, [STAFF] wrote: First Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Hi, I am having error when submitting a job. Here is the error message. 'sbatch: error: slurm_persist_conn_open_without_init: failed to open persistent connection to host:master:6819: Connection refused sbatch: error: Sending PersistInit msg: Connection refused sbatch: error: Sending PersistInit msg: Connection refused sbatch: error: DBD_GET_CLUSTERS failure: Connection refused sbatch: error: Problem talking to database sbatch: error: There is a problem talking to the database: Connection refused. Only local cluster communication is available, remove --cluster from your command line or contact your admin to resolve the problem.'"
"3182506","69219875","2025-05-08 17:14:57","HPC Slurm/Software Issue: [USER] unable to get access to resources","Feel free to schedule a meeting via this link: https://hpcf.umbc.edu/help/office-hours/. The sacct command only shows jobs that have been submitted within the last day. Have any of your jobs that you're having issues with been run today? If not, try again, then run the sacct command. On Thu May 08 12:28:46 2025, [USER] wrote: Can we please have a online meeting to resolve this issue? Thanks and Regards, [USER]. On Tue, May 6, 2025 at 3:40 PM [STAFF] via RT wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3182506. Last Update From Ticket: It seems your jobs are failing immediately. What does an output of 'sacct -M chip-gpu -u [USER]' give you? [STAFF]. On Tue, May 6, 2025 at 2:47 PM [USER] via RT wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3182506. Comment From Ticket: I have pasted the path in ticket and also in the mail. /umbc/rs/iharp/users/[USER]. Thank you. On Tue, 6 May 2025, 7:27 am [STAFF] via RT wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3182506. Last Update From Ticket: Here is best. On Fri May 02 19:17:07 2025, [USER] wrote: Hii, Should I paste it here or should I raise another ticket and paste there? On Fri, 2 May 2025, 9:11 am [STAFF] via RT wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3182506. Last Update From Ticket: Hi [USER], Please provide the location of the sbatch script and its contents (just copy and paste into the body of the ticket). It seems your job is failing immediately. I can't begin to investigate without this information. On Thu May 01 18:27:42 2025, [USER] wrote: There is no error or output file that was generated. even when i did cat *502.out , there was no error message too. On Thu, May 1, 2025 at 6:14 PM [STAFF] via RT wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3182506. Last Update From Ticket: Hi [USER], It's likely that your job failed quickly. I looked at all of the jobs you submitted today and it seems that each of them failed almost immediately. Could you provide any error or output files that are generated by your job? ````[~]# sacct -M chip-cpu,chip-gpu -u [USER] JobID JobName Partition Account AllocCPUS State ExitCode ------------ ---------- ---------- ---------- --------- ---------- -------- 59502 jupyter gpu pi_vjaneja 2 FAILED 127:0 59502.batch batch pi_vjaneja 2 FAILED 127:0 59565 jupyter gpu pi_vjaneja 2 FAILED 127:0 59565.batch batch pi_vjaneja 2 FAILED 127:0 59566 bash gpu pi_vjaneja 2 TIMEOUT 0:0 59566.0 bash pi_vjaneja 2 CANCELLED 0:9 59568 jupyter gpu pi_vjaneja 2 FAILED 127:0 59568.batch batch pi_vjaneja 2 FAILED 127:0 ``` On Thu May 01 17:12:51 2025, [USER] wrote: First Name: [USER]. Last Name: [USER]. Email: [EMAIL]. Campus ID: [USER]. Request Type: High Performance Cluster. Dear team, I am facing the same issue again. I am able to submit a job , but after submitting , I am not able to see my job ID. This Tuesday, I had shared my screen and showed you what was happening and was resolved at that time. but i am facing the same issue again , if possible can we have a meeting and get it resolved. Thank you. Attachment 1: sbatch.png. -- [STAFF]. DoIT Research Computing Team"
"3183846","69147402","2025-05-05 16:35:52","HPC Other Issue: Moving Packages to Research Storage","Hi [USER],   I highly suggest you review our documentation available on our website (hpcf.[DOMAIN], here's the link directly to the documentation: https://[DOMAIN].atlassian.net/wiki/spaces/faq/pages/[PAGE_ID]/[TITLE]) and possibly attending one of our 'Getting Started with chip' events to assist users in the transition to chip. One of those is happening today at 1pm in [BUILDING] [ROOM] (https://my3.my.[DOMAIN]/groups/hpcf/events/[EVENT_ID]). Either way, you should review the 'getting started with chip' page in the wiki, it has answers for all of your questions.  You are correct in your reasoning that the .julia folder in your home directory is causing the out of space error. You are also correct in the steps to solve this issue! Currently, as a member of [GROUP], your research storage is located at /umbc/rs/[DIRECTORY]. This is where you will be able to store all of the data you need. Previously, on taki and ada, we used symbolic links in the home directory to allow users to easily access these files, but those caused some issues so we decided to use aliases instead to provide similar functionality. If you run the command 'alias' you should see a list of available aliases for your user account. Some of the entries will look like the following alias [ALIAS_NAME]='cd /umbc/[DIRECTORY]/[SUB_DIRECTORY]'  These alias entries allow you to type just '[ALIAS_NAME]' to navigate to the research volume directories.   Here is a link to the wiki page where you can find instructions on how to move the hidden folder (.julia in this case) that is taking up space to your research volume and create a symbolic link. https://[DOMAIN].atlassian.net/wiki/spaces/faq/pages/[PAGE_ID]/[TITLE]  If you have any further questions or encounter issues, feel free to create a new ticket (or attend one of our getting started with chip events!! they go over most common questions/concerns/issues!!)  --  Kind regards, [STAFF]."
"3184319","69170424","2025-05-06 15:13:14","HPC Slurm/Software Issue: Slurm Job Does Not Start","Hi [STAFF], There was an issue with the slurm module not being picked up, but this has been resolved. Try it again and let me know if it's still an issue. On Sun May 04 22:36:50 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Job ID: 60668 This occurs on node g24-11. When the job starts, my application never starts. To investigate, I tried to get into the node and get this response: [johnv3@chip rf-dvae]$ srun --jobid=60668 --pty $SHELL Lmod has detected the following error: The following module(s) are unknown: 'slurm' Please check the spelling or version number. Also try 'module spider ...' It is also possible your cache file is out-of-date; it may help to try: $ module --ignore_cache load 'slurm' Also make sure that all modulefiles written in TCL start with the string #%Module"
"3184580","69160869","2025-05-06 11:10:39","REDCap","Hi [USER], UMBC DoIT only manages the server infrastructure for the REDCap machine. I'll connect you via email to the faculty 'owners' of the software. I'll mark this as resolved, I hope you hear back from the REDCap faculty administrators soon. On Mon May 05 11:28:34 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              Help with something else Hi, I would like to have access to REDCap (https://redcap.umbc.edu). When I clicked the link, it mentioned, 'The following user account has not yet been granted access to REDCap: '[USER]'. To request access to REDCap, you may contact REDCap Administrator. Thank you!"
"3184732","69176634","2025-05-06 17:49:01","HPC User Account: [USER] in Student Group","Hi [STAFF], ok I will generate a new ticket with the information. Thanks. On Tue, May 6, 2025 at 1:02 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3184732> Last Update From Ticket: Hi [USER], I don't know what project 3 means in this context, but I have seen it in AWS. Is this what you're looking for? Either way, please submit a new RT ticket on this request. Be sure to note the group and PI for our records, on the same form is the cloud computing ticket form -- in case you're expecting to be on AWS. [STAFF] On Tue, May 6, 2025 at 12:49 PM [USER] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3184732> Comment From Ticket: Hi, I am working on Project 3 of iHarp. Yes, you can create my account in the iHarp group. Thanks. On Tue, May 6, 2025 at 7:02 AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3184732> Last Update From Ticket: Hi [USER], Could you provide information about what project you'll be working on within the student group? I see that you're in the iHARP research lab. Should your account be instead created within the iHARP group? On Mon May 05 13:42:44 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster Create/Modify account in Student group I want to create an account on chip."
"3184750","69153008","2025-05-05 18:40:32","HPC User Account: [ID] in [STAFF]","Hello [USER],  Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is [STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/)  -- Kind regards, [STAFF]  On Mon May 05 14:04:30 2025, [USER] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [USER] > Request Type:              High Performance Cluster > Create/Modify account in existing PI group > Existing PI Email:    [EMAIL] > Existing Group:       [STAFF] > Project Title:        Radiative Transfer for Atmosphere > Project Abstract:     Radiative transfer modeling is essential for understanding the propagation of electromagnetic radiation through Earth’s atmosphere. Using a supercomputer cluster, we efficiently solve complex radiative transfer equations with high-resolution spectral data. This enables precise simulation of atmospheric profiles, aiding climate studies, and remote sensing applications. > I am requesting access to run high-resolution radiative transfer simulations for atmospheric research using LBLRTM and associated tools."
"3185183","69188790","2025-05-07 13:17:45","HPC Other Issue: install AWS interface","Hi [USER], We'll do some testing around networks and see what we come up with. I have some ideas. On Tue May 06 12:46:19 2025, [STAFF] wrote: Thanks [STAFF], It works, so far. The average download speed from S3 bucket to Chip is about 65MB/s, which is good, but a bit lower than I thought. If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://[DOMAIN]/SE/?SID=SV_[ID]&customeremail=[EMAIL]&groupid=EIS&ticketid=3185183&ticketowner=[STAFF]&ticketsubject=HPC Other Issue: install AWS interface. If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://[DOMAIN]/Ticket/Display.html?id=3185183. Thank You. Hi [USER], Easy install today. A module has been created and can be loaded with 'module load awscli'. As a reminder please take precaution when storing your credentials on the cluster. Your home directory is probably the safest place. As you are also the first group to request the use of aws on the cluster, we would love to see what your doing with it. Any information for how you're using it/how you set up your environment would be very helpful. We'll reach out soon! Hi [USER], We'll work on getting this installed. I'll let you know once it's ready! First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Cluster can you install the AWS Command Line Interface (AWS CLI) in Chip so we can access the data in AWS buckets? Thanks"
"3185550","69202822","2025-05-07 19:26:25","HPC User Account: [ID] in iHARP","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is iharp. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) -- Kind regards, [STAFF] DOIT Unix Infra Student Worker On Tue May 06 13:56:16 2025, [USER] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [CAMPUS_ID] > Request Type:              High Performance Cluster Create/Modify account in existing PI group Existing PI Email:    [EMAIL] Existing Group:       iHARP Project Title:        Project 3: Ice Sheet Layer Annotation and Validation Project Abstract:     Glaciers and ice sheets flow to lower elevations where they melt, and their internal structure, imaged by ice-penetrating radar, contains valuable records of past ice flow. Annotating these radar-detected layers is crucial for validating ice sheet models and improving projections of future sea level rise. However, limited expert-annotated data and inconsistent validation metrics in the current literature pose challenges. So our project includes creating a novel ground-truth independent metric used for validating the manual as well as automated annotations of radargram images and then creating automated annotations. Create my account in the iHARP PI group and my PI is [STAFF]."
"3185696","69292567","2025-05-13 16:26:57","RCD Consult: Support for Apptainer environment setup and running on HPC (slurm- 61311)","Hello [STAFF] We have installed Apptainer 1.3.5 and is available as a module. If you can't see apptainer/1.3.5 as available on the cluster. Please try the command 'module --ignore-cache avail apptainer', that should show you both v1.3.5 and v1.4.0-rc.2. On Fri May 09 10:59:47 2025, [STAFF] wrote: The CA bundle can be found under /etc/ssl/certs for all nodes. Let me know if you have trouble accessing them. I'll look into getting another version of apptainer installed. On Tue May 06 15:51:26 2025, [USER] wrote: Request Type: Research Computing & Data Consultation Dear HPCF Support Team, I hope you are doing well. My name is [USER], a research assistant in Dr. [STAFF]'s group ([EMAIL]). I am currently running experiments on flakiness in quantum-related code and rely on an Apptainer-based CI pipeline for reproducibility. 1 TLS CA certificate bundle missing While installing Python dependencies inside the container, I receive the following error: Could not install packages due to an OSError: Could not find a suitable TLS CA certificate bundle, invalid path: /home/[USER]/ca-certificates.crt It appears the standard certificate bundle is not available at the expected path. Could you please provide (or point me to) the correct CA certificate bundle on HPCF so that TLS/HTTPS package installs can proceed? 2 Need for Apptainer 1.3.5 / Singularity compatibility My original workflow was developed with Apptainer 1.3.5 / Singularity 3.11. Although HPCF currently offers apptainer/1.4.0-rc.2, some builds break under the new runtime. Would it be possible to install (or make available) Apptainer 1.3.5—or alternatively Singularity 3.x—on the cluster, or to provide guidance on how I can install a user-level copy? Providing access to the CA bundle and the older container runtime will allow me to replicate earlier results and keep my CI pipeline consistent. In this request, I am also attaching original .sh file. Thank you very much for your help. Please let me know if any additional details would be useful. Best regards [USER] Research Assistant, Department of Information Systems University of Maryland, Baltimore County [EMAIL]."
"3186401","69215439","2025-05-08 15:18:39","HPC Other Issue: cannot submit jobs in taki","Hello [USER] We have informed users that taki has migrated into a new cluster called chip in the announcement here https://my3.my.umbc.edu/groups/hpcf/posts/147513 . All the compute nodes you can access through Taki can now be accessed through Chip. You are getting the error below because no compute nodes are available on taki.  There are changes in how you submit a job, access your storage, and load software.  You can find our documentation here(https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip) and follow it to familiarize yourself with chip.  We also have a Getting started session to discuss how to use the chip you can find them here: https://my3.my.umbc.edu/groups/hpcf/events   On Wed May 07 15:15:08 2025, [STAFF] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [CAMPUSID] >  > Request Type:              High Performance Cluster >  > I get errors that say: >  > Job's account not permitted to use this partition (high_mem allows > is789sp25 not pi_tjo) >  > or >  > ReqNodeNotAvail, UnavailableNodes:cnode053    --       Best,   [STAFF]"
"3187047","69220987","2025-05-08 17:44:18","HPC Remove User: [USER] from the iHARP group Campus ID [ID] Username [USER] Email [USER]","First Name: [STAFF] Last Name: [STAFF] Email: [EMAIL] Campus ID: [USERID] Request Type: High Performance Cluster Name of PI Group: Usernames to remove: [USER] from the [GROUPNAME] group Campus ID [USERID] Username [USERNAME] Email [EMAIL] No longer needs access to [GROUPNAME] Cluster, work has been completed"
"3187605","69296444","2025-05-13 18:04:40","HPC Other Issue: Requesting to reserve CHIP resources","Saksham has been anonymized to [STAFF] and Roy Prouty to [STAFF]. Here is the cleaned text:  [STAFF] and I were able to determine that the cause of the issue was an invisible character in the sbatch file. We deleted the SBATCH lines and rewrote them. This worked. Closing this ticket since the job is now running. -- [STAFF] DoIT Research Computing Team"
"3187687","69282639","2025-05-13 13:15:28","SLURM Array Task Limit","Hi [STAFF], Can you try this again and let me know what happens? Can you also give me the path to the file on the machine? On Mon May 12 17:23:39 2025, [USER] wrote: Hello, I changed the slurm file to include only 20,000 arrays. I still get this error: sbatch: error: Slurm temporarily unable to accept job, sleeping and retrying sbatch: error: Batch job submission failed: Resource temporarily unavailable On Mon, May 12, 2025 at 9:53 AM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hi [USER], We've gone ahead and increased the max-array size to 25001, more than that would need to be a serious internal discussion as it could lead to clogging of resources in the future. Let me know if this works for you. On Fri May 09 12:25:54 2025, [USER] wrote: Request type: General Support Currently, I am running a large-scale radiative transfer simulation, which involves processing approximately 80,000 input files as part of a look-up table (LUT) generation. Given the current configuration, I am facing limitations with the SLURM job array size. I am getting this error: sbatch: error: Batch job submission failed: Invalid job array specification when I checked I saw: MaxArraySize = 1001 Is it possible to increase the limit? Thank you, [USER] Attachment 1: run_libradtran_test.slurm"
"3187881","69367349","2025-05-16 19:44:33","Common Name: [ID] - Expires :  05/21/2025","Seven day notice. -- [STAFF] [EMAIL]"
"3187923","69324315","2025-05-14 19:24:19","HPC Other Issue: We need Xmgrace installed on [SERVER]","Thank you so much. I found a new emulator called putty, and follow ur directives from there..so it worked.  If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3187923&ticketowner=[STAFF]&ticketsubject=HPC Other Issue: We need Xmgrace installed on Chip. If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3187923. R e s o l u t i o n:. Notes on office hours/Steps to use XMGrace. General steps to load/use XMGrace. 1. SSH into chip using the X11 forwarding flag 'ssh -X -Y [USER]@chip.rs.umbc.edu'. 2. Allocate a node using salloc 'salloc --cluster=chip-cpu --mem=500 --time=00:30:00 --qos=normal --account=[STAFF] --partition=general'. Note: modules are not allowed to be loaded on the login node, so to load the Grace module, you need to launch a interactive job using salloc. 3. SSH into the allocated node using X11 forwarding 'ssh -X -Y c18-01' (c18-01 is just an example, replace it with the node you are allocated from the above command). Note: You must also SSH into the allocated node using the -X flag to enable X11 forwarding. If you start an interactive job using 'srun', you will not be able to SSH using X11 forwarding, so you must use 'salloc'. 4. Load the Grace module 'module load Grace'. Note: You can run 'module avail Grace' to display a list of all XMGrace modules installed on chip (there is only one right now, which is 'Grace/5.1.25-foss-2021b'). 5. launch xmgrace 'xmgrace', and it should open for you. However, we found out that Powershell by default does not support X11 forwarding. We have documentation on enabling support on our wiki, along with the necessary steps to perform X11 forwarding on chip (for windows, macos and linux). Link: https://umbc.atlassian.net/wiki/spaces/faq/pages/1202749443/Accessing+GUI+Applications+on+Chip+Using+X11+Forwarding#For-Windows. You can also utilize a different terminal emulator such as PuTTY or use WSL (windows subsystem for linux) which should work by default. If you have any further questions or issues utilizing X11 forwarding or XMGrace, feel free to let us know. -- Kind regards, [STAFF]."
"3188014","69332737","2025-05-15 12:47:02","HPC Other Issue: Request for HPCF Access","Hi [USER], Please read through our documentation: https://umbc.atlassian.net/wiki/spaces/faq/pages/1082589207/UMBC+HPCF+-+chip and the getting started page https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip. These have the information you're looking for. On Wed May 14 15:26:30 2025, [STUDENT] wrote: Hi [STAFF] and Research Computing Team, Thank you for providing access to the HPC cluster under the student group. I have been actively working on my project for the past few days, but I am facing challenges due to the 500MB storage limit. My project involves deep learning models which require handling large datasets and checkpoints, and 500 MB is not sufficient for this work. I kindly request if it is possible to increase my storage allocation to at least 8 GB, or provide any alternative solution to continue my project work effectively. Please let me know if any additional information is required from my side. Thank you very much for your support and consideration. On Mon, May 12, 2025 [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hi [USER], Are you working under a specific PI or research lab that has an account with us already? We allow for users to have be made under the generic 'student' group, but that gets cleared at the end of every academic year. Additionally, it would help us if you could fill out the ticket here: https://rtforms.umbc.edu/rt_authenticated/doit/DoIT-support.php?auto=Research+Computing as described in this help guide: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip#Requesting-a-User-Account-on-chip On Fri May 09 18:40:51 2025, [STUDENT] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Dear UMBC Research Computing Team, I am a graduate student ([EMAIL]) currently working on a deep learning project that requires GPU acceleration. I would like to request access to the UMBC High Performance Computing Facility (HPCF). Please let me know the process to obtain login credentials or whom I should contact for further assistance. Thank you for your support. Best regards, [USER]"
"3188034","69250448","2025-05-10 11:04:53","HPC Slurm/Software Issue: Unable to connect to database","Hi [STAFF], Thanks for letting us know. The cluster experienced a period of high memory load that made certain processes unavailable. We’re taking steps to protect against similar issues in the future. Everything should be resolved now. On Fri May 09 20:16:34 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Hi, I'm using srun and squeue, and meeting some problems in the screenshot. Thanks, [STAFF] Attachment 1: Screenshot 2025-05-09 at 19.16.01.png (https://[DOMAIN]/s/[ attachment ID]) Best, [STAFF]"
"3188087","69250464","2025-05-10 11:05:41","HPC Other Issue: chip unavailable","Hi [STAFF], Thanks for letting us know. The cluster experienced a period of high memory load that made certain processes unavailable. We’re taking steps to protect against similar issues in the future. Everything should be resolved now. On Sat May 10 05:58:57 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster Cannot connect to chip using my password, I connected to it last night, but this morning chip is unavailable. Can you check what is going on? Is it maintenance or something else? after three times requesting my password, the message is: Permission denied (publickey,gssapi-with-mic,keyboard-interactive). Please note I checked my keyboard and it works well"
"3188095","69282286","2025-05-13 13:05:17","HPC Slurm/Software Issue: Slurm problem or Chip down?","Hi [STAFF], I saw this ticket yesterday at 15:23 (3 minutes after you sent it in), and checked the login node for cpu usage. [USER] seemed to be using 100% of 1 core. We have cgroups implemented which allow for a user to use up to 1 core. When I went onto the login myself, I didn't notice it being particularly slow, but we'll keep an eye out and may limit it more if we notice more issues like this. On Mon May 12 15:20:36 2025, [USER] wrote: It look like the user '[USER]' is running some big jobs in the head node. Is that allowed? It slows down the head node quite a bit. On Sat, May 10, 2025 at 11:03 AM [STAFF] via RT wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey. The cluster experienced a period of high memory load that made certain processes unavailable. We’ve taken steps to protect against similar issues in the future. On Sat May 10 08:10:03 2025, [USER] wrote: Since last night (Friday), I cannot submit any jobs to the slurm system and got the following error squeue: error: slurm_persist_conn_open: Something happened with the receiving/processing of the persistent connection init message to master:6819: Unable to connect to database squeue: error: Sending PersistInit msg: Unable to connect to database squeue: error: slurm_persist_conn_open: Something happened with the receiving/processing of the persistent connection init message to master:6819: Unable to connect to database squeue: error: Sending PersistInit msg: Unable to connect to database squeue: error: DBD_GET_CLUSTERS failure: Unable to connect to database squeue: error: Problem talking to database squeue: error: There is a problem talking to the database: Unable to connect to database. Only local cluster communication is available, remove --cluster from your command line or contact your admin to resolve the problem. (tf) [USER@chip ~]$ Read from remote host chip.rs.umbc.edu: Operation timed out Connection to chip.rs.umbc.edu closed. client_loop: send disconnect: Broken pipe"
"3188407","69503715","2025-05-27 12:55:20","HPC Other Issue: Data output different","The provided text is a series of email exchanges between Vijay Sharma and Roy Prouty, with some intervening responses from Max Breitmeyer. The conversation revolves around an issue Vijay is experiencing with different results on his local machine and the cluster when running the same code.  Here's a breakdown of the key points:  1. Vijay thanks Roy for helping him settle version issues and mentions that he encountered a problem during image reconstruction. 2. Vijay states that the code, versions, and results are identical on both his local machine and the cluster, yet he observes different behavior when running `cmake` and building the project. 3. Vijay notes that on the cluster, the process leaves and enters directories, whereas this doesn't happen on his local machine. 4. Vijay attaches a PDF file to help explain the issue, which is not included in the provided text. 5. Roy responds, suggesting that Vijay should check if the issue persists when building the project on the cluster using `cmake` with the `-S` option. 6. Max Breitmeyer chimes in, asking Vijay to provide more information about the environment and versions used on both his local machine and the cluster.  Some possible solutions or directions for investigation:  * Verify that the environment variables, compiler flags, and library versions are identical on both the local machine and the cluster. * Check if there are any differences in the `cmake` configuration files or generated build files between the two environments. * Investigate potential issues with directory permissions or file system configurations on the cluster. * Consider running a debug version of the code to see if it provides more information about the issue.  Without further details, such as the contents of the attached PDF file or the specific error messages encountered, it's challenging to provide a more precise solution."
"3188536","69269850","2025-05-12 17:30:30","HPC User Account: [ID] in Student Group","Hi [USER], Your account ([EMAIL]) has been created on chip.rs.umbc.edu. Your primary group is student. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) Please keep in mind, your account will go away on June 1, along with the 'student' group, so make sure to back up any data you have. On Mon May 12 10:39:33 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster Create/Modify account in Student group I am a graduate student currently enrolled in CMSC 473 (Natural Language Processing). I am working independently on a course project titled FuriGen - Transformer-based Furigana Annotator, which uses a CTC-based deep learning model for Japanese text annotation. This project is not affiliated with any specific research lab or PI. I am requesting access to the HPC cluster as a student user to run model training with GPU support."
"3188615","69264923","2025-05-12 15:35:58","HPC Slurm/Software Issue: Allocation of resource","[USER] is trying to make a virtual environment using conda but getting an error message [pbarman1@chip ~]$ srun --cluster=chip-gpu --mem=4096 --partition=gpu --gres=gpu:1 --time=2:00:00 --account=[STAFF] --pty /bin/bash srun: job 64705 queued and waiting for resources srun: job 64705 has been allocated resources slurmstepd: error: execve(): /bi: No such file or directory srun: error: g24-11: task 0: Exited with exit code 2 -bash: n/bash: No such file or directory Also, it shows lots of unnecessary files. Can you please remove all unnecessary files and solve the issues ASAP?"
"3188623","69282367","2025-05-13 13:07:06","HPC Other Issue: FileZilla and VSCode login issue","Hi [USER], Duo authentication is a required implementation statewide in all public universities. We cannot pause this for your account. You can read more about it here: https://umbc.atlassian.net/wiki/spaces/faq/pages/30743265/Multi-Factor+Authentication+with+DUO On Mon May 12 18:18:53 2025, [USER] wrote: Thanks for your email. I found a dual authentication procedure during the login time which hindered me to login using VScode and FileZilla. Could you please stop the dual authentication for my account? Best, [USER] On Mon, May 12, 2025 at 1:03 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3188623> Last Update From Ticket: Hi [USER], If you really typed the command as the follow: srun --cluster=chip-gpu --mem=4096 --partition=gpu --gres=gpu:1 --time=2:00:00 --account=[ACCOUNT] --pty /bin/bash Then likely the issue is that the '--pty /bin/bash' are on different lines and therefore being executed as different commands. Make sure that they are being typed in the correct way. You mentioned, 'a lot of unnecessary files'. Where are you seeing these files? Are you able to remove them yourself? In general we try not remove other people's files as we don't necessarily know what may be important to them or not. On Mon May 12 11:35:58 2025, [USER] wrote: Request Type: High Performance Cluster I am trying to make a virtual environment using conda. But getting the err message. [pbarman1@chip ~]$ srun --cluster=chip-gpu --mem=4096 --partition=gpu --gres=gpu:1 --time=2:00:00 --account=[ACCOUNT] --pty /bin/bash srun: job 64705 queued and waiting for resources srun: job 64705 has been allocated resources slurmstepd: error: execve(): /bi: No such file or directory srun: error: g24-11: task 0: Exited with exit code 2 -bash: n/bash: No such file or directory Also, it shows me lots of unnecessary files. Can you please remove all unnecessary files and solve the issues ASAP? Best, [STAFF]"
"3189057","69283110","2025-05-13 13:27:07","HPC User Account: [ID] in Student Group","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is student. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) Please be advised the student group will be going away on June 1st. It is highly recommended that you make sure your work is backed up. On Mon May 12 18:53:51 2025, [STAFF] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [USER] > Request Type:              High Performance Cluster > Create/Modify account in Student group > I want a GPU for speed training using a large dataset"
"3189074","69282965","2025-05-13 13:21:56","HPC Slurm/Software Issue: Space Issue","This is not enough information to assist. Where are you trying to save this to? Have you checked how much space is available in that directory? Have you tried clearing things in that directory to make space? On Mon May 12 19:54:29 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster Hi, I am getting an err message regarding the space. Attachment 1: Screenshot 2025-05-12 at 7.53.09PM.png"
"3189178","69288267","2025-05-13 15:08:23","HPC Other Issue: slight permission and ownership issues","Hello I have changed the owner for /umbc/rs/hpcreu/common to [STAFF]. I have also changed the permission of sub directory Lewis to [STAFF]:hpcreu . Let me know if I am missing any other permission change suggested.  On Tue May 13 03:13:29 2025, [USER] wrote: > First Name:                [STAFF] > Last Name:                 [STAFF] > Email:                     [EMAIL] > Campus ID:                 [CAMPUSID] >  > Request Type:              High Performance Cluster >  > Hi, >  > The group 'hpcreu' in /umbc/rs/hpcreu has some slight problems. --- To > be clear, this is likely not your fault, but may result from something > that I myself did on taki. But on taki, I am the owner. >  > (1) In /umbc/rs/hpcreu the sub-directory common is owned by root. Can > you change this to [STAFF]? Then I will fix the permissions myself; > they are clearly wrong for common (no w for group members); I probably > did this on taki for a certain purpose a long time ago, which got > copied to chip here. >  > (2) In /umbc/rs/hpcreu the sub-directory Lewis itself is correct. But > its sub-directories and files should have group hpcreu (instead of > pi_sjkim); please also change ownership to [STAFF] for all these. >  > Thanks, >  > [STAFF]."
"3189713","69312620","2025-05-14 14:31:13","HPC Other Issue: Interactive Debugging Mode","Hi [STAFF], I did not record the job #, but I remembered that it was the 2018 portion, and the job description is something like 'uvspec'. I have reserved the office hours at 11:30 AM today. So if we meet then, we may submit a job together and see whether this will happen again today. Thanks, [USER] On Wed, May 14, 2025 at 9:18 AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=3189713> Last Update From Ticket: Hi [USER], Do you have the job number of your job and the other user that was effected? It shouldn't be possible for you to get placed on a node where someone else already has all the cores working on their own job, so we would love to verify that and correct it if possible. On Tue May 13 14:41:39 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster Hello, I found that when I used the interactive mode to compile and test codes on chip-cpu, a computing node which is running parallel jobs was allocated to me. All 36 cores have been used, and this made my compiling and test run very slow; and of course, the user who are running the parallel job also suffered. Can you reserve nodes for interactive debugging modes like what were used on taki? Any timely action would be appreciated. Thanks, [USER]"
"3189858","69319433","2025-05-14 17:33:23","Can't login to Chip","Hi, I was able to remove the remote SSH extension from VS Code after trying for a while. It solved the problem. Thanks. On Wed May 14 09:13:14 2025, [STAFF] wrote: > Hi [USER], > This isn't enough information for us to go on. I would start by double checking you can login normally via the terminal and ssh, and then check to make sure your home directory isn't full. We can go from there, but any other information you can provide like error messages or screenshots would help quite a bit. On Tue May 13 16:17:50 2025, [USER] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [CAMPUSID] > Request type:                 General Support > Hi, I'm encountering issues while trying to log into the chip server through VSCode's remote SSH extension. When I try to remove the extension, it gives 'resource busy' error. I have a deadline on May 15, so I would appreciate your prompt assistance in resolving this issue. Thank you!"
"3189994","69347056","2025-05-15 19:04:32","HPC Other Issue: Working directory set up","Hi [STAFF], Documentation on both of these things can be found here on our wiki which can be found on our website https://umbc.atlassian.net/wiki/spaces/faq/pages/1082589207/UMBC+HPCF+-+chip For any future questions please open a new ticket On Thu May 15 11:14:33 2025 [USER] wrote Thank you that was helpful I need more information actually Specifically I would like to know 1 How to navigate from the home directory to the working directory after logging in 2 How to properly launch Jupyter Lab on the HPC If there is any documentation or step-by-step instruction available it would be greatly appreciated Thank you for your time and support Best regards [USER] On Wed 14 May 2025 at 12:49 PM [STAFF] via RT wrote Ticket Last Update From Ticket Hi [STAFF] Go to the webpage and rightclick on the file that you would like to download and click the option for Copy Link Address Then on the cluster in the directory you want it to be saved to you can use wget $download_address OR curl -L -o ${filename}.tar.gz $download_address where $download_address is the address you copied to your clipboard Let me know if this works for you On Wed May 14 11:59:24 2025 [USER] wrote Hi I would like to know how to download and store a file in the working directory I have the dataset link and I want to download the data from that link and store it directly in my working directory as my laptop has limited storage For instance Step 1 Download the data from this link https://zenodo.org/records/14498691 Step 2 Store the data directly in the working directory to optimize storage usage Thanks [USER] On Wed May 14 2025 at 9:15 AM [STAFF] via RT wrote Ticket Last Update From Ticket Hi [STAFF] Im not sure what you mean by setting the working directory How were you planning on downloading the files to begin with On Tue May 13 21:09:23 2025 [USER] wrote First Name [USER] Last Name [USER] Email [EMAIL] Campus ID [ID] Request Type High Performance Cluster Hi I would appreciate your help with setting my working directory I need the specific Linux commands to set the directory as I am planning to download a dataset from the following link https://zenodo.org/records/14498691 Could you please guide me on how to download and store the data in my working directory Thank you in advance for your assistance Best [STAFF] DOIT Unix Infra Student Worker"
"3190000","69390957","2025-05-19 17:20:20","HPC Other Issue: Process killed due to memory limit","Hi [USER], Would you mind submitting a new ticket that is distinct from this one. It helps us to have better tracking of tickets and issues/where they currently stand, in the meantime, I'll look into this more. On Sat May 17 14:18:37 2025, [STAFF] wrote: Hi [STAFF], The interactive mode issue happened again - see the screenshot below: My request was directly allocated to a node (c21-02 this time) fully occupied by another user. Thanks, [USER]. On Wed, May 14, 2025 at 8:41 AM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hi [USER], It's hard for us to diagnose slurm/issues without information about the job that was run. Could you provide us with the job ID, slurm script, working directory, and the output of `module list`? On Tue May 13 21:21:20 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID]. Request Type: High Performance Cluster. Hello, I was testing a simulation run which needs about 20 GB memory. I used the 2021 portion, and request a memory of 50 GB (--mem=50000). However, the process still got killed. Here is the error message: [Tue May 13 21:10:52 2025] Memory cgroup out of memory: Killed process 3482774 (high-music) total-vm:27516840kB, anon-rss:450376kB, file-rss:6528kB, shmem-rss:0kB, UID:134033 pgtables:53860kB oom_score_adj:0. Can anyone help fix this issue? Thanks, [USER]."
"3190307","69315609","2025-05-14 15:38:07","RCD Consult: Canceling job on [SERVER]-cpu","Hi [USER], You need to specify the cluster with all slurm utilities. Please see this wiki page for more information as well as some worked examples of scancel. Let me know if there are further questions, but I'll mark this as resolved for now. On Wed May 14 11:34:51 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              Research Computing & Data Consultation Hi, I usually use chip-gpu cluster for jobs. And I can cancel any job by command, 'scancel JOBID'. how do I cancel a job on chip-cpu cluster? scancel command is not working. Thanks"
"3190496","69325550","2025-05-14 19:59:21","HPC Slurm/Software Issue: sbatch not working","Dear [USER], Thank you for providing this information. If you look at the slurm.out files generated for your sbatch submissions, you will see text explaining mpiexec was unable to find the executable for SU2_CFD. SU2_CFD is not a program that was installed by us (DoIT) via the module system, instead, it was manually installed into /umbc/rs/[STAFF]/common/SU2 by [STAFF]. To utilize this install, you need to specify the path to the executable (specifically SU2_CFD). However, you can also define environmental variables inside your ~/.bashrc file to point to the installation of SU2. This is what [STAFF] did when installing SU2. I recommend you do what [STAFF] did, and define environmental variables in your .bashrc file for SU2. You need to add the following 4 lines into your ~/.bashrc file: export SU2_RUN=/umbc/rs/[STAFF]/common/SU2/bin; export SU2_HOME=/umbc/rs/[STAFF]/common/SU2; export PATH=$PATH:$SU2_RUN; export PYTHONPATH=$PYTHONPATH:$SU2_RUN. If you take a look at [STAFF]'s .bashrc file, you will see these entries, which allows [STAFF] to run the code while you cannot. You can find documentation about the necessary environmental variables on the building from source page of the SU2 install guide: https://su2code.github.io/docs/Build-from-Source/. After making the changes, either log out/log back in to refresh the bash environment variables or run 'source ~/.bashrc', which will apply the env variables to your current session. After that, you should be able to run the sbatch file without issue. In the path: /umbc/rs/[STAFF]/common/5_13_25_OpenLoopSweepCases/ConfigFiles I am running the command: sbatch Run_M3b_8000000HF_525V_0AoA_5000h.slrum. I tried twice, which output .out files of slurm-77232.out and slurm-77696.out. Both of which failed and errored. The sbatch command that worked for [STAFF]  and did not work for me is in the path: /umbc/rs/[STAFF]/common/SU2_Test_Runs/M3b . I then ran the command sbatch M3b_test_job_heatflux_2e6_openloop.slurm. Which submitted batch job 77699. After inputting squeue -u [EMAIL] and afterwards just the command squeue no jobs were found and no .out files were found corresponding to the job id in the filepath. As I mentioned before, [STAFF] is able to run this sbatch but I am not. Please let me know if there is any additional information you'd like me to provide and thank you for your help."
"3190553","69505222","2025-05-27 13:30:37","HPC Slurm/Software Issue: Install Gaussian/16.A.03-AVX2 on chip-cpu general partition","Hello, It appears you are attempting to launch an interactive job by using SBATCH, however, SBATCH is used for submitting batch jobs to the cluster. It does not support launching jobs interactively, like srun does. To launch an interactive job, you need to utilize 'srun'. Here is the general formatting for launching an interactive job: 'srun --cluster=chip-cpu --account=pi_group --partition=general --time=00:10:00 --mem=500 --qos=short --pty $SHELL' Additionally, you can add other options like --nodes or --ntasks-per-node as included in your example SBATCH script above. This command will allocate a node with those specifications and throw you into its shell, allowing you to manually run the gaussian code line by line. However, if you do not need to interactively run the code, you can omit the --pty $SHELL line in the SBATCH script. Additionally, I noticed there is no line in your example SBATCH script defining the memory or the cluster. You will need to add '#SBATCH --cluster=chip-cpu' and '#SBATCH --mem=5000' or however much memory your job requires for the SBATCH script to successfully run. If you run into further issues formatting your SBATCH script, feel free to submit a ticket! Have a nice day! -- Kind regards, [STAFF] I'm trying to test out the functionality of Gaussian on chip, but I'm having a little trouble getting my batch file into a format that the new system likes and was hoping you could help me with how to format it. For reference, my old batch files looked like this: #!/bin/sh #SBATCH --job-name=GaussianDFT # Job name #SBATCH --output=slurm.out # Output file name #SBATCH --error=slurm.err # Error file name #SBATCH --partition=highmem # Partition #SBATCH --qos=medium+ # Queue #SBATCH --time=24:00:00 # Time limit #SBATCH --nodes=1 # Number of nodes #SBATCH --ntasks-per-node=16 # MPI processes per node module load Gaussian/16.A.03-AVX2 g16 [[FILENAME]] I have tried changing it to the following: #!/bin/sh #SBATCH --job-name=GaussianDFT # Job name #SBATCH --output=slurm.out # Output file name #SBATCH --error=slurm.err # Error file name #SBATCH --partition=general # Partition #SBATCH --qos=medium # Queue #SBATCH --time=24:00:00 # Time limit #SBATCH --nodes=1 # Number of nodes #SBATCH --ntasks-per-node=16 # MPI processes per node #SBATCH --pty $SHELL # Interactive shell module load Gaussian/16.A.03-AVX2 g16 [[FILENAME]] but this gives me an 'unrecognized option' error from the --pty command. Is there something I'm missing in my formatting? Thanks so much, [USER] Hi [USER], We were able to install Gaussian 16 last Friday for the 2018 and 2021 hardware (but didn't have time to update the ticket). Would you be able to test the software with your code and verify functionality? Thanks! [STAFF]"
"3191146","70161963","2025-07-03 20:38:25","HPC Other Issue: umask and sticky bit issues","Mostly handled by this wiki page: https://umbc.atlassian.net/wiki/spaces/faq/pages/1239810081/Permissions+for+files+directories On Tue Jun 10 21:28:50 2025, [STAFF] wrote: Max/[STAFF]: We can discuss at the next RC Sync (ideally tomorrow). Looking for confirmation that all root-level research volumes, as well as related 'common' and 'users' folders have the correct permissions and file modes. Further, these default permissions should be reflected in our wiki under 'storage' somewhere. On Tue May 27 08:53:05 2025, [STAFF] wrote: Next step here should be confirming that all groups at the share-root level have 770+ group special bit set and are owned by the correct group. On Thu May 15 12:15:18 2025, [USER] wrote: First Name:                [FIRST NAME] Last Name:                 [LAST NAME] Email:                     [EMAIL] Campus ID:                 [CAMPUS ID] Request Type:              High Performance Cluster Hi, [STAFF] and I talked. This is the promised ticket to track this. I had a meeting with another faculty, that is, a member of another Unix group (not just a student in my own Unix group). This brought out the following issues: (1) Files created by me (e.g., sbatch that outputs slurm.err and slurm.out) have my own Unix group, but it should really be the Unix group of the other faculty, when and if I run a job in that faculty's area. This should be fixed by having the sticky bit in the directory such as the common directory in all PI's areas, like drwxrws--- common/ I am not completely sure if this should also be for the users/ directory and/or for the individual users' directory under the users/ one. (2) The other faculty could not write the file that I created, since it was -rw-r--r-- slurm.out The umask by default on the system is 022. But it should be 007 to fully work together among Unix group members. (Also 002 would accomplish this, but I do not see why others should have any permission on our system.) (3) Make sure to document somewhere how to determine available space of storage left. You told me to use df -h in whatever place I wanted to know the information. I do not know if this is on the webpage yet."
"3191169","69347214","2025-05-15 19:09:00","HPC Other Issue: confusion between squeue and others","Hi [STAFF], Running salloc does not put you on a compute node as you correctly point out, but it does start a stream between the compute node and the login node that doesn't end until either the time limit you set in the salloc is up, or until you exit the stream. I'm not sure *why* that's the case. Just one of the funny things of slurm I suppose. Regardless, it seems like you figured it out! On Thu May 15 12:34:02 2025, [USER] wrote: > When I 'exit' from the shell that I was in, when getting that error, > it > turns out that I was in some interactive job or something like that, > as a second 'exit' was needed to actually close my PuTTy shell. > However, the prompt that I copied into the original message here > starts > with [gobbert@chip ~]$ > so I did not think that I was on a compute node!?  Matthias K., Ph.D., Professor of Mathematics Department of Mathematics and Statistics Center for Interdisciplinary Research and Consulting (circ.[DOMAIN]) UMBC High Performance Computing Facility ([DOMAIN]) REU Site: Online Interdisciplinary Big Data Analytics ([DOMAIN]) University of Maryland, Baltimore County [ADDRESS] http://www.[DOMAIN]/~[USER]  On Thu, May 15, 2025 at 12:30 PM via RT <[EMAIL]> wrote: > Greetings, > This message has been automatically generated in response to the creation of a ticket regarding: > Subject: 'HPC Other Issue: confusion between squeue and others' Message: First Name: [USER] Last Name: [STAFF] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Hi, (1) I used salloc to start an allocation. What is the correct way to close this? Sure, I eventually ssh'ed to the node and said exit there. However, is that right/all? If I had wanted to cancel the job without every ssh'ing to the node, would scancel work? (2) I tried scancel -M chip-cpu 77852 However, an hour later, when trying to use srun for a new interactive session, it kept getting me this error message, so my job was somehow still somewhere in that shell: [USER@chip ~]$ srun --cluster=chip-cpu --account=pi_[STAFF] --partition=match --qos=shared --time=7:00:00 --mem=16G --pty $SHELL srun: error: Unable to confirm allocation for job 77852: Invalid job id specified srun: Check SLURM_JOB_ID environment variable. Expired or invalid job 77852 I opened a completely new PuTTy shell, and everything worked there. But in both shells, commands like 'squeue -u [USER]' or 'squeue -M chip-cpu -u [USER]' showed no jobs at all. [STAFF] There is no need to reply to this message right now. Your ticket has been assigned an ID of [RESEARCH COMPUTING #[TICKETID]] or you can go there directly by clicking the link below. Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=[TICKETID]> You can login to view your open tickets at any time by visiting http://my.[DOMAIN] and clicking on 'Help' and 'Request Help'. Alternately you can click on http://my.[DOMAIN]/help Thank you -- Best, [STAFF]"
"3191362","70669365","2025-08-01 18:57:43","HPC Other Issue: where is icc to use in mpiicc","[USER], can you compare the results (the strongPerformanceTable.tex tex files) in /umbc/rs/[STAFF]/common/research/poisson/chip2024/source250716moreOptions/S= tudy250716 /umbc/rs/[STAFF]/common/research/poisson/chip2024/source250801latestOptions/Study250731 The last one is your final result from today. [USER]"
"3191843","69377799","2025-05-19 12:22:33","HPC Other Issue: [USER] is not able to run the slurm file","Hi [USER], Do you have the job number of one of the job's you attempted to run, or the error file that it output? Can you also provide us the path to this slurm file? What are you trying to do with this slurm file right now? It looks like it's just trying to source something, and then ends? On Fri May 16 12:03:01 2025, [STAFF] wrote: Request Type: High Performance Cluster Hi Team, I hope you all are doing well. I am not able to run the slurm file, can you please check it? #!/bin/bash # MAKE SURE TO RUN THIS SLURM FILE FROM # WITHIN THE FOLDER THAT CONTAIN THE OUTPUT # AND ERROR FILES #SBATCH --job-name jupyter #SBATCH --gres=gpu:2 #SBATCH --output=jupyter1.out #SBATCH --error=jupyter1.err #SBATCH --time=72:00:00 #SBATCH --mem=40000 source tokensimhi/bin/activate"
"3191903","69365981","2025-05-16 18:54:31","HPC Other Issue: Running Jupyter Notebooks on Chip","Hi [USER], In the future, I recommend you check our wiki, linked on our website (hpcf.umbc.edu) under user support. This has answers for most questions, including steps to run jupyter notebooks on chip. Here is the link to the wiki page for jupyter notebooks: https://umbc.atlassian.net/wiki/spaces/faq/pages/1104805915/Jupyter+Notebooks This has all of the information you should need to get started running jupyter notebooks on chip. -- Kind regards, [STAFF] On Fri May 16 13:02:40 2025, [USER] wrote: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [CAMPUSID] > Request Type:              High Performance Cluster > Hello, could you please let me know the steps to execute a jupyter notebook on chip?"
"3192152","69377540","2025-05-19 12:08:46","HPC Other Issue: [ID] access request","The reservation of g24-10 is called 'manas-h100', it expires in a week. On Fri May 16 19:04:57 2025, [USER] wrote: Please start as soon as possible. I would need it till 20th May. On Fri, May 16, 2025 at 7:00 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3192152 > Last Update From Ticket: Hi [USER], So long as Dr. Gaur approves, I will submit a slurm reservation for your research group on an H100 machine. When should the reservation start and stop? On Fri May 16 18:48:59 2025, [USER] wrote: > First Name: [USER] > Last Name: [USER] > Email: [EMAIL] > Campus ID: [USER] > Request Type: High Performance Cluster > To whom it may concern, I hope you are doing well. I have an important deadline coming up on May 19th, and I've been working continuously toward it. However, I've been spending a significant amount of time each day trying to secure computing resources, which has impacted my progress. I would sincerely appreciate it if you could let me know if you can give me access to H100? Thank you. Best. -- [STAFF] DoIT Research Computing Team"
"3192980","69391100","2025-05-19 17:24:20","HPC Other Issue: testing","[STAFF] fixed! [STAFF]"
"3193334","69400923","2025-05-19 21:07:41","HPC User Account: [ID] in pi_ryus","Yes, please proceed.  Best regards, [STAFF] On Mon, May 19, 2025 at 4:40 PM RT API via RT <[EMAIL]> wrote: This e-mail is a notification that a UMBC user: [USER] <[EMAIL]> has requested an account within UMBC's HPC environment in your group <pi_[STAFF]>. As the PI, we request that you acknowledge and approve this account creation by replying to this message. Alternatively you can go to this link and review the ticket and indicate your decision here: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3193334 Once we have your approval, we will create the account and you and the new user will receive another e-mail notifying you that the account has been created. If you have any other questions or concerns please contact us. - [STAFF]"
"3193345","70532279","2025-07-24 22:10:50","HPC Other Issue: 2024 job pending despite idle nodes","Hi [USER], The documentation related to your issue can be found here - https://umbc.atlassian.net/wiki/spaces/faq/pages/1249509377/Partitions+within+chip, and here - https://umbc.atlassian.net/wiki/spaces/faq/pages/1259962375/Chip+Slurm+Usage+based+on+Partitions. Please let us know if these documents answer your questions. We would also appreciate your feedback on the same. Thank you. Regards, [STAFF] On Mon May 19 17:12:06 2025, [EMAIL] wrote: Partition 2024, we just brought on the GAs for user support, so I’m hoping we have additional bandwidth for documentation VERY soon. Roy [STAFF] On Mon, May 19, 2025 at 17:09 [USER] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3193345> Comment From Ticket: What is the alternative to --partition=shared to access those PI nodes that are not idle? I am sorry, but I cannot locate it in the documentation. [USER] On Mon, May 19, 2025 at 4:59PM [USER] <[EMAIL]> wrote: > Well, the output of > sinfo -M chip-cpu > CLUSTER: chip-cpu > PARTITION AVAIL TIMELIMIT NODES STATE NODELIST > 2024 up infinite 1 mix c24-13 > 2024 up infinite 28 alloc c24-[01-06,29-50] > 2024 up infinite 22 idle c24-[07-12,14-28,51] > makes it sound like that there are plenty of idle nodes. I can see how that might not be the right ones, that’s true. > At least we need to get that schematic back that [STAFF] had: On Fri, May 17, 2019 at 4:59PM [USER] <[EMAIL]> wrote: > Hi, Last Friday, I was able to run on the 2024 nodes with 2-nodes-per-job. This is not working at all today. A serial (1 node) job worked. It also works on the 2018 nodes (1, 2, 4 nodes). Is there a principal issue? This is the job in squeue and scontrol does not really tell me anything: [gobbert@c18-24 N08192]$ squeue --cluster=chip-cpu -u [USER] 94809 match hello_pa [USER] PD 0:00 2 (Resources) [gobbert@c18-24 N08192]$ scontrol -M chip-cpu show job 94809 JobId=94809 JobName=hello_parallel UserId=[USER](32296) GroupId=pi_[USER](1152) MCS_label=N/A Priority=1 Nice=0 Account=pi_[USER] QOS=shared JobState=PENDING Reason=Resources Dependency=(null) Requeue=1 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0 RunTime=00:00:00 TimeLimit=00:05:00 TimeMin=N/A SubmitTime=2025-05-19T15:30:46 EligibleTime=2025-05-19T15:30:46 AccrueTime=2025-05-19T15:30:46 StartTime=2025-05-22T14:22:02 EndTime=2025-05-22T14:27:02 Deadline=N/A SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-05-19T16:47:22 Scheduler=Backfill:* Partition=match AllocNode:Sid=c24-51:1339307 ReqNodeList=(null) ExcNodeList=(null) NodeList= NumNodes=2-2 NumCPUs=8 NumTasks=8 CPUs/Task=1 ReqB:S:C:T=0:0:*:* ReqTRES=cpu=8,mem=8G,node=2,billing=8 AllocTRES=(null) Socks/Node=* NtasksPerN:B:S:C=4:0:*:1 CoreSpec=* MinCPUsNode=4 MinMemoryNode=4G MinTmpDiskNode=0 Features=(null) DelayBoot=00:00:00 OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null) Command=/umbc/rs/[USER]/common/hpcf/tests_chip-cpu/250515compile/helloparallel01/run-n2ppn4mpi.slurm WorkDir=/umbc/rs/[USER]/common/hpcf/tests_chip-cpu/250515compile/helloparallel01 StdErr=/umbc/rs/[USER]/common/hpcf/tests_chip-cpu/250515compile/helloparallel01/slurm.err StdIn=/dev/null StdOut=/umbc/rs/[USER]/common/hpcf/tests_chip-cpu/250515compile/helloparallel01/slurm.out Power= -- [STAFF]"
"3193826","69480099","2025-05-23 16:08:03","HPC Slurm/Software Issue: Assistance with Accessing Anaconda Module","The error message displayed showed that the home directory was at 100% utilization, specifically from the .cache directory. This needs to be moved and symbolically linked to your research volume, which has plenty of free space. Move folder - moves .cache (which is inside home directory) to /umbc/rs/iha/users/[USER]/.cache mv ~/.cache /umbc/rs/iharp/users/[USER]/.cache create symbolic link (-s), with the source being the folder you just moved, and the destination being ~/.cache ln -s /umbc/rs/iharp/users/[USER]/.cache ~/.cache lastly, verify symbolic link exists in home directory ls -la ~/ Next, we tested conda - started a interactive slurm allocation - loaded conda - 'module load Anaconda3' - created new conda env - 'conda create -n test05' - activate conda env - 'conda activate test05' - install packages - 'conda install numpy' (or any other package needed) - issues installing, ran 'conda clean -p' to clean up old packages - install conda env with specific python version - conda create -n pyt2 python=3.10 - activate new conda env - 'conda activate pyt2' - verify python version is correct - 'python --version' If you run into any future issues, feel free to create a ticket! Have a great day! Kind regards, [STAFF] DOIT Unix Infra Student Worker On Wed May 21 10:56:57 2025, [USER] wrote: Trying to - module load Anaconda3 - modules dont function on login nodes anymore due to previous issues on taki/ada - modules can load on compute nodes, so you can create an interactive job with srun 'srun --time=00:10:00 --mem=500 --gres=gpu:1 --pty $SHELL' (--pty $SHELL makes it an interactive allocation) - load modules 'module load Anaconda3' 'module list - lists currently loaded modules' - create conda environment named test1 'conda create -n test1' Here is some of our documentation for Anaconda https://umbc.atlassian.net/wiki/spaces/faq/pages/1032814637/Conda+Virtual+Environments Here is some more documentation for running interactive slurm jobs https://umbc.atlassian.net/wiki/spaces/faq/pages/1134264329/How+do+I+run+an+interactive+job Home directory full from hidden folders, must move .local to research vol and symlink moves the .local folder inside your home directory to your research volume 'mv ~/.local /umbc/rs/iharp/users/[USER]/.local' creates a symbolic link (source=new .local in research vol, dest=.local in home directory) 'ln -s /umbc/rs/iharp/users/[USER]/.local ~/.local' verify symbolic link in home directory 'ls -la ~/'"
"3194183","69538166","2025-05-28 15:42:30","HPC Other Issue: /asl","Hi [STAFF], Looking better now. I'll play around with seeing how far I get, and get back to you if I notice other issues Thanks [USER] On Wed, May 28, 2025 at 11:21 AM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hi [USER], Please try now. On Tue May 27 15:18:33 2025, [USER] wrote: Can you please fix this issue. It's ok on the headnode today but NOT on the compute nodes I have a deadline and just can't get work done on the cluster. Another pair of screenshots shows xfs2 and xfs3 are identical when viewed on the compute nodes On Wed, May 21, 2025 at 10:52 AM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hi [USER], I forgot to restart autofs on chip, this issue should now be resolved. Let me know if you have any other issues with this problem. On Wed May 21 09:53:24 2025, [USER] wrote: Request Type High Performance Cluster Hi [STAFF] and [STAFF] I've been telling Larrabee recently that something is up with xfs2 and xfs3 on chip ... and today Larrabee figured that xfs2 and xfs3 are completely identical on chip [user@chip asl]$ ls -lt /umbc/xfs2/strow/ total 283740 drwxrwxr-x 22 strow pi_strow 4096 Apr 23 14:09 asl -rw-rwxr-- 1 root root 9428397 Dec 16 2016 hannon.txt -rw-rwxr-- 1 root root 281115780 Dec 16 2016 imbiriba.txt [user@chip asl]$ ls -lt /umbc/xfs3/strow/ total 283740 drwxrwxr-x 22 strow pi_strow 4096 Apr 23 14:09 asl -rw-rwxr-- 1 root root 9428397 Dec 16 2016 hannon.txt -rw-rwxr-- 1 root root 281115780 Dec 16 2016 imbiriba.txt Looks to us that xfs2 is same on chip and strowinteract, so that is good But xfs3 are completely different, because chip/scf2 and chip/xfs3 are identical Can you let us know when this is fixed, thanks -[USER]"
"3194255","69440080","2025-05-21 17:49:08","HPC Other Issue: funky things with libraries","Hi [USER], Good job identifying issue! So as you noticed, users .bashrc files are not sourced during sbatch submissions. The .bashrc file is loaded at login, and when running a sbatch submission, no login occurs, so slurm never loads the .bashrc. However, when running an interactive job with srun or salloc, you are SSHing into the compute nodes, which results in the .bashrc file being loaded. The proper way to address this, as you discovered, is defining the modules needed for your sbatch script inside the sbatch script itself using module load commands instead of relying on the .bashrc to load needed modules. However, I suppose you could also just load the .bashrc file inside the sbatch script as well. You could add this line 'source ~/.bashrc' into your sbatch script, which would load your users .bashrc on execution of the sbatch script. This would include the module loads that you included in your .bashrc. Previously, on [SERVER], I believe you were using [SOFTWARE] for your job submissions, which uses an interactive shell for job submission instead of a sbatch scripts, so it was loaded then. If you would like some more information on the various bash hidden files and when they are executed, you could look at this page: https://www.gnu.org/software/bash/manual/html_node/Bash-Startup-Files.html If you have any further questions or issues, please feel free to reach out! If not, have a great day! I'm very puzzled about something that is happening on the cluster today. I have some module loads in my .bashrc ... then I get a compute node, and compile a code called 'lblrtm' which runs perfectly well for a test at the command line. So then I make a .sbatch file to submit jobs to the cluster, and lo and behold the jobs all fail with output shown below (missing library). Can you tell me what is wrong? I never had this behavior on [SERVER]. Code was compiled on cpu2021 compute node, and I am submitting to cpu2021. Thanks [USER] >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Your command line contains no arguments Copyright 1984-2023 The MathWorks, Inc. R2023b (23.2.0.2365128) 64-bit (glnxa64) August 23, 2023 To get started, type doc. For product information, visit www.mathworks.com. this is a test this is JOB = 1 now running lblrtm lblrtm: error while loading shared libraries: libnetcdff.so.7: cannot open shared object file: No such file or directory real    0m0.002s user    0m0.000s sys     0m0.001s [USER@chip TEST]$ lblrtm lblrtm: error while loading shared libraries: libnetcdff.so.7: cannot open shared object file: No such file or directory"
"3194305","69504010","2025-05-27 13:02:21","HPC Other Issue: [USER]'s home directory full again","Glad to hear it. I'll mark this as resolved. Be sure to open another ticket if you run into further issues. On Sat May 24 15:02:29 2025, [USER] wrote: The issue was resolved and the code ran successfully. Thank you! On Fri, May 23, 2025 at 5:40 PM [STAFF] <[EMAIL]> wrote: I see it has been run for 456 audio files (instead of 1000). I am running it again and will let you know when I can see the whole output. On Fri, 23 May 2025 at 4:58 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3194305 > Last Update From Ticket: We've ended this call. We are able to run the xlsr_extraction2.py file without issue. Here are the steps we follow. 1. Log into chip & navigate to /umbc/rs/iharp/users/[USER] (iharp_user). 2. `sbatch xlsr_extraction.slurm`. 3. Observe output and error file generation in 'logs' directory. There are errors generated, but these are just warnings like 'W0000 00:00:1748031233.407294 1103969 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.' This doesn't stop the execution of your code. Please confirm at your earliest convenience On Fri May 23 16:45:48 2025, [STAFF] wrote: Hi [USER], We're waiting for you to join this call to help you resolve this issue.[STAFF] royprouty.info Appointment Calendar The most dangerous phrase in the language is, 'We've always done it this way.' - Adm Grace Hopper On Fri, May 23, 2025 at 4:15 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3194305 > Last Update From Ticket: https://meet.google.com/csj-bsjt-abt Please join this google meet. We can help you address the issue.[STAFF] DoIT Research Computing Team"
"3194404","69432575","2025-05-21 13:53:24","HPC Other Issue: on chip xfs2 and cfs3 are identical","First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Hi [STAFF] and [STAFF] I've been telling [STAFF] recently that something is up with xfs2 and xfs3 on chip ... and today [STAFF] figured that xfs2 and xfs3 are completely identical on chip [USER@chip asl]$ ls -lt /umbc/xfs2/strow/ total 283740 drwxrwxr-x 22 strow pi_strow 4096 Apr 23 14:09 asl -rw-rwxr-- 1 root root 9428397 Dec 16 2016 hannon.txt -rw-rwxr-- 1 root root 281115780 Dec 16 2016 imbiriba.txt [USER@chip asl]$ ls -lt /umbc/xfs3/strow/ total 283740 drwxrwxr-x 22 strow pi_strow 4096 Apr 23 14:09 asl -rw-rwxr-- 1 root root 9428397 Dec 16 2016 hannon.txt -rw-rwxr-- 1 root root 281115780 Dec 16 2016 imbiriba.txt Looks to us that xfs2 is same on chip and strowinteract, so that is good But xfs3 are completely different, because chip/scf2 and chip/xfs3 are identical Can you let us know when this is fixed, thanks -[USER]"
"3195021","69450520","2025-05-22 12:53:02","HPC Slurm/Software Issue: Intermittent Errors when running slurm job","Maryam, When you have time, could you give as much detailed information as she can related to: 1. The used slurm script 2. The executable location along with environment settings (e.g., loaded modules) 3. Job IDs from jobs that resulted in errors 4. A list of steps we could use to replicate the issue Once you do, someone on my team will take a closer look and get back to you. On Thu May 22 08:51:31 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] On Behalf Of: [USER] ([EMAIL], [ID]) Request Type: High Performance Cluster [USER] reported issues that arise when running or re-running groundwater simulation models through slurm. Will request that [USER] give as much detailed information as she can related to: 1. The used slurm script 2. The executable location along with environment settings (e.g., loaded modules) 3. Job IDs from jobs that resulted in errors 4. A list of steps we could use to replicate the issue"
"3195188","69475737","2025-05-23 14:03:05","RCD Consult: Python Schedule and Workers have different versions","I have a readme which describes all that is installed in my virtual environment. Its located here: /umbc/rs/cybertrn/common/PGML_Example/[USER]virtualPyEnv_Test On Thu, May 22, 2025, 2:10 PM [STAFF] via RT <[EMAIL]> wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3195188 Last Update From Ticket: Hi [USER], Are you using a virtual environment for this? It's not clear to me where the packages for dask are being sourced from. On Thu May 22 13:17:14 2025, [USER] wrote: > Request Type: Research Computing & Data Consultation > I have the error message saved in: /umbc/rs/cybertrn/common/PGML_Example/[USER]virtualPyEnv_Test/postprocessing/scripts/ErrorMessage.txt > The problem is that I am trying to use dask distributed with a python virtual environment. The scheduler versions seem to match my environment but the worker versions don't. How can I fix this when submitting multiple jobs? > The slurm script I am using is: /umbc/rs/cybertrn/common/PGML_Example/[USER]virtualPyEnv_Test/postprocessing/scripts/CHIPrun.slurm > This calls a shell script which calls: /umbc/rs/cybertrn/common/PGML_Example/[USER]virtualPyEnv_Test/postprocessing/code/data_pipeline_manager.py Best, [STAFF] DOIT Unix Infra Student Worker"
"3196185","69502676","2025-05-27 12:38:50","HPC Other Issue: Request to reserve L40S","Sure thing. The reservation 'pi_manas' has been created. Be sure to use the --account flag set to 'pi_manas' and set the --reservation flag to the same ('pi_manas'). On Fri May 23 18:52:53 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Hello Team I hope you are doing well. Can you please reserve L40S for me for 1 week? Thanks [USER]"
"3196439","69581635","2025-05-30 14:44:32","HPC Other Issue: [Errno 28] No space left on device","Office Hours 5/30/25 [USER] Notes  First things noticed, sbatch jobs were being submitted from an interactive session inside a compute node  Troubleshooting steps taken:  Look at llm_blender_67549.err file using cat, discover that it says that it cannot find the torch module  'cat llm_blender_67549.err'  [STAFF] suggested adding the following lines to the sbatch submission script  module load Anaconda3 eval '$(conda shell.bash activate /umbc/rs/iharp/users/[USER]/conda_envs/llmblender)'  The eval line functions the same as 'conda activate' but it is used more so for non interactive sessions (such as scripts or batch submissions)  Reran the sbatch script, checked error file, same error, continue troubleshooting  Now, verified torch is installed using 'conda list'  [STAFF] then manually loaded the conda env, ran python, imported torch, and ran a line similar to...  'print(f'GPUs available: {torch.cuda.is_available()}, Count: {torch.cuda.device_count()}')'  This was able to verify that torch was properly installed and running, which it was   [STAFF] then resubmited sbatch job WITHOUT being inside a compute node, and the job ran without issue  [USER] then attempted to run the job without being inside an interactive session, and the job executed, but failed with a different error. Now, the error is a 'Cannot import name Ensemble from llm_blender...' error, which is different than the inital torch error.   We believe that submitting sbatch jobs inside an interactive compute node can cause some weirdness and unexpected behavior, so jobs should be ran from the login node  Request Type:              High Performance Cluster  Good morning, I would like to implement the code for an LLM Ensemble at https://github.com/yuchenlin/LLM-Blender. I acknowledge that they are large files and the installation of dependencies via pip install -r requirements.txt or conda env create -f environment.yml terminates due to Errno 28 as indicated below: (base) [USER]@g24-11 LLM-Blender]$ nano environment.yml (base) [USER]@g24-11 LLM-Blender]$ conda env create -f environment.yml Channels:   - pytorch   - nvidia   - conda-forge   - defaults Platform: linux-64 Collecting package metadata (repodata.json): done Solving environment: done Downloading and Extracting Packages: Preparing transaction: done Verifying transaction: done Executing transaction: done Rolling back transaction: done [Errno 28] No space left on device ()"
"3196540","69519591","2025-05-27 18:14:35","HPC Other Issue: AttributeError: module pymesh has no attribute 'form_mesh'","On Sun May 25 21:23:27 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Test"
"3196547","69666680","2025-06-04 15:51:41","HPC Other Issue: AttributeError: module pymesh has no attribute 'form_mesh'","Hi [USER], It appears that your home directory is 100% full from the '.local' hidden directory. You will need to move this to your research volume and symbolically link it to resolve the issue. That will allow you to continue installing packages. https://[EMAIL]/wiki/spaces/faq/pages/[ID]/What+to+do+if+I+run+out+of+space+in+my+[SERVER]+home+directory#2.-Use-Symbolic-Links-to-redirect-data-to-your-research-volume Here is the link to our wiki with instructions for moving and symbolically linking the .local folder. Also, it appears you are using a conda environment, but are installing packages with pip. Generally, it is best practice to install packages with 'conda install' instead of 'pip' when using conda environments. Sometimes, using pip can result in packages being improperly installed and can lead to further issues and headache. I am trying to run a project (Python based) from the /[SERVER]/[DIRECTORY] directory on the [SERVER] cluster. After logging in to the login node on the cluster, I did the following: (1)switched to the worker node using srun (2)loaded the anaconda module (using module load Anaconda3/[VERSION]) (3)activated the new-pytorch-3d conda environment (using conda activate new-pytorch-3d) (4)installed pytorch (using pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128) (5)ran setup.py from the extension folder inside /[SERVER]/[DIRECTORY] (using python extension/setup.py install) (6)ran correspondences.py from the inference folder (using python inference/correspondences.py --dir_name learning_elementary_structure_trained_models/1patch_deformation) When I did this, I got the following error: AttributeError: module pymesh has no attribute 'form_mesh' which is an error on line 125 in auxiliary/my_utils.py. Please see the first three screenshots. I double checked the dimensions of input.vertices and input.faces, and they are correct. I also tried to install pymesh2 (using pip install pymesh2), but the installation failed. Please see screenshots 4 and 5 attached. Is the form_mesh function deprecated in the version of pymesh I have installed? Should I install a different version of pymesh? Should I install trimesh instead? Can you please help? Thank you. Regards, [USER]"
"3196660","69502517","2025-05-27 12:34:57","HPC New Group: [USER]","Hi [STAFF], Welcome to UMBC! Cluster research groups on the chip HPC for faculty & staff are completely free and fairly easy to set up. Once your group is created (you'll receive an alert), please instruct your research group members to submit an account request and cite your research group. To create a group, navigate to hpcf.umbc.edu > User Support > Request Help . Login to this page, then select High Performance Cluster as the Research Computing Action, then New Group as the HPC Action. From there, select the type of group and give some information about high-level research goals you'd like to investigate with the cluster resources. This is just for reporting purposes. Submit that, and we'll get you provisioned within a day or so. I'll mark this as resolved, but please reopen if you are curious about other aspects of the group creation and flow. On Mon May 26 12:52:43 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Cluster Group Type: Project Title: [PROJECT_TITLE] Abstract: HPC Access for [USER]'s Lab Hello my name is [USER] and I am a new PI at UMBC. I was hoping to get access to the cluster but I am not entirely sure what the process is for creating a group for my students to use. If y'all could offer any assistance I would greatly appreciate it Best and thank you, [USER]."
"3196956","69587003","2025-05-30 16:56:02","HPC User Account: [USER] in pi_gobbert","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) -- Kind regards, [STAFF] DOIT Unix Infra Student Worker On Tue May 27 11:07:59 2025, [USER] wrote: > Approved. > [STAFF], Ph.D., Professor of Mathematics Department of Mathematics and Statistics Center for Interdisciplinary Research and Consulting (circ.umbc.edu) UMBC High Performance Computing Facility (hpcf.umbc.edu) REU Site: Online Interdisciplinary Big Data Analytics (BigDataREU.umbc.edu) University of Maryland, Baltimore County 1000 Hilltop Circle, Baltimore, MD 21250 http://www.umbc.edu/~[STAFF] On Tue, May 27, 2025 at 8:10 AM RT API via RT <[EMAIL]> wrote: > This e-mail is a notification that a UMBC user: [USER] <[EMAIL]> has requested an account within UMBC's HPC environment in your group <pi_[STAFF]>. As the PI, we request that you acknowledge and approve this account creation by replying to this message. Alternatively you can go to this link and review the ticket and indicate your decision here: Ticket URL: https://rt.umbc.edu/Ticket/Display.html?id=3196956 Once we have your approval, we will create the account and you and the new user will receive another e-mail notifying you that the account has been created. If you have any other questions or concerns please contact us. - UMBC DoIT Research Computing Support Staff"
"3197342","69733864","2025-06-09 15:22:22","RC Suggestion: Adding Modules for ArangoDB3 and Docker","Hi [USER], After some discussion internally we've decided to not move forward with putting in a module for Arangodb3 as we fear there might be port/file/resource contention with a system wide install of a database where people are unaware of how it's being used by other groups. Our recommendation at the moment is to use apptainer to create a container, and install it in the container there. Hopefully this help! On Tue Jun 03 09:06:27 2025, [STAFF] wrote: Hi [USER], Sorry for the delayed response, we'll look into getting arangodb3 installed ASAP. As for docker, we have an alternative that is better suited to most HPC workflows called apptainer. Would you mind trying that out and seeing if it works for you? On Tue May 27 12:56:03 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] Request Type:              Suggest a change to Research Computing Good afternoon, Could you install arangodb3 and docker on the HPC cluster? We're using arangoDB to make our knowledge graph for our lab's project and docker to locally host it."
"3197458","69767402","2025-06-10 18:27:08","HPC Slurm/Software Issue: Gaussian 16","I am able to log in now and have successfully submitted a job through Gaussian. It will take a while for the job to run but from what I can see of the output file so far, it appears to be doing what it should. Thank you so much for all your help! On Tue, Jun 10, 2025 at 1:04 PM [STAFF] via RT &lt;[EMAIL]&gt; wrote: Ticket &lt;URL: https://rt.umbc.edu/Ticket/Display.html?id=3197458&gt; Last Update From Ticket: Hi [USER], It appears some users of chip were running jobs on the login node that used all of its resources, which resulted in no one being able to log in. We have killed these processes, and users should be able to log in as normal again. Let me know if you are able to access, as well as if you are able to get gaussian to work. Thanks! -- Kind regards, [STAFF] (they/them/theirs) DOIT Unix Infra Student Worker On Tue Jun 10 12:46:16 2025, [USER] wrote: Hi, Is chip down at the moment? I'm trying to test the functionality of Gaussian but am unable to log in both via Putty and directly from my terminal. The putty session starts but won't recognize my password, and trying to open a secure shell from my terminal window immediately fails. [USER] (they/them/theirs) UMBC Department of Chemistry and Biochemistry PhD Candidate [EMAIL] On Mon, Jun 2, 2025, 10:32 AM [STAFF] via RT &lt;[EMAIL]&gt; wrote: Ticket &lt;URL: https://rt.umbc.edu/Ticket/Display.html?id=3197458&gt; Last Update From Ticket: Hi [USER], We have created a group for Gaussian users, and due to Gaussians licensing setup, all users who require Gaussian access must be members of the Gaussian group. I added your user account to this group, so if you run an interactive (or batch) job on the cluster, and 'module load Gaussian' you should be able to execute Gaussian files with g16. When you get a chance, would you please be able to test the functionality of Gaussian? It has been built for both 2018/2021 and 2020/2024 nodes. Thanks!"
"3197663","69564098","2025-05-29 16:31:07","HPC Other Issue: tensorflow installation","The issue was resolved by performing a fresh install of TenserFlow. Steps taken included uninstalling TensorFlow and verifying its removal, uninstalling astunparse as a precaution, running 'pip install tensorflow' in the terminal, and verifying the installation. Additionally, the kernel was restarted to ensure the notebook recognized the changes. The requester was able to replicate these steps successfully, confirming the resolution."
"3198791","69559165","2025-05-29 14:30:15","HPC Other Issue: running in CPUs only in CHIP","Hi [USER], https://umbc.atlassian.net/wiki/spaces/faq/pages/1134264329/How+do+I+run+an+interactive+job I recommend you look at this link, it has example commands for running interactive jobs. It looks like you are trying to run an interactive job on chip-cpu. Here is the command for that 'srun --cluster=chip-cpu --account=[STAFF] --partition=general --qos=normal --time=0:30:00 --mem=1G --pty $SHELL' When running an interactive job on chip-cpu, you need to specify the cluster is chip-cpu, the partition its being ran on, the time limit of the job, and the memory limit for the job. In the screenshot, the partition was not being specified, or it was not the correct partition. https://umbc.atlassian.net/wiki/spaces/faq/pages/1033142321/Using+slurm+on+chip Here is some more info on using slurm on chip, which has some info about the available partitions. For most users, the 'general' partition is fine. Now, if you want to run a job on chip-gpu, here is how you do that: 'srun --cluster=chip-gpu --account=[STAFF] --mem=1G --time=0:30:00 --gres=gpu:1 --pty $SHELL' The main differences is specifying chip-gpu instead of chip-cpu, and adding --gres=gpu:1. The gres flag allows you to choose how many gpus are being requested. --gres=gpu:1 means 1 gpu is requested. When running on chip-gpu, you do not need QOS or partitions, as the chip-gpu cluster is set up differently than chip-cpu, so it does not use those features. If you run into any further issues running jobs on chip, please consult the documentation available on our website. If you are unable to find a solution to your issue, feel free to open an ticket! Have a nice day! [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster Hi I am trying to run my code using 'chip-cpu' only, however, ending up with getting time error."
"3199002","69640128","2025-06-03 14:16:47","HPC Slurm/Software Issue: Difficulty running Rclone","Hi [STAFF], So, according to the error message, the system does not know where to look for the rclone.conf file. With rclone, there are a couple commands you can use to setup and create the config file. First, you can use the command 'rclone config' to create the configuration file. This command will guide you through creating and setting up rclone. Next, you can use 'rclone --config=~/.config/rclone/rclone.conf' to set the location of the configuration file. You can also set this as an environmental variable with 'export RCLONE_CONFIG=/home/[USER]/.config/rclone/rclone.conf'. After that, you should not experience errors from the rclone.conf file not existing. If you run into any problems with this process, or have any further questions, feel free to reach out! Hi [USER], I am having problems running 'rclone' on chip. I don't see this as an available module using the module spider, so I am attempting to run it myself. I am requesting a compute node: srun --time=01:30:00 --mpi=pmix --mem=100G --partition=2018 --gres=gpu:0 --cluster=chip-cpu --pty bash Once the node is allocated, I am loading other modules and specifying the PATH location for rclone: module load Anaconda3/2024.02-1 module load GRASS/8.2.0-foss-2021b conda activate /umbc/rs/[USER]/common/huc_test/Essential_Scripts/HydrographyWorkflow/Cang/conda_envs export PATH=/umbc/rs/[USER]/common/huc_test/Essential_Scripts/HydrographyWorkflow/Cang/rclone-v1.69.1-linux-amd64:$PATH When I run a python script to call rclone I recieved the following error: NOTICE: Config file '/home/[USER]/.config/rclone/rclone.conf' not found - using defaults I can see that the system is looking in a different location than I specified in my PATH, so I am thinking that this could be an issue of using the wrong alias. Can you help?"
"3199283","70057611","2025-06-27 18:02:57","HPC Other Issue: program packages already installed on facilities","Hi [USER], I was able to install GAMESS version 20230930-R2 on chip. You can load it using 'module load GAMESS-US'. I tested the install using the example files provided by GAMESS, and all files passed. Let us know if you have any issues using GAMESS. Also, we have not heard back regarding obtaining a SPARTAN license. I will keep this ticket stalled until we are able to follow up regarding SPARTAN. On Wed Jun 25 12:46:37 2025, [STAFF] wrote: Hi [USER], I wanted to update you on this matter. I am still working on getting GAMESS installed on chip. Unfortunately, the authors of GAMESS, while providing their code for free for research use, do not publicly publish previous versions of GAMESS. I have been attempting to contact the authors, and request a download to the source code for older versions of GAMESS which should build on chip, but I have not been receiving any response. I will let you know if there are any updates. On Tue Jun 10 13:32:11 2025, [STAFF] wrote: Hi [USER], GAMESS doesn't seem to support slurm workflows, so we were unable to finish the process. Were you able to look at PSI4 or Gaussian? I'll leave this open for a few days and wait to hear back from you. On Wed Jun 04 13:37:56 2025, [STAFF] wrote: Hi [USER], We currently have Gaussian and PSI4 working on the chip HPC cluster and are working on installing GAMESS, you can find more info about having your students sign up here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1082589207/UMBC+HPCF+-+chip. We're also looking into SPARTAN, but at the moment we don't currently have a license for that. Will update further once we know more. On Thu May 29 15:51:08 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID]. Request Type: High Performance Cluster Colleagues: Please remind me if we have any of the following programs available for use by my undergraduate research group: SPARTAN, GAUSSIAN, GAMESS and PSI4."
"3199862","69689681","2025-06-05 16:36:35","HPC Slurm/Software Issue: Assistance with Band Structure Calculation Error in QE on CHIPS","Office Hours (in person) 6/5/25 [STAFF] Notes Issue: Quantum Espresso module does not work properly, code does not run=. Solutions 1. I will compile a new QE module for chip, hopefully that can resolve the issue with the current one 2. Use manually installed QE binaries in /umbc/rs/[STAFF]/common First steps To use a manually compiled/installed module, you will need to add the install location to your PATH variable, so your account is able to locate the QE install. export PATH=/umbc/rs/[STAFF]/common/qe-7.3.1/bin:$PATH The line above can be added to your sbatch script, runscript, and/or your ~/.bash_profile, which would make it be executed on login. During the meeting, we added that line to your .bash_profile for testing purposes, however it is not needed anymore, so I am going to comment it out. You can uncomment it if you need it at a future point. But, exporting that path inside your runscript will produce the same result. After adding that line to your runscript sbatch script, we reattempted submission. Now, the system was able to see the installed files, however there were errors generated from missing modules/packages necessary for QE. From here, we were able to narrow down the compatible module versions: OpenMPI/4.1.6-GCC-13.2.0 intel/2023a libxc/5.2.3-intel-compilers-2022.1.0 imkl/2021.4.0 Above are all the modules you need to load, in that order. During our meeting, we tested the QE install through an interactive slurm allocation. After finding compatible modules, we ran module save qe-7-1-3 This command creates a collection of modules named qe-7-1-3. Now, you are able to restore the collection to automatically load all the modules needed for QE-7.1.3 using... module restore qe-7-1-3 We added 'module restore qe-7-1-3' inside your runscript in lieu of individual module loads. Now that we have the proper modules loaded, and the path to the QE install defined, the code should run without issue! If you have any further questions about this or run into further issues, feel free to open a new ticket. Have a great day!-- Kind regards, [STAFF] (she/her/hers) DOIT Unix Infra Student Worker On Thu Jun 05 12:02:49 2025, [USER] wrote: Hi [STAFF], I haven't had a chance to write the report on everything we did today, however I figured out the error! I just wanted to let you know. The current version of the runscript should execute without issue. Specifically we needed libxc/5.2.3-intel-compilers-2022.1.0 to be loaded. I will make the write up now!-- Kind regards, [STAFF] (she/her/hers) DOIT Unix Infra Student Worker On Wed Jun 04 13:22:34 2025, [USER] wrote: Dear [STAFF], Thank you very much for your response. I have scheduled in-person office hours tomorrow (June 5, 10:45am - 11:15am) to discuss recompiling QE on CHIPS. In addition, I am wondering if we can run quantum espresso by using the previously compiled executable in our local directory, which has been working well. Best Regards, [USER] On Tue, Jun 3, 2025 at 1:43PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3199862 > Last Update From Ticket: Hello [USER], If it is running on Taki, then hopefully it might work on chips. so far, what we're seeing the Cholesky error is most likely due to numerical incompatibilities between input data and the CHIPS-installed binary, or minor differences in how math libraries (like MKL) behave. Please let us know if you'd like assistance recompiling QE on CHIPS with consistent settings, schedule office hours using this link: https://hpcf.umbc.edu/help/office-hours/ Thank you. Regards, [STAFF] On Fri May 30 14:32:44 2025, [USER] wrote: > First Name: [USER] > Last Name: [USER] > Email: [EMAIL] > Campus ID: [CAMPUS_ID] > Request Type: High Performance Cluster > Hello, I was trying to submit a band structure calculation using Quantum ESPRESSO (QE, 7.3.1-intel-2023a) on CHIPS, but encountered an error in the attached output file (FGaT-3x3x1_ML_bands.log). The error message appears at the end of the output and reads: Error in routine cdiaghg (701): problems computing Cholesky The same input file works correctly when run using our previously compiled version of QE located in our common directory in Taki. I was wondering if there is a way to resolve this issue when using the version installed on CHIPS? Additionally, we attempted to copy our previous executables to our local directory and run the calculation from there. Could you please suggest a runscript for submitting jobs using our locally compiled QE executable? The attached runscript, input, and output(.log) are for reference. Thank you very much for the help and support. Best Regards, [USER]"
"3200341","69607438","2025-06-02 13:27:18","HPC Slurm/Software Issue: Cancelling jobs","Hi [USER], When you want to kill a job with scancel, you need to also specify the cluster the job resides on (ie, chip-cpu or chip-gpu) using the -M flag. So, for example, to cancel job id 12345 running on chip-cpu, you would run 'scancel -M chip-cpu 12345'. For chip-gpu, it is the same, except chip-gpu instead of chip-cpu. You can find all this documented on the wiki, located here https://umbc.atlassian.net/wiki/spaces/faq/pages/1033142321/Using+slurm+on+chip#Cancelling-Jobs-(scancel) -- Kind regards, [STAFF] On Sun Jun 01 10:03:50 2025, [USER] wrote: > First Name: [USER] > Last Name: [USER] > Email: [EMAIL] > Campus ID: [ID] > Request Type: High Performance Cluster > I am trying to cancel jobs I submitted in Chip using the command 'scancel'. But it is not working, and the job is still running. I tried using both with the JOBID and using my USER, but without success. Any ideas why this is happening? My colleague can use this command."
"3200390","69641228","2025-06-03 14:44:38","HPC New Group: [ID]","Hi all, I've added the users to cybertrn and given them access to the '2024' partition. I tested it on one or two of the users, but please have as many of them try it beforehand to let us know if other issues come up. On Mon Jun 02 12:34:35 2025, [STAFF] wrote: Great catch, [USER], but not in the way you think. This is once again an example of this RT form just cutting off after, I think, 5000 characters. I had composed a much longer text that I copied into there. As it happens it got cut off, so you cannot tell. Here is the missing information; notice that [USER] had a note with him; that's where the cut-off happened: [USER] <-- was participant last year, so should be set already; please check Graduate RAs, please check that they are in cybertrn (as secondary group): [USER] h***@umbc.edu Xingyan Li x***@umbc.edu s*** <-- may be her username Hussam Fateen h***@umbc.edu <-- please check that primary Unix group is pi_gobbert Faculty Matthias Gobbert gobbert JIanwu Wang jianwu On Mon, Jun 2, 2025 at 12:01 PM [USER] via RT <UMBCHelp@rt.umbc.edu> wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3200390 Last Update From Ticket: I did not see my RA's name in the list. Adding her below. Thanks! Xingyan Li, x***@umbc.edu, chip account: s*** On Sun, Jun 1, 2025 at 3:00 PM RT API via RT <UMBCHelp@rt.umbc.edu> wrote: Greetings, This message has been automatically generated in response to the creation of a ticket regarding you were Cc'd on: Subject: 'HPC New Group: pi_gobbert' Message: First Name: Matthias Last Name: Gobbert Email: g***@umbc.edu Campus ID: [USER] Request Type: High Performance Cluster Group Type: Project Title: Big Data REU at UMBC in Summer 2025 Project Abstract: This Big Data REU program is funded by the NSF since 2021 to conduct undergraduate research training on how to utilize modern data science and high-performance computing (HPC) techniques to process and analyze big data in many science and engineering disciplines such as Atmospheric Science, Mechanical Engineering, and Medicine. Hi, Roy, As we discussed (e-mail), the accounts on chip for the Big Data REU Site participants need to be created. Dr. Wang is the other faculty involved. Please create the following accounts and add to the cybertrn group. We discussed that the cybertrn group should have access to the 2024 partition. I list the Campus ID and usernames below as I know them; recall that I cannot look up the usernames in the Advanced Directory, since these are not active UMBC students. I list the graduate RAs below as well as the faculty for clarity. Please check the RAs, the faculty should be fine. This program is for Summer 2025 and they need access afterwards to finalize a conference paper. So, the ending date should be 12/31/2025, which is also what I used in the sponsorship for non-UMBC accounts. Matthias Danielle Murphy [USER] dm*** Autumn Sterling [USER] as*** Caleb Parten [USER] cp*** Kevin Zhang [USER] kz*** Haoxiang Zhang [USER] hz*** Sidhya Pathak [USER] sp*** Michelle Zhao [USER] mz*** Bikash Gautam [USER] bg*** Angelo Calingo [USER] ac*** Peter Jin [USER] pj*** There is no need to reply to this message right now. The ticket has been assigned an ID of [Research Computing #3200390] or you can go there directly by clicking the link below. Ticket https://rt.umbc.edu/Ticket/Display.html?id=3200390 You can login with your UMBC credentials to view open tickets at any time by visiting http://my.umbc.edu and clicking on 'Help' and 'Request Help'. Thank you Best wishes Sincerely yours [USER], Ph.D. (he/him) [EMAIL] Website: https://bdal.umbc.edu/people/[USER]/ Professor of Data Science and Liaison for Research Innovation, Department of Information Systems Director, Big Data Analytics Lab Director, Center for Scalable Data and Computational Science (ScaleS) Co-Director, NSF REU Site on Online Big Data Analytics Co-Lead, NSF HDR institute for Data and Model Revolution in the Polar Regions (iHARP) University of Maryland, Baltimore County ***-***-**** ITE 423 Best, [STAFF]"
"3201161","71037769","2025-08-20 13:05:04","Need help with SYNOPSYS simulation software","Sorry for the long silence here. We've been told that the best course of action would be for you or someone in your lab to submit a software request in PAW (https://procurement.umbc.edu/cloud-services-software-request/). Linked on that page is the PAW portal as well as a wiki page describing how to interact with the portal and what to expect. Sorry we couldn't be of more immediate help after this long delay. I'll mark this as resolved for now. On Fri Jul 11 17:04:11 2025, [STAFF] wrote: Hi [USER], To install the Synopsis Simulation Software on the chip cluster, we need a University License, and there is an ongoing internal conversation about whether we can obtain it and what we need to do to be able to obtain it. One of our constraints is that we cannot buy a license for a software for a single researcher. When you said 'We need to start using this asap', could you please let us know if there other members in your group (or otherwise) that are planning on using this software? The more researchers we have who need to use this software, the stronger our case for obtaining a license for them. We will let you know as we have more information on this. In the meantime, if you know more researchers who are interested in using this software, it would be great if they can submit a ticket on RT for the same. Thank you for your patience. Thank you. Regards, On Fri Jul 11 09:26:31 2025, [USER] wrote: Hi [STAFF], Any update on this? We need to start using this asap. [USER] On Tue, Jun 3, 2025 at 6:22 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=320116> Last Update From Ticket: Hi [USER], Please refer to public documentation on how to use the Synopsis Simulation software on the cluster. Here are a few helpful links: https://researchcomputing.princeton.edu/faq/how-to-run-synopsys-and-c https://inst.eecs.berkeley.edu/~inst/test/cgi/?file=cx.help#Synopsys-on-ECS-Instructional-computers In the meantime, let us check the availability of the Synopsis simulation software on our clusters and get back to you. Thank you. Regards, On Mon Jun 02 15:32:35 2025, [USER] wrote: > First Name:  [USER] > Last Name:   > Email:   [EMAIL] > Campus ID: > Request Type: Help with something else Hi, I need to simulate the characteristics of High Electron Mobility Transistors (HEMT) devices by using Synopsys simulation software. Is there any training or tutorial available for setting up the required test environment and running the simulation?"
"3201176","69696755","2025-06-05 20:05:40","HPC Slurm/Software Issue: Error Loading Packages on Julia","I was able to install DiffEqSensitivity on Julia 1.7.3. There were no issues, errors, or warnings produced during that install. I also tested SciMLSensitivity, however that produced a couple small errors, related to other packages installs hanging. But, I was able to still load the package with 'using SciMLSensitivity'. I installed both of these in new Julia project folders. I just wanted to start with a completely clean Julia install state. First, I created a folder for the project with 'mkdir $project-name', then loaded Julia with 'julia --project=./$project-name'. In this case, $project-name is just a name you can choose for this specific Julia project. After this, I used 'Pkg.use('DiffEqSensitivity')' to install DiffEqSensitivity (tested on Julia 1.7.3, and I believe you tested on 1.8.2). If you run into further issues with this, feel free to open another ticket. Hope this helps! HI [USER], Please schedule an office hours using this link: https://hpcf.[DOMAIN]/help/office-hours/. Thank you. Regards, [STAFF]. First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID]. Request Type: High Performance Cluster. Hi, so for a week or two now, I've been trying to get myself setup on the chip cluster. I was previously using another university's cluster and so I thought the switch should be easy. The code I run is on Julia, and even the exact same version of Julia (1.9.3) is used on the old cluster I was using. So, before running anything on chip, I wanted to download all the necessary packages, and so I began downloading the exact same versions of every package I had running on the old cluster. I've been running into many error messages for awhile now which was weird to me given that the same packages were able to run just fine on the same version of Julia but only on another cluster. I've narrowed down the main issue to installing the package DiffEqSensitivity.jl, and I've found no version of it that will properly install. I've finally come to an error message that may be the cause, which is in the following attached file 'error_message1.txt'. This error comes after running merely Pkg.add('DiffEqSensitivity') and using DiffEqSensitivity. In the error message it says 'CodecZlib.jl is not installed properly', and to try running Pkg.build('CodecZlib.jl'). After doing that on a separate run on the cluster, I got the error message in 'error_message2.txt' which then describes being unable to download something from github."
"3201210","69638654","2025-06-03 13:30:01","HPC Other Issue: add new user ([ID]) to my ([STAFF]) PI group","Hi [STAFF], I have added [USER] to your PI group, pi_[STAFF]. They can access the cluster via ssh, using ssh [USER]@chip.rs.umbc.edu, and their typical UMBC Single Sign On password. If you have any further questions or need additional help, feel free to open an RT ticket! Have a nice day!  --  Kind regards, [STAFF] DOIT Unix Infra Student Worker  On Mon Jun [DATE] [TIME], [USER] wrote: > First Name:                [STAFF] > Last Name:                 [STAFF] > Email:                     [EMAIL] > Campus ID:                 [CAMPUSID] >  > Request Type:              High Performance Cluster >  > Hi,  >  > Please add my PhD student [USER] ([EMAIL]) to my PI group on CHIP. >  > Thanks, > [STAFF]"
"3201266","69639174","2025-06-03 13:43:01","HPC Other Issue: add [USER] to Unix group","This is done, I'm working on giving the cybertrn access to the 2024 partition per your other ticket. On Mon Jun 02 17:37:20 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster Hi, Please add (already existing UMBC and chip) users to the cybertrn Unix group (as secondary group): [USER] [USER] [USER] Thanks, [STAFF]"
"3202026","69664494","2025-06-04 15:03:49","conda slurm documentation","Hi [STAFF], Per our discussion on webex, please add an example to https://umbc.atlassian.net/wiki/spaces/faq/pages/1032814637/Conda+Virtual+Environments#How-do-I-create-a-Virtual-Environment-using-Anaconda%3F on using the bash eval command.  On Tue Jun 03 16:23:08 2025, [USER] wrote: > Hi [STAFF], >  > We just added to the chip document. >  > Thank you. >  > Best, >  > [STAFF] >  > On Tue Jun 03 14:58:46 2025, [USER] wrote: >  > > hi there, > > > > can either you or [STAFF] document some stuff for activating conda environments when using slurm/sbatch submissions ? thank > > > > sometimes when activating conda environments in non-interactive submissions (ie, scripts, batch jobs, etc), conda can sometimes not be properly activated, which can result in issues with conda. 'conda activate env' can sometimes fail if the shell/conda is not initialized properly, which is why the following line can be useful. > > > > # using eval command takes a string as input and then executes it as a shell command, the 'conda shell.bash activate /path...' command is the command being run > > eval '$(conda shell.bash activate /path/to/your/file)' > > > > # verifies conda prefix is loaded correctly > > echo $CONDA_PREFIX > > > > you can also use... > > eval '$(conda shell.bash hook)' > > conda activate myenv > > > > which would do the same thing, initializing conda and activating env"
"3202387","69670139","2025-06-04 17:40:41","HPC Other Issue: scp between chip and linux.gl","Hi [STAFF], Yes I am off-campus home on verizon and using VPN Same username on chip.rs and linux.gl of course Your suggestion to use /tmp/ to test is good The permissions cannot really be controlled by me in an AFS file system And I have made no changes ever to these I have copied many things around many times before In any case the system has recovered on its own It works now to my home directory on linux.gl [STAFF] On Wed Jun 4 2025 at 11:05AM [STAFF] via RT wrote Ticket URL https//rt.umbc.edu/Ticket/Display.htmlid=3202387 Last Update From Ticket Hello [USER] It looks like the SCP connection is working but the issue is with write permissions on your home directory in linux.gl.umbc.edu The error message Permission denied during dest open suggests that SCP could log in but wasnt allowed to write the file You might try specifying a different destination directory where you have write access like scp -p run-hello-n2ppn4mpi.slurm linux.gl.umbc.edu/tmp/ Or check and update permissions on your home directory if needed Try transferring the file to /tmp on GL you usually have write access there scp -p run-hello-n2ppn4mpi.slurm [USER]@linux.gl.umbc.edu/tmp/ If youre off-campus make sure youre connected to the UMBC VPN After authentication the file should upload successfully to /tmp on linux.gl.umbc.edu Please let me know if that works Regards [STAFF]"
"3202941","69802284","2025-06-12 10:51:30","HPC User Account: [USER] in [LAB]","Hi [STAFF], In the future, copy the output of the hpc_addUser script to these messages and cc the users. This will help us in the long-run by aligning new users with our documentation. On Fri Jun 06 17:23:04 2025, [USER] wrote: Hello [USER], The two accounts you requested have been created. Students should be able to login by running 'ssh $USER@chip.rs.[DOMAIN]' with their my[DOMAIN] password, with $USER being the student's my [DOMAIN] ID. Best regards, [STAFF]"
"3203103","69979418","2025-06-24 12:49:53","HPC Other Issue: Storage space","I'm going to go ahead and unmount the old /umbc/rs/[USER] directory. If anything comes up, we can remount it and all of your (and your student's) work will still be there/intact. I'll be closing this ticket, but if you need to reopen it, you can respond to this message. On Sat Jun 21 05:28:05 2025, [STAFF] wrote: Dear [STAFF], I have checked with my students. All work has been moved correctly. Thanks for your help. Mohamed. On Mon, Jun 16, 2025 at 8:45 AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=[ID]> Last Update From Ticket: Hi Dr. [USER]. Were you able to confirm all of your work was moved correctly? On Tue Jun 10 10:02:19 2025, [STAFF] wrote: Thanks [STAFF]. I'll confirm with my students and get back to you. Regards Mohamed On Tue, Jun 10, 2025 at 9:53 AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=[ID]> Last Update From Ticket: Hi Dr. [USER], We've created a new mount for your group under /umbc/rs/pi_[USER], and cloned all your work from /umbc/rs/[USER]. The new mount has 25T available for you and your group. Please, you and your students go through and verify that all the data was properly copied to the new directory. We plan on sunsetting the old mounts/directories by October, though if you're able to confirm everything is working for you sooner, that would be great. On Thu Jun 05 08:28:56 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster Hello, Can you increase the storage space allocated to my research group? Thanks. Best, [STAFF] DOIT Unix Infra Student Worker"
"3203193","69730588","2025-06-09 14:21:57","HPC Other Issue: remove [USER] from some Unix groups","Hi [STAFF], This is completed. On Thu Jun 05 10:15:15 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Hi, I am a member of several Unix groups. This was sensible for collaborative research back then. But not needed currently. Therefore, please remove me ([USER]) from the groups [GROUPS]. To cross-check, the memberships in the following groups should remain: pi_[USER], vitals, cybertrn, zmclaren, hpcreu, student. Thanks, [USER]"
"3203721","69717300","2025-06-06 21:12:49","HPC User Account: [USER] in MLSP","Hello [USER], It appears that you had a user account on taki. During our migration to chip, we transferred all user accounts on taki and ada. You should be able to log-in by using 'ssh [USER]@chip.rs.[DOMAIN]' using your my[DOMAIN] password. Let us know if you have any issues logging into chip. Best regards, [STAFF]."
"3203840","69733647","2025-06-09 15:19:18","HPC User Account: [USER] in Bennett Research Group","Hello, The user [USER] has been added in the Bennett Research Group. Please let us know if you run into any issues. Best regards, [STAFF]"
"3203961","69717413","2025-06-06 21:21:14","HPC Other Issue: [USER] cannot log into interact since about 10 am","OK cool, now I'm in thanks - [STAFF] On Fri, Jun 6, 2025 at 4:18 PM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hi [USER], Please try again and let us know if it is working. Thank you. Regards, [STAFF] On Fri Jun 06 15:03:28 2025, [USER] wrote: Hi Can you give me an update? I need to prepare a talk and I'm quite stuck right now with strowinteract still being unavailable. ssh: connect to host strowinteract.rs.umbc.edu port 22: Operation timed out -[USER] On Fri, Jun 6, 2025 at 1:04 PM [USER] <[EMAIL]> wrote: Hi [STAFF], Still cannot get in [USER] On Fri, Jun 6, 2025 at 12:43 PM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hi [USER], Due to a network hiccup, you might have faced issues when trying to login. It has been resolved now. Can you please try again and let us know if you are successful? Thank you. Regards, [STAFF] On Fri Jun 06 11:53:59 2025, [USER] wrote: First Name: [USER] Last Name: [LAST NAME] Email: [EMAIL] Campus ID: [CAMPUS ID] Request Type: High Performance Cluster cannot log into strowinteract since about 10 am today"
"3204122","69741769","2025-06-09 18:50:51","HPC Other Issue: new publication","Thank you, this has now been updated to reflect on the HPCF webpage. Best regards, [STAFF]"
"3204203","69732881","2025-06-09 15:01:59","HPC User Account: [ID] in [USER]'s Research Group","Ticket is resolved. Best regards, [STAFF]"
"3205148","69741471","2025-06-09 18:43:40","HPC User Account: [USER] in Student Group","Hello, The user [USER] has been added to the requested pi_group. Please reach out if you are having any issues with this. Best regards, [STAFF]"
"3205276","69756340","2025-06-10 14:32:57","Requesting Access to Chip","Hi [USER], Follow the instructions here (https://umbc.atlassian.net/wiki/spaces/faq/pages/1082589207/UMBC+HPCF+-+chip). I'm going to close this ticket. On Mon Jun 09 16:29:17 2025, [STAFF] wrote: Hi, Mr. [STAFF] I have not requested access to the cluster before. How do I do that? Best regards, [USER] On Mon, Jun 9, 2025 at 4:09 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3205276> Last Update From Ticket: Hi [USER], I'm looking at our users, and I don't see you as one of them. Have you requested access to the cluster before? On Mon Jun 09 15:48:07 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CID] Request Type: Help with something else Good afternoon, I'm sending this ticket to request access to chip as the following is happening on terminal as I use a mac. Best regards, [USER] Attachment 1: Screenshot 2025-06-09 at 3.46.30PM.png -- Best, [STAFF] DOIT Unix Infra Student Worker"
"3205633","69760912","2025-06-10 16:05:18","RCD Consult: Requesting a Chip Account for [USER]","Hello [USER], To access the Cluster resources please request form here, https://rtforms.umbc.edu/rt_authenticated/doit/DoIT-support.php?auto=Research%20Computing Or if you need further guidelines, or have questions on using the cluster you can join us on office hours at https://hpcf.umbc.edu/help/office-hours/ Thank you. Best, [STAFF] On Tue Jun 10 10:34:14 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] Request Type:              Research Computing & Data Consultation Refer to [STAFF] for questions"
"3205788","69763467","2025-06-10 17:09:03","Problem with accessing CHIP","Hi [USER], We experienced a moment of network issues, this should be resolved now though. Please try again and let us know. On Tue Jun 10 12:46:27 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Hello, I am currently having some issues with accessing CHIP. When I attempt to log in, it keeps asking me for my password, as if I am entering it wrong, and eventually gives me an access denied message. I am certain that I am not entering my password incorrectly, I've tried many times, and I was on CHIP earlier in the day. I have included a screenshot for reference. My log in credential is [EMAIL]. Thank you. Attachment 1: Screenshot 2025-06-10 at 12.44.14PM.png Best, [STAFF]"
"3205817","69764461","2025-06-10 17:28:31","HPC Other Issue: Access denied to chip","Thanks, it's working now On Tue, Jun 10, 2025 at 1:17PM [STAFF] via RT wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3205817 Last Update From Ticket: Hi [USER], We experienced a moment of network issues, this should be resolved now though. Please try again and let us know. On Tue Jun 10 13:01:18 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USERID] Request Type: High Performance Cluster Hello, When I go into Putty and enter: [EMAIL] and then go to enter my password I get an Access denied message. I know I'm not entering the wrong password because I've tried logging in several times and am not sure what the problem is. Thanks so much for your help. Best, [STAFF]"
"3205906","69778746","2025-06-11 12:54:04","HPC User Account: [USER] in Department of Biological Sciences","Hi [STAFF], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_mkann. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) Best regards, [STAFF]"
"3205974","69770888","2025-06-10 19:56:58","HPC Other Issue: Permission Issue while running '.sh' files in terminal line","Hi [USER], The error you are receiving, 'Permission Denied', when trying to run tuning.sh results from improper file permissions. If you run 'ls -la tuning.sh', you can see the file permissions for your script. Currently, your files permissions are '-rw-rw---- 1 [STAFF] pi_adali 189 Jun 10 14:35 tuning.sh'. If you are new to Unix systems, these can be a little confusing. But, the part you need to focus on is the first section, '-rw-rw----'. In unix systems, file permissions displayed in 3 main sections. The first section -(rw-)rw---- is for the owner of the file, and their permissions. The second, -rw-(rw--)--- is for the owners group's permissions (so, users in the same group as the owner will have these permissions). Lastly, -rw-rw-(---), is for other users, ie people who are not the owner and not in the owners group. Permissions are displayed with 3 characters, R, W, and X. R is for read, W is for write, and X is for execute. Right now, tuning.sh allows for the owner and group to read and write to the file (see -rw-rw----, there is a rw- in both the user and group section). It is missing execution permission, so, you cannot execute the file without error. To change the files permissions, you can use the 'chmod' command. To fix the permissions for your file, you are able to run 'chmod +x tuning.sh', which will add the X to the file permissions. This can then be verified with 'ls -la tuning.sh', and you should see the file permissions reflected as '-rwxrwx---'. For more information about Unix file permissions, I recommend taking a look at this page https://phoenixnap.com/kb/linux-file-permissions. On Tue Jun 10 14:57:28 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS ID] Request Type: High Performance Cluster Good Afternoon, I hope this message finds you well. My name is [USER] ([CAMPUS ID]). I was recently added to the pi_group adali and am now attempting to run a .sh file to execute my MATLAB code. However, I am encountering a 'Permission Denied' error (see attached screenshot). I wanted to reach out to ask whether this is a permissions issue or if there may be something I’m doing incorrectly. I’ve also attached my .sh and .sbatch files and a screenshot showing that all necessary files are in the same directory. Thank you for your time and assistance. Best regards, [USER]"
"3206376","69812770","2025-06-12 17:15:39","HPC Slurm/Software Issue: Shell script for utilizing chip-cpu","Hello [USER], You are able to run on the general 2021 and 2018 chip-cpu partitions. Please refer to this wiki regarding this: https://umbc.atlassian.net/wiki/spaces/faq/pages/1249509377/Partitions+within+chip. If there are any questions or concerns let us know. Best regards, [STAFF]"
"3207330","69807599","2025-06-12 14:38:22","HPC User Account: [USER] in pi_[ID]","Hi [USER], Your account ([EMAIL]) has been added to the pi_[STAFF] group on chip.rs.umbc.edu . Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) Best regards, [STAFF]"
"3207350","69867920","2025-06-16 17:05:27","HPC Slurm/Software Issue: Updating the time limit","Good afternoon [USER], It looks like your jobs have ran. If you are experiencing any further issues feel free to reach out. I will be closing this ticket. -- Best regards, [STAFF]"
"3207507","69831454","2025-06-13 15:16:45","need access to research files that were on [SERVER]","Hi [USER], Yes, taki has been completely decommissioned and rolled into our current cluster, chip. Chip combines all nodes from taki and ada, along with many new ones. All of the storage for taki has also been transferred to chip. However, it seems you are not currently actively part of a project/research that uses the cluster, so your account was not transferred to chip. But, I have created a user account for you on chip. You will be able to log in and transfer all of your data off of the cluster. Currently, your account is not allowed to run jobs on the cluster, due to the aforementioned reasons. But you will be able to retrieve all of your data. To log in, run 'ssh [USER]@chip.rs.[STAFF]' and log in with your my[STAFF] password. I recommended using our VPN when logging in, as that will allow you to bypass 2 factor authentication when logging in and copying files. You can find information on our wiki for logging into the VPN here: https://[STAFF].atlassian.net/wiki/spaces/faq/pages/30754220/Getting+Connected+with+the+[STAFF]+GlobalProtect+VPN Next, if you run the 'alias' command, you can see a list of the preinstalled aliases created. You should see a couple aliases for 'student_user', 'student_common' and student_ada'. I believe your data is located in 'student_user'. If you run 'student_user', the alias created changes directories to the path of your data (/umbc/rs/student/users/[USER]/). To copy files, I recommend using scp or rsync from your host machine. Here is a page on our wiki with steps on copying files from chip: https://[STAFF].atlassian.net/wiki/spaces/faq/pages/1161756678/File+Transfer+To+and+From+chip Currently, my supervisor set the deadline for copying user data from the student group to September. After then, the data will no longer be accessible. If you run into issues accessing your data, feel free to let us know. Kind regards, [STAFF]"
"3207816","69830460","2025-06-13 14:46:51","HPC Other Issue: Trying to Resolve an Issue, Possibly with Numpy","Hi [USER], If you look at the screenshot you provided, you can see it says 'No module named 'numpy.core._multiarray_umath''. After a quick google, I found a stack overflow discussion post with some people saying that they have had that error solved for them specifically with Numpy 1.21.0. I do not know what code you are attempting to run, but from the error message it seems that the SciPy-bundle module is being loaded, and the version that is being loaded has Numpy 1.26.2. Currently, no 'SciPy-bundle' modules with 1.21.0 exist, however, when using Python, you are able to install every package you require inside of virtual environments. I do not know if you have one already set up for your code yet. On our wiki, we have many pages dedicated to using virtual environments. Commonly, there are pyVenv and Anaconda/conda virtual environments. I will include links for both, but I personally prefer conda, so I will elaborate a bit more on that. https://umbc.atlassian.net/wiki/spaces/faq/pages/1032814637/Conda+Virtual+Environments https://umbc.atlassian.net/wiki/spaces/faq/pages/1033863206/pyVenv+virtual+environments https://umbc.atlassian.net/wiki/spaces/faq/pages/1134264329/How+do+I+run+an+interactive+job These pages have some information about using virtual environments on the cluster. Inside an interactive session, you can run 'module load Anaconda3' to load the Anaconda3 package. After this, you may need to run 'conda init' to add the conda information to your users PATH. Next, you can create the conda environment with 'conda create -n testEnv'. This creates the environment. To activate, run 'conda activate testEnv'. Once activated, you can install whatever packages and package versions you require. Specifically, you needed numpy version 1.21.0 using 'conda install numpy=1.21.0'. This will install the proper version of numpy. You can then continue installing all of the other packages you need for your code to run. If you need further help, please provide the location of your code and what you are running. Thanks! -- Kind regards, [STAFF]"
"3207823","69916894","2025-06-18 19:25:41","HPC [USER] Account: [ID] in [Lab Name]","You are now a member of pi_oates. You should be able to access the chip cluster as normal (with ssh [USER]@chip.rs.[DOMAIN]). If you run into issues, feel free to create a new ticket. Have a good day! -- Kind regards, [STAFF] [STAFF] Unix Infra Student Worker On Wed Jun 18 15:17:23 2025, [EMAIL] wrote: I approve. Thanks! On Thu, 12 Jun 2025, RT API via RT wrote: This e-mail is a notification that a [DOMAIN] user: [USER] <[EMAIL]> has requested an account within [DOMAIN]'s HPC environment in your group <CoRaL Lab>. As the PI, we request that you acknowledge and approve this account creation by replying to this message. Alternatively you can go to this link and review the ticket and indicate your decision here: Ticket URL: https://rt.[DOMAIN]/Ticket/Display.html?id=[ID] Once we have your approval, we will create the account and you and the new user will receive another e-mail notifying you that the account has been created. If you have any other questions or concerns please contact us. - [DOMAIN] DoIT Research Computing Support Staff"
"3208022","69904542","2025-06-18 13:33:21","HPC User Account: [ID] in [DEPARTMENT NAME]","Hi [USER], your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/). First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Create/Modify account in existing PI group Existing PI Email: [EMAIL] Existing Group: Center for Navigation, Timing & Frequency Research department Project Title: Modeling of Spatial Modes in Microresonator Project Abstract: The objective of this project is to find the mode families in silica microresonator using finite-element method simulation(COMSOL multiphysics package)."
"3208135","69906163","2025-06-18 14:10:55","HPC New Group: [ID]","Hi [USER], The group pi_[USER] now exists on the chip cluster! Members of this group can therefore access and contribute to the research storage space allocated to the group. This storage is located at /umbc/rs/[STAFF] and currently has a quota of 10T. Please review documentation on the hpcf.umbc.edu website. Additionally, I have created you a user account for chip! Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[USER]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Submit any questions or issues as separate RT Tickets at the following URL: https://doit.umbc.edu/request-tracker-rt/doit-research-computing/. I highly recommend walking through the Getting Started with Chip page on our wiki (I'll include the link below). It runs through and explains the basic set up/layout of chip, and some examples on how to interact with the cluster. The wiki also contains lots of other information that explains further how to use the cluster. But if you cannot solve a problem, feel free to open a new ticket and we can assist you. Have a great day! https://umbc.atlassian.net/wiki/x/R4BPQg On Fri Jun 13 11:41:03 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Group Type:            Project Title:        African Environmental Processes and Water-Cycle Dynamics Project Abstract:     Africa’s vast landmass harbors a variety of physical processes that affect the environment and the water cycle. This research project on the “African Environmental Processes and Water-Cycle Dynamics” addresses various phenomena from different but complementary perspectives. Fires used for agricultural and related purposes play a major role in land-cover change, surface albedo modifications, and smoke emission; all of which affect the environment and the water cycle in different ways. However, emissions of aerosols and trace gases are not restricted to fires, but also emanate from other natural and human activities. The African water cycle undergoes significant perturbations that are attributable to several factors, including the aforesaid environmental processes. These changes in the water cycle have produced severe drought and flooding events in recent decades that affect societal wellbeing across sub-Saharan Africa. The combined effects of the environmental processes and water-cycle dynamics affect and are affected by climate variability and can be propagated beyond the continent. The included studies utilize the wealth of observations and modeling tools that are constantly improved to clearly elucidate the interrelationships between all of these phenomena for the benefit of society. This project will comprise several studies focused on different sub-Saharan African regions."
"3208569","70057569","2025-06-27 18:00:22","MATLAB jobs failing","Hello [USER], I wanted to check in if you are still having issues with running jobs on chip? I noticed that there are multiple jobs (10) that ran, to view this you can use the command squeue -u [STAFF]. Are they still appearing to fail on your end? Best regards, [STAFF]"
"3208570","70311105","2025-07-14 17:06:46","MATLAB jobs taking too long to run","Hi [USER], Sure, I will gather information and create a new ticket. Thank you so much for helping us with this matter.  Best, [STAFF]  On Mon, Jul 14, 2025 at 9:36 AM [STAFF] via RT <[EMAIL]> wrote:  Ticket https://rt.umbc.edu/Ticket/Display.html?id=3208570 Last Update From Ticket: Hi [USER], Sounds like the original issue is resolved then! As for your other issue, we aren't seeing any instability from slurm or chip generally right now. Since this seems to be a different issue, would you mind putting in a new ticket with more description of your problem? Keeping issues to separate tickets is an important part of our workflow and helping understand where we need to spend more or less time on a problem.  On Sat Jul 12 01:04:50 2025, [USER] wrote: Hi [STAFF] and [STAFF], I apologize for the delay. I have run a considerable number of jobs over the past week, and when I checked the execution time numbers, I didn't notice any difference in speed. However, I also tested changing the QOS flag between 'long' and 'medium.' Based on my results, I didn't experience any long executions in either case this time.  My main issue now is that some tasks are completing without any output and with an empty error file. For example, I recently submitted a batch of 20 jobs, 10 of which finished after some time without saving the output. The rest managed to run to completion, and I got the expected results. In addition, I noticed that some random tasks are disappearing from the queue list and not even creating an .err or .out file. Do you know if there is any instability with the chip? Best,[USER]"
"3208598","69846432","2025-06-14 23:51:31","HPC Slurm/Software Issue: --gres option for CHIP","Glad to hear it. I'll close this out. On Sat Jun 14 18:39:35 2025, [USER] wrote: Hi [STAFF], Thanks for the update. I guess that explains why it worked okay yesterday, maybe it hadn't attempted to submit the job to the GPU cluster previously. Everything is working now! On Sat, Jun 14, 2025, 6:02 PM [STAFF] via RT wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=[ID]> Last Update From Ticket: Hi [USER], The slurm submission file submitted around 1630ET today (job ID 177715) has the sbatch directive '#SBATCH --cluster=chip-cpu'. This directive does not exist in the file you attached to the ticket. Without the slurm cluster specified, slurm may attempt to assign your job to the GPU cluster, in which case the --gres flag is required. Try adding this flag to specify the CPU cluster and resubmit -- assuming that you're trying to submit to the CPU cluster. I'll leave this ticket stalled in case there's some other issue. On Sat Jun 14 16:11:52 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Cluster Hello, I have an issue with submitting jobs to chip today. I resubmitted the same job, unaltered from yesterday, which had ran and completed previously. This time, i received the following message. sbatch: error: Missing: '--gres' sbatch: error: You must specify a Generic RESource to use in your job. sbatch: error: See this webpage for more details: https://hpcf.umbc.edu/compute/overview/. sbatch: error: Batch job submission failed: Unspecified error I could not find anything regarding this on the hpcf website. I am not trying to use any gpu resources, but I attempted to specify --gres=gpu:1 anyway, which did not change the error message. Here is the job file attached below. Thank you,[USER] Attachment 1: [FILE_NAME].slurm"
"3208860","69859884","2025-06-16 14:24:08","HPC Other Issue: Access Issue - Common and [USER] Directories","Yep, my apologies, I did not mean to double email you. I had started looking into the ticket before I knew [STAFF] was also working on it, and I never refreshed RT, so I did not see his response before sending mine. Glad he was able to get your issue resolved though! Have a good day! -- Kind regards, [STAFF]. On Mon Jun 16 10:09:42 2025, [USER] wrote: Hello [STAFF], Thank you for your follow-up email. I received a message from [STAFF], who resolved the issue. I now have access to all locations within /umbc/rs/weltyc. Best, [USER]. On Mon, Jun 16, 2025 at 9:54 AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=32308860 > Last Update From Ticket: Hi [USER], By chance, have you figured out how to solve this issue between now and when you submitted this ticket? I started to look into your user account on chito see what was going on, however, after running 'ls -la' inside your home directory, i can see that the symbolic links are not red, (red means its inaccessible, as shown in your picture), and I am able to change directories to all locations inside /umbc/rs/weltyc. What I am seeing on my end, should be exactly the same as what you are seeing. Would you be able to log back in, and check again just to confirm the issue is still present? If it is, I can dig into the issue further. Thanks! -- Kind regards, [STAFF]. On Mon Jun 16 08:45:51 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USER] Request Type: High Performance Cluster Hello, Since Thursday, June 12, I’ve been experiencing an issue where I no longer have permission to access any of the directories in my PI’s common and user folders. I would be grateful if you could look into this and let me know what the issue might be. Best regards, [USER]."
"3209843","69893493","2025-06-17 18:17:19","HPC Other Issue: Correct owner of [USER]'s project.","Hello,  Sorry about that, fixed it. Best, [STAFF]"
"3210293","70013749","2025-06-25 17:32:56","HPC Other Issue: VS Code Issue","No problem. If you have any more issues, reach out and [STAFF] will be glad to help. Best regards, [STAFF]"
"3211156","69930481","2025-06-20 13:00:05","[USER] is unable to SSH to knacc1","Hi [USER], Ada has been shutdown for some time, and moved over to chip. Please see the following announcement: https://my3.my.umbc.edu/groups/hpcf/posts/147513 Additionally, here is our getting started documentation: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip Please let us know if you have any questions about any of this, I'll leave this open for a few days just in case. Note that all of your data has gone untouched (although it's location might be different now, please verify with the documentation and your group director). On Fri Jun 20 03:11:46 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: Help with something else Hi Officer, I cannot ssh ada from my laptop (MAC). I used globalprotect vpn, and also tried ssh linuxserver1. But via both, ssh [USER]@ada.rs.umbc.edu doesn't work. Could you plz help check for me? My email [EMAIL], campus ID [ID], under Prof. [STAFF]'s team. Thanks, [USER]"
"3211265","70858680","2025-08-12 15:22:27","HPC Other Issue: [USER] is unable to delete student files","This appears to be a lengthy email chain between Dr. Joseph W. Bennett and Max Breitmeyer, discussing issues with accessing student directories on the high-performance cluster at the University of Maryland Baltimore County.  To summarize:  1. Dr. Bennett reported that he is unable to access his students' directories on the cluster after an upgrade from 'taki' to 'chip'. He used to be able to delete unnecessary files using command-line prompts, but now lacks permission. 2. Max Breitmeyer, a student worker in the DOIT Unix Infra team, responded that they had changed the permissions on individual user volumes to prevent group-wide write access due to security concerns. 3. Dr. Bennett replied that he understands the security concerns but needs a solution to manage his students' files. He also mentioned that undergraduate students often leave behind large amounts of data that take up storage space. 4. Max Breitmeyer offered to grant group-wide write access to Dr. Bennett's group, but warned that this poses a potential security risk. 5. The conversation continued with discussions about finding alternative solutions, such as using scripts to manage files or exploring options for increasing storage capacity.  The main issue appears to be the balance between security concerns and the need for faculty members like Dr. Bennett to manage their students' files on the cluster."
"3211565","69944423","2025-06-20 20:46:06","HPC Slurm/Software Issue: Sbatch error for [USER]'s purchased GPU node","Hi [STAFF], I've recreated [USER]'s reservation to run until the end of August (hopefully we'll have a new system by then). -- [STAFF]"
"3211836","69979716","2025-06-24 12:58:19","HPC User Account: [ID] in na","Hi [USER], Yes it is absolutely possible to do what your describing. Please submit a ticket that appropriately captures your need for a new PI group, with the spaces filled in. You can see the appropriate actions that need to be taken at the top of this page: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip  On Sun Jun 22 00:25:05 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Create/Modify account in existing PI group Existing PI Email: [EMAIL] Existing Group: na Project Title: na Project Abstract: na Hello, I am an associate professor in the Math & Stat department. I (and my students) often need to use Matlab to run larger jobs, for example Monte Carlo simulation for finite element discretization of PDEs - time-stepping for linear/nonlinear problems with thousands of degrees of freedom. Would it be possible to use https://hpcf.umbc.edu/ resources to this end? More details on my work can be assessed from my papers at:  https://userpages.umbc.edu/~[USER]/papers/ Please, let me know, thank you. [USER]"
"3211979","69988900","2025-06-24 16:46:42","Requesting to be Given Slurm Account for [USER]","Hello, I appreciate the help [STAFF]! Best regards, [USER] On Mon, Jun 23, 2025 at 11:00 AM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hello [USER], Please go to this page to handle your request (https://hpcf.umbc.edu/publications/) Follow the instructions below. 1. Select 'User Support' 2. Select 'Request Help' 3. In the 'Research Computing Action' dropdown select 'High Performance Cluster'. 4. In the 'HPC Action' dropdown select 'User Account Creation/Modification' 5. In the 'I'd like to' dropdown select 'Create/modify account in existing pi group' 6. Proceed with entering the following information (Existing PI Email, Existing Group Name, Project Title, Project Abstract) 7. Submit If you have any issues with this let me know and I can help out. Best regards, [STAFF]"
"3213036","70010312","2025-06-25 15:48:58","HPC Other Issue: Urgent: fix owner and question","The text appears to be an email exchange between Matthias Gobbert, a researcher at UMBC (University of Maryland, Baltimore County), and the IT support team, specifically Max Breitmeyer, a student worker in the DOIT (Division of Information Technology) Unix Infrastructure department.  Matthias is requesting assistance with two issues related to file permissions on the university's high-performance computing cluster. The first issue is that a research directory does not have an owner, which prevents him from making changes to it. He requests that the IT team make him the owner of the directory as soon as possible.  The second issue is that he wants to give access to certain users who are not members of his group (pi_gobbert) to a subdirectory within the PromptGamma directory. They tried using permissions o+rwX, but it did not work. He also attempted to change the group ownership of the directory to cybertrn using chgrp, but that didn't solve the problem either.  Max Breitmeyer responds with some suggestions and explanations:  * To find other directories or files without an owner, they can use a command like `find /umbc/rs/gobbert/common/PromptGamma -nouser`. * To give access to users who are not members of pi_gobbert, it's not possible to do so if the higher-level directory does not have o+rwX permission. He explains that permissions are inherited from parent directories and cannot be overridden by child directories.  The email exchange also includes some meta-information about the ticketing system used by the IT team, including a link to view the open tickets and instructions on how to log in to access them."
"3213076","69990751","2025-06-24 17:44:31","HPC User Account: [USER] in KAI² - Knowledge-infused AI and Inference","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_manas. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) Kind regards, [STAFF] DoIT Unix Infra Student Worker On Tue Jun 24 12:45:12 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] Request Type:              High Performance Cluster Create/Modify account in existing PI group Existing PI Email:    [EMAIL] Existing Group:       KAI^2 – Knowledge-infused AI and Inference Project Title:        Dialogue Systems for Academic Research: A Guide to Create Humanly Academic Chatbots Project Abstract:     Dialogue systems offer a powerful medium for academic dissemination, yet creating chatbots that effectively translate complex research for non-experts remains a significant hurdle. This guide addresses the lack of a comprehensive framework for developing 'humanly' academic chatbots that can present a researcher's work intelligently and empathetically. We introduce a methodology for structuring academic work into a conversational flow, guided by core principles of natural language understanding (NLU), dialogue management, and personality design. The framework also includes a system for evaluating chatbot effectiveness based on user engagement and knowledge transfer. By following this guide, researchers and developers can create more engaging academic chatbots, thereby improving public understanding of complex topics and pioneering a new method for scholarly dissemination. This work seeks to advance the future of academic communication by making research more accessible and interactive."
"3213144","69992422","2025-06-24 18:22:17","Overleaf Account upgrade","Hi [USER], We don't provide licenses for premium Overleaf. You'll have to discuss that with your advisor. Sorry we couldn't be of more help! On Tue Jun 24 13:48:55 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] Request Type:              Help with something else I recently signed up for an Overleaf account via SSO under the guidance of my Advisor, [STAFF]. However, I am using the free version but would like to request for an upgrade to the Premium subscription. Thank you. Regards, [USER]"
"3213963","70109702","2025-07-01 17:07:48","HPC User Account: [ID] in africa-wcd","Were you trying to schedule a virtual meeting with us? I just saw this reply, and saw there was apparently a meeting at one scheduled. If you want to meet with our team, please schedule directly with us from our website: https://hpcf.[DOMAIN]/help/office-hours/. Kind regards, [STAFF]. On Tue Jul 01 12:59:07 2025, [USER] wrote: . You have been invited by [USER] to attend an event named [Research Computing #3213963] HPC User Account: [USER] in africa-wcd [RESOLVED] on Tuesday Jul 1, 2025 · 1pm – 1:30pm (Eastern Time - New York). Join Webex meeting https://[DOMAIN].webex.com/[DOMAIN]/j.php?MTID=... ID: ... password: .... Join using SIP ...@.[DOMAIN].webex.com. Organizer [USER] [EMAIL]. Guests [EMAIL]. Reply for [EMAIL]."
"3214166","70029339","2025-06-26 14:06:55","HPC User Account: [ID] in iHARP","Hi [USER], Your account ([USER]) has been added to the iharp group on chip.rs.umbc.edu. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Wed Jun 25 18:12:54 2025, [USER] wrote: Approved [STAFF], Ph.D. Associate Dean for Research and Faculty Development College of Engineering and Information Technology Professor, Information Systems Department, Director NSF HDR Institute-iHARP University of Maryland, Baltimore County A Carnegie R1 Institution Lab : https://mdata.umbc.edu/ NSF Institute: https://iharp.umbc.edu/ webex: https://umbc.webex.com/join/[STAFF] Land Acknowledgement: UMBC was established upon the land of the Piscataway Conoy and Susquehannock peoples. Over time, citizens of many more Indigenous nations have come to reside in this region. We humbly offer our respects to all past, present, and future Indigenous people connected to this place. On Wed, Jun 25, 2025 at 6:09 PM RT API via RT <[EMAIL]> wrote: This e-mail is a notification that a UMBC user: [USER] <[EMAIL]> has requested an account within UMBC's HPC environment in your group <iHARP>. As the PI, we request that you acknowledge and approve this account creation by replying to this message. Alternatively you can go to this link and review the ticket and indicate your decision here: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3214166> Once we have your approval, we will create the account and you and the new user will receive another e-mail notifying you that the account has been created. If you have any other questions or concerns please contact us. - UMBC DoIT Research Computing Support Staff"
"3214583","70035978","2025-06-26 17:10:06","HPC Slurm/Software Issue: Nodes required for job are DOWN","Thank you so much On Thu Jun 26 13:02:19 2025, [STAFF] wrote Not to my knowledge. It looks like this is working so I'll go ahead and close this ticket. Please submit a new one if anything else comes up. On Thu Jun 26 12:58:40 2025, [USER] wrote Hi [STAFF], Thank you for your patient reply. I submitted job 194517 yesterday, and from what I saw, it ran for approximately ten hours. And I see the run time is about 5 hours from the output. That's why I said it has been restart. Do you know what happened yesterday? I mean was there any maintenance? It works well now. Thanks again. [USER] On Thu Jun 26 12:49:49 2025, [STAFF] wrote Hi [USER], If you get to it relatively soon after the job completes (usually within 3 hours) you can use the following command 'scontrol show job ${jobid}' to see some of the details. I've the output below: [root@chip-mgt1 ~]$ scontrol show job 194517 JobId=194517 JobName=YCQ UserId=[USER](220201) GroupId=pi_yelu(1085) MCS_label=N/A Priority=1 Nice=0 Account=pi_yelu QOS=shared JobState=RUNNING Reason=None Dependency=(null) Requeue=1 Restarts=2 BatchFlag=3 Reboot=0 ExitCode=0:0 RunTime=05:10:54 TimeLimit=4-04:00:00 TimeMin=N/A SubmitTime=2025-06-26T07:32:49 EligibleTime=2025-06-26T07:34:50 AccrueTime=2025-06-26T07:34:50 StartTime=2025-06-26T07:34:55 EndTime=2025-06-30T11:34:55 Deadline=N/A SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-06-26T07:34:55 Scheduler=Main Partition=match AllocNode:Sid=chip:2283370 ReqNodeList=(null) ExcNodeList=(null) NodeList=c24-38 BatchHost=c24-38 NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=35 ReqB:S:C:T=0:0:*:* ReqTRES=cpu=35,mem=400G,node=1,billing=35 AllocTRES=cpu=64,mem=400G,node=1,billing=64 Socks/Node=* NtasksPerN:B:S:C=0:0:*:1 CoreSpec=* MinCPUsNode=35 MinMemoryNode=400G MinTmpDiskNode=0 Features=(null) DelayBoot=00:00:00 OverSubscribe=NO Contiguous=0 Licenses=(null) Network=(null) Command=/umbc/rs/[USER]/common/YCQ/ep0.22/run_python_chip.txt WorkDir=/umbc/rs/[USER]/common/YCQ/ep0.22 StdErr=/umbc/rs/[USER]/common/YCQ/ep0.22/result.err StdIn=/dev/null StdOut=/umbc/rs/[USER]/common/YCQ/ep0.22/result.out Power= TresPerTask=cpu:35 Looking at the run time of the job: EndTime-StartTime you can see that it ran for 4 days and 4 hours. If you check the TimeLimit you set, it's also 4 days and 4 hours. So it wasn't 'cancelled' so much as it reached its natural conclusion according to the settings that you put in. Let me know if you have more questions On Thu Jun 26 12:39:45 2025, [USER] wrote Hi, It works well now. Thank you so much. Besides, I submitted a Job(194517) to match partition. But it has been restart this morning by system. Could you please help me to check the details Best [USER] On Thu Jun 26 12:31:22 2025, [STAFF] wrote Hi [USER], I just reset those nodes and they look good to go now. Give it a try again and let me know if you have any more issues"
"3214690","70056750","2025-06-27 17:25:18","Publication Information","Hello [USER], This has been added on our publications page here https://hpcf.umbc.edu/publications/. Your publication is number 18 under the 2024 lists of publications. If you have any issues let us know. Best regards, [STAFF]"
"3214726","70055055","2025-06-27 16:25:20","HPC Other Issue: HPCF in the news","Ticket https://rt.umbc.edu/Ticket/Display.html?id=3214726 Last Update From Ticket This is amazing Thanks for the share I'll certainly have this posted to our HPCF Website but I'll chat with our communications team on a broader posting if that's alright with you On Thu Jun 26 14:36:42 2025 [USER] wrote First Name [STAFF] Last Name [STAFF] Email [EMAIL] Campus ID [CAMPUSID] Request Type High Performance Cluster Just wanted to make you aware of this https://umbc.edu/stories/high-resolution-stream-maps/ https://www.chesapeakebay.net/news/pressrelease/chesapeake-bay-program-releases-most-detailed-data-on-the-chesapeakes-lands-and-waters-to-date [STAFF] DoIT Research Computing Team"
"3214763","70048291","2025-06-27 13:09:02","HPC Slurm/Software Issue: System performance","Hi [USER], It is typical for AWS to sign you out after a 'work' day of use. It's also typical for the AWS to sign you out if you try to open another instance of AWS. Could you give a little more context as to how often you were signed out, how long you were on the webpage, and what you were doing? If there were any running jobs, were they cancelled as well? On Thu Jun 26 15:06:29 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster The system signs-out automatically Attachment 1: signed_out.png Best, [STAFF]"
"3215005","70057135","2025-06-27 17:44:52","HPC Other Issue: Connecting to Taki","Hello [USER], Currently we have migrated from taki over to chip. I recommend taking a look at chip's documentation that we have created in order to provide user's proper setup alongside any common issues they may face. (https://umbc.atlassian.net/wiki/spaces/faq/pages/1082589207/UMBC+HPCF+-+chip). If you need do not have access when logging into chip you may need to request an account here (https://rtforms.umbc.edu/rt_authenticated/doit/DoIT-support.php?auto=Research%20Computing) following the below steps: 1. <Research Computing Action> select 'High Performance Cluster' in the dropdown. 2. <HPC Action:> select 'User Account Creation/Modification' in the dropdown 3. <I'd like to> select 'Create/Modify account in existing PI group' 4. After this step a bunch of items you can input from will pop up such as <Existing PI Email>, <Existing Group Name> <Project Title> and <Project Abstract> (fill this out and submit any additional information in the Notes sections) I recommend doing this if you are unable to follow the first recommendation of viewing our documentation on chip (https://umbc.atlassian.net/wiki/spaces/faq/pages/1082589207/UMBC+HPCF+-+chip) and you are not able to log in via ssh. If you have any issues please reach out. Best regards, [STAFF]"
"3215017","70073855","2025-06-30 13:23:22","HPC Other Issue: SSH internationally","Hi [USER], If you're on the VPN this shouldn't be an issue. Let's try a few things: 1.) Connect to the vpn and send us your ip address. This can be done by going to your terminal on your local machine and running 'ipconfig' if on a windows machine, and 'ip a' if on a mac/linux machine. 2.) When ssh'ing to the cluster use the '-vvv' option, ie 'ssh [STAFF]@[SERVER] -vvv' and send us that output. When you attempt to connect if you could let us know approximately what time you attempted to connect, that will help us look through the logs (you're in CST right?). Port 22 is the world-wide standard for ssh, so that seems unlikely. On Fri Jun 27 06:56:39 2025, [STAFF] wrote: We disallow all foreign access to the cluster by default. Let me check with our security team on what might be able to be done as a temporary measure. On Fri Jun 27 06:50:36 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Hi, I am currently at a conference in Italy and cannot ssh into [SERVER] from here. I suspected it may have something to do with the network configuration here though multiple wifi connections and use of the global protect VPN did not change the result of timing out. I can however ping [SERVER] with no issues. Some others here at the conference have successfully ssh'd into their hpc with similar looking configurations like the use of duo, though they had mentioned they were not using port 22. Do we have another connection port to try?"
"3215022","70048142","2025-06-27 13:04:47","Confirm [USER] has access to contributed node partition","Hi [USER], I've gone ahead and verified that you didn't have proper permissions to access the pi_lobo and made some changes to the account pi_burnsm which should allow you to access the needed qos to access the partition. Please try again, and let me know if it's still not working. On Fri Jun 27 07:20:59 2025, [STAFF] wrote: Please confirm that user [USER] has access to the pi_lobo partition. The user is having issues running jobs on this hardware. Please work with [USER] to confirm/identify any issue with slurm job submission. Best, [STAFF]"
"3215173","70053830","2025-06-27 15:38:02","HPC Other Issue: unable to use run jobs on pi_[ID] queue","Hi [USER], You managed to throw in a job while there was a small hiccup with our manager service. We were able to release the job from the held position, and it 'completed' in about a minute. Would you verify that the job ran as expected? On Fri Jun 27 11:14:34 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID]  On Behalf Of:             [STAFF] ([EMAIL], [CAMPUS_ID]) Request Type:              High Performance Cluster Hi, we are received error messages like 'launch failed requeued held' when submitting to the pi_[USER] queue. We are not using all 10 of our nodes or the match queue. Also, there are many other processes without jobIDs and some also have similar messages. Is slurm behaving normally?"
"3215400","70074341","2025-06-30 13:31:07","HPC User Account: [USER] in LARA Lab","Hi [USER], The account ([USER]) has been created on chip.rs.umbc.edu. It's primary group is pi_[STAFF]. The home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) Kind regards, [STAFF] DoIT Unix Infra Student Worker On Fri Jun 27 15:25:59 2025, [EMAIL] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Create/Modify account in existing PI group Existing PI Email:    [EMAIL] Existing Group:       [GROUP] Project Title:        Add Student to Cluster Project Abstract:     [USER] - [PROJECTID] Please add [USER] to Chip."
"3215778","70074007","2025-06-30 13:25:42","HPC User Account: [USER]","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/). -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Sun Jun 29 21:37:11 2025, [USER] wrote: Yes, I approve. Thanks! On Sun, Jun 29, 2025 at 6:42PM RT API via RT <[EMAIL]> wrote: This e-mail is a notification that a UMBC user: [USER] <[EMAIL]> has requested an account within UMBC's HPC environment in your group <[STAFF]>. As the PI, we request that you acknowledge and approve this account creation by replying to this message. Alternatively you can go to this link and review the ticket and indicate your decision here: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3215778> Once we have your approval, we will create the account and you and the new user will receive another e-mail notifying you that the account has been created. If you have any other questions or concerns please contact us. - UMBC DoIT Research Computing Support Staff Best wishes Sincerely yours [STAFF], Ph.D. [EMAIL] Website: https://bdal.umbc.edu/people/[STAFF]/ WebEx: https://umbc.webex.com/meet/[STAFF] Professor of Data Science, Department of Information Systems Director, Big Data Analytics Lab Director, Center for Scalable Data and Computational Science (ScaleS) Co-Director, NSF REU Site on Online Big Data Analytics Co-Lead, NSF HDR institute for Data and Model Revolution in the Polar Regions (iHARP) University of Maryland, Baltimore County [PHONE NUMBER] ITE 423"
"3216693","70108111","2025-07-01 16:22:35","HPC Slurm/Software Issue: Can't access chip-gpu","Interesting... for whatever reason they are part of your unix group, but not on your slurm account. Were they recent additions to the group? Either way, they've been added now. On Tue Jul 01 10:47:07 2025, [USER] wrote: Thanks [STAFF], that worked. Could you also give access to my lab members [USER] and [USER]? They already have an account with my group in chip. Daniel Lobo, Ph.D. Associate Professor, Biological Sciences UG Program Director, Bioinformatics and Computational Biology University of Maryland, Baltimore County 1000 Hilltop Circle, Baltimore, MD 21250, USA Phone: [PHONE NUMBER REMOVED] Email: [EMAIL REMOVED] Web: lobolab.umbc.edu On Tue, Jul 1, 2025 at 10:07 AM Max Breitmeyer via RT <[EMAIL REMOVED]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL REMOVED]&groupid=EIS&ticketid=3216693&ticketowner=[EMAIL REMOVED]&ticketsubject=HPC Slurm/Software Issue: Can't access chip-gpu. If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3216693 >. Thank You Resolution: Hi [USER], Apologies for this but you were more or less right. When we first added you to chip, chip-gpu had not been set up yet. We thought we got everyone successfully associated to chip-gpu with our scheduler, but we missed your group. I've remedied that now, and verified that you have access using the same command you sent to us. Sorry for the confusion! On Tue Jul 01 09:43:52 2025, [USER] wrote: First Name: Daniel Last Name: Lobo Email: [EMAIL REMOVED] Campus ID: DQ02490 Request Type: High Performance Cluster Hi, I'm unable to run any jobs in the new gpu cluster: $ srun --cluster=chip-gpu --account=pi_lobo --mem=5000 --time=1:00:00 --gres=gpu:1 --pty $SHELL srun: error: Unable to allocate resources: Invalid account or account/partition combination specified. I was able to access the former ada cluster. Does my account need to be activated after the migration? Thanks, [USER]."
"3216728","70101314","2025-07-01 14:18:14","HPC Other Issue: fail to run calculations in 'match-shared'","Hi [USER], Sometimes when jobs get stuck a certain number of times they need to be 'released' in order for them to get moving again. We've gone ahead and done that now, thanks for the heads up, and we'll continue to monitor! On Tue Jul 01 10:05:00 2025, [USER] wrote: First Name: [USER], Last Name: [USER], Email: [EMAIL], Campus ID: [USER], Request Type: High Performance Cluster, Hello, I am trying to submit calculations to 'match-shared,' but the submissions have been failing since last weekend. I noticed that the user '[USER]' has many calculations stuck in the queue with the status 'launch failed requeued held.' As a result, only two nodes are currently running in the match, and no other calculations can be processed. Please see the attached screenshot showing the calculations stuck in the queue. Could you please help resolve this issue? Thank you very much. Best Regards, [USER]"
"3216952","70142796","2025-07-02 21:14:01","HPC New Group: [ID]","Hello [STAFF], pi_sousedik group has been provisioned successfully. The group pi_sousedik now exists on the chip cluster. Members of this group can therefore access and contribute to the research storage space allocated to the group. This storage is located at /umbc/rs/pi_sousedik and currently has a quota of 10TB. I also listed the project here at https://hpcf.umbc.edu/libraries/research-projects-hpcf/ with the provided project abstract you had provided. https://hpcf.umbc.edu/?page_id=5571&preview=true Best regards, [STAFF]"
"3217394","70162320","2025-07-03 20:50:34","HPC Other Issue: please fix [ID] interact","One of our other team members is looking at it. I'll poke them to see where it's at. In the meantime, I'll close this ticket. Yes, I was able to get back into strowinteract and am doing things, hopefully no hiccups over the weekend since the paper submission deadline is by Tuesday! Did you get a chance to look at the other ticket I submitted yesterday, about permissions on /asl/ftp/pub/incoming? I cannot move those files to our regular locations, and I cannot change their permissions. [Research Computing #3217398] HPC Other Issue: /asl/ftp permissions Thanks [USER]. On Thu, Jul 3, 2025 at 4:25 PM Max Breitmeyer via RT wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3217394> Last Update From Ticket: This expected behavior. Were you able to access everything? On Wed Jul 02 09:45:35 2025, [USER] wrote: Hi max and Roy It seems a little happier but have the ssh keys changed? I have not actually logged in but it seems a little more alive The authenticity of host 'strowinteract.rs.umbc.edu (130.85.28.216)' can't be established. ED25519 key fingerprint is SHA256:QF3Egf7dYp9waKC3ruQvX8ekvXOCgmfCxEPIup7XbQI. This key is not known by any other names Are you sure you want to continue connecting (yes/no/[fingerprint])? On Wed, Jul 2, 2025 at 9:42 AM [USER] wrote: Hi Max I still can't get in [USER]-Mini:~ $ ssh -X -Y -vvv -l [USER] strowinteract.rs.umbc.edu OpenSSH_9.0p1, OpenSSL 1.1.1u 30 May 2023 debug1: Reading configuration data /Users/[USER]/.ssh/config debug1: /Users/[USER]/.ssh/config line 5: Applying options for * debug1: Reading configuration data /usr/local/etc/ssh/ssh_config debug3: expanded UserKnownHostsFile '~/.ssh/known_hosts' -> '/Users/[USER]/.ssh/known_hosts' debug3: expanded UserKnownHostsFile '~/.ssh/known_hosts2' -> '/Users/[USER]/.ssh/known_hosts2' debug2: resolving 'strowinteract.rs.umbc.edu' port 22 debug3: resolve_host: lookup strowinteract.rs.umbc.edu:22 debug3: ssh_connect_direct: entering debug1: Connecting to strowinteract.rs.umbc.edu [130.85.28.216] port 22. On Wed, Jul 2, 2025 at 9:38 AM Max Breitmeyer via RT wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3217394> Last Update From Ticket: Hi [USER], I'm unable to replicate the time out that you're having. I am able to ssh and ping strow-interact.rs.umbc.edu. Could you try again using the '-vvv' flag send us the output? I would also recommend making sure you are on the VPN. On Wed Jul 02 09:22:10 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [STAFF] Request Type: High Performance Cluster I can log into chip, but I cannot log into strowinteract. Can you please fix that ASAP, I have a paper due on Monday and need to get work done, thanks ssh: connect to host strowinteract.rs.umbc.edu port 22: Operation timed out"
"3217398","70168793","2025-07-06 04:27:42","HPC Other Issue: /asl/ftp permissions","Great thanks, I was able to move files sent to us between April 2025 and July 2, 2025. These are daily pushes, I'll keep an eye on future pushes and let you know if any issues crop up. - [USER] On Thu, Jul 3, 2025 at 7:14 PM [STAFF] via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey. Ticket can be found at: https://rt.umbc.edu/Ticket/Display.html?id=[TICKETID]. Thank You Resolution: Hello [USER], The permissions have been updated for files in the incoming/L1c directory. We have a task running every 15 minutes that will apply these changes to additional incoming files in that directory. If you continue to experience any issues, please don't hesitate to reach out. Best regards, [STAFF]. Original Request: Requestors: [USER] First Name:                [FIRSTNAME] Last Name:                 [LASTNAME] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Looks like sometime in April when there was a changeover from taki to chip, the files pushed to us from JPL every day and placed into /asl/ftp/incoming seems to have changed permissions. This is what one of them looks like right now [USER@c21-04 airs]$ ls -lt /asl/ftp/incoming/L1c/AIRS.2025.04.30.065.L1C.AIRS_Rad.v6.7.5.0.G25120163953.hdf.met -rw------- 1 ftp pi_strow 30439 Apr 30 16:41 /asl/ftp/incoming/L1c/AIRS.2025.04.30.065.L1C.AIRS_Rad.v6.7.5.0.G25120163953.hdf.met Can you change the permissions (or tell me how to do it, because I keep getting a permission denied) so I can move them to our /asl/data (wherever that is on /xfs2 or /xfs3). As an example of earlier files that could easily be moved by our script : [USER@strow-interact git]$ ls -lt /asl/airs/l1c_v675/2025/091/AIRS.2025.04.01.018.L1C.AIRS_Rad.v6.7.5.0.G25091125150.hdf -rw-rwxrw- 1 [USER] pi_strow 117626017 Apr 1 12:53 /asl/airs/l1c_v675/2025/091/AIRS.2025.04.01.018.L1C.AIRS_Rad.v6.7.5.0.G25091125150.hdf Thanks [USER]"
"3217446","70152221","2025-07-03 14:44:09","HPC Other Issue: [USER] can not submit jobs to the knacc1 match_shared","Hi [USER], Thanks, I got it. This is because all nodes for c24 are currently in use. Anyway, the pi_bennettj partition is working well as usual, so I can still submit calculations. Thank you very much for your time and help. Have a good day.  Best Regards, [STAFF] On Wed, Jul 2, 2025 at 3:42 PM [STAFF] via RT <[EMAIL]> wrote:  > Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3217446 > > Last Update From Ticket: > Hi [USER], It looks like the scontrol command required the flag '-M chip-cpu' to get the proper job. It was looking at chip-gpu, and got the wrong job. But I was able to run the command and get the necessary info. I will include this at the bottom of the message If you run sinfo -M chip-cpu, you can see that all of the 2024 CPU nodes are allocated or partially allocated. Your job will have to wait for a node to become available on the match partition. However, since you are a member of pi_bennettj, you should be able to access the pi_bennettj partition, which should give you/your group priority over other users. You can use --partition=pi_bennettj along with --qos=pi_bennettj, which should allow you to run on that partition with priority. This partition has access to the following nodes: c24-[01-10]. You can try that and see if your job will run sooner. Let me know if you have issues running on the pi_bennettj partition. scontrol output: (base) [desposi1@chip-mgt1 ~]$ scontrol show job 216787 -M chip-cpu JobId=216787 JobName=<4RM2> UserId=[USER](172085) GroupId=pi_bennettj(1010) MCS_label=N/A Priority=1 Nice=0 Account=pi_bennettj QOS=shared JobState=PENDING Reason=Nodes_required_for_job_are_DOWN,_DRAINED_or_reserved_for_jobs_in_higher_priority_partitions Dependency=(null) Requeue=1 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0 RunTime=00:00:00 TimeLimit=5-00:00:00 TimeMin=N/A SubmitTime=2025-07-02T12:47:52 EligibleTime=2025-07-02T12:47:52 AccrueTime=2025-07-02T12:47:52 StartTime=Unknown EndTime=Unknown Deadline=N/A SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-07-02T15:24:58 Scheduler=Backfill:* Partition=match AllocNode:Sid=chip:307662 ReqNodeList=(null) ExcNodeList=(null) NodeList= NumNodes=1-1 NumCPUs=64 NumTasks=64 CPUs/Task=1 ReqB:S:C:T=0:0::*:* ReqTRES=cpu=64,mem=300G,node=1,billing=64 AllocTRES=(null) Socks/Node=* NtasksPerN:B:S:C=64:0::*:1 CoreSpec=* MinCPUsNode=64 MinMemoryNode=300G MinTmpDiskNode=0 Features=(null) DelayBoot=00:00:00 OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null) Command=/umbc/rs/bennettj/users/[USER]/[USER]/Quantum-Espresso/Project2_2_functionalmaterial/CIPSe_FGT_MBA/FGaT+MBA/FGaT+4R-NH2-st/runscript WorkDir=/umbc/rs/bennettj/users/[USER]/[USER]/Quantum-Espresso/Project2_2_functionalmaterial/CIPSe_FGT_MBA/FGaT+MBA/FGaT+4R-NH2-st StdErr=/umbc/rs/bennettj/users/[USER]/[USER]/Quantum-Espresso/Project2_2D_functionalmaterial/CIPSe_FGT_MBA/FGaT+MBA/FGaT+4R-NH2-st/slurm.216787err StdIn=/dev/null StdOut=/umbc/rs/bennettj/users/[USER]/[USER]/Quantum-Espresso/Project2_2D_functionalmaterial/CIPSe_FGT_MBA/FGaT+MBA/FGaT+4R-NH2-st/slurm.216787out Power= -- Kind regards, [STAFF] On Wed Jul 02 15:03:40 2025, [USER] wrote: > Hi [STAFF], Please see the attached runscript I used in this email. The path to the input and runscript files is:/umbc/rs/bennettj/users/[USER]/[USER]/Quantum-Espresso/Project2_2D_functionalmaterial/CIPSe_FGT_MBA/FGaT+MBA/FGaT+4R-NH2-st > I also copied all output using the command you provided into the attached file named 'output'Thank you Best Regards,[USER] On Wed, Jul 2, 2025 at 12:38 PM [STAFF] via RT <[EMAIL]> wrote: >> Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3217446 > >> Last Update From Ticket: >> Hi [USER], Could you send your updated sbatch file? Along with the path to the file. Could you clarify what you mean by 'I removed both the memory allocation...'? The memory allocation should not be removed, 300G is the desired allocation, which you need to specify in your job request. And, due to all nodes being allocated, this will fail. Could you remove the --exclusive option from for sbatch file and test again? Thanks! -- Kind regards, [STAFF] On Wed Jul 02 10:19:57 2025, [USER] wrote: > First Name: [USER] > Last Name: [USER] > Email: [EMAIL] > Campus ID: [USER_ID] > Request Type: High Performance Cluster > Hello, I am trying to submit a job to the match_shared partition. However, I received the following error message: 'Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions.' Could you please help me resolve this issue? Is there anything that needs to be modified in the runscript to successfully run calculations in match_shared? I have attached the runscript to this ticket. It was working well yesterday, but it is no longer functioning today. Thank you very much for your assistance. Best Regards, [USER]"
"3217453","70219126","2025-07-08 20:29:45","RC Suggestion: HPCF Does Not Allocate Requested Amount of GPU Memory, Arbitrary Amount of GPU Memory is Allocated","Hi [USER], To specify the exact amount of GPU memory, you need to calculate it using the 'Cluster Specifications' wiki page here https://umbc.atlassian.net/wiki/spaces/faq/pages/1289486353/Cluster+Specifications Suppose you need 240 GiB of GPU memory and 500GiB of CPU memory. From the page above, this requirement can be met using a GPU node containing the RTX 8000 GPU cards. There are two such nodes. You can specify the number of GPU cards you need using the --gres flag and the type of GPU card you need (which is available on certain nodes) using the --constraint flag as follows: srun --cluster=chip-gpu --account=pi_doit --mem=500G --time=1:00:00 --gres=gpu:5 --constraint='RTX_8000' --pty $SHELL Suppose you need 96 GiB of GPU memory and 200GiB of CPU memory. From the page above, this requirement can be met using a GPU node containing the RTX 8000 GPU cards or a GPU node containing the L40S GPU cards. There are two nodes with RTX 8000 GPU cards and 10 nodes with L40S cards. You can specify the number of GPU cards you need using the --gres flag and the type of GPU card you need (which is available on certain nodes) using the --constraint flag as follows: srun --cluster=chip-gpu --account=pi_doit --mem=96G --time=1:00:00 --gres=gpu:2 --constraint='RTX_8000|L40S' --pty $SHELL Mentioned below is a list of identifiers for the GPUs in the constraint flag: GPU card Identifier in '--constraint' flag RTX 2080Ti RTX_2080TI RTX 6000 RTX_6000 RTX 8000 RTX_8000 H100 H100 L40S L40S We are working on creating a page for requesting GPU memory on our wiki, and we will let you know once it has been published. I hope the two examples above answer your question. Thank you. Regards, [STAFF]"
"3217894","70332743","2025-07-15 14:41:52","HPC Other Issue: [USER] cannot get tensorflow to detect GPU on Jupyter Notebook","Hi [STAFF] and [STAFF], I was able to recreate the 5 steps you mentioned in the previous email last Friday. Jupyter Notebook is now able to detect multiple GPUs and also use them for training the CNNs. [USER] and [STAFF] created a new account for [USER] on chip, and that helped since [USER]'s account was (almost) full on storage. For the documentation of the same issue on HPCF wiki, I created a draft page and I will share it with the team when it is ready for review. Let me know if you want me to close the ticket or wait for the documentation to be completed to close the ticket. Thank you. Regards, [USER] Ticket Last Update From Ticket: Hello [USER], In our latest call we were able to view the disk usage running the command df -h and we saw your current location is full [root@chip tmp]# df -h /umbc/ada/[USER] /umbc/rs/[USER] Filesystem Size Used Avail Use% Mounted on nfs.iss.rs.umbc.edu:/ifs/data/rs/[USER] 250G 250G 126M 100% /umbc/rs/[USER] The potential options we have is you can move over conda files to your ada research volume here [root@chip tmp]# df -h /umbc/ada/[USER] /umbc/rs/[USER] 10.2.42.254:/export/[USER] 3.0T 2.6T 418G 87% /umbc/ada/[USER] Your ada research volume has a decent amount of space left to have these files moves over. Since moving over the files was a risk you did not want to take, the next suggestion is to re-download conda into your ada research volume. We are unable to do this given our policy but as a user owning this you can do this."
"3217950","70196703","2025-07-08 02:51:44","HPC Other Issue: help to access directories","This appears to be an email thread related to a research computing issue at the University of Maryland, Baltimore County (UMBC). Here's a breakdown of the content:  **Initial Issue**  The initial issue is that someone (likely a researcher or student) is having trouble accessing a directory on the university's high-performance computing (HPC) cluster, specifically `/common/rs/cichoku`.  **Resolution**  Danielle Esposito from the UMBC DOIT Unix Infra team resolves the issue by creating a new group called `pi_cichoku` and allocating 10 TB of storage to it. She also creates a user account for Charles Ichoku (cichoku) on the chip.rs.umbc.edu cluster.  **Follow-up**  Later, Tartela from the same team follows up with the researcher (MD43972) to troubleshoot an issue related to accessing the directory. She asks them to check their current working directory, list the contents of the directory, and verify their group ID and username to ensure they have access to the directory.  **Additional Context**  The email thread includes some additional context, such as links to documentation on the hpcf.umbc.edu website and a wiki page for getting started with the chip cluster.  Overall, this email thread appears to be related to resolving issues with accessing research computing resources at UMBC."
"3218327","70160064","2025-07-03 19:14:10","HPC Other Issue: no node available!","Hi [USER], thank you for your patience just to let you know setting the account to [CODE] might give you access to certain nodes or priorities but it won’t make nodes available if they’re all busy or offline we understand your frustration Are you requesting specific node features (--constraint) or a specific node (--nodelist)? Are you asking for very high resources (e g multiple GPUs huge memory)? Please let me know if your job is too constrained and if no node matches You can try Checking node status with sinfo -p gpu Relaxing job constraints (request fewer GPUs) if you have any Best [STAFF] On Thu Jul 03 13:49:36 2025 [USER] wrote First Name [USER] Last Name [USER] Email [EMAIL] Campus ID [ID] Request Type High Performance Cluster Hi trying to get a node since this morning and the first job with ID (75045) was pending a long time so I canceled it The second job with ID (75050) shows this message below [USER]@chip [USER]$ squeue -u [USER] CLUSTER chip-cpu JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) CLUSTER chip-gpu JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 75050 gpu HuBERT_e [USER] PD 0 00 1 (ReqNodeNotAvail UnavailableNodes g20-[01-13] g24-[01-12]) How I request the job sbatch HuBERT_extraction slurm Path to HuBERT_extraction slurm cd /umbc/rs/iharp/users/[USER]/ I have assigned the account in my slurm file to [CODE] to get the nodes sooner but weirdly I am waiting a lot"
"3218339","70159992","2025-07-03 19:09:56","HPC Other Issue: Add account for [ID] to pi_[USER] group at chip","This is done, the listed users should be able to run on the `[SERVERNAME]` reservation on chip-gpu. Make sure they also specify the --account flag as '--account=[ACCOUNT]'. On Thu Jul 03 14:02:58 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster The students below are doing REU research with me this summer. Would you please add them to my group, [ACCOUNT], at slurm group setup so they can use my GPU reservation (g24-01)? Thanks! [USER], [EMAIL] [USER], [EMAIL] [USER], [EMAIL] [USER], [EMAIL] [USER], [EMAIL]"
"3219275","70321334","2025-07-14 20:54:22","accessing directories","Hi [USER], In the future, please open a new RT ticket for new issues. Additionally, also check out our wiki, as we have lots of pages that include information to help you get started (such as the Getting Started on chip page linked here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip, this page walks you through all of the issues/things you are encountering). But, to address your questions... 1. Yes, modules are not able to be loaded on the log in node. On previous clusters, some users would attempt to load modules and run jobs directly on the log in node, not the actual compute nodes, which resulted in a disrupted user experience for all cluster users. For this reason, we have disabled loading modules on the login node. If you want to load modules, you need to start an interactive slurm job, which lets you directly access a compute node, and test/run code. Questions/Comments 2 and 3 seem to be related, so I will address both of those next. To start an interactive job, you need to use the 'srun' command. For example, if I wanted to start an interactive job, with 5 gigabytes of RAM, using chip-cpu general partition, I would run the command... 'srun --cluster=chip-cpu --mem=5G --time=00:30:00 --partition=general -account=pi_group --qos=normal --pty $SHELL'. This would open an interactive session on a compute node. All of the attributes here can be tuned to your liking, along with various other attributes that you can configure that are not mentioned in this basic example. If you wanted to start a batch job, you would need to create and properly format an sbatch file, which, similar to the srun command above, will include all of those attributes defined as required. An example sbatch file could look something like this... #!/bin/bash #SBATCH --cluster=chip-cpu #SBATCH --mem=5G #SBATCH --time=00:30:00 #SBATCH --qos=normal #SBATCH --account=pi_group #SBATCH --partition=general python test.py For more information on different sbatch/srun options, please visit the page on our wiki: https://umbc.atlassian.net/wiki/spaces/faq/pages/1335951387/Basic+Slurm+Commands Once you get into a compute node and load the modules necessary to compile your software, the steps to compile should be the same as compiling the code on any other Linux OS. For your specific package, there should be instructions available, provided by the developers, on how to compile that code. If you run into any other errors using the cluster environment, please consult our wiki. If you cannot find a solution to your issue there, feel free to create a new RT ticket. Have a nice day! -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Mon Jul 14 15:37:15 2025, [USER] wrote: Request for Compute Node Access on CHIP Cluster to Compile NetCDF Hello HPC Support Team, I hope this message finds you well. I am currently working on the CHIP cluster from the login node (chip) and attempting to compile the NetCDF-C and NetCDF-Fortran libraries as part of my research workflow. However, I have encountered several limitations that are preventing me from progressing: The module system returns the message: 'Modules do not function on the login nodes.' Common job submission commands available in my current shell environment. As a result, I am unable to access a compute node where I can safely compile large software packages such as NetCDF. I would like to ask: What is the correct procedure for submitting a batch or interactive job to request a compute node for compilation purposes? Any guidance you can provide on compiling software on CHIP would be greatly appreciated. Please let me know the recommended steps for compiling custom packages in my user space. Thank you in advance for your assistance. Warm regards, [USER] Ph.D. Student Department of Geography & Environmental Systems University of Maryland, Baltimore County UMBC Username: [EMAIL]"
"3219507","70192222","2025-07-07 19:40:45","HPC User Account: [USER] in pi_doit","I APPROVE [USER] ([USER]) [EMAIL] Appointment Calendar https://calendar.google.com/calendar/u/0/appointments/[CALENDAR_LINK] The most dangerous phrase in the language is, 'We've always done it this way.' - [STAFF] On Mon, Jul 7, 2025 at 3:39 PM RT API via RT <[EMAIL]> wrote: This e-mail is a notification that a UMBC user: [USER] <[EMAIL]> has requested an account within UMBC's HPC environment in your group <pi_doit>. As the PI, we request that you acknowledge and approve this account creation by replying to this message. Alternatively you can go to this link and review the ticket and indicate your decision here: Ticket https://rt.umbc.edu/Ticket/Display.html?id=[TICKET_ID] Once we have your approval, we will create the account and you and the new user will receive another e-mail notifying you that the account has been created. If you have any other questions or concerns please contact us. - [STAFF]"
"3219896","70207103","2025-07-08 15:30:24","HPC Other Issue: Cannot Cancel Jobs","Hi [USER], When attempting to cancel jobs on chip, you now need to provide the '-M' flag and pass the cluster (either chip-cpu or chip-gpu) to the command. For example, if you are running on chip-cpu, with job ID 12345, you would run 'scancel -M chip-cpu 12345'. If you were running on chip-gpu, you would specify 'scancel -M chip-gpu 12345'. If you have any further issues with this, feel free to reach out. For more information, please view our wiki: https://umbc.atlassian.net/wiki/spaces/faq/pages/1033142321/Using+slurm+on+chip#Cancelling-Jobs-(scancel) Have a nice day! -- Kind regards, [STAFF] On Tue Jul 08 11:18:41 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Hello, we found that skill [jobID] and scancel [jobID] fail to cancel submitted jobs and they hang for an extended period of time on chip. This is very different behavior than previously observed on taki. What is a command that works quickly for chip?"
"3220091","70214967","2025-07-08 18:43:06","HPC Other Issue: Unable to SSH to Taki (Previously Working) - Account [ID]","Hi [STAFF],  Thank you so much, now I am able to login in my accounts.  Thanks [USER]  On Tue, Jul 8, 2025 at 2:22 PM [STAFF] via RT <[EMAIL]> wrote:  Ticket  Last Update From Ticket: Hello [USER], The Taki is now in chip. * Type into the terminal ssh ${yourUMBCUsername}@chip.rs.umbc.edu * You’ll then be prompted to enter your UMBC password. * If you are not on campus wifi or the VPN, you may be prompted for a Duo login. Let me know if you can get in like that. If not you can check this page. https://umbc.atlassian.net/wiki/spaces/faq/pages/1033437227/Access+User+Environment Please let me know if it is working or not. Thank you. Best, [STAFF] On Tue Jul 08 13:59:40 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Hi HPCF Support Team, I hope you are well. I am currently unable to SSH into Taki, whereas I was previously able to log in without any issues. My account is: [EMAIL] I have confirmed that I am connected to the UMBC VPN and that my internet connection is working. However, when I try to connect, I receive: 'ssh: Could not resolve hostname taki.rs.umbc.edu: No such host is known.' I also tried checking taki.umbc.edu, but it is not resolving either. Could you please check if there have been any hostname changes or updates to the SSH access policies? If possible, please let me know the current IP or hostname for Taki so I can continue my work. For reference, my PI is [STAFF] ([EMAIL]). Thank you very much for your assistance. Best regards, [USER]"
"3220435","70287160","2025-07-11 20:34:22","HPC Slurm/Software Issue: VSCode on chip","Hi, The link to the page [STAFF] mentions is here: https://[DOMAIN].atlassian.net/wiki/spaces/faq/pages/[PAGEID]/Why+is+[SOFTWARE]+not+connecting+to+[SERVER]. I'll mark this as resolved for now, feel free to reopen if you have additional questions or issues. -- [STAFF] DoIT Research Computing Team"
"3220610","70237373","2025-07-09 18:11:53","HPC Slurm/Software Issue: Chip Login Server - /tmp is full","Thanks for the heads up. We've gone ahead and cleared it out. Let me know if you still have issues. On Wed Jul 09 11:17:55 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] Request Type:              High Performance Cluster Having trouble starting a remote VS Code session on the Chip login server - I can see that /tmp is full, causing my issue. Can this be emptied?"
"3220653","70237672","2025-07-09 18:21:41","HPC Other Issue: Continuously being disconnected from chip server","Thanks, it worked. On Wed, Jul 9, 2025, 2:11 PM [STAFF] via RT wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3220653 Last Update From Ticket: Hi [USER], We noticed /tmp was full on our login node. We've gone ahead and cleared that, this should help with your experience. I'll leave this stalled, please let me know if you still have more issues. Note that you might have to fully disconnect from the session and restart to experience the change. On Wed Jul 09 13:47:52 2025, [USER] wrote: It logs in. Then after a few seconds, password prompts pop up. Best [USER] On Wed, Jul 9, 2025, 1:42 PM [STAFF] via RT wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3220653 Last Update From Ticket: What happens when you enter your password? On Wed Jul 09 13:39:34 2025, [USER] wrote: Ssh works. I only get these issues when logging in through vs code. I don't see any messages. It just prompts to enter password. Best [USER] On Wed, Jul 9, 2025, 1:37 PM [STAFF] via RT wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3220653 Last Update From Ticket: Hi [USER], Are you seeing this issue only with the vscode? Or with SSH login as well. Do you get any messages when you disconnect? On Wed Jul 09 11:52:42 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CID] Request Type: High Performance Cluster Hi, I use vscode to login to chip server. Currently I am facing an issue. The ssh connection is continuously getting disconnected. I am using a window pc which is connected to umbc internet through LAN port. So the issue is not the network connectivity. I tried different PC[mac] and having the same issue. My user account has space, so it might not be due to space issue. Could you please look into this? Thank you for your help."
"3220687","70234236","2025-07-09 16:52:08","HPC Other Issue: urgent: delete a directory that [USER] does not own","Hi [USER], I have given you ownership of the directory: /umbc/rs/cybertrn/reu2024/team2/base $ ls -la | grep base drwxr-s--- 11 [STAFF] cybertrn   344 Nov 1  2024 base You should be able to remove the files now. Have a nice day. -- Kind regards, [STAFF] On Wed Jul 09 12:27:22 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Hi, In the cybertrn area, we are out of space. I would like to delete one directory that is large, but I do not own it. The owning user is not on the system any more (was an undergrad student last year). Please delete 'base' with 'rm -r base'; I believe, this should work. Here is the directory (pwd) and listing; it is the 'base' directory that I would like deleted. [USER]@chip team2]$ pwd -P /umbc/rs/cybertrn/reu2024/team2 [USER]@chip team2]$ ll total 568 drwxrws--- 20 [STAFF]   cybertrn    515 Jan  3  2025 ada_envs/ drwxr-s--- 11 [STAFF] cybertrn    344 Nov  1  2024 base/ drwxr-s---  7 [STAFF] cybertrn    216 Jul 24  2024 base_test/ drwsrws---  6 [STAFF] cybertrn    276 Jun 25  2024 data_analysis/ drwxrws---  3 [STAFF] cybertrn    207 Jun 25  2024 data_analysis2/ drwxrws---  2 [STAFF] cybertrn    486 Jul 23  2024 datasets/ -rw-rw----  1 [USER] cybertrn    911 Jul 16  2024 du240716.txt drwxr-s--- 10 [STAFF] cybertrn    221 Jul 25  2024 envs/ drwxr-s---  2 [STAFF] cybertrn    233 Aug  2  2024 figures/ drwxr-s---  2 [STAFF]  cybertrn    319 Jul 29  2024 image_recon/ drwxrwx---  6 [STAFF] pi_[USER] 1057 Jun 26 15:37 postprocessing/ drwxrws---  7 [STAFF] cybertrn    713 Jun 25 11:34 preprocessing/ drwxrws--- 23 [STAFF] cybertrn   1391 Jun 30 11:18 preprocessing_new/ drwxrwx--- 22 [STAFF]   cybertrn   1318 Jun 25 11:57 preprocessing_new_ruth/ drwxrwx---  6 [STAFF]  cybertrn    102 Jul  1  2024 pytorch-test-env/ drwxrws--- 10 [STAFF] cybertrn    205 Aug  2  2024 Research/ drwxrws--- 11 [STAFF]   cybertrn    274 Jul  8  2024 reu2023_pytorch/ drwxrws---  8 [STAFF] cybertrn    161 Jun 28  2024 training"
"3220835","70242956","2025-07-09 20:43:10","HPC New Group: pi_[ID]","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[USER]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/). Best regards, [STAFF]"
"3221129","70309786","2025-07-14 16:30:28","HPC Other Issue: general questions/help needed","Hi [USER], Great thanks! That worked!!!! I probably mis-typed about [STAFF], what I meant was both he and I were able to look at Matlab plots from chip compute nodes a month ago, so I was surprised I could no longer look at Matlab plots now. I'll keep an eye out but for now I think this is resolved! Thanks again! [USER] It looks like the issue actually coming from incorrect permissions for your .ssh folder. If you run 'ls -la ~ | grep .ssh' , you can see all three .ssh folders you have in your home directory. If you notice, you can see the permissions for the taki backup and the .ssh folder are the same, and are both 775. However, for the chip backup, you can see it reflects the proper permissions (700). But for the .ssh folder, the 775 level of permissions is way too high. You need to restrict this to just 700 for .ssh, and 600 for the actual key files inside the .ssh folder. The key's permissions inside the folder are already fine, so you just need to fix the permissions for the .ssh directory itself. Run 'chmod 700 ~/.ssh', and this should fix your ssh issues. Additionally, you should be able to copy/move your previous keys from taki back to the .ssh directory after verifying this is working. I believe those keys themselves are fine, it was just the folder permissions from the taki backup that originally messed up SSH. Can you please elaborate on the issues [STAFF] is encountering? I have tested all of the steps listed above with their user account, and had no issues. Assuming you follow the steps outlined previously, and have no outstanding configuration issues preventing you from using the cluster (which in this case, you did), then you will be able to access the MATLAB GUI. If you continue running into issues accessing the MATLAB GUI, let me know. salloc --cluster=chip-cpu --account=[ACCOUNT] --partition=[PARTITION] --qos=[QOS] --time=30-00:00:00 --mem=10G Original Request: Requestors: [USER] First Name: [FIRST NAME] Last Name: [LAST NAME] Email: [EMAIL] Campus ID: [CAMPUS ID] Request Type: High Performance Cluster Hi [STAFF], A few (three) points so far about strowinteract --> chip a) I'll have to stop by your office hours to get 'git' going for me on chip : I can git add, I dont think I can commit and definitely cannot push to github. Or maybe you have suggestions for me (copying over some files from strowinteact --> chip?) b) I cannot find a latex module on chip or compute nodes [USER]@c21-02 PAPER15_ALLSKYRATES_vs_AIRSL3]$ pdflatex paper1.tex bash: pdflatex: command not found [USER]@c21-02 PAPER15_ALLSKYRATES_vs_AIRSL3]$ module spider pdflatex Lmod has detected the following error: Unable to find: 'pdflatex'. [USER]@c21-02 PAPER15_ALLSKYRATES_vs_AIRSL3]$ module spider latex Lmod has detected the following error: Unable to find: 'latex'. c) as of this morning I still cannot log into our node, using what [STAFF] suggested yesterday [USER]@chip PAPER15_ALLSKYRATES_vs_AIRSL3]$ srun --cluster=chip-cpu --account=[ACCOUNT] --partition=[PARTITION] --qos=[QOS] --time=01:00:00 --mem=10G --pty $SHELL srun: error: Unable to allocate resources: Invalid qos specification Thanks [USER] PS is there an easier way to communicate a help request/open a ticket with you rather than going to HPCF webpage, pulldown request help, log in, duo push, go though more pull down options, finally write something ..."
"3221160","70253758","2025-07-10 15:34:03","HPC Other Issue: Password not recognized","Hi [USER], Please note that you need to request an account for yourself on chip first. This section on the 'Getting Started on Chip' page will guide you on requesting a user account on chip by creating an RT ticket: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip#Requesting-a-User-Account-on-chip Once you submit the ticket, someone from our team will create an account for you and let you know once it is done. Please try to ssh into your account then and let us know if you are able to access your account. Thank you. Regards, [STAFF] On Thu Jul 10 09:39:55 2025, [EMAIL] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster Hi, I'm trying to access for the first time my account on the CHIP cluster. I followed the instructions on the user documentation (https://umbc.atlassian.net/wiki/spaces/faq/pages/1033437227/Access+User+Environment) and tried to ssh into my account (username: [USER]). However, the password that grants me access to MyUMBC is not recognized, so I cannot access my account. Can you help me with this? Thank you in advance, [USER]"
"3221192","70595612","2025-07-29 16:18:15","grant proposal","Sounds good, thanks! Marking this as resolved. -- [STAFF] [TEAM]"
"3221225","70266293","2025-07-10 21:57:30","HPC User Account: [USER] in iHARP","Your account ([USER]) has been created on [SERVER]. Your primary group is [GROUP]. Your home directory has 500M of storage. Please read through the documentation found at [WEBSITE] > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link ([LINK])."
"3221231","70519186","2025-07-24 14:22:22","HPC Other Issue: Proposal Support (description of HPCF Facilities and Data Management)","Hi [STAFF], Thanks a lot for getting back to me. This page from [USER] is very much what I'm looking for -- if it is not too much of a hassle, I'd really appreciate an updated version! Best, [USER] -- On Tue, Jul 22, 2025 at 10:28 AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3221231 > Last Update From Ticket: Hi [USER], Matthias authored this page a few years ago: https://hpcf.umbc.edu/supporting-materials-for-research/ It's certainly not up to date. I can quickly draft something more updated and supply to you if you need it. There's been such a wait here because I'm chatting with folks in OSP to ensure what we put on the webpage will work best for all campus researchers/agencies. Hoping to have something fresh and accurate here in the coming days. On Thu Jul 10 10:48:16 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USER] Request Type: High Performance Cluster Hello, I am submitting an NSF proposal which requires 'Facilities' and 'Data Management' documents. These are a good place to put a paragraph or two about UMBC's HPC facility and computing resources, especially the chip cluster. I couldn't find these descriptions on the HPCF website. I suppose these would be useful for all PIs submitting proposals. Pretty standard for most agencies. Once created, all PIs could simply copy these descriptions into their Facilities and Data Management documents. Would HPCF be interested in creating this helpful resource? See 'Investigator Resources --> Research and Proposal Support' from ASU Research Computing as an example: https://cores.research.asu.edu/research-computing/investigator-resources cc'ing [STAFF] who's been putting together several proposal-related resources for COEIT PIs, and [STAFF], Asst. Director for Research Computing, who's helped with policies surrounding chip. Best, [USER]"
"3221377","70259858","2025-07-10 18:04:34","HPC New Group: [ID]","Hi [USER], The group pi_[USER] now exists on the chip cluster. Members of this group can therefore access and contribute to the research storage space allocated to the group. This storage is located at /umbc/rs/pi_[USER] and currently has a quota of 10T. Additionally, I have created a user account for you: Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[USER]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) If you encounter any issues using the cluster, please feel free to reach out. Our wiki (https://umbc.atlassian.net/wiki/spaces/faq/pages/1082589207/UMBC+HPCF+-+chip) also contains many answers to common issues, along with a Getting Started on chip page for new users: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip -- Kind regards, [STAFF] DoIT Unix Infra Student Worker"
"3221432","70261347","2025-07-10 18:44:36","HPC Slurm/Software Issue: Unable to get the GPU -- H100 has been busy for a couple of days","Hi [USER],  Thank you for the explanation. I'll try to do what you've suggested. Appreciate your help! On Thu, Jul 10, 2025, 14:37 [STAFF] via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3221432&ticketowner=[STAFF]&ticketsubject=HPC Slurm/Software Issue: Unable to get the GPU -- H100 has been busy for a couple of days. If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3221432 Thank You R e s o l u t i o n:= = = = = = = = = = = Hi [USER], Chip is a shared resource, so there is no guarantee that a H100 node will be available when you submit your job. Scheduling occurs on a first come first serve basis. Your job will run when a node opens up, and depending on the current usage on the cluster, this time can vary. Are you absolutely sure that your job requires H100 gpus? On chip, we only have 4 H100 GPUs, and therefore they are almost always 100% allocated. But there is a variety of other GPUs that are currently available, and your job might be able to run on that hardware instead. Additionally, after looking into your command history, it looks like you are attempting to launch interactive jobs on the H100 nodes. When trying to launch an interactive job on an allocated node, you will have to wait on that menu until a node is available. This is not optimal. I am assuming that this is what you mean when you said 'queued for a couple hours at a go'. Are you canceling your jobs while they were in the queue? This is essentially forfeiting your spot in the line, which puts you back to the end of the queue... Instead, you should be formatting your job as an sbatch file, and running it that way. When you use sbatch files, a job will stay in the queue until a node is open, even if you are not actively logged into the cluster. This means, you can submit a job, and let it do its thing, and come back to it after a day or two when it has completed running. I recommend formatting your job like this, and letting it run overnight/over a weekend, then you should be able to come back to a completed job. Have a nice day. Kind regards, [STAFF] DoIT Unix Infra Student Worker On Thu Jul 10 13:31:35 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [ID] Request Type:              High Performance Cluster Hi, I've been unable to requisition a H100 GPU for my research for the last couple of days. I've been queued for a job for hours at a go, and have not received any resources. Please check and let me know. Thank you, [USER]"
"3222080","70436258","2025-07-21 13:46:06","HPC Other Issue: Increase Storage","Thank you! As far as I know so far, the migration went well and caused no issues during the migration or after. I'm very grateful for the additional space and for your help. If we run into any issues, I'll be sure to let you know. — [STAFF] Associate Vice President for Strategic Research Initiatives Director of the Center for Space Sciences and Technology (CSST) Associate Professor of Computer Science and Electrical Engineering On Sat, Jul 19, 2025 at 2:25 PM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hello [USER], It took a little longer than expected, but I've finished migrating your storage volume at /umbc/rs/[USER] to our new Ceph cluster. There are some things that have changed from the old storage: * The new storage location is /umbc/rs/pi_[USER] * The aliases for accessing your storage volume are now pi_[USER]_common and pi_[USER]_user * Your new storage volume has 25TB allocated to it. When you or your users have a chance, could you try using it to verify everything is working as expected? Also, I apologize for not sending an email when I started the migration. I hope this didn't cause any issues with your group. Thank you, [STAFF]"
"3222920","70383589","2025-07-17 14:56:33","HPC Slurm/Software Issue: Exact behavior of slurm and related","Yes, you can close this. An interesting idea to look up full details like confirming that there were no mistakes in the slurm script or confirm which directory the job was in using 'sacct'. [STUDENT] did not know there was a partition 'contrib'; only knew of 'match' and '2024'. Typical failure is either time limit or manual cancellation, both reflecting that the job took longer than it should have. Let's consider Joe owning 10 nodes. Assume I am on one of these nodes and he submits a job to his queue of 10 nodes. If there are idle nodes of his 10, slurm should go to one of the idle ones, instead of preempting and killing my job. Preemption works by running until resources required by another user's job are needed; then the current job is automatically requeued. The command 'scontrol show job' used to work for hours after a job finished, but now gives an error minutes after finishing. Use 'sacct' with some flag magic to look at job names, ending state and exit codes. Exit code 127 implies an issue with 'Command not found'."
"3222964","70321740","2025-07-14 21:13:45","HPC User Account: [USER] in Kestner Group","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/). The project on display is located here (https://hpcf.umbc.edu/libraries/research-projects-hpcf/). If you have anymore issues feel free to reach out. Best regards, [STAFF]"
"3223107","70321476","2025-07-14 20:59:43","HPC Other Issue: g20-12 GPU down","Hi [USER], Thank you for letting us know. g20-12 is back to showing all 8 GPUs as expected. If you run into an issue with a GPU having issues like that again, please let us know. Thank you, have a nice day! -- Kind regards, [STAFF] On Sun Jul 13 17:56:06 2025, [EMAIL] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster GPU 7 on g20-12 has an error and trying to run anything on that GPU fails. Attachment 1: Screenshot 2025-07-13 at 5.54.46PM.png"
"3223663","70323992","2025-07-15 02:30:50","HPC Other Issue: Requesting H100 node reservation","This reservation is in place for the next three weeks. 'reservation=[STAFF]' On Mon Jul 14 12:24:22 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [ID] Request Type:              High Performance Cluster Hi, My students are unable to access our H100 GPUs and we need it for our research ASAP. I'm requesting a reservation on the H100 node for 3 weeks. Note: I paid for 1xH100 in the last GPU purchase. Thanks, [USER]"
"3223699","70618774","2025-07-30 16:46:45","HPC User Account: [USER] in cmat","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_cmat. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Tue Jul 29 13:31:50 2025, [USER] wrote: Yes, I approve! Thank you, [USER] On Tue, Jul 29, 2025 at 12:00 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3232699> Last Update From Ticket: Hi Dr. [USER], Could you approve the generation of [USER]'s account within your research group on chip? On Tue Jul 15 09:45:40 2025, [STAFF] wrote: > Hi [USER], > Once I receive approval from your PI, I can create an account on chip for you. -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Mon Jul 14 12:44:42 2025, [USER] wrote: >> [USER] -- Roy Prouty DoIT Research Computing Team"
"3224905","70349561","2025-07-15 22:48:42","HPC Slurm/Software Issue: uncompress .Z file","No worries. Glad you figured this out. I was going to suggest using 'gunzip', tar -zvf or similar works just as well. I'm marking this as resolved. On Tue Jul 15 14:08:18 2025, [USER] wrote: Silly me, it is just tar -zxf ppmpi_c.tar.Z You can close this ticket, unless you see value to having compress/uncompress on chip. Greetings, This message has been automatically generated in response to the creation of a ticket regarding: Subject: 'HPC Slurm/Software Issue: uncompress .Z file' Message: First Name: [USER] Last Name: [STAFF] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Hi, I have a .Z file. I am supposed to use uncompress to open this. But we do not have uncompress on chip, it seems. What is your advice? Other options? Or can you install uncompress? [USER] Ticket ID: [TICKETID] You can login to view your open tickets at any time by visiting http://my.umbc.edu and clicking on 'Help' and 'Request Help'. Alternately you can click on http://my.umbc.edu/help Thank you -- [STAFF]"
"3226406","70381585","2025-07-17 14:01:28","HPC Other Issue: Increase in GPU","Thank you for your help! Ticket Last Update From Ticket: Hi [USER], you can absolutely get more gpus. In the line where you use srun: srun --cluster=chip-gpu --account=pi_[STAFF] --mem=5000 --time=1:00:00 --gres=gpu:1 --pty $SHELL simply change the section of 'gres=gpu:1' to however many you need. Note that the more resources you ask for the longer it may take for resources to be allocated, and in addition you can only request a number of gpus equivalent to the number of gpus on the node that you're running when using an interactive job. For instance g24-03 only has 4 L40S gpus, so you wouldn't be able to request more than that. A full list of all the nodes with their specifications can be found here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1289486353/Cluster+Specifications Hopefully this helps! On Wed Jul 16 22:22:16 2025, [USER] wrote: First Name: [USER] Last Name: [STAFF] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster I have an issue running a python script. Loading checkpoint shards remains at 0%, eventually the code is Killed. From a google search, it seems like the issue is I am maxing out my resources. I've tried a few different attempts to modify the code to use different resources, but none make a difference. Would it be possible to get more GPU while using chip? / Is this the actual issue? I've attached a screenshot of the terminal + and the code running. Attachment 1: code_generator.py Attachment 2: Screenshot 2025-07-16 221824.png Best, [STAFF]"
"3226480","70391930","2025-07-17 18:53:01","HPC Other Issue: making temporary directories on our machine (/tmp) is failing","The conversation appears to be between Sergio DeSouza-Machado, a Research Associate Professor at UMBC, and Max Breitmeyer, a DOIT Unix Infra Student Worker. The topic of discussion is an issue with creating directories on the /scratch partition of a high-performance cluster.  Sergio reports that he is unable to create a directory on /scratch, despite having done so successfully two days prior. He can, however, create directories on /tmp. Max responds by explaining that users are not allowed to create directories on /scratch, and instead should use the mkdir command within their job scripts or interactive sessions to create directories in a location where they have write permission.  Max also mentions that /scratch is cleaned up automatically on all compute nodes, whereas /tmp is not. He suggests that Sergio's workflow may need to be adjusted to accommodate this change.  The conversation is technical in nature and assumes some knowledge of Unix/Linux commands and high-performance computing environments. The tone is polite and helpful, with Max providing explanations and suggestions to assist Sergio in resolving the issue."
"3226506","70381314","2025-07-17 13:56:25","HPC User Account: [ID] in PI_[ID]","Hi [USER], Your account ([STAFF]) has been created on chip.rs.umbc.edu. Your primary group is pi_zzbatmos. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/). You can also view information on your project located here (https://hpcf.umbc.edu/libraries/research-projects-hpcf/?preview_id=76&preview_nonce=cd653d434a&preview=true). It will be the first Project listed at the top of our webpage. Best regards, [STAFF]"
"3227608","70595768","2025-07-29 16:22:00","HPC Other Issue: Matlab plot error messages","Please work to include this information on a wiki page related to GUI forwarding. [STAFF] can answer questions, if you get stuck. Make sure you can replicate this process. -- [STAFF], [TEAM]"
"3227613","72031935","2025-10-01 11:25:08","HPC Other Issue: Matlab open dap not working","Hello [USER], Okay, I will close this ticket, but in the meantime, we have this information noted down on our end. Feel free to re-open this ticket once you decide to look into again. Best regards, [STAFF]"
"3227923","70482249","2025-07-22 18:00:02","HPC User Account: [USER] in cybertrn","I created the user account [USER], who is a member of cybertrn and pi_[STAFF] (cybertrn is primary group).  Have a nice day! -- Kind regards, [STAFF]. On Tue Jul 22 11:46:24 2025, [STAFF] wrote: Dear [STAFF], And this is crazy, we have an 8th student, who I was only told about last night. Please add user rkadisi1 as soon as you can. I am really sorry about this crazy timing; I had tried to fend this off months ago by demanding that they close registration on (past) Wednesday. Matthias. On Mon, Jul 21, 2025 at 12:56 PM [STAFF] via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_[ID]&customeremail=[EMAIL]&groupid=EIS&ticketid=3227923&ticketowner=[STAFF]&ticketsubject=HPC User Account: [STAFF] in cybertrn. If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3227923>. Thank You. _______________________________________. Resolution: = = = = = = = = = = = = = = = = = = No problem! -- Best regards, [STAFF]. Original Request: Requestors: [STAFF]. First Name: Matthias Last Name: Gobbert Email: [EMAIL] Campus ID: [ID]. Request Type: High Performance Cluster. Create/Modify account in existing PI group Existing PI Email: [EMAIL] Existing Group: cybertrn Project Title: SEA Parallel Programming 2025 Project Abstract: Summer Enrichment Academy (SEA) on Parallel Programming in Summer 2025, Mon-Fri July 21-25, 2025, 01-04pm. Hi, I communicated with Roy, and we agreed on the following being a sensible setup. I do not have everyone's username, yet, but let's get started with these 4. There should be an additional 3. I know, it is awkward that I do not have all 7 at this point. The program starts this Monday, July 21, at 01pm, so I hope you can create the 4 accounts today (Friday) and I can send you the remaining ones on Monday morning. Please put these into the cybertrn group as primary, then add them as secondary group to pi_[STAFF]. bdubucl1, mdubucl1, ayank1, greeshm2. Thank you, [STAFF]."
"3228180","70449559","2025-07-21 18:45:59","HPC Other Issue: /asl is mounted on c24-52 but not on chip","I've created the /asl symlink on the chip login node, and I double-checked other nodes in the cluster to verify it existed there too. We won't change the symbolic link without first notifying you and your group of any changes that need made. Let me know if you have any questions or run into any more issues. Best, [STAFF] On Mon Jul 21 13:02:40 2025, [USER] wrote: Hi [STAFF], OK that's fine/ But please don't change this moving forward, else I'll forever keep needing to scratch my head about 'odd, this worked two weeks ago' -[USER] On Mon, Jul 21, 2025 at 10:24 AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=32XXXX> Last Update From Ticket: Hello [USER], Instead of removing the symlink from c24-52, would it be okay for me to create the symlink on the Chip login node? This way would also make the environments consistent for you. The reason I'm asking is because with the way we have our nodes setup, we can't remove the symlink from just a single node without removing that symlink for the entire CPU 2024 partition. And I feel removing that symlink across the cluster would be a bit too disruptive of a change to make at this time. Best, [STAFF] On Fri Jul 18 16:27:45 2025, [USER] wrote: > First Name: [USER] > Last Name: [USER] > Email: [EMAIL] > Campus ID: [USER] > Request Type: High Performance Cluster > Can you remove it from c24-2 because I'm beginning to get so confused, seeing it on our machine but not on chip headnode [USER@chip ~]$ ls /asl ls: cannot access '/asl': No such file or directory [USER@c24-52 ~]$ ls /asl airs cris data ftp iasi iasi2 iasi3 isilon leroy leroy_downloads matlab2012 matlib models n20 n21 oco2 packages rtp s1 s2 stats users val www xfs3"
"3228856","70529495","2025-07-24 19:33:10","New [USER] accounts on knacc1 and knacc2 servers","The following users have been added to both machines in the general rpc group and added as sudoers to the machines. [USER] ([USER]). [STAFF] ([STAFF]). [USER] ([USER]). -- [STAFF] DoIT Research Computing Team"
"3229068","70521865","2025-07-24 15:28:39","HPC Other Issue: Assistance Request: Accessing JupyterHub on UMBC HPC","Hello HPC Team Thank you for your clarification This is very helpful Kind regards On Thu Jul 24 2025 at 10=17 AM [STAFF] via RT [EMAIL] wrote Ticket Last Update From Ticket Hi [USER] Following up on this since you haven=t responded I incorrectly wrote that we don*t have a way of self-hosting jupyter notebooks when I meant we do Hopefully that was understood from the link to the documentation I sent In any case I=ll leave this open until end of business today to see if you still have any questions On Mon Jul 21 08=59=36 2025 [STAFF] wrote Hi [USER] We don=t have a JupyterHub system available at the moment but we do have a way of self-hosting jupyter notebooks This can be found in our documentation here https=//umbc atlassian net/wiki/spaces/faq/pages/1104805915/How+do+I+run+a+new+jupyter+notebook+on+chip Let me know if you have any trouble getting this going On Sun Jul 20 23=24=48 2025 [USER] wrote First Name [USER] Last Name [USER] Email [EMAIL] Campus ID [USER] Request Type High Performance Cluster Hello HPC Support Team I hope this message finds you well I am a PhD student at UMBC and I would like to inquire about how to access and use JupyterHub on the UMBC High-Performance Computing HPC environment Could you kindly provide guidance on the following Whether JupyterHub is supported on the UMBC HPC system If yes what is the correct URL or portal for access Are there any prerequisites or modules I need to load beforehand Any steps or best practices for launching notebooks or managing resources via JupyterHub Your assistance would be greatly appreciated as this would greatly support my workflow for scientific computing and data analysis Kind regards [USER] PhD Student UMBC Best [STAFF] DOIT Unix Infra Student Worker"
"3229182","70517777","2025-07-24 13:39:14","HPC Other Issue: how many processors can I get on cpu2024","Yep, no worries. Have a good one! [STAFF]"
"3229565","70456879","2025-07-22 03:04:18","HPC Slurm/Software Issue: Unable to connect to server through vscode remote SSH","The issue is resolved. You can close the ticket. On Mon, Jul 21, 2025 at 3:21 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=[ID] > Last Update From Ticket: Hello [USER], Could you please try this for the VS Code issue? https://[DOMAIN].atlassian.net/wiki/spaces/faq/pages/[PAGE_ID]/Why+is+vscode+not+connecting+to+[SERVER] If that still does not work, please feel free to make an appointment with us here: https://hpcf.[DOMAIN]/help/office-hours/ Or you can meet us tomorrow (Tuesday) at room [ROOM], 1-2 pm. Please let me know if the above instructions work for you or not. Best, [STAFF] On Mon Jul 21 13:17:07 2025, [USER] wrote: First Name:                [USER] Last Name:                 [LAST_NAME] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] Request Type:              High Performance Cluster Hi, I am trying to connect to remote server through vscode remote SSH extension. The extension failed to connect to the server, so I removed the .vscode-server dir from the server through the terminal (connecting to the server through terminal works fine). I uninstalled the remote SSH extension from my local pc. I am still having issues connecting to the remote server through vs code. Please let me know what else I can do to resolve this issue. Thanks."
"3229646","70453516","2025-07-21 20:12:43","HPC Other Issue: How to use DUO to log in to chip","You can close this ticket. I think we figured it out. Naturally, I do not recall such things since I set it up years ago. [STAFF] [EMAIL] On Mon Jul 21 2025 at 2:03 PM via RT wrote Greetings This message has been automatically generated in response to the creation of a ticket regarding Subject HPC Other Issue How to use DUO to log in to chip Message First Name [USER] Last Name [STAFF] Email [EMAIL] Campus ID [CID] Request Type High Performance Cluster Hi I assumed that the participants in the SEA with the brand new accounts could log in without using DUO What is really needed As low as possible as an approach Do they need to activate DUO How long does it take to be able to log in after that Minutes [STAFF]"
"3229819","70797023","2025-08-08 14:05:53","Migrating [USER] over to ceph","Good morning [STAFF], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly, albeit a bit longer than initially expected. There are a few things to note: The path has changed, and is available under /umbc/rs/[USER]. The aliases used to reach the volume are now pi_[USER]_common and pi_[USER]_user. The new volume has a 25TB quota. When you have a chance, could you try running some jobs using the new volume to verify everything looks good? I apologize for any inconvenience the extended length of this migration may have caused. Best, [STAFF]. On Thu Aug 07 17:02:27 2025, [EMAIL] wrote: Got it, thanks for the update. - [USER]. On Thu, 7 Aug 2025, [STAFF] via RT wrote: Ticket Last Update From Ticket: Hey [USER], I hope this message finds you well. I apologize the migration is currently still running. There were some complications happening last night and this morning that ended up delaying this process. It looks like this migration will be completed sometime tonight. We will ensure that this update is provided once complete. -- Best regards, [STAFF]."
"3230084","70840671","2025-08-11 19:00:26","HPC Slurm/Software Issue: Unable to request the required resources for array job","Hi [USER], Apologies for the no-response. I will reach out again if I need any help regarding this, but I am set for now. Thank you. On Mon Jul 28 09:13:04 2025, [STAFF] wrote: Hey [USER], Just wanted to check in if you still needed support on this? -- Best regards, [STAFF]"
"3230085","70840599","2025-08-11 18:58:09","HPC Slurm/Software Issue: Jobs were terminated with no explanation","The system wasn't supposed to use CPU instead of CUDA. And it's alright, I don't need any more support/help on this anymore. Thanks a lot for looking into it. On Tue Jul 29 11:58:40 2025, [STAFF] wrote: Hi [USER], I haven't seen any update on this ticket in a few days, could you please let us know if the information [STAFF] was able to provide resolved your issue? On Tue Jul 22 08:52:19 2025, [STAFF] wrote: Hi [USER], It might be helpful if you could include the slurm submission script. As you mentioned, the error doesn't give a ton of info, but it does say specifically that it failed at line 42 of the slurm script. Maybe something to do with the python file that it tried to run. I do notice in the error files it seems to say that gpu CUDA devices weren't initialized properly and that it was attempting to use cpu devices. Was that expected? At the very least I can say that they failed with exit code 9, which seems to signal that it ran out of memory, and was killed by slurm that way. [root@chip-mgt1 ~]$ sacct -j 81405_5 --cluster=chip-gpu --format=JobID,User,Partition,State,ExitCode,Start,End,Elapsed,NodeList JobID User Partition State ExitCode Start End Elapsed NodeList ------------ --------- ---------- ---------- -------- ------------------- ------------------- ---------- --------------- 81405_5 [USER] gpu FAILED 9:0 2025-07-20T15:14:05 2025-07-20T15:19:23 00:05:18 g20-12 81405_5.bat+ gpu FAILED 9:0 2025-07-20T15:14:05 2025-07-20T15:19:23 00:05:18 g20-12 81405_5.ext+ gpu COMPLETED 0:0 2025-07-20T15:14:05 2025-07-20T15:19:23 00:05:18 g20-12 [root@chip-mgt1 ~]$ sacct -j 81405_6 --cluster=chip-gpu --format=JobID,User,Partition,State,ExitCode,Start,End,Elapsed,NodeList JobID User Partition State ExitCode Start End Elapsed NodeList ------------ --------- ---------- ---------- -------- ------------------- ------------------- ---------- --------------- 81405_6 [USER] gpu FAILED 9:0 2025-07-20T15:14:05 2025-07-20T15:18:57 00:04:52 g20-12 81405_6.bat+ gpu FAILED 9:0 2025-07-20T15:14:05 2025-07-20T15:18:57 00:04:52 g20-12 81405_6.ext+ gpu COMPLETED 0:0 2025-07-20T15:14:05 2025-07-20T15:18:57 00:04:52 g20-12 On Tue Jul 22 00:34:50 2025, [STAFF] wrote: As shown in the error, it only says the job was killed. No clue why. On Tue Jul 22 00:32:59 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USER] Request Type: High Performance Cluster Two of my jobs from an array job were unexpectedly stopped. I have attached the error log file. The main line of interest is: /cm/local/apps/slurm/var/spool/job81411/slurm_script: line 42: 1438310 Killed python /umbc/ada/oates/users/[USER]/Thesis_Work/UNetSeg_PyTorch/kits_optuna_train_multiloss.py -pl=True -e=80 -b=20 -th=${th[$SLURM_ARRAY_TASK_ID]} -j=$concatenated_id -m=${md[$SLURM_ARRAY_TASK_ID]} Attachment 1: output_81405_5.err Attachment 2: output_81405_6.err"
"3230399","70594960","2025-07-29 15:57:04","HPC Other Issue: Jupyter notebook not recognizing python venv on chip","I haven't seen any update on this ticket in a few days, so I'll mark it as resolved. On Wed Jul 23 09:52:20 2025, [STAFF] wrote: Hi [USER], The error reported '/umbc/rs/pi_slaha/users/[USER]/test/astro/bin/python: bad interpreter: No such file or directory' is the underlying issue. It's entirely possible that the migration to new storage has broken your pipeline. The easiest thing to do here would be to delete the virtual environment and recreate it in the new volume. Otherwise, you can try to find where everything lives and move things back into place. Happy to discuss this afternoon. On Tue Jul 22 11:18:18 2025, [STAFF] wrote: First Name: [USER] Last Name: [LAST NAME] Email: [EMAIL] Campus ID: [CAMPUS ID] Request Type: High Performance Cluster Hi, I have been trying to run my scripts on the python virtual environment 'astro' in a jupyter notebook on the chip cluster. When I log in to jupyter notebook on the cluster using the sbatch slurm script, the kernel corresponding to the same virtual environment is not showing up. This venv was created more than two weeks ago in /umbc/rs/pi_slaha/users/[USER]/test/astro and this have never happened before. Before submitting the sbatch job for the jupyter notebook from inside /umbc/rs/pi_slaha/users/[USER]/astrophysics-anom_det (which is my project folder), I tried this link: https://umbc.atlassian.net/wiki/spaces/faq/pages/1104805915/How+do+I+run+a+new+jupyter+notebook+on+chip#How-do-I-make-sure-jupyter-is-aware-of-my-virtual-environments%3F to ensure that jupypter is aware of my environment. The first issue was: (astro) [USER]@chip astrophysics-anom_det]$ python -m ipykernel install --user --name astro /usr/bin/python: No module named ipykernel Hence, I tried to install ipykernel using pip: (astro) [USER]@chip astrophysics-anom_det]$ pip install ipykernel -bash: /umbc/rs/pi_slaha/users/[USER]/test/astro/bin/pip: /umbc/rs/pi_slaha/users/[USER]/test/astro/bin/python: bad interpreter: No such file or directory and got the above error. I have not seen this before. Does this have anything to do with the fact that [STAFF]'s research volume storage was increased and hence the path to certain directories and symbolic links were changed? Please help. I am attaching a copy of the jupyter.slurm file and the screenshot of the contents of the folder which has the symbolic links in red (/umbc/rs/pi_slaha/users/[USER]/test/astro/bin/python) Thank you. Regards, [USER] Attachment 1: jupyter.slurm Attachment 2: Screenshot 2025-07-22 111448.png"
"3230574","70490660","2025-07-22 22:17:54","Request to Install NVIDIA HPC SDK (nvhpc)","Thanks for submitting this ticket. Neither of us did our due-dilligence checking for the nvhpc module that was already installed! Please have [USER] load `NVHPC/22.7-CUDA-11.7.0` and try to build their program again. I'll resolve this for now. We can reopen if we need a newer version. On Tue Jul 22 13:54:47 2025, [STAFF] wrote: Requesting that for a student install the NVIDIA HPC SDK (`nvhpc`) on the cluster to support building the gRASPA molecular simulation software. The compilation instructions for gRASPA rely on the `nvc++` compiler, which is included with the `nvhpc` suite. The relevant build guide can be found here for reference: https://github.com/snurr-group/gRASPA/blob/main/Cluster-Setup/NERSC/NVC_COMPILE_NERSC On Tue Jul 22 13:46:35 2025, [STAFF] wrote: I would like to request the installation of the NVIDIA HPC SDK (`nvhpc`) on the system. This installation should include support for `nvc++` as well. Thank you. Best, [STAFF]"
"3230762","70488375","2025-07-22 20:02:44","HPC Other Issue: Missing Intel C Compiler (icc) in intel/2024a Environment - WRF Build Issue","Hi [STAFF], I wouldn't expect any software to work on the taki cluster ;) On the chip cluster, and with the newer intel compiler toolchains, you'll need to use `icx` instead of `icc`. https://www.intel.com/content/www/us/en/developer/articles/guide/porting-guide-for-icc-users-to-dpcpp-or-icx.html I'll mark this as resolved. -- Roy Prouty DoIT Research Computing Team"
"3230837","70490631","2025-07-22 22:15:33","HPC Other Issue: Cannot login to chip.umbc.edu","Hi [USER], Thanks for bringing this to our attention! There was a momentary issue with the login service. I've reset it and can now login as normal. We'll put some checks in place tomorrow morning to avoid this in the future. I'll mark this as resolved for now, but please let me know if you encounter this issue again. -- [STAFF]"
"3230893","71313268","2025-08-28 18:11:35","HPC Slurm/Software Issue: MATLAB jobs disappearing or finishing with no output","I ran several jobs after that with the same algorithm but I did not notice this issue anymore. So I believe it was probably a brief instability.  Best [STAFF]    On Fri Aug 22 2025 at 4:02PM [STAFF] via RT <[EMAIL]> wrote:  Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=[ID]> Last Update From Ticket: Hi [USER] What is the current status of your issue? If you have any further questions or concerns please let us know.  Best [STAFF]    On Wed Jul 22 2025 at 11:47PM [USER] wrote:  First Name: [FIRST NAME] Last Name: [LAST NAME] Email: [EMAIL] Campus ID: [CAMPUS ID] Request Type: High Performance Cluster Good evening I have been experiencing issues with some MATLAB jobs disappearing and finishing with no output. In one case I ran 20 jobs at the same time 10 started running and 10 stayed in the queue. From the first 10 1 disappeared and the rest finished after 8~9 hours with no error but also no .mat files were saved in the location indicated by the code. From the latter 10 1 I decided to terminate due to the time limit and the other 9 finished after 2 days running. In this case I was able to recover the .mat files saved in the correct location. Another issue that I noticed is that when I used the code below to run another batch of 20 jobs the third one disappeared completely from the queue list and shows no .err/.out files. I am attaching the log files to this ticket. #!/bin/bash for k in {1..20} do name='ebm_Chicago_subset_${k}' sbatch --job-name='${name}' --export=k=${k} --output='${PWD}/Logs/${name}.out' --error='${PWD}/Logs/${name}.err' 'sub_tuning.sbatch' done Best [USER] Attachment 1: Logs_ditf_lambda017.zip Attachment 2: Logs_ebm_Chicago_subset.zip"
"3231189","70576350","2025-07-28 18:08:19","HPC Other Issue: location of the icx and ifort","Ticket [NUMBER] Comment just added. [STAFF] in the future, for tickets like this where we are like -- 100 % sure they just didnt do something basic (like load a module) , you should just mark it as resolved when adding your first reply. and if they for some reason cannot figure that out and reply/reopen the ticket, we can address it then On Mon Jul [DAY] [TIME] [YEAR], [STAFF] wrote: Hello [USER], I hope this message finds you well. I am reaching out if you are continuing to experience issues moving forward? best regards, [STAFF]"
"3231383","70510069","2025-07-23 19:38:04","HPC User Account: [USER] in Student Group","Unfortunately, I am unable to create an account for you at this moment. We no longer add users to the 'student' group, all users need to be affiliated with a PI, who is generally the faculty member you are working under for your research. Your PI also needs to already have their own group (or needs to create a new group) on chip. Then, you can create an account under their group. If you have any questions, feel free to let me know. I'll close this ticket for now though. Have a nice day! First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Create/Modify account in Student group Can you please help me get access to the GPUs on chip? I am a Ph.D. student working in the CSEE department, and I need to run some computations. Thank you!"
"3231432","70551551","2025-07-25 20:26:41","HPC User Account: [USER] in CARTA_345","I have created users accounts for [USER], [USER], [USER], [USER] under pi_halem on the chip cluster. Please look at the Getting Started on chip page on our wiki, it contains lots of helpful information for new users. Here is the link: https://umbc.atlassian.net/wiki/x/R4BPQg Additionally, it appears there is another user, [USER], attempting to request an account under pi_halem in another RT ticket. Please provide approval in that RT ticket (you are CC'd on it) to add that user. Each user will need a simple 'i approve' written approval for each account request. In the future, please also include project descriptions/abstracts for each user with your request. On Thu Jul 24 17:29:49 2025, [STAFF] wrote: Here is a list of students that needs an account under PI [USER]: [USER] <[EMAIL]> [USER] <[EMAIL]> [USER] <[EMAIL]> [USER] <[EMAIL]> On Thu, Jul 24, 2025 at 5:26 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3231432> Last Update From Ticket: Hi [USER], It appears Dr. [USER] already has an existing PI group on chip. It looks like it is an older group, transferred from previous hpc clusters. The only user in the group is '[USER]'. But I can still use this existing group, I still need written confirmation from Dr. [USER] to create the accounts. Once I get that, I can create an account for you. On Wed Jul 23 15:50:14 2025, [STAFF] wrote: > First Name: [USER] > Last Name: [USER] > Email: [EMAIL] > Campus ID: [USER_ID] > Request Type: High Performance Cluster > Create/Modify account in existing PI group > Existing PI Email: [EMAIL] > Existing Group: CARTA_345 > Project Title: DUNE2: A Physics-Informed Deep Learning Model for High-Resolution, Long-Lead ENSO Forecasting > Project Abstract: The El Niño–Southern Oscillation (ENSO) significantly impacts global weather and climate-related risks, but its long-range prediction remains difficult due to complex dynamics and limited model resolution. This project introduces DUNE2, a high-resolution deep learning framework for weekly ENSO forecasting up to 12 months ahead. Building on the previous DUNE model, DUNE2 incorporates physics-informed inputs—such as wind divergence, moisture flux, and sensible heat flux—and a spatiotemporal attention mechanism inspired by video transformers. Using only high-resolution atmospheric data from ERA5, DUNE2 avoids reliance on coupled ocean models, aiming for improved accuracy, interpretability, and early detection of ENSO events. Its performance will be benchmarked against both deep learning and traditional dynamical models across key Niño regions using standard forecast metrics. > It's a new account. My advisor and PI ([STAFF]) is not on the system yet. Can you please create a new account for him? Please let me know if you need anything else from my end. Thank you!"
"3231503","70512923","2025-07-23 23:50:52","HPC Other Issue: Cannot complete tensorflow[and-cuda] installation into new python venv; no output from inside a python venv when detecting GPUs","I was able to follow these steps and successfully connect to tensorflow. Please perform the same actions with the only replacement being the research volume and report back. [STAFF]$ srun -M chip-gpu --time=100 --mem=5000 --gres=gpu:1 --pty $SHELL srun: job queued and waiting for resources srun: job has been allocated resources (2024.02-1) [USER@SERVER ~]$ conda deactivate [USER@SERVER ~]$ module list Currently Loaded Modules: 1) slurm/chip-gpu/23.11.4 2) git/2.33.1 3) shared 4) DefaultModules 5) hpc_tools/hpc_tools [USER@SERVER ~]$ which python /usr/bin/python [USER@SERVER ~]$ module avail python ----------------------------------------------- Core & Custom Modules ------------------------------------------------ python/3.12.4 python3 python39 ------------------------------------------ For use on 2020 & 2024 Machines ------------------------------------------- IPython/8.17.2-GCCcore-13.2.0 Python/3.10.4-GCCcore-11.3.0-bare Python-bundle-PyPI/2023.06-GCCcore-12.3.0 Python/3.11.3-GCCcore-12.3.0 Python-bundle-PyPI/2023.10-GCCcore-13.2.0 (D) Python/3.11.5-GCCcore-13.2.0 Python/2.7.18-GCCcore-12.3.0 Python/3.12.3-GCCcore-13.3.0 (D) Python/3.9.6-GCCcore-11.2.0-bare meson-python/0.15.0-GCCcore-13.2.0 Python/3.9.6-GCCcore-11.2.0 wxPython/4.2.0-foss-2021b Where: D: Default Module Module defaults are chosen based on Find First Rules due to Name/Version/Version modules found in the module tree. See https://lmod.readthedocs.io/en/latest/060_locating.html for details. Use 'module spider' to find all possible modules and extensions. Use 'module keyword key1 key2 ...' to search for all possible modules matching any of the 'keys'. [USER@SERVER ~]$ module load Python/3.9.6-GCCcore-11.2.0 [USER@SERVER ~]$ python -V Python 3.9.6 [USER@SERVER ~]$ python -m venv /umbc/rs/doit/users/[USER]/rb_test [USER@SERVER ~]$ source /umbc/rs/doit/users/[USER]/rb_test/bin/activate (rb_test) [USER@SERVER ~]$ python -V Python 3.9.6 (rb_test) [USER@SERVER ~]$ pip install tensorflow[and-cuda] <[long output; successful install]> (rb_test) [USER@SERVER ~]$ python -c 'import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))' 2025-07-23 19:48:34.617274: I tensorflow/core/util/port.cc:153 oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2025-07-23 19:48:38.848857: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467 Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered WARNING: All log messages before absl::InitializeLog() is called are written to STDERR E0000 00:00:1753314519.874486 2525531 cuda_dnn.cc:8579 Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered E0000 00:00:1753314520.295634 2525531 cuda_blas.cc:1407 Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered W0000 00:00:1753314524.521590 2525531 computation_placer.cc:177 computation placer already registered. Please check linkage and avoid linking the same target more than once. W0000 00:00:1753314524.521635 2525531 computation_placer.cc:177 computation placer already registered. Please check linkage and avoid linking the same target more than once. W0000 00:00:1753314524.521639 2525531 computation_placer.cc:177 computation placer already registered. Please check linkage and avoid linking the same target more than once. W0000 00:00:1753314524.521643 2525531 computation_placer.cc:177 computation placer already registered. Please check linkage and avoid linking the same target more than once. 2025-07-23 19:48:44.803791: I tensorflow/core/platform/cpu_feature_guard.cc:210 This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations. To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags. [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
"3231551","70584040","2025-07-28 23:54:03","HPC User Account: [USER] in Student Group","Hi [STAFF], I do approve [USER] having access to chip for his processing of Landsat and Sentinel 2 burnt area observations. Thanks for your help. [STAFF] On 7/28/25 11:03 AM, [STAFF] via RT wrote: Ticket Last Update From Ticket: Hi [USER], Before you can create an account on chip, you need approval from your PI. I have already discussed this with your PI in a separate ticket chain, since they have had already requested multiple new users. I specifically mentioned that there is a separate ticket, for [USER], that also needs approval. As previously communicated to your PI, all I need is a quick 'I approve', replied to this ticket chain to create your account. This process is also outlined on our wiki: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip#Requesting-a-User-Account-on-chip Kind regards, [STAFF] DoIT Unix Infra Student Worker On Mon Jul 28 10:41:15 2025, [USER] wrote: To whom it may concern, I am writing to check on the account creation progress. I have submitted the ticket for several days and have not heard back. I just want to make sure everything is alright and if there is anything needed on my end. Best,[USER] On Thu, Jul 24, 2025 at 8:41 AM via RT wrote: Greetings, This message has been automatically generated in response to the creation of a ticket regarding: Subject: 'HPC User Account: [USER] in Student Group' Message: First Name: [USER] Last Name: [USER] Email:[EMAIL] Campus ID: [ID] Request Type: High Performance Cluster Create/Modify account in Student group To whom it may concern, My name is [USER], currently a research assistant at CARTA Lab. I would like to request my user account creation on the high performance cluster. We are training a deep learning model that requires access GPU for efficient model training. To facilitate the account creation process, please let me know if you require any specific information. I can provide: - Name: [USER] - Department: CSEE - Lab: CARTA Lab - Project Name: Near real-time validation of WDT - PI: Dr.[STAFF] - Mentor: Dr.[STAFF] Thank you,[USER]"
"3231726","70530233","2025-07-24 19:50:31","HPC Slurm/Software Issue: HPC Storage Issue","Hi [USER], For future reference, please do not come by our office without prior discussion or an appointment. If you would like to schedule an appointment with us, you can do so from our website: https://hpcf.[DOMAIN]/help/office-hours/. Additionally, in the future, we strongly recommend contacting us via an RT ticket before scheduling office hours. Most issues can be solved without an in-person meeting. When submitting RT tickets to us, please include all relevant information regarding the problem you are facing, ie: what commands you are running, what you are attempting to accomplish, screenshots of any error messages, etc. You said you are receiving a 'Not enough storage' error. Another resource that we strongly recommend you check out before submitting RT tickets is our wiki, which also includes answers and steps to solve many common issues, especially issues such as 'Not enough storage'. After taking a look at your user account on [SERVER], I can see the issue stems from your home directory being completely full. This can happen when programs, such as python/pip, attempt to write to hidden folders (folders appended with . periods). If you run the command 'df -h ~', you can see your home directory is 100% full. Now, if you run 'du -sh ~/.cache/', you can see the size of the ~/.cache folder in your home directory. Currently, this folder is taking up all available space in your home directory. So, you need to move this folder to your research volume, then create a symbolic link to point to the new location of the folder. The steps for this are outlined on our wiki, but I will include the exact commands here: https://[DOMAIN].atlassian.net/wiki/spaces/faq/pages/[PAGEID]/What+to+do+if+I+run+out+of+space+in+my+[SERVER]+home+directory. First, move the offending folder 'mv ~/.cache /[DIRECTORY]/.cache'. Create symbolic link 'ln -s /[DIRECTORY]/.cache ~/.cache'. This should then free up space in your home directory and allow you to continue running your code. If you run into any issues with the above steps, let me know. Kind regards, [STAFF]"
"3232111","70593365","2025-07-29 15:22:38","HPC Other Issue: Need help on chip","user submitted a separate ticket, addressed issue, i will close this one On Fri Jul 25 13:06:20 2025, [STAFF] wrote Hello, I am able to run ollama server on one gpu. However I would require another terminal window for the same gpu to execute the code. How can I split the access to the same gpu such that on one the code is running and on the other the server is running Regards,[USER] On Fri, Jul 25, 2025 at 7:13 AM [STAFF] via RT [EMAIL] wrote If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey https//umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3232111&ticketowner=[EMAIL]&ticketsubject=HPC Other Issue Need help on chip If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note A full record of your request can be found at Ticket https//rt.umbc.edu/Ticket/Display.html?id=3232111 Thank You _________________________________________ R e s o l u t i o n Hi [USER], Ollama is already installed on the cluster as a module. See below [root@chip-mgt1 ~]$ module avail ollama ------------------------------------------------------------ Core & Custom Modules ------------------------------------------------------------ ollama/0.6.5 You can find more information about how to search and load modules here https//umbc.atlassian.net/wiki/spaces/faq/pages/1032880207/Available+Software+and+Packages On Thu Jul 24 17:58:08 2025, [STAFF] wrote First Name [USER] Last Name [USER] Email [EMAIL] Campus ID [ID] Request Type High Performance Cluster Hello, I am trying to install ollama on chip using the curl command but it asks me for a password which is not the one used by me. Please help. gemma-scope [ndas2@g24-08 ndas2]$ curl -fsSL https//ollama.com/install.sh | sh Installing ollama to /usr/local We trust you have received the usual lecture from the local System Administrator. It usually boils down to these three things #1) Respect the privacy of others. #2) Think before you type. #3) With great power comes great responsibility. [sudo] password for ndas2 Best,[STAFF] DOIT Unix Infra Student Worker ______________________________________ Original Request Requestors [USER] First Name [USER] Last Name [USER] Email [EMAIL] Campus ID [ID] Request Type High Performance Cluster Hello, I am trying to install ollama on chip using the curl command but it asks me for a password which is not the one used by me. Please help. gemma-scope [ndas2@g24-08 ndas2]$ curl -fsSL https//ollama.com/install.sh | sh Installing ollama to /usr/local We trust you have received the usual lecture from the local System Administrator. It usually boils down to these three things #1) Respect the privacy of others. #2) Think before you type. #3) With great power comes great responsibility. [sudo] password for ndas2"
"3232359","70583650","2025-07-28 22:12:05","HPC Other Issue: BLAS and LAPACK for ifort","Great thanks [STAFF]! That worked!  [USER] Sent from my iPhone  On Jul 25, 2025, at 10:47 AM, [STAFF] via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://www.google.com/url?q=https://umbc.us2.qualtrics.com/SE/?SID%3DSV_etfDUq3MTISF6Ly%26customeremail%3D[EMAIL]%26groupid%3DEIS%26ticketid%3D3232359%26ticketowner%3D[STAFF]%26ticketsubject%3DHPC%20Other%20Issue%3ABLAS%20and%20LAPACK%20for%20ifort If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket <URL: https://www.google.com/url?q=https://rt.umbc.edu/Ticket/Display.html?id%3D3232359&source=gmail-imap> Thank You Hi [USER], For using BLAS and LAPACK with Intel compilers, please use the Intel Math Kernel Library (imkl), which includes optimized for intel compilers, and it includes functions such as BLAS, LAPACK, ScaLAPACK, Sparse Solvers, Fast Fourier Transformations, Vector Math, etc. Please check out intels website for more information about imkl: https://www.google.com/url?q=https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html&source=gmail-imap This module is already available on chip, you can load it with 'module load imkl' Kind regards, [STAFF] On Fri Jul 25 10:04:45 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] Request Type:              High Performance Cluster Hi, I was wondering if you can make modules for the above two using ifort? Module spider showed me many gcc versions I am using >>> /usr/ebuild/installs/software/intel-compilers/2023.1.0/compiler/2023.1.0/linux/bin/intel64/ifort -[USER] Original Request: Requestors: [USER] First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] Request Type:              High Performance Cluster Hi, I was wondering if you can make modules for the above two using ifort? Module spider showed me many gcc versions I am using  /usr/ebuild/installs/software/intel-compilers/2023.1.0/compiler/2023.1.0/linux/bin/intel64/ifort -[USER]"
"3232485","70901457","2025-08-13 20:17:36","HPC Slurm/Software Issue: Error 0:53 for submitting slurm job","Hi [USER], We have discovered why this error was occurring in the first place, and as of last week it has been resolved. There was an issue with the research volumes that caused the mounts to break, and when you attempt to submit a job that uses the research volume with a broken mount, it instantly fails because it cannot access the location. At the time of the error, the pi_donengel volume must have been mounted on some specific nodes, but not all nodes. Which is why some of the nodes work, and others did not. Since the issue has been resolved, I will go ahead and close this ticket. If you run into further issues, please feel free to submit a new ticket! Have a nice day! On Mon Jul 28 15:41:17 2025, [STAFF] wrote: Hi [USER], That is quite interesting. I am wondering if they are only failing on a specific type of GPU node or something along those lines. Do you know which nodes those failed jobs ran on, and what node the job that succeeded ran on? That could help narrow down the issue. Additionally, for further testing, you can attempt to explicitly limit which type of GPU is being used with the --constraint flag in your SBATCH file. This wiki page has some more information on the syntax and available options for using '#SBATCH --constraint=$GPU' in your code: https://umbc.atlassian.net/wiki/spaces/faq/pages/1321664513/How+do+I+request+GPU+memory On Mon Jul 28 08:55:36 2025, [USER] wrote: Weirdly, if I try submitting a bunch of jobs at once, roughly ~1/6 of them run. For example, I have a script called many_attempts.sh and it consists of sbatch runpygpu_chip.sh rom_import.py ... And usually one or two of them actually run as normal. On Fri, Jul 25, 2025 at 3:25 PM [USER] wrote: Unfortunately that did not solve the problem. Same issue as last time. On Fri, Jul 25, 2025 at 1:06 PM [STAFF] via RT wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=323485 Last Update From Ticket: Hi [USER], It looks like your home directory is completely full, and has no free storage space left. Because your home directory is full, it might cause some programs that need to write to that location to fail. We believe that this could be why your jobs are failing. So we recommend you follow the steps outlined on our wiki to resolve this. If you run 'du -sh ~/.gradle', you can see the .gradle directory in your home directory takes up 1.2GB of space. To resolve this, you need to move the directory to your research volume, then create symbolic links pointing to the new location (like you have for .local and .cache already). The steps are outlined in the wiki page above. Here is the link to our wiki page with the commands you need: https://umbc.atlassian.net/wiki/spaces/faq/pages/1118765095/What+to+do+if+I+run+out+of+space+in+my+chip+home+directory Once you free up space, attempt to rerun your code. Let us know if it works! On Fri Jul 25 11:47:28 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Cluster I am working in this directory '/umbc/rs/pi_donengel/users/[USER]/doom' And ran this command: 'sbatch runpygpu_chip.sh rom_import.py' The files are also on GH: https://github.com/[USER]/doom/blob/main/rom_import.py https://github.com/[USER]/doom/blob/main/runpygpu_chip.sh And nothing happened, other than printing to the console 'Submitted batch job 83765' I tried 'sacct -u [USER] --format=JobID,JobName,Partition,AllocCPUs,State,ExitCode' and the result was: 83765 runpygpu_+ gpu 2 FAILED 0:53"
"3232702","70613721","2025-07-30 14:33:02","HPC Slurm/Software Issue: Slurm 'CUDA devices are busy or unavailable' error","Yes, that is the exact node having the issues we are currently working on resolving. In the meantime all other nodes on RTX_6000 are working fine for you to run your job. Feel free to include a ticket if you ever run into an issue like this again. Best regards, [STAFF]"
"3232760","70575625","2025-07-28 17:50:33","Global Protect not working","Hi [USER], Could you confirm if you have a different browser profile for your personal account and UMBC accounts? We have also recently discovered, that sometimes with the Global Protect app, if the last browser profile you have used/opened was your personal account, it can sometimes mix up your identities and not work. To work around this, we recommend that first, you close any personal browser sessions, then, clear your browsers cache/cookies, then open your UMBC browser profile. Now, when attempting to connect with Global Protect, it should hopefully attempt to open the authentication page in your UMBC browser session. Also, can you confirm how you downloaded the application? Was it from the App Store or downloaded from the links in our wiki page? Also, can you confirm if you have followed all necessary steps to ensure the application has the correct security permissions? In MacOS, apps often need explicit permissions to properly run. You can find this information on our wiki page: https://umbc.atlassian.net/wiki/spaces/faq/pages/30754220/Getting+Connected+with+the+UMBC+GlobalProtect+VPN Look under the 'macOS Security Note' section to see steps to ensure the application has proper authorization. Let me know if these steps work for you! Thanks for following up! I’m currently using a MacBook Air (macOS), and I’ve just updated to the latest version of GlobalProtect after uninstalling the previous one completely. Yes, I’ve set the portal to gpvpn.umbc.edu in the GlobalProtect app settings I made sure it doesn’t include https:// or any slashes. I reached the UMBC login page when trying to connect. It shows an error saying “Missing parameters” right after hitting connect. Let me know if there’s anything else I should check or try! Can you confirm what type of device you are attempting to use Global Protect on? Can you also confirm that you have updated to the latest version? Additionally, can you confirm that you have correctly configured the portal settings in the global protect app? If you navigate to the settings inside the app, you should see “Portal”, and you should have already set this value to ‘gpvpn.umbc.edu’. Can you also confirm if you were getting to the UMBC login page when trying to connect? This will help me understand what is going on. Yes I am attaching the screenshot here. Can you help me fix it asap? On Fri, Jul 25, 2025 at 4:57 PM [STAFF] via RT <[EMAIL]> wrote: Hi [USER], Can you please provide a screenshot of the error you are receiving? First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USER] Request Type: Help with something else I have been trying to connect to global protect and its not working it shows missing parameters."
"3233263","72092756","2025-10-03 19:53:15","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","[STAFF] told [USER] that he usually resolves the migration tickets a week after they've migrated. Given how old this is, [USER] thinks you have the go-ahead to just resolve this."
"3233621","70580034","2025-07-28 19:34:46","HPC Other Issue:  Permission Denied on /umbc/rs/pi_[ID]/users/[ID]/model During Slurm Job Execution","Ah, yes that makes sense. I am glad you figured it out. I will close this ticket now. Kind regards, [STAFF] DoIT Unix Infra Student Worker  On Mon Jul 28 15:28:48 2025, [USER] wrote: Hi [STAFF], this is an appreciation for the fix. The first command you gave worked after rebooting and it is now working perfectly with the compute mode. Best regards   On Mon, Jul 28, 2025 at 3:21 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3233621 > Last Update From Ticket: Hi [USER], From what I can tell, volumes are accessible on the compute nodes. Can you please provide exactly what you are trying to run? Can you include all relevant commands/path's to files? -- Kind regards, [STAFF] DoIT Unix Infra Student Worker  On Mon Jul 28 14:23:47 2025, [USER] wrote: Follow-Up on Group Volume Mount Issue (Access Denied on Compute Nodes) Hi [STAFF], Thanks for the earlier suggestion. I've removed the module purge line from my .bashrc, sourced the file, and retried the srun command. However, I'm still receiving the same error: slurmstepd: error: couldn't chdir to `/umbc/rs/pi_cichoku/users/[USER]/model': Permission denied: going to /tmp instead I believe this may be related to the group volume not being properly mounted on the compute node as you mentioned. Could you please help look into that? Best regards, [USER] On Mon, Jul 28, 2025 at 2:04 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3233621 > Last Update From Ticket: Hi [USER], All of the permissions for your directory are correct, and you should have no trouble accessing the storage location (your user account can access the storage location on the login node). There are two things I believe could be happening here. 1. This is what I believe is most likely. In your .bashrc file, you appear to be resetting all previously loaded modules, which removes all modules that need to be loaded by default. This includes modules such as the slurm module, which is what gives you access to all slurm commands (which are fairly important for using slurm...). I recommend you remove the 'module purge' line in your .bashrc file. Attempt to do this first, and see if it works. If not, it could be option two 2. There is a chance that your groups volume is not being properly mounted on the compute nodes. If the above does not work, let me know and we will look into this. -- Kind regards, [STAFF] DoIT Unix Infra Student Worker  On Mon Jul 28 13:46:20 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Cluster Dear HPC Support Team, I am encountering a persistent “Permission denied” error when launching a Slurm job that attempts to run in my user space under the shared research directory: /umbc/rs/pi_cichoku/users/[USER]/model Slurm is defaulting to /tmp instead, and I am unable to change into my model directory after job allocation. This issue is interfering with my ability to compile and run WRF. Could you please verify and correct the permissions on my directory, or advise on how to proceed? Thank you, [USER]"
"3233701","70595501","2025-07-29 16:13:01","HPC Other Issue: Two technical reports to schedule","You can consider those two IDs reserved for these reports. Thanks for the clarification. When you submit those reports, reference this ticket to avoid any confusion. I am in support of the tech report on the Poisson problem, is there any help we can provide there? Yes. I need to have the numbers finalized, so I can put them on posters as References, slides as References, and in the byline of the reports themselves. Actually, I also wanted to raise the idea that I can publish a tech report that shows a test of the new nodes with the Poisson problem. Like the HPCF-2019-1 and many others over the years. On Tue Jul 29 12:02:18 2025, [USER] wrote: Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=[NUMBER]> Last Update From Ticket: Hi [STAFF], I'm not sure what your question/request is here. Do you just want us to confirm that we'll name your technical reports HPCF-2025-4 and HPCF-2025-5? On Mon Jul 28 14:47:46 2025, [USER] wrote: > First Name: [FIRST NAME] > Last Name: [LAST NAME] > Email: [EMAIL] > Campus ID: [CAMPUS ID] > Request Type: High Performance Cluster > Hi, [STAFF], Our Big Data REU Site program is running (as you know), and we would like to put two tech. reports in the HPCF series again. The PDF files will be delivered next week. But in order to cite them already on a poster (for SURF) that needs to go into print, can we firm up their numbers? Could we reserved HPCF-2025-4 and -5, please? [USER]"
"3233913","70900964","2025-08-13 20:05:42","HPC Other Issue: [USER] execution on chip","Hi [USER], I have not received a response, so I am going to go ahead and close this ticket. If you still need further assistance, please submit a new ticket and include all information regarding your issue, including what commands you are running, what errors you are receiving, location/path to any related/relevant files (ie, sbatch, logs, etc). Have a nice day! Kind regards, [STAFF] DoIT Unix Infra Student Worker On Thu Jul 31 16:18:34 2025, [EMAIL] wrote: Hi [USER], I am still not sure where you are running into the error 'cannot import ollama'. No where in the code you provided is causing that error, and based on the logs ollama is running when you execute that script. If you wanted to run a model, you can run 'ollama run llama3.2:1b'. Do note, this command will pull the llama3.2:1b model, which will attempt to be downloaded to the .ollama directory in your home dir. This will result in your home directory getting filled up. So when using ollama, we recommend you move the .ollama folder to your user space on your research volume, and then create a symbolic link to point to the new location. The commands for that are... mv ~/.ollama /umbc/rs/manas/users/[USER]/.ollama ln -s /umbc/rs/manas/users/[USER]/.ollama ~/.ollama Also, yes, that behavior regarding the kill command is expected. Since you are attempting to execute the ollama serve command in a script, and are assigning the variable inside the script. This assigned variable stays only inside the script unless you say otherwise. If you try to call it from outside the script, it will throw an empty value, which then prints the help information for the kill command. If you attempt to kill it from inside the script, it will work. Or, if you run all the commands directly in your shell, it will also work. You can also get the process ID manually, using 'ps aux'. 'ps aux | grep [USER]' - this command will search through the running processes, and only show you your user's processes. One of these should say 'ollama server'. The value directly to the right of your username will be the process ID for that process. So you could instead use 'kill 12345678', where that number is the process id of the ollama serve process. You could also add a line to your script... echo $OLLAMA_SERVER_PID This line will print the PID to the terminal. Now, you could just copy it from there and be done. But instead, you could change how you call the ollama.sh script, and assign the variable directly from the scripts output. ie, OLLAMA_SERVER_PID=$(./ollama.sh) This just creates a new environment variable, OLLAMA_SERVER_PID, which is equal to the output of the ollama.sh script (which is just the PID). This would allow you to use 'kill $OLLAMA_SERVER_PID' from your terminal when starting ollama from that script. Anyways-- I still don't see where the issue is, could you show me where you are getting the error you mentioned earlier? Kind regards, [STAFF] DoIT Unix Infra Student Worker On Thu Jul 31 15:10:50 2025, [EMAIL] wrote: Hello, Yes I checked it is showing personal account and prompting to click on ask to join. Next time I will join using my umbc id. Following are the steps I performed:- 1) I did module load ollama/0.6.5 2) Inside /umbc/ada/manas/users/[USER]/subspace-rerouting/reproduce_experiments/run_ssr I created a file ollama.sh with the following content:- # ollama_run.sh #!/bin/bash ollama serve > ollama_server.log 2>&1 & OLLAMA_SERVER_PID=$! 3) Then I perform bash ollama.sh Following are the contents of my ollama_server.log:- 2025/07/31 15:07:00 routes.go:1231: INFO server config env='map[CUDA_VISIBLE_DEVICES:0 GPU_DEVICE_ORDINAL:0 HIP_VISIBLE>time=2025-07-31T15:07:00.509-04:00 level=INFO source=images.go:458 msg='total blobs: 0' time=2025-07-31T15:07:00.509-04:00 level=INFO source=images.go:465 msg='total unused blobs removed: 0' time=2025-07-31T15:07:00.511-04:00 level=INFO source=routes.go:1298 msg='Listening on 127.0.0.1:11434 (version 0.6.5)' time=2025-07-31T15:07:00.511-04:00 level=INFO source=gpu.go:217 msg='looking for compatible GPUs' time=2025-07-31T15:07:00.755-04:00 level=INFO source=types.go:130 msg='inference compute' id=GPU-3ef5e189-4589-9c01-b9c> Also, doing kill $OLLAMA_SERVER_PID gives kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec] Regards, [USER]"
"3233960","70711085","2025-08-04 21:33:08","HPC Other Issue: funny error message while submitting jobs, but they appear to run","Hi [USER], In the sbatch file located at /home/[USER]/git/MATLABCODE_Git/REGR_PROFILES_SARTA/RUN_KCARTA/REG_R49_400ppm_H2020_July2025_ECMWF83Profiles_AIRS2834_3CrIS_IASI/[USER]_matlab_chip.sbatch please add #SBATCH --error=job-%j.err and #SBATCH --output=job-%j.out to capture the output/error files for each slurm job itself. We can then hopefully look at the specific job that failed, and see why. Thank you. Regards, [STAFF] On Wed Jul 30 11:38:05 2025, [EMAIL] wrote: Hi [STAFF], Like I said the message showed up on submission ... but jobs still ran. Nothing showed up in the logs or slurm output that I noticed. And I noticed it happened when I submitted a load of jobs (about 1300) but not when I submitted fewer (eg 200) The job ID is on the message [USER]@c24-52 REGR49_400ppm_H2020_July2025_ECMWF83Profiles_AIRS2834_3CrIS_IASI]$ sbatch -p 2024 --array=1-455 [USER]_matlab_chip.sbatch Submitted batch job 273751 on cluster chip-cpu -[USER] On Wed, Jul 30, 2025 at 11:31 AM [STAFF] via RT <UMBC Help@rt.umbc.edu> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3233960 > Last Update From Ticket: Hi [USER], Since you have not pointed to any error or log files, we haven't been able to dig deeper into the error. Could you please try to replicate the error with both log files and error files included in your slurm sbatch file, so that we can look into them when the error happens? Don't forget to include the job ID. Finally, let us know after processing the output if the mat files also have any errors. Thank you. Regards, [STAFF] On Tue Jul 29 07:13:14 2025, [EMAIL] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USER] Request Type: High Performance Cluster Hi Yesterday evening I submitted tons of jobs to cpu2024. See /home/[USER]/git/MATLABCODE_Git/REGR_PROFILES_SARTA/RUN_KCARTA/REG_R49_400ppm_H2020_July2025_ECMWF83Profiles_AIRS2834_3CrIS_IASI/[USER]_matlab_chip.sbatch On submission I got this weird message [USER]@[USER] REGR49_400ppm_H2020_July2025_ECMWF83Profiles_AIRS2834_3CrIS_IASI]$ sbatch -p 2024 --array=1-455 [USER]_matlab_chip.sbatch Submitted batch job 273751 on cluster chip-cpu [USER]@[USER] REGR49_400ppm_H2020_July2025_ECMWF83Profiles_AIRS2834_3CrIS_IASI]$ srun: error: _half_duplex: wrote -1 of 2132 but they ended up mostly running (later on I had to resubmit to do the jobs which were not completed) and got the same error message (for job 275098) Randomly loading in one of the output files shows no errors, but I'll be processing the output later today and will know better if any of the mat files have errors(corrupt)."
"3234116","70592928","2025-07-29 15:10:58","HPC User Account: [ID] in Student Group","Hi [USER], To create an account on chip, you need to be affiliated with a PI. We no longer add users to the 'student' group, all users need to be affiliated with a PI, who is generally the faculty member you are working under for your research. Your PI also needs to already have their own group (or needs to create a new group) on chip. Your current request is missing the PI information and your Project Abstract. You will also need written approval in the RT ticket from your PI to create an account. All I need is a simple two word 'i approve' from your PI. Please submit a new ticket for this issue. Be sure to include all of the necessary info, as outlined on our wiki: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip#Requesting-a-User-Account-on-chip. -- Kind regards, [STAFF]. On Tue Jul 29 10:43:44 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] Request Type:              High Performance Cluster Create/Modify account in Student group Simulating Hamiltonian evolution for large scale quantum systems."
"3234239","70624296","2025-07-30 18:56:56","HPC New Group: [ID]","Hi [USER], It appears that the group, pi_[USER], already exists on the chip cluster. You already have an account and should be able to log in and run jobs. I will create the two additional requested accounts and add them to your group! Accounts for [STAFF], [STAFF], and [USER] exist and are in pi_[USER]! I recommend you take a look at the Getting started on chip page on our wiki, as it walks you through using the cluster for the first time! Here is the link: https://umbc.atlassian.net/wiki/x/R4BPQg Have a nice day! -- Kind regards, [STAFF] On Tue Jul 29 12:37:30 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster Group Type: Project Title: Towards Accurate Sense-Making of Data Visualization using LLM Project Abstract: Sense-making refers to the process of interpreting the meaning of data visualizations—a skill that is becoming increasingly critical in a society where data literacy and analytical competencies are essential. However, there remains a lack of efficient solutions to support students in developing sense-making skills. Our prior work has demonstrated the potential of large language models (LLMs) to evaluate the depth of students’ understanding. Yet, a gap persists in accurately quantifying the correctness of students’ interpretations of data visualizations. This project aims to explore various LLMs and their configurations to assess student responses and deliver actionable feedback that enhances chart-reading and data interpretation skills. Please create accounts for the following students and myself [STAFF], [EMAIL] [STAFF], [EMAIL] Project Resources This project uses the DePLOT model to extract data from chart images. The data helps evaluate student answers using LLMs (run off-cluster). DePLOT needs a GPU with at least 8GB VRAM for batch inference. Compute use will be light and limited to occasional testing. Also, 16GB RAM and less than 12GB SSD is fine."
"3234355","70599809","2025-07-29 18:15:41","Test for [USER]","Foo 22 On Tue Jul 29 14:11:29 2025, [STAFF] wrote: Text"
"3234476","70829258","2025-08-11 15:03:19","HPC Slurm/Software Issue: Numpy error: machine doesn't support: (AVX512_CNL).","Hi [USER], We are closing this ticket since you are not seeing the issue anymore. Please submit a new ticket if it occurs again. Thank you. Regards, [STAFF] On Fri Aug 08 14:39:29 2025, [USER] wrote: Hi! The code was working fine again. Not sure what changed at the backend, but it seems to not be producing that error which is a good sign. On Fri, Aug 8, 2025, 14:16 [STAFF] via RT wrote: Ticket Last Update From Ticket: Hi [USER], It is interesting to note that you could not disable the CPU feature. We will look deeper into this. In the meantime, could you please try the other two options I mentioned in the previous email, i.e. 2. Try to install a specific version of numpy inside your specific environment 3. Reinstall all your packages inside a fresh conda environment For both options 2 and 3, you could (a) Reinstall Numpy using the --no-binary flag that tells pip not to install packages from precompiled binary wheels (.whl files) after uninstalling the current version of numpy inside your conda environment as follows: pip uninstall numpy pip install --no-binary :all: numpy or do conda install numpy --force-reinstall You could also try to install a version of numpy less than v2.0 which is usually cluster compatible as follows: conda install -c conda-forge 'numpy<2.0' Thank you. Regards, [STAFF] On Fri Aug 01 16:49:01 2025, [USER] wrote: Hi! I tried the fixes you suggested but I received the following message: RuntimeError: During parsing environment variable 'NPY_DISABLE_CPU_FEATURES': You cannot disable CPU feature 'AVX512_CNL', since it is part of the baseline optimizations: (SSE SSE2 SSE3 SSSE3 SSE41 POPCNT SSE42 AVX F16C FMA3 AVX2 AVX512F AVX512CD AVX512_SKX AVX512_CLX AVX512_CNL AVX512_ICL) I tried it on the 2024 partition. On Fri, Aug 1, 2025 at 10:45 PM [STAFF] via RT wrote: Ticket Last Update From Ticket: Hi [USER], I recommend trying the following 3 options: 1. Setting an environment variable recognized by NumPy that allows you to disable certain CPU features at runtime in the .sh file calling the python script that throws the error as follows: export NPY_DISABLE_CPU_FEATURES='AVX512_CNL' or add the following line of code inside the python script itself before using numpy import os os.environ['NPY_DISABLE_CPU_FEATURES'] = 'AVX512_CNL' Note that you need to do either of the two above as they do the same thing. 2. Try to install a specific version of numpy inside your specific environment 3. Reinstall all your packages inside a fresh conda environment Let us know if you get the same error after trying all three of the above-mentioned steps. Thank you. Regards, [STAFF] On Fri Aug 01 09:15:59 2025, [USER] wrote: Hi, I wanted to know if you were able to troubleshoot this any further On Wed, Jul 30, 2025, 21:50 [USER] wrote: Hi [STAFF] I logged into chip through VS Code, then I navigated to the directory, /umbc/rs/cybertrn/reu2025/team2/research/postprocessing/recon, where I executed the shell script, recon.sh using CHIPrun.slurm But I had tried to run post processing script at /umbc/rs/cybertrn/common/PGML_Example/2k-0.1x-NN/postprocessing/scripts/test_pipeline2 and ran into the same error, but this script was executed successfully with the same conda env in /umbc/rs/cybertrn/common/PGML_Example/DanTFvirtualPyEnv_Test/postprocessing/scripts On Wed, Jul 30, 2025 at 9:13 PM [STAFF] via RT wrote: Ticket Last Update From Ticket: Hi [USER], Could you please specify the exact steps you executed from the moment you SSHed into chip until you got this error? A preliminary investigation suggests that the version of numpy you are using is not compatible with the CPU node on which your job ran (and it was compatible on a different CPU node on which it ran a few weeks ago, as different CPU nodes on chip have different architectures). I would try to install the correct version of numpy inside your conda environment and then try to replicate the error by running the job. If you are able to replicate the error, please send us the job ID, the sbatch slurm file or the srun command you used, and the outputs of any log or error files you used as well. A detailed description of the all the steps you executed would definitely help us dive deeper into the error. Thank you. Regards, [STAFF] On Tue Jul 29 16:07:37 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Cluster I am using conda environment ((/umbc/rs/gobbert/users/dkelly7/conda_envs/NN_train)) for image reconstruction , which was working fine a few weeks ago, but is now printing the following error and interrupting my job: RuntimeError: NumPy was built with baseline optimizations: (SSE SSE2 SSE3 SSSE3 SSE41 POPCNT SSE42 AVX F16C FMA3 AVX2 AVX512F AVX512CD AVX512_SKX AVX512_CLX AVX512_CNL AVX512_ICL) but your machine doesn't support: (AVX512_CNL). Can you please guide me on what can help me fix this. Thank you!"
"3234718","70806276","2025-08-08 18:33:55","Research Storage Migration to Ceph Cluster","Hi [USER], I just tested it and looks good. Thanks! [STAFF]  On Fri, Aug 8, 2025 at 2:23 PM [STAFF] via RT <[EMAIL]> wrote: Ticket  Last Update From Ticket: Hello [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: * The path has changed, and is available under /umbc/rs/[STAFF]. * The aliases used to reach the volume are now [STAFF]_common and [STAFF]_user. * Your new volume has a 10TB quota. When you have a chance, could you try running some jobs using the new volume to verify everything looks good? Best,[STAFF] On Fri Aug 08 10:29:24 2025, [USER] wrote: Great. Thanks. [USER] On Fri, Aug 8, 2025 at 10:28 AM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Good morning [USER], This is a reminder that we're going to be starting the migration of your research volume from the old storage server to the new Ceph cluster today. If there are any jobs running on chip that are accessing the old volume, they will be terminated. I expect this should be completed by COB today. We will send you an update when it's finished. Best,[STAFF] On Wed Aug 06 09:37:30 2025, [USER] wrote: Hello [USER], I hope this message finds you well. Friday the 8th works. -- Best regards, [STAFF]"
"3234853","70694744","2025-08-04 15:37:09","HPC User Account: [USER] in pi_[USER]","Thanks, everything seems to be working OK for me again.  [STAFF] via RT wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=[TICKETID]&ticketowner=[STAFF EMAIL]&ticketsubject=[SUBJECT] If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at Ticket [URL: https://rt.umbc.edu/Ticket/Display.html?id=[TICKETID]] Hi [USER], It looks like [USER] still has his previous account/pi_group active on the cluster. He should already be able to log in and use the cluster as normal. Since you were requesting him to have an account in pi_[USER], I will add pi_[USER] as a secondary group for his existing account. This way, [USER] will be able to access both files in the existing group, pi_[USER], and new files, under pi_[USER]. Since [USER] will theoretically have ownership of all the files, you should be able to change the permissions as needed yourselves! If there does end up being a permission issue that we need to address, feel free to submit a new ticket for it! Have a great day! -- Kind regards, [STAFF]"
"3235189","70629481","2025-07-30 23:59:09","HPC Other Issue: Require more memory (>550GB)","Hi [USER], Oh, good to know it. I just submitted the job using partition: pi_bennettj, which allow me to allocate more memories. Thank you very much for your help. I am really appreciate it. Best Regards, [STAFF] On Wed, Jul 30, 2025 at 6:17 PM [STAFF] via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3235189&ticketowner=[STAFF EMAIL]&ticketsubject=HPC Other Issue: Require more memory (>550GB) If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3235189 Thank You R e s o l u t i o n: Hi [USER], Ah! So, currently you have the partition set to '#SBATCH --partition=match'. This partition only includes nodes that DoIT purchased, matching the value of funds provided by contributors (nodes c24-[29-52], so only low_mem nodes). So this does not include all available 2024 nodes. Instead, you could use either the contrib or 2024 partition (i believe both of these partitions are the same, and include all 2024 nodes). Additionally, I just realized you are a member of pi_bennettj. And, as it turns out, your group contributed c24-[01-10], which is most of the high_mem nodes. You can also use pi_bennettj as your partition, which will give your jobs priority over other jobs (from groups other than pi_bennettj) on those nodes. -- Kind regards, [STAFF] On Wed Jul 30 17:53:18 2025, [USER] wrote: Hi [STAFF], Thank you very much for your quick response. I just modified my runscript by adding the line '#SBATCH --constraint=high_mem' and change the memory specification in the line '#SBATCH --mem=700G', however, I received an error saying 'Requested node configuration is not available' when I submitted the job. I have attached the runscript I used to this email. Could you please help me to correct the configuration error inside the runscript? Thank you. Best Regards,[USER] On Wed, Jul 30, 2025 at 5:28 PM [STAFF] via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[USER EMAIL]&groupid=EIS&ticketid=3235189&ticketowner=[STAFF EMAIL]&ticketsubject=HPC Other Issue: Require more memory (>550GB) If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3235189 Thank You Hi [USER], If you take a look at our website: https://hpcf.umbc.edu/compute/overview/, you can see all currently available hardware. As you can see, some of the 2024 nodes have 1024GB of RAM. Currently, there are 13 available 'high_mem' nodes, c24-[01-13]. If you have used the GPU cluster before, you may be familiar with the --constrant option to select GPU models (ie, #SBATCH --constraint=L40S). With the 2024 nodes, there also exists an available constraint; high_mem and low_mem. If you add '#SBATCH --constraint=high_mem' to your sbatch file, it will only run your code on nodes that have 1TB of memory. If you run into any issues, feel free to let me know! -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Wed Jul 30 16:31:28 2025, [USER] wrote: First Name: [USER] Last Name: [USER LAST NAME] Email: [USER EMAIL] Campus ID: [CAMPUS ID] Request Type: High Performance Cluster Hello, I am encountering insufficient memory issues when submitting one of my calculations in Quantum Espresso. The output estimates that the total dynamic RAM required exceeds 526.07 GB. However, the maximum memory I can currently set in the runscript is around 460 GB, which is lower than the required memory for this calculation. I would like to ask if it’s possible to request more memory for specific calculations (e.g., 600-650 GB). Additionally, could you please suggest how to configure the runscript to accommodate this? I have attached my runscript and output file for your reference. Thank you very much for your help. Best regards, [USER]"
"3235271","70642712","2025-07-31 17:01:16","HPC Slurm/Software Issue: Software unavailable","Thank you for all the help! I am able to run my job now. If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3235271&ticketowner=[STAFF]&ticketsubject=HPC Slurm/Software Issue: Software unavailable. If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3235271. Hi [USER], My apologies regarding this, the steps to use Gaussian should be documented on our wiki, however it appears to be missing at the moment. I will be fixing this today. Due to how Gaussian designed their software, they added an (arguably obtuse and pointless) requirement to only allow users who are a member of a specific unix group to run the software. While the software is free for researchers, they feel the need to restrict their software from functioning properly unless it is restricted to only allowing a specific group to access the software for silly copyright reasons. This is intended to prevent non-researchers from accessing the software, but in our deployment, it just adds extra hurdles that we cannot easily work around without manual work. So, anytime a user wants to use the Gaussian software (for the first time), they need to reach out to us to request to be added to the 'gaussian' group on chip. I just added you to this group, so if you load the Gaussian model, you should be able to use 'g16' along with other gaussian functions. If you run into any issues with Gaussian, please feel free to let us know! -- Kind regards, [STAFF]. On Wed Jul 30 19:59:38 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster. Hello, I know that we currently have the g16 module available for use, but I was trying to submit a job but it tells me that the module isn't available. So I wasn't really sure what do do . '/cm/local/apps/slurm/var/spool/job276572/slurm_script: line 19: g16: command not found slurm.err (END)'. Thank you for looking into this with me."
"3235730","70644755","2025-07-31 17:55:51","HPC User Account: [USER] in fanza","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_fanza. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/). Kind regards, [STAFF]. On Thu Jul 31 13:51:19 2025, [USER] wrote: Testing Observable Statistical Mechanics for global observables in interacting, long-range, many-body quantum systems"
"3235826","70651200","2025-07-31 20:45:45","HPC User Account: [USER] in halem","Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_halem. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) Kind regards, [STAFF] On Thu Jul 31 15:24:15 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: Research Computing & Data Consultation Respected Team, I hope this message finds you well. My name is [USER], and I am a graduate student at UMBC, currently working in the CARTA Research Lab. As part of my research on climate prediction models, I require access to large-scale GPU resources for high-performance computing. Dr. [STAFF] recommended that I reach out to request the necessary chip access. I would greatly appreciate your guidance and support in facilitating this. Thank you for your time and assistance. Best regards, [USER]"
"3236164","70662612","2025-08-01 15:57:01","HPC Slurm/Software Issue: How to Cancel Jobs in Queue","Hi [USER], While sometimes the 'scancel' command may work without mentioning the flag for whether the job is running on chip-cpu or chip-gpu (--cluster flag), it is good practice to include it to avoid any ambiguity. Excluding the flag may sometimes cause it to not be effective. We have multiple pages on wiki with documentation of how to use the 'scancel' command, and one of them does not mention using the --cluster flag. We are working on updating it. Using the '--cluster' flag, the way to cancel a job with jobid XXXXXX running on chip-cpu would be with the command: scancel -M chip-cpu XXXXX or scancel --cluster=chip-cpu XXXXX If your job is running on chip-gpu, replace chip-cpu with chip-gpu in the above two commands. The documentation on this page (https://umbc.atlassian.net/wiki/spaces/faq/pages/1335951387/Basic+Slurm+Commands) in the 'Managing and Controlling Jobs' subsection reiterates what I mentioned above. It also mentions how to cancel all jobs for a user. Please let us know if you were able to cancel your jobs using the information shared above. Thank you. Regards, [STAFF] On Fri Aug 01 10:04:09 2025, [EMAIL] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Hi, I've been trying to cancel some jobs on Chip that are currently running that I don't need to run anymore. I thought the way to cancel them is doing the command 'scancel ' but that is not working. Also doing 'scancel -u ' is not working to cancel all jobs at once. How do I properly cancel running jobs on the cluster? Thanks"
"3236197","72245211","2025-10-13 18:26:37","RCD Consult: Server for AI Project","Hi [STAFF], Sorry this ticket got lost! Are you still looking to set up a server for an AI chatbot? If so, I'd like to find a time to chat briefly about what you have in mind and how we can find some infrastructure to get things going. On Fri Aug 01 10:39:47 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [ID] Request Type:              Research Computing & Data Consultation Hello Research Computing Team Representative, I am currently in process of developing an AI-based research project that involves the development of an AI-chatbot. I am reaching out to you to inquire whether UMBC is allowed and able to provide a server to house this AI-chatbot once developed for use. Sincerely,"
"3236210","70663099","2025-08-01 16:12:42","NVivo software request for [USER]","Hi [USER], Only Faculty/Staff/Graduate Students are eligible for Nvivo. When a user logs in, their affiliation is checked, and if it doesn't have one of those keywords they won't have access to it. I tried looking up the id that you gave to us, but that's not a UMBC id. I also checked against the student that's CC'd here ([STAFF]) and it says they are an undergraduate student. For more information, check this out: https://umbc.atlassian.net/wiki/spaces/faq/pages/30748183/NVivo On Fri Aug 01 10:48:09 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: Help with something else Can i please get my student access to NVivo to do research? Her id is [CAMPUSID]"
"3236298","71451949","2025-09-04 14:28:45","HPC User Account: [USER] in [USER]","How to access GPU: https://[DOMAIN].atlassian.net/wiki/spaces/[SPACE]/pages/[PAGEID]/How+do+I+run+an+interactive+job"
"3236662","70710588","2025-08-04 20:50:11","HPC Other Issue: Large memory issue","Hello [USER],  No worries about the ticket. I've figured it out. Thanks.  On Mon, Aug 4, 2025 at 1:11 PM [STAFF] via RT <[EMAIL]> wrote:  Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3236662 > Last Update From Ticket: Hi [USER], Could you provide some additional information on what you are running after starting your slurm allocation with srun? It seems like your job is attempting to access memory that is not available. You said you were attempting to request the value that 'cat /proc/meminfo' says is 'memfree'. But you initially requested 120GB of memory via your srun command, so you should have that amount available for your job. Let me know what all you are running to get that error! -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Fri Aug 01 16:33:08 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] Request Type:              High Performance Cluster Hello, I found some large memory request issues when using the following command: srun --cluster=chip-cpu --mem=120G --time=12:00:00 --qos=medium --account=[ACCOUNT] --partition=general --ntasks-per-node=48 --nodes=1 --pty $SHELL It gave a c21 node, i.e. c21-12 in my case. When using cat /proc/meminfo, it shows MemTotal:       196495180 kB MemFree:        15582944 kB MemAvailable:   192234392 kB Buffers:            2188 kB Cached:         175746248 kB ... The 'MemFree:        15582944 kB' seems to cause trouble as my run got killed directly by showing the following error message: [0]PETSC ERROR: Caught signal number 11 SEGV: Segmentation Violation, probably memory access out of range [0]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger [0]PETSC ERROR: or see https://petsc.org/release/faq/#valgrind [0]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors [0]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run to get more information on the crash. This worked well for low memory cases. Please help fix this issue ASAP. Thanks, [USER]"
"3237101","70911958","2025-08-14 14:43:07","HPC User Account: [USER] in IRAL Lab","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_cmat. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) On Tue Aug 12 14:08:07 2025, [STAFF] wrote: I do approve this request. Thanks for your patience while I was on travel! Hi all, Just checking in on this ticket again. [STAFF], do you approve of adding [USER] to your hpc account? On Thu Aug 07 11:37:10 2025, [STAFF] wrote: Sure, thanks for letting me know. On Thu, Aug 7, 2025, 11:02 AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3237101> Last Update From Ticket: Hi [USER], I'm sorry, but we can't just take your word for it. We only require an email response from [STAFF] saying she approves. You'll have to wait until approval is given. Apologies for the inconvenience. On Tue Aug 05 11:22:56 2025, [STAFF] wrote: > Currently [STAFF] is out of town and she's going to return on August > 8th. Actually she's the one who told me make a request. Is it possible to > approve the request now since I'm having many tasks that needs to be > completed? Thanks [USER] On Tue, Aug 5, 2025, 10:30 AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3237101> Last Update From Ticket: Hi [USER], We're just waiting on [STAFF] to approve your request. Once that's done, we can get you on the system immediately. On Sun Aug 03 11:03:42 2025, [USER] wrote: > First Name: [USER] > Last Name: [USER] > Email: [EMAIL] > Campus ID: [CAMPUS_ID] > > Request Type: High Performance Cluster > > Create/Modify account in existing PI group > Existing PI Email: [EMAIL] > Existing Group: IRAL Lab > Project Title: BIAS in Language Models > Project Abstract: N/A > > N/A"
"3237138","70899380","2025-08-13 19:28:05","HPC Slurm/Software Issue: JOBS FAILING/ MODULE ERRORS on GPU Partition","Hi [USER], I wanted to let you know that I resolved the error with ollama being unable to use GPUs. It turns out by default Slurm sets the environment variables for CUDA_VISIBLE_DEVICES and ROCR_VISIBLE_DEVICES as the same value, even when there are no ROCM devices present. This confuses ollama when trying to identify and use GPUs. I was able to just unset the ROCR_VISIBLE_DEVICES env variable and got the new ollama version to work! We were also able to resolve the error with slurm, so now it will only set env variables for CUDA devices, so this will not be a problem in the future. You should be able to load both ollama/0.10.1 and ollama/0.11.4. I do believe that 0.11.4 has some bugs regarding downloading models.... so when the next version is released I will update it. I will go ahead and close this ticket now. If you need any further help, feel free to submit a new ticket. Kind regards, [STAFF] On Fri Aug 08 17:20:43 2025, [EMAIL] wrote: Hi [USER], Regarding ollama, the latest version that works right now is 0.9.2, which is installed. In 0.9.3, they made changes that have messed up how the drivers are loaded in our HPC environment. Does this version work for you? If you need newer versions, it may be worth looking into using ollama in docker/apptainer. I will also submit a issue to the ollama github repo for further troubleshooting. Regarding your jobs disappearing, I believe I have identified the error. When jobs disappear, and throw the Reason in scontrol as 'JobState=FAILED Reason=RaisedSignal:53(Real-time_signal_19) Dependency=(null)', it is generally because slurm cannot access the path to certain files (usually log files). As it turns out, there was some issues with the Ceph storage cluster, which resulted in certain mounts being broken on some nodes. Your group, [GROUP], has been migrated over to the ceph cluster. I believe that the node's that your job was failing on were nodes that had broken research volume mounts. I have fixed all the broken mounts, so hopefully you no longer experience this issue!"
"3237832","70783062","2025-08-07 17:55:56","HPC User Account: [USER] in [STAFF]","Joseph asked me to add these 4 students in this ticket https://rt.umbc.edu/Ticket/Display.html?id=3211265&amp;results=f43b5f9010e120cebdb990e7ed4e9a51: drwxr-s--- 8 [USER] pi_[STAFF] 238 Jul 8 2024 [USER] drwxr-s--- 10 [USER] pi_[STAFF] 477 Jun 11 2024 [USER] drwxr-s--- 11 [USER] pi_[STAFF] 863 Feb 26 2024 [USER] drwxr-s--- 7 [CAMPUS_ID] pi_[STAFF] 385 Jul 27 2021 [USER] On Tue Aug 05 14:08:00 2025, [EMAIL] wrote: Hi [STAFF], You now have read/write/execute for all of these users, user directories in your research volume (/umbc/rs/[STAFF]/users). Please allow a little more time to remove the users completely from the cluster. If you have other users who you would removed, please let us know! On Mon Aug 04 14:05:32 2025, [EMAIL] wrote: First Name:                [STAFF] Last Name:                 [STAFF] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] Request Type:              High Performance Cluster Create/Modify account in existing PI group Existing PI Email:    [EMAIL] Existing Group:       [STAFF] Project Title:        PI File CleanUp Project Abstract:     I need to clean up files on chip  Hello, the following are student accounts of students that have left the university or my group. As PI of the group, I would like to have ownership of their files."
"3238305","70730550","2025-08-05 18:00:31","HPC Other Issue: /asl/ftp/incoming not working","Hi [STAFF], Yes I checked the file size and they seem to be fine. I haven't actually tried to read any of the recent files, I'll do so in a few minutes and will let you know if I cannot read with Matlab. We'll be trying to process them in a few days but as I said above I'll keep you posted - [STAFF] On Tue, Aug 5, 2025 at 1:53 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3238305> Last Update From Ticket: Hello [USER], After looking into our server logs, it appears to me that the file transfers are failing for about 5-10 minutes at a time with a 'Could not create file.' error - which matches the error that you sent - and afterwards the file transfers start working normally again. We're unsure what's causing this and have enabled some additional logging to try and capture what's causing the transfers to fail periodically. Are you able to confirm all of the files are being transferred eventually, even if they fail the first attempt at being uploaded? Thank you, [STAFF] On Tue Aug 05 07:07:22 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Hello, I just received this message, could you please look into this? I do see recent files on /asl/ftp/incoming/L1c, so I'm a bit puzzled. From: [STAFF][ADNET SYSTEMS INC] Date: Mon, Aug 4, 2025 at 10:28 Subject: AIRS L1C push subscription errors To: [STAFF][UNIVERSITY OF MARYLAND BALTIMORE CO], [STAFF][University of Maryland, Baltimore County] CC: [STAFF][TELOPHASE CORP] Good morning Chris, We have been getting failures pushing AIRS L1C v6.7 data to your machine since late last week: 2025-07-31 15:11:26 3884396 s4paops INFO s4pa_file_pusher.pl: Local directory is /vol1/AirsL1/OPS/s4pa/airsl1v6_7/postoffice/RUNNING.130_85_28_205.PUMBC_L1CT20250725003043S11 2025-07-31 15:11:27 3884396 s4paops INFO s4pa_file_pusher.pl: Using local address gs6102dsc-airsl1.gesdisc.eosdis.nasa.gov, blocksize 10240, ftplog 2025-07-31 15:11:27 3884396 s4paops INFO s4pa_file_pusher.pl: Logged in to 130.85.28.205 for FTP 2025-07-31 15:11:27 3884396 s4paops INFO s4pa_file_pusher.pl: Changed directory to /incoming/L1c 2025-07-31 15:11:27 3884396 s4paops ERROR s4pa_file_pusher.pl: Failed to put /ftp/data/s4pa/.5kNTX5B9SOGXxsFi/Aqua_AIRS_Level1/AIRICRAD.6.7//2025/204/AIRS.2025.07.23.199.L1C.AIRS_Rad.v6.7.5.0.G25205202348.hdf in /incoming/L1c on 130.85.28.205: Could not create file. 2025-07-31 15:11:27 3884396 s4paops ERROR s4pa_file_pusher.pl: Failed to push /ftp/data/s4pa/.5kNTX5B9SOGXxsFi/Aqua_AIRS_Level1/AIRICRAD.6.7//2025/204/AIRS.2025.07.23.199.L1C.AIRS_Rad.v6.7.5.0.G25205202348.hdf to 130.85.28.205:/incoming/L1c by ftp Please let me know if there's anything on our end you'd like for us to test."
"3238861","70736271","2025-08-05 20:03:12","HPC Other Issue: Please add [USER] to my group","Hi [STAFF], I created an account for [USER] in your group! If you run into any issues, feel free to create a new ticket! Have a nice day! -- Kind regards, [STAFF] (she/her/hers) DoIT Unix Infra Student Worker On Tue Aug 05 15:40:14 2025, [EMAIL] wrote: [USER]"
"3239251","70763520","2025-08-06 23:48:17","HPC Other Issue: Requesting to reserve GPU memory on chip","This is done   ``` [~]$ scontrol -M chip-gpu show reservation [RESERVATION] StartTime=2025-08-06T19:47:00 EndTime=2025-08-20T19:46:00 Duration=13-23:59:00 Nodes=[SERVER] NodeCnt=1 CoreCnt=32 Features=(null) PartitionName=(null) Flags=IGNORE_JOBS,SPEC_NODES TRES=cpu=32 Users=(null) Groups=(null) Accounts=[ACCOUNT] Licenses=(null) State=INACTIVE BurstBuffer=(null) Watts=n/a MaxStartDelay=(null) [~]$   --  [STAFF] DoIT Research Computing Team"
"3239359","70832251","2025-08-11 15:51:27","HPC Other Issue: how many jobs can slurm 'array' handle","Hi [USER], We have just updated the number of max allowed jobs on the cluster to be 100K jobs each for chip-cpu and chip-gpu. This is the maximum value for all users jobs on either chip-cpu or chip-gpu. However, for that many profiles, it would probably be wise to split the job into chunks. You could probably do something similar to... JOB = str2num(getenv('SLURM_ARRAY_TASK_ID')); profiles_per_job = 40; total_profiles = 2000000; start_prof = (JOB-1) * profiles_per_job + 1; end_prof = min(JOB * profiles_per_job, total_profiles); for prof = start_prof:end_prof process_profile(prof); end You could submit that with 'sbatch --array=1-50000 example.sbatch'. And it would process 40 profiles per job across 50K jobs. This is just a quick example, but if you have any further questions let me know! -- Kind regards, [STAFF] On Wed Aug 06 12:16:48 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster Hi Usually I set up my jobs to be embarrassingly parallel, and then use eg sbatch --array=1-0168 [USER]_matlab_chip.sbatch to submit my jobs (I have 168 sets to process in this case) I was wondering what the upper limit on jobs would be? I have a new dataset to process, which has 2,000,000 individual profiles. I suppose I should get my code to loop within those profiles for each JOB array ID inside Matlab? If you tell me the max limit then I could do something like JOB = str2num(getenv('SLURM_ARRAY_TASK_ID')); ind=1:10000; newind = (JOB-1)*10000 + ind; for ii = 1 : length(newind) prof = newind(ii); process_profile(prof); end Thanks [USER]"
"3239433","70779384","2025-08-07 16:04:46","HPC User Account: [USER] in Mdata Lab/iHARP","I am sorry, I forgot to add the ssh command. It is working now. Thank you so much! On Thu, Aug 7, 2025 at 12:00 PM [STAFF] wrote: I am unable to login into account. Below is the response that I am getting. C:\Users\[USER]>ssh [USER]@chip.rs.[DOMAIN] The authenticity of host 'chip.rs.[DOMAIN] (130.85.28.213)' can't be established. ED25519 key fingerprint is SHA256:KssMZdd+0v72I1Rd3H/zj161sMEr8mVON/Ylg27wHNk. This key is not known by any other names. Are you sure you want to continue connecting (yes/no/[fingerprint])? yes Warning: Permanently added 'chip.rs.[DOMAIN]' (ED25519) to the list of known hosts. ([USER]@[USER]@chip.rs.[DOMAIN]) Password: ([USER]@[USER]@chip.rs.[DOMAIN]) Duo two-factor login for [USER] Enter a passcode or select one of the following options: 1. Duo Push to XXX-XXX-XXXX 2. Phone call to XXX-XXX-XXXX 3. SMS passcodes to XXX-XXX-XXXX Passcode or option (1-3): 3 Connection closed by 130.85.28.213 port 22 C:\Users\[USER]@[USER]@chip.rs.[DOMAIN] '[USER]@chip.rs.[DOMAIN]' is not recognized as an internal or external command, operable program or batch file. On Thu, Aug 7, 2025 at 11:04 AM [STAFF] via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://[DOMAIN].us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3239433&ticketowner=[STAFF]&ticketsubject=HPC User Account: [USER] in Mdata Lab/iHARP If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.[DOMAIN]/Ticket/Display.html?id=3239433 Thank You ______________________________________ R e s o l u t i o n Hi [USER], It was nice speaking to you today during your office hours appointment. As mentioned, I have created an account for you on chip, with your primary group as iharp. We also discussed the various documentation available for using chip. I will include some links below for easy reference. HPCF Chip Wiki: https://[DOMAIN].atlassian.net/wiki/x/FwCHQ Getting Started on Chip Wiki: https://[DOMAIN].atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip Getting Started on Chip Video Tutorial: https://www.youtube.com/watch?v=pGC9Fom5Xrc If you have any further questions or issues with using the cluster, feel free to submit a ticket! Have a nice day! -- Kind regards, [STAFF] (she/her/hers) DoIT Unix Infra Student Worker On Wed Aug 06 13:25:30 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: XXXXXXXX Request Type: High Performance Cluster Create/Modify account in existing PI group Existing PI Email: [STAFF]@umbc.edu Existing Group: Mdata Lab/iHARP Project Title: Audio deepfake detection in Multi-speaker Project Abstract: The increasing sophistication of audio deepfakes, generated by AI techniques such as text-to-speech (TTS) synthesis and voice conversion (VC), poses significant challenges in various sectors, including media, telecommunications, and cybersecurity. While current research has made substantial progress in detecting single-speaker deepfakes, the detection of deepfakes in multi-speaker environments such as conversations, debates, and meetings remains largely underexplored. The primary research gaps in this field lie in the lack of multi-speaker datasets and the inability of existing models to handle the complexities of overlapping speech, speaker diarization, and real-world acoustic conditions. Our project aims to address these critical gaps by creating datasets specifically designed to simulate real-world conversations and propose new detection models. I would greatly appreciate it if I can hear back soon. Thank you! Also, I have been involved in a project that required us to use UMBC HPCF before, but I was in different program at the time with different advisor. Thanks."
"3239801","70919508","2025-08-14 17:56:14","HPC Slurm/Software Issue: Request for Access - Permission Denied to [USER] on CHIP GPU Node","Glad things are working. If you continue to have any issues please reach out. Best regards, [STAFF]"
"3239868","70857444","2025-08-12 14:52:15","HPC Other Issue: slurm sleeping, why?","This appears to be a long email thread between Sergio DeSouza-Machado and Max Breitmeyer regarding an issue with submitting jobs to a High-Performance Computing (HPC) cluster using the Slurm job scheduler.  The initial issue reported by Sergio is that he receives a 'slurm sleeping' error when trying to submit a large number of embarrassingly parallel jobs. Max responds by increasing the `MaxJobArraySize` limit, which allows Sergio to submit more jobs.  However, Sergio later reports that he still encounters issues with submitting large numbers of jobs and asks for help in implementing a workflow where he can submit batches of jobs that depend on each other completing successfully. Max provides some guidance on using Slurm's job dependencies feature to achieve this.  Throughout the thread, there are also some minor issues discussed, such as Sergio accidentally deleting his own files and Max providing some troubleshooting tips.  Some key points from the conversation:  * The initial issue was caused by a limit on the maximum number of jobs that can be submitted at once (`MaxJobArraySize`). * Max increased this limit to allow Sergio to submit more jobs. * Sergio later asked for help in implementing a workflow where he can submit batches of jobs that depend on each other completing successfully. * Max provided guidance on using Slurm's job dependencies feature to achieve this.  Overall, the conversation is quite technical and specific to HPC clusters and job schedulers."
"3240145","70949954","2025-08-15 22:49:00","Common Name: [DOMAIN NAME] - Expires : 08/19/2025","This has been renewed and deployed. [STAFF]. On Fri Aug 15 15:44:22 2025, [USER] wrote: Four day notice. -- [STAFF] [EMAIL]"
"3240358","70928156","2025-08-15 00:15:19","HPC Other Issue: No space on the device--device full","Thank you so much [STAFF] The issues have been solved On Thu Aug 14 2025 at 12:04 PM [STAFF] via RT wrote Ticket Last Update From Ticket Hello [USER] I hope this message finds you well I am just checking in to see if you are still experiencing any issues Best regards [STAFF]"
"3240527","70804050","2025-08-08 17:32:17","HPC New Group: [ID]","Hi [USER], The group pi_[USER] now exists on the chip cluster. Members of this group can therefore access and contribute to the research storage space allocated to the group. This storage is located at /umbc/rs/pi_[USER] and currently has a quota of 10T. Additionally, your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[USER]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Group Type: Project Title: [PROJECTTITLE] Abstract: [PROJECTABSTRACT]. I am a [POSITION] working at [ORGANIZATION]. I would like to request a new research group under UMBC HPC. To insure an efficient collaboration with my mentees from [UNIVERSITY1] and [UNIVERSITY2], I would like to use this group to facilitate collaboration between myself and my two mentees; A graduate student from [UNIVERSITY1] and a graduate student from [UNIVERSITY2]. Furthermore, this group will enable straightforward integration of prospective collaborators, ideally UMBC students, to the [PROJECTTITLE] project. Please submit additional questions or issues as separate tickets via the following link (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/). Kind regards, [STAFF]."
"3240647","70902005","2025-08-13 20:30:37","HPC Other Issue: Matlab license error","Hi [USER], Sounds good! Also, I wanted to make a slight correction to my original message regarding how many jobs you can run in an array. I originally gave you the value for the total number of max jobs allowed, however it turns out there is a separate limit for array jobs that I missed previously. The max array size is actually 25k, which makes sense to prevent one user from using all available resources. Nonetheless, you can just increase the amount of profiles per task to fit the actual array size. Apologies for that mistake. Have a nice day! -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Wed Aug 13 16:23:13 2025, [USER] wrote: Hi [STAFF], Thanks!! I'll try this and see what I get! It'll probably be a few days since I have some Matlab interactive work to do first. Cheers Sergio On Mon, Aug 11, 2025 at 12:28 PM Danielle Esposito via RT <UMBCHelp@rt.umbc.edu> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3240647&ticketowner=desposi1@umbc.edu&ticketsubject=HPC+Other+Issue%3A+Matlab+license+error If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3240647 Thank You R e s o l u t i o n: Hi [USER], I believe you meant to send this reply in ticket #3239359, https://rt.umbc.edu/Ticket/Display.html?id=3239359. Nonetheless, the slurm environment variables will be the same between chip-cpu and chip-gpu. If you submit an array job on chip-cpu, you use the SLURM_ARRAY_TASK_ID environment variable to get the task id. On chip-gpu, it is the same! All of our documentation for chip is available via our wiki: https://umbc.atlassian.net/wiki/x/FwCHQ I may be misunderstanding your question, but I believe using sbatch array jobs would be embarrassingly parallel. Here is an example of what I mean... #!/bin/bash #SBATCH --array=1-10 #SBATCH --gres=gpu:1 #SBATCH --cluster=chip-gpu #SBATCH --mem=1G #SBATCH --time=01:00:00 echo 'Starting job on host $HOSTNAME' echo 'Array ID: $SLURM_ARRAY_JOB_ID' echo 'Task ID: $SLURM_ARRAY_TASK_ID' matlab -nodisplay -r 'your_matlab_script; exit' On Thu Aug 07 22:18:42 2025, [USER] wrote: First Name: [USER] Last Name: De souza-machad Email: [EMAIL] Campus ID: VR64161 Request Type: High Performance Cluster No idea which nodes, but this happened on cpu2024, 4000 jobs out of 5000 requested more slurm-311045_4297.out License checkout failed. License Manager Error -16 Make sure the vendor daemon path in the license file is correct. Troubleshoot this issue by visiting: https://www.mathworks.com/support/lme/16 Diagnostic Information: Feature: MATLAB License path: /home/[USER]/.matlab/R2023b_licenses:/usr/ebuild/software/emerald/software/MATLAB/2023b/licenses/license.dat:/usr/ebuild/software/emerald/software/MATLAB/2023b/licenses/network.lic Licensing error: -16,10009. System Error: 104"
"3241434","70826392","2025-08-11 14:06:53","HPC Other Issue: c24-52 : [USER] cannot log in","Great, thanks! [USER] Sent from my iPhone On Aug 11, 2025, at 9:58 AM, [STAFF] via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://www.google.com/url?q=https://umbc.us2.qualtrics.com/SE/?SID%3DSV_etfDUq3MTISF6Ly%26customeremail%3D[EMAIL]%26groupid%3DEIS%26ticketid%3D3241434%26ticketowner%3D[STAFF]%26ticketsubject%3DHPC%2520Other%2520Issue%253A%2520c24-52%2520%253A%2520cannot%2520log%2520in If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://www.google.com/url?q=https://rt.umbc.edu/Ticket/Display.html?id%3D3241434 Thank You _________________________________________ R e s o l u t i o n: Hi [USER], When slurm encounters errors with jobs (such as OOM issues), it places the nodes into a drained (or draining) state, where no new jobs can be started. However, all currently running jobs would still run until completion (which is why there is still another job running). To see the state of nodes, you can use the 'sinfo' command. Before, you could see that c24-52 was 'draining'. However, since the node itself is fine, I undrained the node. It is now back in a normal state, you should be able to start jobs on it without issue now. -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Mon Aug 11 09:41:50 2025, [USER] wrote: slurmstepd: error: Detected 2 oom_kill events in StepId=278289.0. Some of the step tasks have been OOM Killed. srun: error: c24-52: task 0: Out Of Memory Original Request: Requestors: [USER] First Name: [FIRST_NAME] Last Name: [LAST_NAME] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Cluster Hi, I underestimated amount of memory needed for something I was doing interactively on our machine; so Matlab crashed [fchan, allcoef, rmsperr] = fit_nh3_all_generic(opts); Fitting for: AIRS_L1C,prod_2025,aug2025_saf703,SAF704 Loading merged data file: /asl/s1/[USER]/alldata/ftcprod/prod_2025/airs_l1c/aug2025_saf703/NH3/merged_nh3_data_saf704_all.mat NH3 multiplier: 1 0 26818366 0 Killed [sergio@c24-52 fit_tracegas_refltherm_wrapper]$ exit slurmstepd: error: Detected 2 oom_kill events in StepId=278289.0. Some of the step tasks have been OOM Killed. srun: error: c24-52: task 0: Out Of Memory Anyway then I logged out and tried to start afresh, with more memory but I get this message now srun --cluster=chip-cpu --account=pi_strow --partition=pi_strow --qos=pi_strow --time=1-00:00:00 --x11 --mem=20G --pty $SHELL srun: Required node not available (down, drained or reserved) srun: job 328661 queued and waiting for resources Could you help the poor thing? I still seem to have one other interactive job running on our machine. [USER]"
"3242104","70984948","2025-08-18 18:28:57","Software availability on HPC (chip)","I was able to successfully install IDL version 8.4.1 on chip. You should be able to load it with 'module load idl/8.4.1'. I tested the software with a couple simple commands, just to verify basic arithmetic functionality. However, if you are able to test the software yourself and let us know if you run into any issues, that would be wonderful. For now I will mark this ticket as resolved, if you need any further assistance feel free to submit a new ticket. Have a great day. Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3242104 > Last Update From Ticket: Hi [USER], You're totally right, that's my apologies. For some reason on the interface I'm looking at it wasn't showing it as a link in a way that was obvious. We're working on getting it installed now. Thanks for your patience. On Tue Aug 12 14:01:06 2025, [USER] wrote: Hi [STAFF], The link is highlighted in my email - if you click on Interactive Data Language (IDL) it should show you to the IDL page. Thank you. [USER]. On Tue, Aug 12, 2025 at 10:08 AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3242104 > Last Update From Ticket: Hi [USER], I understand that it may have been available on taki, but due to the sheer volume of modules, it wasn't feasible for us re-install everything that was on taki to chip. We installed some base modules we know people (python, rust, R, git, etc.) and installed new modules as others needed/requested it. It looks like you did not attach the link. Please be advised, generic information about the program is fine, but I will assume the most recent version of IDL is what you would like installed. If there's a specific version number of IDL you would like installed, please specify it or attach the link to the download page. On Tue Aug 12 09:50:31 2025, [USER] wrote: Hello [STAFF], This is a licensed software and was available on taki! This link provides information about Interactive Data Language (IDL). Thank you. [USER]. On Tue, Aug 12, 2025 at 9:05 AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3242104 > Last Update From Ticket: Hi [USER], It looks like that's not a module that anyone has requested before, but we can certainly work to get this installed for you. Could you provide a little more information the version of IDL you would like (a link directly to the download would also be of great help). On Mon Aug 11 11:07:21 2025, [USER] wrote: First Name: [USER]. Last Name: [USER]. Email: [EMAIL]. Campus ID: [CAMPUS_ID]. Hello, I am a UMBC HPC user. I can't find IDL software on chip when I check available modules. I'd appreciate it if you can advise on how to access IDL on chip. Thank you. [USER]"
"3242642","70846639","2025-08-11 21:21:13","HPC Other Issue: Unable to ssh into chip cluster","Hi [USER], The issue has been resolved. You should be able to login now! -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Mon Aug 11 16:14:35 2025, [EMAIL] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Hi all, I was able to login to CHIP a couple of hours ago, but when I try to do so now, I am getting the following error. I have not changed my password or any other credentials lately. Attachment 1: login_error.png"
"3242643","70846861","2025-08-11 21:36:13","HPC Other Issue: unable to connect","worked! thank you so much  The issue has been resolved. Please try to ssh in now - it should work. Thank you. Regards, [STAFF] On Mon Aug 11 16:14:56 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] Request Type:              High Performance Cluster Hi, since this morning I am unable to connect to my account on chip, when I add the password it does not accept it, and after three times of adding the password, it denies the permission. Could you please check what is going on?"
"3242679","70846621","2025-08-11 21:20:17","HPC Other Issue: Chip login issue","Hi [USER], The issue has been resolved. You should be able to login now! -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Mon Aug 11 16:42:36 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster I am unable to log into chip. Please help."
"3242813","70853214","2025-08-12 13:08:18","HPC Other Issue: Port forwarding","Hi [USER], I need a little more information before I'm able to assist you. When you say you ran this on chip, I assume you mean you ran it on either one of the gpu or cpu nodes? If so, how are you running it? Are you using a batch script, or an interactive job? On Mon Aug 11 20:57:53 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [LAST NAME] Email:                     [EMAIL] Campus ID:                 [CAMPUS ID] Request Type:              High Performance Cluster Hello, Following is a code snippet:- 'from circuit_tracer.frontend.local_server import serve port = 8046 server = serve(data_dir='./graph_files/', port=port, host='0.0.0.0') if IN_COLAB: from google.colab import output as colab_output # noqa colab_output.serve_kernel_port_as_iframe(port, path='/index.html', height='800px', cache_in_notebook=True) else: from IPython.display import IFrame print(f'Use the IFrame below, or open your graph here: f'http://localhost:{port}/index.html'') display(IFrame(src=f'http://localhost:{port}/index.html', width='100%', height='800px')) ' I ran this on chip. Please let me know how do I access http://localhost:{port}/index.html from my laptop? -- Best, [STAFF]"
"3242831","70917960","2025-08-14 17:05:50","HPC Slurm/Software Issue: OSError: [Errno 28] No space left on device","Ok, just resubmitted a ticket!  On Thu, Aug 14, 2025 at 12:55 PM [STAFF] via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey. If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at Ticket https://rt.umbc.edu/Ticket/Display.html?id=3242831. Thank You. Hi, I would be happy to assist with your new issue! However, since your original issue was resolved, please open a new ticket for your new issue and we will assist you! Have a nice day! -- Kind regards, [STAFF] On Thu Aug 14 12:36:01 2025, [USER] wrote: Thank you, you were able to resolve my issue however, I now have a new issue. After installing packages, the error message, bitsandbytes/cextension.py', line 263, in throw_on_call raise RuntimeError(f'{self.formatted_error}Native code method attempted to call: lib.{name}()') RuntimeError: CUDA VERSION MISMATCH Requested CUDA version: 12.8 Detected PyTorch CUDA version: 12.8 Available pre-compiled versions: - 12.9 This means The version you're trying to use is NOT distributed with this package Attempted to use bitsandbytes native library functionality but it's not available. To make bitsandbytes work, the compiled library version MUST exactly match the linked CUDA version. If your CUDA version doesn't have a pre-compiled binary, you MUST compile from source. You have two options: 1. COMPILE FROM SOURCE (required if no binary exists): https://huggingface.co/docs/bitsandbytes/main/en/installation#cuda-compile 2. Use BNB_CUDA_VERSION to specify a DIFFERENT CUDA version from the detected one, which is installed on your machine and matching an available pre-compiled version listed above Original error: Configured CUDA binary not found at /umbc/rs/laramar/users/[USER]/conda_envs/codeGen/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda128.so Run this command for detailed diagnostics: python -m bitsandbytes If you've tried everything and still have issues: 1. Include ALL version info (operating system, bitsandbytes, pytorch, cuda, python) 2. Describe what you've tried in detail 3. Open an issue with this information: https://github.com/bitsandbytes-foundation/bitsandbytes/issues Native code method attempted to call: lib.cquantize_blockwise_fp16_fp4() ([USER]@[HOST]) [USER]$ I find this message confusing because the version of CUDA requested is the version found. How should I proceed to remove the error? Thank you,[USER] On Tue, Aug 12, 2025 at 9:27 AM [STAFF] via RT <[EMAIL]> wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3242831 Last Update From Ticket: Hello [USER], Pip works by downloading the necessary files for the packages you are installing into the /tmp directory, and then uses those files to install into your Python environment. After the installation finishes, the downloaded files are removed from the temporary directory. However, for larger packages, /tmp can get filled, throwing errors such as OSError: [Errno 28] No space left on device. In these cases, you need to specify an alternative temporary directory for the installation of those packages. TMPDIR='/umbc/rs/<pi_group>/users/<username>' pip install <package-name> You will get more details on this here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1118765095/What+to+do+if+I+run+out+of+space+in+my+chip+home+directory https://umbc.atlassian.net/wiki/spaces/faq/pages/1129578504/Why+am+I+getting+OSError+Errno+28+No+space+left+on+device+error Please let us know if that resolves the issue or not. Thank you. Best, [STAFF] On Mon Aug 11 21:43:35 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USER] Request Type: High Performance Cluster Previously, I had created a virtual environment with the same packages, but when I tried to create it again, when installing the final package, the error message, pip._vendor.urllib3.exceptions.ProtocolError: ('Connection broken: OSError(28, 'No space left on device')', OSError(28, 'No space left on device')) commands: srun --cluster=chip-gpu --account=pi_laramar --mem=20000 --time=1:00:00 --gres=gpu:1 --pty $SHELL conda create -n codeGen python=3.10 conda activate codeGen conda install conda-forge::pytorch conda install conda-forge::bitsandbytes conda install conda-forge::accelerate conda install nvidia::cuda conda install conda-forge::datasets pip install transformers==4.28.0 pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128 pip install torch ... runs out of space How should I proceed?"
"3243249","70867631","2025-08-12 18:18:43","HPC Slurm/Software Issue: Submitting jobs in Contributor Partitions","Thanks for the prompt response. It is working now! On Tue, Aug 12, 2025 at 1:40 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=[ID]> Last Update From Ticket: Hello [USER], You could do either: Option 1: Change partition=shared to partition=p_i_tjo and qos=long to qos=p_i_tjo. or Option 2 (Use the match partition for shared contributor resources): Change partition=shared to partition=match and ensure qos=shared. Let us know how it goes. For more information, please look at this page. Chip Partitions and Usage - Find Help (FAQs) - Confluence chip-cpu QOS Restrictions - Find Help (FAQs) - Confluence Thank you. Best, [STAFF] On Tue Aug 12 12:12:53 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster Hello, my PI is a contributor, and I haven't been able to submit jobs in the contributor partitions. Is there anything I need to do before it can work? Also, I wanted to check if I have access to submitting jobs with unlimited time? This is the script I am using: #!/bin/bash #SBATCH --job-name=eps100 #SBATCH --cluster=chip-cpu #SBATCH --mem=500 #SBATCH --time=05-00:00:00 #SBATCH --qos=long #SBATCH --account=p_i_tjo #SBATCH --partition=shared source /umbc/rs/tjo/common/groupshared/[USER]/myfeasst/feasst-envs/rxn2/bin/activate python launch_1_slit_pore_rxn.py And I get this error: sbatch: error: invalid partition specified: shared sbatch: error: Batch job submission failed: Invalid partition name specified"
"3243275","70862657","2025-08-12 16:46:14","HPC User Account: [USER] in Student Group","This account request was made in error - another RT ticket has been submitted for having this student join a PI group instead of the Student Group. Best, [STAFF]. On Tue, Aug 12, 2025 at 12:31 PM RT API via RT [EMAIL] wrote: Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=3243275 > Last Update From Ticket: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Cluster Create/Modify account in Student group CPU resources will be utilized to perform Monte Carlo simulations using the MCCCSMN software, DFT calculations using ASE and GPAW, and to run ML programs written in Python and Julia."
"3243297","70881906","2025-08-13 13:40:02","HPC User Account: [USER] in tjo","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) I recommend stepping through the Getting Started on Chip tutorial to learn more about how to use the chip! Here is the link: https://umbc.atlassian.net/wiki/x/R4BPQg -- Kind regards, [STAFF] (DoIT Unix Infra Student Worker) On Tue Aug 12 12:43:34 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster Create/Modify account in existing PI group Existing PI Email: [EMAIL] Existing Group: [STAFF] Project Title: AI & Theory-Oriented Molecular Science Project Abstract: The ATOMS lab at UMBC uses molecular simulation and machine learning to gain molecular-scale insights on processes in the environment to enable new solutions for cleaner air and water. CPU resources will be utilized to perform Monte Carlo simulations using the MCCCSMN software, DFT calculations using ASE and GPAW, and to run ML programs written in Python and Julia. GPU resources will be used to run MLIP calculations in g-RASPA."
"3244009","70886468","2025-08-13 14:56:40","HPC New Group: [ID]","Hi [USER], To answer some of your questions.. 1. User names are assigned based on your UMBC ID. Some people, such as yourself, setup a username for UMBC instead of keeping the default Campus ID. In this case, since your UMBC ID is [STAFF], your account on chip will have the same username. 2. Unfortunately, the documentation is out of date, and the 250GB quota no longer reflects the default for new PI groups on chip. Now, the default quota for new PI groups is 10TB, which is what your group now has! 3. Lastly, you are correct -- scratch space is only meant for transient storage while your job is running. When you job finishes, access to the storage space is removed and the data stored there is as well. Each node on chip has its own individual local scratch space, so even if it was saved for x amount of time after your job completes, it would only be located on the node your job ran on. For this reason, data does not remain after the job finishes. To work around this, at the end of your job, after the main processing completes, you can copy the data stored in the scratch space over to your research volume for long term storage. Anyways -- I created a new group and user account for you, here is the information regarding both of those: The group pi_[STAFF] now exists on the chip cluster. Members of this group can therefore access and contribute to the research storage space allocated to the group. This storage is located at /umbc/rs/pi_[STAFF] and currently has a quota of 10T. Your account ([STAFF]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) If you have any issues or need further assistance, feel free to submit a new ticket! Have a nice day! Kind regards, [STAFF] DoIT Unix Infra Student Worker On Wed Aug 13 10:33:06 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Cluster Group Type: Project Title: [PROJECT_TITLE] Project Abstract: [PROJECT_ABSTRACT] I'm not sure how you assign user account names, but please could mine be [STAFF] rather than the '[CAMPUS_ID]' alphabet soup? From reading the documentation, the default research volume size is 250GB, please could I request an increase? My research will fill that quite quickly, and on previous HPCs I've worked with I find that 2-3TB is a better minimum for my work, particularly for when I hopefully have students in the future. Also, please could I clarify whether there is a non-transient scratch space? Previous systems I've worked with have a high I/O scratch that can host files for ~1 month, but it seems that scratch here is just whilst a job is running? Thanks!"
"3244480","70917536","2025-08-14 16:51:54","HPC User Account: [USER] in Student Group","Sorry for bugging you. Now, people tell me that it works.  It must have been the 12 hours when I could not log in either.  You can close this ticket.  [STAFF], Professor of Mathematics Department of Mathematics and Statistics Center for Interdisciplinary Research and Consulting (circ.[DOMAIN]) [DOMAIN] High Performance Computing Facility (hpcf.[DOMAIN]) REU Site: Online Interdisciplinary Big Data Analytics ([PROJECT].[DOMAIN]) University of Maryland, Baltimore County 1000 Hilltop Circle, Baltimore, MD 21250 http://www.[DOMAIN]/~[USER] On Thu, Aug 14, 2025 at 10:40 AM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hi [USER], We've done nothing that would cause them to lose access, and I was still able to access their accounts as normal. Can you be more specific about the error they are seeing when they try to login? Are these all users who are facing this issue? On Wed Aug 13 15:57:44 2025, [USER] wrote: First Name: [USER] Last Name: [STAFF] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Create/Modify account in Student group Hi, this request concerns all students in the [PROJECT] Site. It is true that the full-time program runs in the summer and ended 08/01/2025. But the participants still need access to [SERVER] to finish the paper and research. Can the accounts please be extended to 12/31/2025 (or a similar date around there). Some students report that they seem to be unable to log in to [SERVER]. If this is not looking like this to you, please check what else could be the problem. The [DOMAIN] level sponsorship is until 12/31/2025, which I am certain about, since I did that. The users are: [EMAIL], [EMAIL], [EMAIL], [EMAIL], [EMAIL], [EMAIL], [EMAIL], [EMAIL], [EMAIL] Best, [STAFF]"
"3244918","70918194","2025-08-14 17:16:32","Large space for ML training dataset","Got it. Thank you so much [STAFF]. Have a great day.  Sincerely [USER] Our system uses an application called autofs, that keeps large directories from being constantly mounted unless someone tried to access them. Your group directory is also a little bit of a special case as it exists under /umbc/rs/pi_[STAFF] instead of the usual /umbc/rs/[STAFF]. If you type 'alias' you can see you have a direct command to your research space: [USER]@chip ~]$ alias alias egrep='egrep --color=auto' alias fgrep='fgrep --color=auto' alias grep='grep --color=auto' alias l.='ls -d .* --color=auto' alias ll='ls -l --color=auto' alias ls='ls --color=auto' alias pi_[STAFF]_common='cd /umbc/rs/pi_[STAFF]/common' alias pi_[STAFF]_user='cd /umbc/rs/pi_[STAFF]/users/[USER]' alias sinfo='sinfo -M chip-cpu,chip-gpu -p 2024,2021,2018,general,gpu' alias squeue='squeue -M chip-cpu,chip-gpu' alias xzegrep='xzegrep --color=auto' alias xzfgrep='xzfgrep --color=auto' alias xzgrep='xzgrep --color=auto' alias [STAFF]_ada='cd /umbc/ada/[STAFF]' alias zegrep='zegrep --color=auto' alias zfgrep='zfgrep --color=auto' alias zgrep='zgrep --color=auto' [USER]@chip ~]$ pi_[STAFF]_common [USER]@chip common]$ pwd /umbc/rs/pi_[STAFF]/common Hopefully that helps! Hi [STAFF], Thank you very much. In 'research volumes' I didn't see my advisor Prof. [STAFF]'s folder. Do we need to apply for it? Can I apply for it or it must be Prof. [STAFF] to apply for it? [USER]@[SERVER] rs]$ pwd /umbc/rs [USER]@[SERVER] rs]$ ls adali cybertrn ferraro gokhale hbarbosa iharp kekechen nasa-access psanjay vitals zmclaren bennettj doit gobbert halem hpcreu jkestner manas pi_lobo sjkim vjaneja zzbatmos [USER]@[SERVER] rs]$ Thank you very much. Sincerely,[USER] Hi [USER], I would recommend reading this page: https://umbc.atlassian.net/wiki/spaces/faq/pages/1072267344/Storage#Accessing-Research-Volumes All PI's have access to 'research volumes' that are significantly larger than the home directories available to users. If this is your first time using chip I would also recommend reading this page: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip Please let me know if you have more questions. First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: Help with something else Hi officer, Hope you are doing well. I'm CS PhD student under Prof. [STAFF]. also noticed this article https://umbc.atlassian.net/wiki/spaces/faq/pages/1118765095/What+to+do+if+I+run+out+of+space+in+my+chip+home+directory It says each user has only 500MB space? What if we need 100GB for machine learning model training dataset? Could you please help guide me? Thank you so much."
"3245081","70942699","2025-08-15 18:01:23","HPC Slurm/Software Issue: bitsandbytes library load error: Configured CUDA binary not found","The provided text appears to be an email chain between Paul Abili (QD36016) and Danielle Esposito, a DoIT Unix Infra Student Worker at the University of Maryland, Baltimore County (UMBC). The conversation revolves around a CUDA version mismatch error that Paul encountered while compiling his code on the High-Performance Cluster.  Here's a summary of the conversation:  1. Paul Abili submits a request to the IT department, reporting an error message when compiling his code on the HPC cluster. He attaches a text file with the error message. 2. Danielle Esposito responds, explaining that the error is due to a CUDA version mismatch between the requested and detected versions (12.8 vs 12.9). She suggests loading the correct CUDA module using `module load CUDA/12.8.0`. 3. Paul tries this solution but still encounters issues. He provides more information about his code, including the commands he ran. 4. Danielle responds again, pointing out that there might be a mismatch between the CUDA versions requested by the Python packages and the currently loaded CUDA version. She suggests checking the `module list` output to verify which CUDA version is loaded. 5. Paul reports back with the `module list` output, showing that CUDA/12.9.0 is loaded. Danielle advises him to specifically load the desired version (CUDA/12.8.0) using the command she provided earlier. 6. The conversation ends with a final response from Danielle, providing additional information and resources for resolving the issue.  Key points:  * The initial error message was due to a CUDA version mismatch between 12.8 and 12.9. * Danielle suggested loading the correct CUDA module using `module load CUDA/12.8.0`. * Paul provided more context about his code, including the commands he ran. * Danielle pointed out potential issues with the CUDA versions requested by Python packages and the loaded version. * The conversation provides a step-by-step exchange between Paul and Danielle as they troubleshoot the issue.  If you'd like me to extract any specific information or clarify certain points, please let me know!"
"3245219","70934759","2025-08-15 13:55:18","HPC User Account: [ID] in particle therapy","Hi [USER], Your user has been added to [SERVER] as a secondary group. Please read through the documentation found at [WEBSITE]. Please submit additional questions or issues as separate tickets via the following link (https://[WEBSITE]/request-tracker-rt/[CATEGORY]/). Kind regards, [STAFF] DoIT Unix Infra Student Worker On Thu Aug 14 14:43:48 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Create/Modify account in existing PI group Existing PI Email:    [EMAIL] Existing Group:       [GROUP] Project Title:        Quantitative numerical analysis in Medical Treatment Project Abstract:     In order to optimize the particle therapy treatment, in particular, proton therapy it is required to perform the sensitive analysis on topics such as particle range uncertainties, dose calculations, organ cavity filling layers, image guidance, etc."
"3245429","71293061","2025-08-28 12:59:05","HPC Other Issue: [USER] account to be transferred to [STAFF]'s group","Good morning, So sorry for how long this took, but your change in primary group has been moved to pi_[STAFF]. You now have access to the common directory in /umbc/rs/pi_[STAFF]/common, and a personal directory in /umbc/rs/pi_[STAFF]/[USER]. If you have any other issues, please don't hesitate to reach out. On Tue Aug 19 16:25:02 2025, [STAFF] wrote: Dear [USER], I approve [USER]'s request. Thank you Mohamed [STAFF]. On Tue, Aug 19, 2025 at 4:21 PM [USER] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3245429> Last Update From Ticket: Hi [STAFF], I have cc-ed Professor [STAFF] here as well. Here are the followings: *Existing pi_group:* Professor [STAFF] *Project Title:* Deep learning-based analysis of tumor margins in oral squamous cell carcinoma *Project Abstract:* Oral squamous cell carcinoma (OSCC) is a common and aggressive cancer where accurate detection of tumor margins is critical for treatment. In this project, we use whole-slide images scanned with Aperio to classify three key tissue types: morphologically normal margin (MNM), dysplasia, and tumor. Image patches are extracted from WSIs and used to train convolutional neural networks (CNNs). A baseline ResNet-18 model is implemented, with comparisons to ResNet-50 and VGG-16. We evaluate model performance with accuracy and F1-score, and use Grad-CAM for interpretability. This study aims to demonstrate the feasibility of deep learning in assisting pathologists by improving margin classification, offering a step toward faster and more reliable oral cancer diagnosis. Since, moving forward, I will not work with the previous group (pi_[STAFF]), I believe not using their resources would be the best practice. Many thanks, [USER]. On Mon, Aug 18, 2025 at 5:23 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3245429> Last Update From Ticket: Hello [USER], I hope this message finds you well. I would be happy to add you to Professor [STAFF]'s group once we get approval from him. There is also some additional information needed to do this such as Existing pi_group: Project Title: Project Abstract: Once this information is filled out alongside approval from the pi owner, I can proceed with adding you to this group. I see you are in pi_[STAFF] group is this what you would like to be removed from? Best regards, [STAFF]. -- Best, [STAFF] DOIT HPC System Administrator"
"3245853","70947274","2025-08-15 19:54:16","HPC Other Issue: Making directories under common","Hi [USER], I have gone ahead and fixed the permissions issue! Your user now owns the research volume (and should have before, however there appears to be a bug in one of our scripts). If you attempt to create a file/directory in the common directory of your research volume, it should now work without issue. Also, just letting you know, no one besides system administrators have permission to use the sudo command, so you would not have been able to use that. If you run into any further issues, feel free to submit a ticket! Have a nice day! -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Fri Aug 15 11:50:44 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Hello, A new group has been created for my group with the user name [USER]. I would like to make directories under /umbc/rs/pi_[USER]/common however it seems like I did not have permission. Before using the sudo command, I wanted to consult with you. Best regards,"
"3245857","71088395","2025-08-21 17:42:21","HPC Slurm/Software Issue: Heasoft install","Dear [USER], Thank you very much for setting up Heasoft for me and my students. Apologies for the late reply. I was working at a panel last week and this week was basically a catch-up with work game :)  Heasoft is a set of data reduction and analysis tasks for high energy astrophysics missions.  I confirm that me and the students could load the module and could initialize a subroutine. However, it will take some time to test it as it has other dependencies that we are working on at the moment.  I will keep you posted. Best regards, [STAFF] was able to successfully compile HEAsoft version 6.35.2 on chip. You should be able to load it with 'module load heasoft/6.35.2'. To be completely honest, [STAFF] have no clue what this software is used for/how to use/verify it is functioning as expected. So if you are able to test it out yourself, and let me know if it is working as expected, that would be wonderful. I can also provide documentation on how to compile the software on chip yourself if the module ends up not working. For now, I will close this ticket. But if you are able to test it, feel free to reply to this ticket with whether or not it works! [STAFF] has been in the process of looking into setting up and compiling the HEAsoft module on slurm. This is taking a little more time than expected. However, there are other methods available for using the HEAsoft software. If you take a look at the website for HEAsoft, which i will link below, you can find out information about the various options available. The easiest option (and to be honest, what seems to be recommended by the devs) is to use the conda packages. You can create a conda environment, and install the listed HEAsoft packages from conda-forge. Alternatively, you could compile the software yourself and run it that way. Either option would work! Link: https://heasarc.gsfc.nasa.gov/docs/software/heasoft/ Nonetheless, I will keep working on the HEAsoft install, and I will let you know regarding the status of that! Have a nice day! [USER] was not able to find heasoft in the available module list. Is heasoft available on Chip?"
"3245898","70943177","2025-08-15 18:12:15","HPC User Account: [ID] in [USER]","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) Kind regards, [STAFF] DoIT Unix Infra Student Worker On Fri Aug 15 12:37:06 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Create/Modify account in existing PI group Existing PI Email: [EMAIL] Existing Group: [GROUP] Project Title: AI Agents in Healthcare Project Abstract: Create privacy aware agents that can handle sensitive medical data to automize tasks such as appointment scheduling, insurance verification, analyzing health records, etc. The abstract and title will change in the future as I explore more and really hone in on what the project will be."
"3246512","70987684","2025-08-18 19:07:26","HPC Other Issue: [USER] requesting help to submit the job","Got it, thanks On Mon, Aug 18, 2025 at 3:06 PM [STAFF] via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3246512&ticketowner=[STAFF]&ticketsubject=HPC Other Issue Requesting help to submit the job If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note A full record of your request can be found at Ticket https://rt.umbc.edu/Ticket/Display.html?id=3246512 Thank You Hi [USER], Yes. Currently, you are unable to use the GPUs in the reservation. The reservation is for your entire pi_group, so all of pi_manas has access to this reservation. Currently, [USER] is running a job on g24-09 that is using both H100 gpus. You will not be able to start a job using those GPUs while another job is already using them. It appears the requested job has a 10 day time limit-- so I am not sure when it will finish. But your job will be able to run on the reservation when that job finishes running. Kind regards, [STAFF] On Mon Aug 18 14:35:34 2025, [USER] wrote Actually i am not able to use my reserved gpu. Roy has given me access to this. But still my jobs are in the queue, and I am not able to access the gpu. `[~]$ scontrol -M chip-gpu show reservation manas ReservationName=manas StartTime=2025-08-06T19:47:00 EndTime=2025-08-20T19:46:00 Duration=13-23:59:00 Nodes=g24-09 NodeCnt=1 CoreCnt=32 Features=(null) PartitionName=(null) Flags=IGNORE_JOBS,SPEC_NODES TRES=cpu=32 Users=(null) Groups=(null) Accounts=pi_manas Licenses=(null) State=INACTIVE BurstBuffer=(null) Watts=n/a MaxStartDelay=(null) `[~]$` This is the ssh file that i am making #!/bin/bash #SBATCH --cluster=chip-gpu #SBATCH --account=pi_manas #SBATCH --reservation=manas #SBATCH --job-name=mistral_phi # Job name #SBATCH --mail-user=[EMAIL] # Where to send mail #SBATCH --mem=44G # Job memory request #SBATCH --gres=gpu:1 # Number of requested GPU(s) #SBATCH --time=100:00:00 #SBATCH --constraint=H100 # Time limit days-hrs:min:sec #SBATCH --error=logerror/jupyter2.log # Error file name #SBATCH --output=logerror/jupyter2.log # Output file name python imhi_5_tokens_test_final.py On Mon, Aug 18, 2025 at 10:15 AM [STAFF] via RT <[EMAIL]> wrote If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3246512&ticketowner=[STAFF]&ticketsubject=HPC Other Issue Requesting help to submit the job If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note A full record of your request can be found at Ticket https://rt.umbc.edu/Ticket/Display.html?id=3246512 Thank You Hi [USER], After reviewing the error message you provided, I can see the issue is due to omitting the --account=pi_manas flag in sbatch/srun commands. If you add this to your SBATCH file, you should be able to request a job on your reservation without issue. Have a nice day Kind regards, [STAFF] On Mon Aug 18 10:04:50 2025, [USER] wrote This error is coming when i submit the job sbatch: error: Batch job submission failed: Access denied to requested reservation On Mon, Aug 18, 2025 at 9:36 AM [STAFF] via RT <[EMAIL]> wrote Ticket https://rt.umbc.edu/Ticket/Display.html?id=3246512 Last Update From Ticket Hi [USER], Could you please share what error you are receiving when you attempt to run that sbatch file In your initial message, there was no indication of the error received. My best guess without knowing the exact issue is that you require '#SBATCH --account=pi_manas' in your sbatch file. Let me know what the exact error you are receiving is, and I can better help assist you. Kind regards, [STAFF] On Sat Aug 16 17:54:24 2025, [USER] wrote First Name [USER] Last Name [USER] Email [EMAIL] Campus ID [USER] Request Type High Performance Cluster Hi Team, I hope you’re doing well. I was submitting my jobs using the reservation I had taken, but I’m currently unable to use it. Could you please check and let me know if there’s an issue with my .ssh file #!/bin/bash #SBATCH --cluster=chip-gpu #SBATCH --reservation=manas #SBATCH --job-name=mistral_phi              # Job name #SBATCH --mail-user=[EMAIL]       # Where to send mail #SBATCH --mem=44G                    # Job memory request #SBATCH --gres=gpu:1                     # Number of requested GPU(s) #SBATCH --time=100:00:00 #SBATCH --constraint=H100                    # Time limit days-hrs:min:sec #SBATCH --error=logerror/jupyter2.log                # Error file name #SBATCH --output=logerror/jupyter2.log               # Output file name python  imhi_5_tokens_test_final.py Thanks [USER]"
"3246824","70958728","2025-08-17 22:03:42","HPC Slurm/Software Issue: General slurm issue","Hi [USER],  It works now. Thank you so much for the quick fixing and response on the weekend. I really appreciate this. Have a good rest of the weekend.  Thanks, [USER]  On Sun, Aug 17, 2025 at 5:56 PM [STAFF] via RT <[EMAIL]> wrote:  > Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3246824 >  > Last Update From Ticket:  > Hello [USER],  > It looks like we had an issue on the management node that caused the Slurm database to fail, which is what was causing the error you were seeing. I've fixed this, and in my testing was able to run squeue and other slurm commands with success.  > When you have a chance, could you try running squeue (or any other slurm command) and see if it works for you now?  > I apologize for any inconvenience this may have caused.  > Thank you,  > [STAFF]  On Sun Aug 17 16:09:13 2025, [USER] wrote:  > First Name:                [USER]  > Last Name:                 [USER]  > Email:                     [EMAIL]  > Campus ID:                 [CAMPUS_ID]  > Request Type:              High Performance Cluster  > Hi Officer,  > Hope you have a great weekend.  > I found this error message on CHIP. It looks there are some issue on slurm. Could you please help check out? Thank you very much.  > $ squeue --me  > squeue: error: slurm_persist_conn_open: Something happened with the receiving/processing of the persistent connection init message to master:6819: Unable to connect to database  > squeue: error: Sending PersistInit msg: Unable to connect to database  > squeue: error: slurm_persist_conn_open: Something happened with the receiving/processing of the persistent connection init message to master:6819: Unable to connect to database  > squeue: error: Sending PersistInit msg: Unable to connect to database  > squeue: error: DBD_GET_CLUSTERS failure: Unable to connect to database  > squeue: error: Problem talking to database  > squeue: error: There is a problem talking to the database: Unable to connect to database.  Only local cluster communication is available, remove --cluster from your command line or contact your admin to resolve the problem."
"3246838","70958839","2025-08-17 22:48:28","HPC Slurm/Software Issue: squeue not working","Thanks, it worked. All is well. :) On Sun, Aug 17, 2025 at 5:57 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3246838 > Last Update From Ticket: Hello [USER], It looks like we had an issue on the management node that caused the Slurm database to fail, which is what was causing the error you were seeing. I've fixed this, and in my testing was able to run squeue and other slurm commands with success. When you have a chance, could you try running squeue (or any other slurm command) and see if it works for you now? I apologize for any inconvenience this may have caused. Thank you, [STAFF] On Sun Aug 17 17:01:49 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] Request Type:              High Performance Cluster When I type 'squeue -u [USER]', the output is: 'squeue: error: slurm_persist_conn_open: Something happened with the receiving/processing of the persistent connection init message to master:6819: Unable to connect to database squeue: error: Sending PersistInit msg: Unable to connect to database squeue: error: slurm_persist_conn_open: Something happened with the receiving/processing of the persistent connection init message to master:6819: Unable to connect to database squeue: error: Sending PersistInit msg: Unable to connect to database squeue: error: DBD_GET_CLUSTERS failure: Unable to connect to database squeue: error: Problem talking to database squeue: error: There is a problem talking to the database: Unable to connect to database.  Only local cluster communication is available, remove --cluster from your command line or contact your admin to resolve the problem.' This issue is new and only started this afternoon (4 PM 8/17 at the earliest)"
"3246852","71387774","2025-09-02 17:00:59","HPC Slurm/Software Issue: libpng.so and libwrap.so dependencies","I have installed the libpng-devel package across the Chip cluster, and have verified that /usr/lib64/libpng.so is available. However, as far as we can tell the libwrap-devel package is not available on Red Hat Enterprise Linux 9, which is what we're running on Chip. This seems to be because the functionality provided by the package was deprecated in RHEL 7.4 and removed in RHEL 8, in favor of newer tools like systemd and firewalld: https://access.redhat.com/solutions/3906701 unfortunately this documentation is behind a Red Hat access subscription, but I can get it to you if you wish. In this case, to build Geant4/DCMTK we would suggest you try to use apptainer. Using apptainer, you'd create a container using an older Red Hat version that has libwrap-devel (it looks like RHEL 7 still has the package available) or a different Linux distribution like Ubuntu 24.04 or Debian 13 that still has libwrap-dev available for their current versions. We have instructions for how to get started with apptainer on the HPCF wiki: https://umbc.atlassian.net/wiki/spaces/faq/pages/1398407192/Apptainer+on+Chip+via+Slurm and we will be more than happy to assist you with using it. I apologize for the delay in resolving this issue and for omitting that crucial piece of info as to why it wasn't as simple as just installing a couple of packages on the cluster. Thank you, [STAFF]. On Tue Sep 02 08:39:44 2025, [USER] wrote: Correction, they're called libpng-devel and libwrap-devel. The suggested fix https://github.com/justadudewhohacks/opencv4nodejs/issues/595 is to install libpng-devel which will populate /usr/lib64/libpng.so https://commandfound.com/post/libpnglib-not-found-centos/ and libwrap-devel (or tcp-wrappers?) which will populate /usr/lib64/libwrap.so https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/6/html/security_guide/sect-security_guide-tcp_wrappers_and_xinetd. On Tue Sep 02 08:37:45 2025, [USER] wrote: Is it possible to schedule a virtual meeting to resolve this issue? This is time-sensitive. On Thu Aug 28 12:33:42 2025, [USER] wrote: Is there any update on this issue? On Sun Aug 24 15:33:36 2025, [USER] wrote: Hello [STAFF], The error is persistent between Cmake versions. What's happening is that the compilation requires this dependency because of DCMTK (a package which handles DCM images from CT scans, etc) and it's just not there. For instance, the same code is running on my colleague's cluster at another institution, they have not been able to run this particular code since the transition to chip, and we are trying to help them. They are asking us in fact why this has not been fixed, so this issue is urgent, frankly. On Fri, Aug 22, 2025 at 3:05PM [STAFF] via RT <[EMAIL ADDRESS]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3246852> Last Update From Ticket: Hello [USER], Could you provide me more information to help me diagnose your issue - e.g. what version of CMake are you using, and the steps you're taking to build your Geant4 project? We've had other researchers compile Geant4 projects on Chip in the past, so I'm hoping to find what's different between your build and the others that have succeeded. Thank you, [STAFF]. On Sun Aug 17 18:31:29 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL ADDRESS] Campus ID: OT40491 Request Type: High Performance Cluster I'm trying to compile a Geant4/DCMTK project on Chip (CMake and Make), but I don't have any way of pointing cmake somewhere other than /usr/lib64/libpng.so and /usr/lib64/libwrap.so (otherwise I would try to install these things myself and point it there). make[2]: *** No rule to make target '/usr/lib64/libpng.so', needed by 'dicom/dicomReader/libdicomReader.so'. Stop. make[2]: Leaving directory '/umbc/rs/hpcreu/users/[USER]/2025_Summer_BigDataREU/PJMC/DCMTK_PJMC/build' make[1]: *** [CMakeFiles/Makefile2:140: dicom/dicomReader/CMakeFiles/dicomReader.dir/all] Error 2 make[1]: Leaving directory '/umbc/rs/hpcreu/users/[USER]/2025_Summer_BigDataREU/PJMC/DCMTK_PJMC/build' make: *** [Makefile:147: all] Error 2. The suggested fix https://github.com/justadudewhohacks/opencv4nodejs/issues/595 is to install libpng-devel which will populate /usr/lib64/libpng.so https://commandfound.com/post/libpnglib-not-found-centos/ and libwrap-devel (or tcp-wrappers?) which will populate /usr/lib64/libwrap.so https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/6/html/security_guide/sect-security_guide-tcp_wrappers_and_xinetd. Could you install this for me? Thanks. Best, [STAFF] DOIT HPC System Administrator"
"3248789","71201804","2025-08-25 21:34:23","Need help with updated storage (Research Volumes)","Hi [USER],  I had seen the Chip outage email. And I was able to login and run jobs normally on Chip.  Thank you for everyone's help in this matter.  Best, [STAFF] On Mon, Aug 25, 2025 at 4:54 PM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hi [USER], You may have seen the messages on the hpc mymbc page (if you're not following I suggest you do), https://my3.my.umbc.edu/groups/hpcf. We had an unplanned outage, that should be resolved at this point. Please give it a try and let us know if you have any more issues. On Mon Aug 25 10:50:59 2025, [USER] wrote: Thank you, [STAFF]! I was trying to run a few jobs and test the migration, but I am not able to login. Is there a downtime scheduled for Chip that is not communicated? I will try again after sometime today if it is just a temporary issue. [USER] On Fri, Aug 22, 2025 at 2:38 PM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Yay! Thank you so much. [USER], would you mind running something to test it? All the best, [STAFF] On Fri, Aug 22, 2025 at 2:36 PM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hello [STAFF], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_[STAFF]. The alias used to reach the volume is now pi_[STAFF]_common and pi_[STAFF]_user. Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF] On Fri Aug 22 10:42:14 2025, [STAFF] wrote: Today still works! Go for it! Thanks for taking care of this. All the best,[STAFF] On Fri, Aug 22, 2025, 10:05 AM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Good morning [STAFF], I apologize for the delay, but if today still works for you then I can do the migration today. All I'll need is for you to make sure your students aren't running any jobs on Chip, else I will need to terminate them to complete the migration. If that's too short of a time frame, then we can move forward with the 26th. Thank you, [STAFF] On Thu Aug 21 17:22:01 2025, [STAFF] wrote: Hi [STAFF], Thanks for the information. I asked my students and I got 2 date suggestions: tomorrow (22nd) or the 26th. Let me know if these are too soon and you need a date farther out. Regardless of what date works for y'all, I ask that you let me know when you plan to move things so that I can tell everyone. All the best,[STAFF] On Thu, Aug 21, 2025 at 11:28 AM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hello [USER], That is because [STAFF]'s storage volume has not been migrated over to the new storage server, and thus is still using the old quota that was assigned. We will need to work with her to schedule a date where we can perform the migration. [STAFF], Since you're CC'd on this ticket: as per the communication via myUMBC earlier this summer (https://my3.my.umbc.edu/groups/hpcf/posts/150838), DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 206GB of a 250GB quota on the old storage server. To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at “/umbc/rs/[STAFF]”. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. Below we’ve listed two options for handling this data migration - please let us know which of these you’d prefer. Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day. Option 2: If you don’t respond to this email by October 15th, DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes. Note: After this process has completed, the new storage volume will have a new name. For example, group “pi_doit” will find its data under “/umbc/rs/pi_doit”, or in your group’s case you will find your volume under “/umbc/rs/pi_[STAFF]”. Thank you, [STAFF] On Tue Aug 19 12:34:12 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: Help with something else Hi, I need help with updating the research volume storage for my PI group ([STAFF]). This was mentioned in HPCF's May newsletter. It currently shows 250 GB. I believe it should be 10 TB now. Thanks!"
"3250512","71086121","2025-08-21 16:47:08","HPC User Account: [USER] in -","Hi [STAFF], Thanks, it worked. Best regards, [USER] On Thu, Aug 21, 2025 at 7:36 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.um= bc.edu/Ticket/Display.html?id=3250512> Last Update From Ticket: Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[USER]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link (https://doit.um= bc.edu/request-tracker-rt/doit-research-computing/) You can also view your project abstract here (https://hpcf.um= bc.edu/[USER]-nasa-gsfc-center-for-space-sciences-and-technology/) Try accessing chip and let me know if you are running into any issues Best regards, [STAFF]"
"3251019","71093608","2025-08-21 19:24:11","HPC Other Issue: [USER]s cannot access chip","Yes, no problem, glad everything worked out! Best regards, [STAFF]"
"3251176","71087088","2025-08-21 17:12:31","HPC User Account: [USER] in pi_[ID]","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) Your project abstract can be viewed here (https://hpcf.umbc.edu/[STAFF]-nasa-gsfc-center-for-space-sciences-and-technology/) Best regards, [STAFF]"
"3251701","71201542","2025-08-25 21:21:22","HPC Slurm/Software Issue: ERROR: Could not install packages due to an OSError: [Errno 28] No space left on device","Thank you On Mon Aug 25 2025 at 1 00 PM [STAFF] via RT UMBCHelp rt umbc edu wrote If you agree your issue is resolved please give us feedback on your experience by completing a brief satisfaction survey https //umbc us2 qualtrics com/SE/SID=3DSV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=3DEIS&ticketid=3D3251701&ticketowner=[EMAIL]&ticketsubject=3DHPC Slurm Software Issue ERROR Could not install packages due to an OSError [Errno 28] No space left on device If you believe your issue has not been resolved please respond to this message which will reopen your ticket Note A full record of your request can be found at Ticket https //rt umbc edu/Ticket/Display html?id=3D3251701 Thank You Hi After looking through the path you provided I believe I have found the issue I am guessing that perhaps you previously had cache symbolically linked to your research volume So when attempting to copy the current cache folder it got upset because it was already there But nonetheless for cache it is safe to just delete This folder serves as a download cache for pip packages so it will just cause pip to redownload packages when requested First delete the cache folder in both your research vol and home folder rm -rf /home/[USER]/cache rm -rf /umbc/rs/laramar/users/[USER]/cache Then make a new cache directory in your research vol umbc/rs/laramar/users/[USER]/cache Lastly symlink the new cache to your home folder ln -s /umbc/rs/laramar/users/[USER]/cache ~/.cache That should resolve the issues for you Let me know if you continue to run into issues with this Have a nice day On Sat Aug 23 20 23 23 2025 [USER] wrote Hi I attempted to move the cache folder with mv ~/.cache /umbc/rs/pi_laramar/users/[USER]/cache mv cannot overwrite non-directory '/umbc/rs/pi_laramar/users/[USER]/cache/.cache' with directory '/home/[USER]/cache' Should I simply delete the cache folder inside of /umbc/rs/pi_laramar/ or will that lead to further complications Alternatively should I just delete the cache folder inside of the home directory and attempt to create a symbolic link to /umbc/rs/ I'm not sure how to proceed Thanks On Fri Aug 22 2025 at 10 21 AM [STAFF] via RT UMBCHelp rt umbc edu wrote If you agree your issue is resolved please give us feedback on your experience by completing a brief satisfaction survey https //umbc us2 qualtrics com/SE/SID=3DSV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=3DEIS&ticketid=3D3251701&ticketowner=[EMAIL]&ticketsubject=3DHPC Slurm Software Issue ERROR Could not install packages due to an OSError [Errno 28] No space left on device If you believe your issue has not been resolved please respond to this message which will reopen your ticket Note A full record of your request can be found at Ticket https //rt umbc edu/Ticket/Display html?id=3D3251701 Thank You Hi It appears that your home directory is out of storage space which is causing the errors you are getting However it is not the specific model that you are attempting to use that is the issue You already symbolically linked the mistral_models directory to your research volume which is great But when using pip to install packages it attempts to write to a hidden directory in your home directory which can get filled up quickly depending on what you are installing The solution for this issue is the same as you did for the mistral_models directory First move the cache folder to your users research volume then create a symbolic link that points to its new location Here is some documentation on how to go about doing that https //umbc atlassian net/wiki/spaces/faq/pages/1118765095/What+to+do+if+I+run+out+of+space+in+my+chip+home+directory#2-Use-Symbolic-Links-to-redirect-data-to-your-research-volume If you run into any issues with this process feel free to let me know Have a great day On Thu Aug 21 21 30 31 2025 [USER] wrote First Name [USER] Last Name [USER] Email [EMAIL] Campus ID [CAMPUSID] Request Type High Performance Cluster I was attempting to install Mamba-Codestral-7B-v0 1 While installing ... File '/umbc/rs/laramar/users/[USER]/conda_envs/codeGen/lib/python3 10/site-packages/pip/_internal/utils/logging py' line 197 in emit self handleRecord record Message '%s %s' Arguments 'Preparing metadata pyproject toml' 'finished with status 'done'' ERROR Could not install packages due to an OSError [Errno 28] No space left on device I recall running out of space with a pip install so I ran with the command TMPDIR='/umbc/rs/laramar/users/[USER]' pip install mistral_inference>=1 mamba-ssm causal-conv1d Is there anything I could do to increase my storage or should I use a different model Thank you"
"3252267","71121835","2025-08-22 18:46:00","HPC Other Issue: Requesting H100 for 30B parameter model","I've created a reservation on g24-02 that will expire in two weeks. I'll mark this as resolved. ReservationName=[RESOURCE] StartTime=2025-08-22T14:44:00 EndTime=2025-09-05T14:44:00 Duration=14-00:00:00 Nodes=g24-02 NodeCnt=1 CoreCnt=32 Features=(null) PartitionName=(null) Flags=IGNORE_JOBS,SPEC_NODES TRES=cpu=32. As a note, I get each RT ticket sent to [TEAM] to my inbox by default, so there's no need to CC me or send a separate email. -- [STAFF]"
"3253414","71639199","2025-09-12 17:25:35","HPC Other Issue: Class accounts for [COURSE] students","Hi [STAFF], This is an excellent point and something we'll consider for the creation of future classes. I've gone ahead and removed the two students who left the class. On Tue Sep 09 09:19:37 2025, [USER] wrote: Hi [STAFF], Good question. Thanks for keeping it open. Indeed, no additional students added the class during drop/add schedule adjustment period. However, some dropped. Should we 'shut down' or close somehow these ones? Namely, checking classlists and such, the following two could be deleted: [USER]  [EMAIL] [USER]  [EMAIL] They really left after the first class meeting. So, chances are that their directories are empty. If I can discuss another fine point, the permissions of the user directories are [gobbert@chip-login2 math447fa25]$ ll users/ drwxr-S---+ 2 [USER]  math447fa25 0 Aug 26 14:38 [USER]/ drwxr-S---+ 5 [USER]  math447fa25 3 Sep 4 11:20 [USER]/ drwxr-S---+ 5 [USER] math447fa25 3 Sep 3 20:53 [USER]/ drwxr-S---+ 2 [USER]  math447fa25 0 Aug 26 14:35 [USER] Do I see this right that each student can read 'r' each other's directory? Can we maybe remove that 'r' permission? It is not logical that students in a class should read each other's directory. They do homework in there after all. Of course, if two students wanted to share, they could change the permissions, but it should maybe not be the default. On Tue, Sep 9, 2025 at 9:04 AM [STAFF] via RT wrote: Ticket Last Update From Ticket: Hi [STAFF], Can I close this ticket out? On Tue Aug 26 21:31:55 2025, [USER] wrote: Thank you, [STAFF]! Of course, just now chip seems to have a problem again; I cannot log in; I will file a ticket. Yes, we need to keep this ticket open, since students can still register for the class for more than 10 days, the drop/add period. On Tue Aug 26 14:03:22 2025, [USER] wrote: Hi [STAFF], Sorry to not get to this fast enough. Yes, they can use the 2024 partition. This is all the information we need. The class will be given 5TB of storage space. I will let you know once the group has been made and you and your students have been added. On Tue Aug 26 13:26:06 2025, [USER] wrote: Hi, I would have preferred a round of e-mails (here in ticket) to lay out the setup, but I cannot wait now. My class starts Thursday, but we really need the accounts set up on Wednesday as early as possible. The list below are students in Math 447/627. Please create their accounts on chip. We used to put students in a 'student' group. But I seem to recall that you want to create a Unix group for each class like 'Math447627' or similar (I do not care deeply about the name). Like we did this summer for the REU Site students and the SEA students, I suggest that the students get access to the 2024 partition. The load from the homework in my class will be light, like jobs running seconds if using many nodes; but having access to many nodes is vital to see speedup. [USER] [USER] [EMAIL] [USER] [EMAIL] [USER] [EMAIL] [USER] [EMAIL] [USER] [EMAIL] [USER] [EMAIL] On Sun Aug 24 21:57:11 2025, [USER] wrote: First Name: [USER] Last Name: [STAFF] Email: [EMAIL] Campus ID: [USER] Request Type: High Performance Cluster Hi, We need to create chip accounts for the students in my MATH 447/627. There are only about 7 at present, so a small class. I would wait until late Tuesday before filing the request to allow for more to join. Is there a typical system for how to set up classes already? What information do you need? Can we let them use the 2024 partition? [USER]"
"3253736","71200996","2025-08-25 21:04:55","HPC Other Issue: Unable to access CHIP","Hi [STAFF], I'm able to access [SYSTEM] and all my research work. I have NOT scheduled jobs and so cannot vouch for that bit, but am able to access everything as intended. Thanks! On Mon, Aug 25, 2025 at 5:01 PM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hello, It looks like the issues with [SYSTEM] have been resolved on our end, however we would like to verify this on the user's end. Could you verify if you are still having issues within [SYSTEM]? (Logging in, accessing research volume, accessing existing files/work in research volume) Best regards, [STAFF]"
"3253841","72244864","2025-10-13 18:12:57","DUA with CCBC-Questions","Hi [USER], Box is a cloud platform and we do have a DUA with Box, if that's what the researcher was looking for. I am not familiar with from where the cybersecurity insurance comes from, but I'll ask around. In the meantime, let me know if there are other questions related to this and we can get the answers to you more quickly. Hi [USER] On Mon Aug 25 10:46:42 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: Help with something else Hello All, I'm working on a DUA with CCBC for a PI here at UMBC, presently they have the following questions: Whether the UMBC Box is a cloud based storage platform and, if so, whether there are any third party agreements with vendors for cloud based storage of data uploaded to the Box? UMBC's cybersecurity insurance coverage I was able to let them know that Box is cloud based but I'm not sure about the later half of their question. Additionally I'm unsure if we have separate cybersecurity insurance or if this is apart of the state of Maryland's liability insurance coverage. Thank you! [USER]"
"3254000","71200181","2025-08-25 20:45:25","HPC Other Issue: [USER] Downtime","Hello. It looks like the issues with CHIP have been resolved on our end, however we would like to verify this on the user's end. Could you verify if you are still having issues within CHIP? (Logging in, accessing research volume, accessing existing files/work in research volume). Best regards, [STAFF]."
"3254005","71211771","2025-08-26 13:34:34","HPC Other Issue: no connection to [ID] from outside","I guess, my mail crossed yours here. Sorry to create confusion.  Yes, no rush. On Tue, Aug 26, 2025 at 9:21 AM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: We'll work on getting this connection opened up, but please allow us some time as a good portion of our staff is out today. On Tue Aug 26 09:14:30 2025, [USER] wrote: Hi [STAFF], We had a user try to run a computationally intensive job on the login node. This is one of the things we're going to be attempting prevent in the future with the schedule downtime that's upcoming. As for scp'ing from linux.gl, is that something you've been able to do in the past? I spoke with some of the other team members who maintain that environment and they said in general they try to keep gl pretty isolated from other environments don't think we should be allowing that kind of access. On Mon Aug 25 16:58:03 2025, [USER] wrote: Hi, [STAFF], Yes, it works now. What was really the problem? And can you please tell me how to ssh from linux.gl to chip.rs? It's not really the ssh that I need in the end, but the scp. So, this really needs to work and should work in both directions. This is what I currently see: [USER]@linux6 ~]$ ssh -p 22 chip.rs.umbc.edu ssh: connect to host chip.rs.umbc.edu port 22: No route to host Thanks, On Mon, Aug 25, 2025 at 4:46 PM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hello, It looks like the issues with CHIP have been resolved on our end, however we would like to verify this on the user's end. Could you verify if you are still having issues within CHIP? (Logging in, accessing research volume, accessing existing files/work in research volume) Best regards, [STAFF]"
"3254007","71200352","2025-08-25 20:49:13","HPC Other Issue: Can't connect to chip","Hello, It looks like the issues with CHIP have been resolved on our end, however we would like to verify this on the user's end. Could you verify if you are still having issues within CHIP? (Logging in, accessing research volume, accessing existing files/work in research volume) Best regards, [STAFF]"
"3254244","71199544","2025-08-25 20:33:09","HPC Other Issue: Unable to access files on CHIP since this morning's outage","Yes that works normally now On Mon Aug 25 2025 at 3 16 PM [STAFF] via RT <[EMAIL]> wrote Ticket Last Update From Ticket Hi [USER] We believe the issue has been resolved Can you attempt to access your research volumes and let us know if it works as expected Thanks Kind regards [STAFF] DoIT Unix Infra Student Worker On Mon Aug 25 14 31 15 2025 [USER] wrote Hi [USER] Apologies for the issue with accessing research volume files We are currently looking into the issue now Kind regards [STAFF] DoIT Unix Infra Student Worker On Mon Aug 25 13 44 03 2025 [USER] wrote First Name [USER] Last Name [USER] Email [EMAIL] Campus ID [ID] Request Type High Performance Cluster You may already be aware but since the outage was fixed I am not able to access my usual directory on chip for some reason -bash cd /umbc/rs/[USER]/users/[USER] Permission denied"
"3254269","71194450","2025-08-25 19:21:48","HPC Other Issue: [USER] cannot access folders","Yes it's working now, thank you! On Mon, Aug 25, 2025 at 3:18 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3254269> Last Update From Ticket: Hi [USER], We believe the issue has been resolved. Can you attempt to access your research volumes and let us know if it works as expected? Thanks! -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Mon Aug 25 14:34:39 2025, [CAMPUSID] wrote: Hi [USER], Apologies for the issue with accessing research volume files. We are currently looking into the issue now. -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Mon Aug 25 13:53:03 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster I cannot access any of my files and it says I don't have permission to enter those directories. -bash: cd: /umbc/rs/tjo/common: Permission denied"
"3254273","71194544","2025-08-25 19:22:46","HPC Slurm/Software Issue: Cannot access working directories","Thank you for the quick resolution, I can access it alright now. On Mon Aug 25 15:17:36 2025, [STAFF] wrote: Hi [USER], We believe the issue has been resolved. Can you attempt to access your research volumes and let us know if it works as expected? Thanks! Kind regards, [STAFF] (she/her/hers) DoIT Unix Infra Student Worker On Mon Aug 25 14:33:58 2025, [STAFF] wrote: Hi [USER], Apologies for the issue with accessing research volume files. We are currently looking into the issue now. Kind regards, [STAFF] (she/her/hers) DoIT Unix Infra Student Worker On Mon Aug 25 13:53:49 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Hi, We are not able to (me and other students in our group cc'd here, PI: [STAFF] cc'd here) access our usual working directory (umbc/rs/[STAFF]/users/....) on chip-- says permission denied. Can you please help us resolve this issue?"
"3254332","71195187","2025-08-25 19:30:08","HPC Other Issue: Permissions Issues","Everything appears to be working now.  Thank you very much! [STAFF] On Mon, Aug 25, 2025 at 3:15 PM [STAFF] via RT <[EMAIL]> wrote: Ticket  Last Update From Ticket: Hi all, We believe the issue has been resolved. Can you attempt to access your research volumes and let us know if it works as expected? Thanks! Kind regards, [STAFF] On Mon Aug 25 14:33:33 2025, [USER] wrote: Ok, thank you. We understand these things happen when there's an outage, especially on a newer setup like chip. Please let us know when we have access to our volumes again. [USER] On Mon, Aug 25, 2025, 14:31 [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hi all, Apologies for the issue with accessing research volume files. We are currently looking into the issue now. Kind regards, [STAFF] On Mon Aug 25 14:21:02 2025, [USER] wrote: Hello, I am seeing the same error, even as PI of the group bennettj_pi and can not login to either the common shared directory or our research space. Thank you,[USER] On Mon, Aug 25, 2025, 14:12 RT API via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: First Name: [STAFF] Last Name: [STAFF] Email: [EMAIL] Campus ID: UMXXXX Request Type: High Performance Cluster Hello, I seem to have no permissions to cd into any directory. When I log in, I'm able to list the contents of my home directory, but can't cd into any other directory. -bash: cd: bennettj_user/: Permission denied Also, when I try to auto-complete with the tab button (bash shell), it doesn't work either. Thank you, [STAFF]"
"3254400","71200441","2025-08-25 20:52:35","HPC Other Issue: Lost access to /umbc/rs/pi_[STAFF]/users/[ID]/doom","It looks good right now! Thanks again! On Mon, Aug 25, 2025 at 4:46 PM [STAFF] via RT <[EMAIL]> wrote: Ticket [URL: https://rt.[DOMAIN]/Ticket/Display.html?id=3254400] Last Update From Ticket: Hello, It looks like the issues with CHIP have been resolved on our end, however we would like to verify this on the user's end. Could you verify if you are still having issues within CHIP? (Logging in, accessing research volume, accessing existing files/work in research volume) Best regards, [STAFF]"
"3254721","71310642","2025-08-28 17:33:40","HPC Slurm/Software Issue: conda issues","Thank you. On Thu Aug 28 2025 at 930AM [STAFF] via RT <[EMAIL]> wrote If you agree your issue is resolved please give us feedback on your experience by completing a brief satisfaction survey https//umbc.us2.qualtrics.com/SE/SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3254721&ticketowner=[STAFF]&ticketsubject=HPC Slurm/Software Issue conda issues If you believe your issue has not been resolved please respond to this message which will reopen your ticket Note A full record of your request can be found at Ticket https//rt.umbc.edu/Ticket/Display.htmlid=3254721 Thank You Hi [USER] Weve gone ahead and modified the script we use to export the necessary conda packages to now account for the ceph directories In the future you can always export these yourself by modifying your .bashrc and .bash_profile files and adding the following lines to it export CONDA_ENVS_PATH=/path/to/file export CONDA_PKGS_PATH=/path/to/file export CONDA_PKGS_DIRS=/path/to/file On Mon Aug 25 182007 2025 [USER] wrote First Name [USER] Last Name [USER] Email [EMAIL] Campus ID [CAMPUSID] Request Type High Performance Cluster When attempting to create a new conda virtual environment conda create -n codeGen python=310 I recieved the following error NoWritablePkgsDirError No writeable pkgs directories configured - /umbc/rs/laramar/users/[USER]/conda_pkgs Notably on last friday the lab account was moved for larger storage From /umbc/rs/laramar/ To /umbc/rs/lpi_aramar/ I noticed in the error the previous storage location was referenced how should I proceed Thank you"
"3255302","71742627","2025-09-16 21:09:29","iHARP: AWS -- Add users to AWS projects","[STAFF], This has been done. Please let me know if there are reports of problems. Have a nice day. -- [STAFF] DoIT, Windows System Administrator [EMAIL]"
"3255308","72245081","2025-10-13 18:22:52","iHARP: AWS Account","Sorry for the wait here, [USER]. I've added these three users to Project 10. On Tue Aug 26 11:55:20 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [ID] Request Type:              Help with something else Please add users: [USER], [USER], [USER] to Project X aws account 700664161370."
"3255322","71868883","2025-09-22 20:30:00","iHARP: AWS New [USER] + add to account","Hi [STAFF], Mostafa has been added to project 12. We've been rearranging permissions and responsibilities for adding users, so this is now a task I'll share with [STAFF]. You can always use this link to get to the enclave: https://awsresearchlogin.umbc.edu/. On Mon Sep 22 14:23:02 2025, [USER] wrote: Hi All, Ticket was submitted at the end of August we are approaching the end of September, our credits expire at the end of December. Any updates would be greatly appreciated. We are trying to generate products and usable outcomes for the grant. On Mon Sep 15 12:27:11 2025, [USER] wrote: Gentle nudge on update please. :) User is asking for accession. thank you! On Tue Aug 26 11:58:10 2025, [USER] wrote: Request Type: Help with something else. Please create new user: Mostafa Cham, Username: mcham2. Add to AWS project XII account number 240282106583"
"3255328","71349639","2025-08-29 18:40:04","iHARP: AWS User Report","Hi [STAFF], The suggested reports would be great, he's been the primary/ the only person utilizing those projects. thank you! Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=3D[NUMBER]> Last Update From Ticket: Hello! So, this isn't something we can get for you. Usage of resources isn't logged as a time per user (or cost) thing. I recommend only giving the user access to the account desired (one or more AWS accounts) and watching the spend there. We can give you login reports, if you think he's the only one running things in certain accounts. Please let me know. [STAFF] On Thu Aug 28 15:19:04 2025, [USER] wrote: Hi All, If possible, would I be able to have the report by end of day on Tuesday, September 2? On Tue Aug 26 12:01:05 2025, [USER] wrote: Request Type: Help with something else Hi All, would you kindly run a report on the AWS usage of User: [USER] on all assigned accounts? Please run for the full duration of the reporting period you are able to. We are focusing on what resources are being used, duration of resources, and any information related to his spend habits. Please note this report is being requested by the PIs so they may be able to talk to the user regarding AWS usage. If you have any questions, please let me know."
"3255454","71227029","2025-08-26 17:08:38","UMBC HPCF","Hi [USER], There are no costs to get started on chip! You can have as many users as you would like under your group, and your group will have access to 10TiB of storage by default. By default you will only have access to the general partitions on chip-cpu, but you will have access to all nodes on chip-gpu. Additional computing power or storage is available, but requires a buy-in of some kind (depending on what you need more of). You can find more information on what is currently offered here https://umbc.atlassian.net/wiki/spaces/faq/pages/1289486353/Cluster+Specifications. If you have more questions, please reach out! On Tue Aug 26 12:52:12 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] Request type:                 General Support Hello, I'm writing a grant proposal for a project that would plan to use the HPCF. Are there any related costs I should include in a budget, like for use or storage? Please advise. Thank you, [USER] Department of Marine Biotechnology [EMAIL]."
"3255485","71230708","2025-08-26 18:10:33","HPC User Account: [ID] in pi_[ID]","Hi [USER], Your account ([STAFF]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) On Tue Aug 26 13:34:43 2025, [STAFF] wrote: Hello, I'm writing to approve this account creation request. [STAFF] On Tue, Aug 26, 2025 at 1:15 PM RT API via RT <[EMAIL]> wrote: This e-mail is a notification that a UMBC user: [USER] <[EMAIL]> has requested an account within UMBC's HPC environment in your group <pi_[STAFF]>. As the PI, we request that you acknowledge and approve this account creation by replying to this message. Alternatively you can go to this link and review the ticket and indicate your decision here: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3255485> Once we have your approval, we will create the account and you and the new user will receive another e-mail notifying you that the account has been created. If you have any other questions or concerns please contact us. - UMBC DoIT Research Computing Support Staff Best, [STAFF] DOIT Unix infra, Graduate Assistant"
"3256084","71339851","2025-08-29 15:08:45","HPC Other Issue: Getting error on chip","Hi [USER], The error is more or less telling you what the problem is. The RTX8000 doesn't support the specific operation you're trying to run. This can happen if you try to run code that you developed on more advanced gpus such as the L40S or H100s. After a little bit of digging, it appears that the bf16 was developed using the ampere architecture of GPUS which was started with the A100, so the only gpus in our system that would be able to run this natively is the h100 and l40s cards. Hopefully this helps. Let me know if you have more questions. On Wed Aug 27 13:23:56 2025, [USER] wrote: Hello, I am getting a different error now. Following is the error:- 'Internal error (Illegal instruction). Please report this bug. /home/[USER]/.local/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:2177: UserWarning: Quadro RTX 8000 does not support bfloat16 compilation natively, skipping' I am running on rtx_8000. I have Python/3.10.4-GCCcore-11.3.0-bare module loaded. This error comes when I am trying to execute my code 'final_entity.py' that is doing model inferencing. I have loaded gemma-scope conda environment. File path is : '/umbc/[STAFF]/users/[USER]/MI_ADV/mi' Regards, [USER] On Wed, Aug 27, 2025 at 6:14 AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3256084 > Last Update From Ticket: Hi [USER], We need a lot more information before we are able to assist. Can you give an example of the 'simple command' you are trying to run? What node are you trying to run this on, and from where? Your research volume? Do you have any modules loaded? Please try to give us as much information as possible to attempt to replicate your issue. The more information you give us the faster we can work on this. On Tue Aug 26 20:48:05 2025, [USER] wrote: > First Name:     Nilanjana > Last Name:      Das > Email:          [EMAIL] > Campus ID:      [ID] > Request Type:   High Performance Cluster > Hello, on chip even when I try to run a simple command like clear I am getting the error:- 'Illegal instruction (core dumped)'. Please help. Best, [STAFF] DOIT HPC System Administrator"
"3256116","71291511","2025-08-28 12:32:49","HPC Other Issue: chip does not allow login","The provided text appears to be an email conversation between Matthias Gobbert and the UMBC Help Desk, specifically with Roy Prouty and Max Breitmeyer, regarding issues with connecting to a server called 'chip.rs.umbc.edu' using SSH.  The main issue is that Matthias is able to connect to another server, 'linux.gl', but not to 'chip.rs.umbc.edu', despite using the same tools and methods. The error message suggests that there may be an issue with SSH keys on Matthias' end.  Max Breitmeyer asks Matthias to run the SSH command with the '-vvv' flag to provide more information on where SSH is looking for the keys. Max also suggests deleting the PuTTY session and restarting it to ensure a clean start.  The conversation does not seem to have reached a resolution, as the last message from Max is asking Matthias to try running the SSH command with the '-vvv' flag.  There is no specific question or request in the provided text that requires a step-by-step response. However, if I were to provide a response based on the context of the conversation, it would be:  To troubleshoot the issue with connecting to 'chip.rs.umbc.edu', please try running the SSH command with the '-vvv' flag and send the output to the UMBC Help Desk for further analysis. Additionally, you can try deleting the PuTTY session and restarting it to ensure a clean start."
"3256263","71267853","2025-08-27 16:42:08","HPC Other Issue: PI Group Creation","Hello [USER], Your PI will need to request a group through an RT ticket. You can find more information on how to request a ticket here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1327431728/How+to+request+a+user+group+account+on+chip. A user can be a member of more than one PI groups. You will have access to both PI's groups research storage and will be able to submit a job under both group accounts. We will not be creating a new account for you, you will just be a member of two groups. On Wed Aug 27 08:06:32 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster I have a couple of questions regarding cluster usage. 1) What would be the process to create a new group for a PI? I am the lab manager for [STAFF]'s CDL, and we are looking to utilize the HPC clusters for some of the work we are doing. 2) Can a user have multiple accounts on the cluster under different groups? For example, I currently have an account under pi_[USER]. Am I allowed to have another account under the pi_[STAFF] group, or will my current account be shared under both user groups? I am curious about how the space allocation would work in this case. I am guessing I will have two directories pointing to two different partitions? Thanks, [USER]"
"3257585","71293114","2025-08-28 13:00:12","HPC User Account: [ID] in Student Group","Hi [USER], An account has already been made for you in the class per [STAFF]'s request. Thanks On Thu Aug 28 08:41:22 2025, [EMAIL] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Create/Modify account in Student group Hello, My name is [USER] and I am enrolled in MATH 447 with Professor [STAFF] and need an account created. Thank you, [USER] Best, [STAFF]"
"3258113","71338663","2025-08-29 14:45:48","HPC Other Issue: Which GPU is fast?","Hi [USER], We just noticed that you have a new ticket with more clarification and trying to submit a job on the h100s. I have merged the two tickets. As [STAFF] clarified, we don't expect similar jobs to take this long to run compared to A100s. There are other dependencies to be considered that affects performance things like: your code, where your data is stored, number of gpu's allocated and how much data is being processed. You new ticket shows that you are submitting a job to the H100 nodes. The h100s have more gpu memory compared to L40s and you may see improved performance if the problem with your previous jobs is gpu power. Your new slurm script looks correct. Your job is still pending, that is why your not getting an allocation. In your script you requested 2 gpu's, currently there is only 1 h100 gpu available. Thus, your job is pending until the physical resource you requested is available. Once the other jobs complete, your job will start running. I will mark the ticket resolved for now, you can reopen the ticket if you have related questions. On Fri Aug 29 10:06:03 2025, [STAFF] wrote: Hi [USER], Are you certain that your code is actually utilizing the GPUs? L40S and A100 GPUs have very similar performance (though the A100 has more VRAM), it should not result in taking 14 days compared to 40 minutes. What are you attempting to run? Please share the path/location of the code you are running. -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Thu Aug 28 13:57:42 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] Request Type:              High Performance Cluster Hello, I am struggling with a very slow feature extraction codes, while for me it takes 14 days to complete, same task for my college, who is at another university with A100 NVDIA GPUs it takes only 40 minutes! I need to connect to the much fastest GPUs available? How can I do that? Thank you!"
"3258199","71390771","2025-09-02 17:46:36","HPC Slurm/Software Issue: ecCodes Module Installation","The module, libfabric/1.11.0-GCCcore-10.2.0, does exist and is loadable on chip. When attempting to load the ecCodes module on my personal account, I ran into no issues and was able to use grib commands as expected. However, I tested loading the ecCodes module on [USER]'s account and was able to replicate their issue. It appears that something specific to [USER]'s user account is causing the module to fail loading. After taking a look into [USER]'s .bashrc file, I can see that they are loading some modules, specifically 'module load ROOT/6.24.06-foss-2021b'. This appears to be loading a bunch of modules that are likely incompatible with the ecCodes-2.20.0 module, which causes the issue when loading ecCodes. I was able to verify this by running 'module reset' and then attempting to load ecCodes again (successfully), along with manually loading the 'module load ROOT/6.24.06-foss-2021b' module and verifying the error occurred again when loading ecCodes 2.20.0. Is there a specific reason [USER] requires version 2.20.0 of ecCodes? I installed version 2.24.2, which is compatible with the same toolchain that ROOT/6.24.06-foss-2021b uses, so it is able to be loaded and used without issue. If [USER] requires version 2.20.0, I can attempt to install a version of ROOT that is compatible with the toolchain used there. Let me know if either of these solutions works for [USER]. Thank you for installing the modules. [USER]'s having an issue loading it though. hlewis3@c24-52:v1$ module load ecCodes/2.20.0-gompi-2020b; Lmod has detected the following error: These module(s) or extension(s) exist but cannot be loaded as requested: 'libfabric/1.11.0-GCCcore-10.2.0' Try: 'module spider libfabric/1.11.0-GCCcore-10.2.0' to see how to load the module(s). Seemingly because of this error, the grib commands (from ecCodes) are run, they aren't found. bash script calling grib (after successful ecCodes loading): ## Run ecCodes grib command in terminal window to translate specific variables in grib file to csv grib_ls 'era_year${year}_month${month}.grib'; grib_get_data -p shortName,dataDate,dataTime,stepRange 'era_year${year}_month${month}.grib'> 'era_year${year}_month${month}.csv' This is reflected in the error output, seeming to indicate 'libfabric' isn't loading: Lmod has detected the following error: These module(s) or extension(s) exist 1 but cannot be loaded as requested: 'libfabric/1.11.0-GCCcore-10.2.0' stdout: new.sh: line 81: grib_ls: command not found new.sh: line 82: grib_get_data: command not found [USER] tried loading the package manually with 'module load libfabric/1.11.0-GCCcore-10.2.0 but that didn't change anything. The line in new.sh which generates the LMod error is just loading the ecCodes module itself. ##Load ecCodes module if ! module is-loaded ecCodes/2.20.0-gompi-2020b; then module load ecCodes/2.20.0-gompi-2020b; fi [STAFF] installed the ecCodes/2.20.0-gompi-2020b module on chip, as well as a newer version too, ecCodes/2.31.0-gompi-2023b. Let [USER] know if they experience any issues when using these modules. Have a nice day! First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster [USER]'s research colleague was utilizing the ecCodes/2.20.0-gompi-2020b module on Taki, but Chip has no such module. https://www.ecmwf.int/en/elibrary/80526-eccodes Could [STAFF] please install it?"
"3258270","71317701","2025-08-28 19:24:37","HPC Other Issue: how to get h100 gpu","First Name: [USER] Last Name: [STAFF] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster Hello, I need significantly fast GPUs. I see h100 gpus are available. sinfo -o '%N %G %C' CLUSTER: chip-cpu NODELIST GRES CPUS(A/I/O/T) c18-[01-42],c21-[01-18],c24-[01-52] (null) 1904/3800/0/5704 CLUSTER: chip-gpu NODELIST GRES CPUS(A/I/O/T) g20-12 gpu:7 4/92/0/96 g24-[09-10] gpu:2 2/62/0/64 g20-[01,03,05-11,13] gpu:8 58/902/0/960 g20-02 gpu:5 0/96/0/96 g20-04,g24-[01-08,11-12] gpu:4 27/389/0/416... And I am requesting that using slurm job id: [ID]. The slurm file path: cd /umbc/rs/[STAFF]/users/[USER]/[FILE_PATH]. Although it seems it is available, it does not give me those GPUs. I have these constraint on my slurm file: #SBATCH --cluster=chip-gpu #SBATCH --account=[ACCOUNT] #SBATCH --job-name=[JOB_NAME] #SBATCH --output=[OUTPUT_FILE] #SBATCH --error=[ERROR_FILE] #SBATCH --partition=gpu #SBATCH --gres=gpu:2 #SBATCH --mem=225G #SBATCH --time=48:00:00 #SBATCH --constraint=h100. How can I get h100 gpus ?"
"3259121","71960110","2025-09-26 14:15:26","HPC Other Issue: Add [USER] to my Unix group","Thank you! And thanks for the quick fix the other day with explanation; it is fascinating how one permission can cause this problem! Yes, you can close this. Ticket https://rt.[USER]/Ticket/Display.html?id=[NUMBER] Last Update From Ticket: Hi [USER], You mention explicitly unix groups, but that's not what allows users to access your slurm partition. Can you clarify what you want to do with these users? On Fri Aug 29 14:02:23 2025, [STAFF] wrote: First Name:[USER] Last Name:[USER] Email:[EMAIL] Campus ID:[CAMPUS_ID] Request Type: High Performance Cluster Hi, Would you please add the following users as secondary members to my Unix group on chip? I presume, this automatically gives them access to my slurm account, right? [USER], [USER], [USER], [USER] This is for [USER] from [DEPARTMENT] and three of his students. I hope this is clear like this. [USER]."
"3259589","71386660","2025-09-02 16:39:04","HPC User Account: [ID] in statistics","Hello [STAFF] and [USER], I wasn't able to find an existing group for [STAFF] on our cluster chip. In order to add [USER] as a user, a new ticket needs to be submitted by the PI ([STAFF]) requesting the creation of a group. The ticket should include details about the research project, and list of users. [STAFF] can submit a request via UMBC RT tickets following this link: (https://rtforms.umbc.edu/rt_authenticated/doit/DoIT-support.php?auto=Research Computing). Once that request is submitted, I will proceed with creating the group and adding [USER] as a user. On Sun Aug 31 02:54:34 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [ID]. Request Type:              High Performance Cluster. Create/Modify account in existing PI group Existing PI Email:    [EMAIL] Existing Group:       statistics Project Title:        Robustness of Deep-learning survival models Project Abstract:     We are working on it.  I am a PhD. Student and need help to compute a bulky simulation study."
"3259745","71374212","2025-09-02 13:37:25","HPC Other Issue: Error Submitting Job with Reserved GPU","Hello [USER], I am seeing there's no reservation for '[SERVER]', which means it currently does not exist in the system. To proceed, please submit a reservation request via another ticket. I think [STAFF] has to request that reservation. Thank you. Best, [STAFF]. On Sun Aug 31 22:52:14 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [USER] Request Type:              High Performance Cluster Hello, I’m writing to report an error when attempting to use the reserved GPU under [STAFF]'s group (CC'd). Each submission returns the following message: 'sbatch: error: Batch job submission failed: Requested reservation is invalid' Below is the SLURM configuration used in the submission file: #SBATCH --job-name=train_dp                        #SBATCH --mem=120G                                  #SBATCH --output=slurm_logs/STL/unet%j.out               #SBATCH --error=slurm_logs/STL/unet%j.err        #SBATCH --account=pi_[STAFF]     #SBATCH --reservation=[SERVER] #SBATCH --cluster=chip-gpu  #SBATCH --cpus-per-task=8  #SBATCH --gres=gpu:4         #SBATCH --ntasks-per-node=4            #SBATCH --time=00-23:50:00 Currently, the GPUs are fully occupied, and our group is waiting to access computing resources. Could you please help us check this issue? Thank you for your assistance. Best regards, [USER]."
"3260523","72186877","2025-10-09 15:53:06","HPC Slurm/Software Issue: Problem with mpi4py","The issue at hand involves the use of MPI (Message Passing Interface) and mpi4py on a high-performance cluster. The user is experiencing issues with MPI processes not being utilized correctly, resulting in incorrect test results.  To address this issue, I would recommend the following steps:  1. **Verify MPI installation**: Ensure that MPI is properly installed and configured on the cluster. Check the version of MPI and its compatibility with the used software (e.g., Anaconda3). 2. **Check mpi4py installation**: Verify that mpi4py is correctly installed and imported in the Python environment. You can use `pip show mpi4py` to check the version and location of mpi4py. 3. **Use mpirun correctly**: When executing the Python script, make sure to use `mpirun` with the correct options. For example, `mpirun -np $(nproc) python -c 'from mpi4py import MPI; print(f'Rank {MPI.COMM_WORLD.Get_rank()} of {MPI.COMM_WORLD.Get_size()}')'`. 4. **Avoid loading OpenMPI module**: As suggested by Danielle Esposito, try not loading the OpenMPI module when using mpi4py, as it may cause conflicts. 5. **Check environment variables**: Ensure that the environment variables (e.g., `PATH`) are set correctly to include the MPI and mpi4py installations.  Additionally, I would like to clarify a few points:  * The warning message about Open MPI's OFI driver detecting multiple equidistant NICs is not directly related to the issue at hand. It's more of a performance-related warning. * The test results showing 'Hello from rank 0 of 2' instead of the expected 36 thresholds might be due to the incorrect usage of `mpirun` or issues with the MPI installation.  If these steps do not resolve the issue, please provide more details about your environment, code, and error messages for further assistance."
"3260816","71403384","2025-09-02 20:47:43","HPC User Account: [ID] in Student Group","Hello [USER]. The student group isn't active anymore. In order to have access to Chip (HPC), you need to be a user under your PI's (Faculty or Professor) group. If you are working with a faculty, a new ticket needs to be submitted by them requesting the creation of a group. In the ticket, they will need to provide details about the research project, and list of users. Once that request is submitted, I will proceed with creating the group and adding you as a user. On Tue Sep 02 15:15:48 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] Request Type:              High Performance Cluster Create/Modify account in Student group I am requesting HPCF access to support my graduate research on GNN-based radio signal strength prediction and uncertainty modeling. High-performance computing resources will allow me to efficiently run my models and manage datasets that might be difficult to run on a personal computer. Thank you."
"3261039","71404310","2025-09-02 22:05:14","HPC Other Issue: so when is the cluster down, today or tomorrow???","Hi [STAFF], Please excuse the error in the date. I will update it immediately. The downtime is tomorrow.  On Tue, Sep 2, 2025 at 6:03PM RT API via RT <[EMAIL]> wrote:  > Tue Sep 02 18:03:14 2025: Request [ID] was acted upon. Transaction: Ticket created by [USER]. Queue: DoIT-Research-Computing. Subject: HPC Other Issue: so when is the cluster down, today or tomorrow???. Owner: Nobody. Requestors: [EMAIL]. Status: new. Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=[ID]>. First Name: [USER]. Last Name: [USER]. Email: [EMAIL]. Campus ID: [CAMPUS_ID]. Request Type: High Performance Cluster. Recieved this just now! REMINDER: Downtime starting 0800 09/02/2025 Good afternoon all, A reminder to all users, tomorrow will be our scheduled downtime from 0800 to 1800. During this time, users will not have access to the cluster, and new jobs may not be submitted. Additionally, jobs submitted that were already submitted and run into the downtime may be cancelled, so checkpoint your data if you have any jobs running. -- V/R, [STAFF]"
"3261046","71638372","2025-09-12 17:03:09","HPC Other Issue: GPU reservation.","We apologize for the late reply. As of September 2, our Slurm resource allocation model has been updated to improve resource utilization. We don't reserve nodes anymore. As a contributing PI, you group now has priority access to a dedicated node. When a user in your group submits a job, any non-priority jobs currently running will be preempted, allowing your group's job to begin immediately. More information can be found on the announcement here: https://my3.my.umbc.edu/groups/hpcf/posts/152071 On Tue Sep 02 18:13:13 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] Request Type:              High Performance Cluster I purchased a GPU at UMBC HPCF and would like reserve it for my group to use it. Please help with it. Thanks!"
"3261556","71424356","2025-09-03 16:24:46","HPC Other Issue: Dedicated access to GPU nodes","Hello [USER]. It is not possible to reserve a node for your group. Groups that contributed towards purchasing 2024 chip gpu nodes are the ones that get dedicated access and reserve nodes. On Wed Sep 03 11:48:59 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [LAST NAME] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Hello, We need dedicated access to a worker node with 4 GPU cards (preferably RTX 6000 or RTX 8000) for the next one month for our project on Anomaly Detection. Is this possible on chip? What is the process to get started on this? By dedicated access, I mean we should be able to run a job on that node whenever we need, and no one else should be able to run jobs on that node for the required time period. Thank you. Regards, [USER] Best, [STAFF]."
"3261710","71481618","2025-09-05 14:33:14","HPC User Account: [USER] in LARA Lab","The account for [USER] and [USER] has been created on chip.rs.umbc.edu. Their primary group is pi_[STAFF]. Their home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. They can find instruction on how to get started on chip at this page: https://[DOMAIN]/wiki/spaces/faq/pages/[NUMBER]/Getting+Started+on+chip. Please submit additional questions or issues as separate tickets via the following link. (https://[DOMAIN]/request-tracker-rt/[DEPARTMENT]/). On Wed Sep 03 13:18:47 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster Create/Modify account in existing PI group Existing PI Email: [EMAIL] Existing Group: [GROUP] Project Title: [PROJECT] Abstract: Guardrails for code generation & RAG research. I'd like to make accounts for [USER] ([ID]) and [USER] ([ID]), please."
"3261717","71427968","2025-09-03 17:30:43","HPC Other Issue: Access to chip","Hi [USER], The original post, sent yesterday afternoon, had a typo and meant to say September 3rd. The post has been corrected to reflect the actual timeline of the outage, September 3rd 0800 - 1800. For more information, check out the myUMBC post: https://my3.my.umbc.edu/groups/hpcf/posts/151573 Kind regards, [STAFF] DoIT Unix Infra Student Worker On Wed Sep 03 13:22:03 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Hi there, In the previous email it was mentioned that there will be a outage on 2nd September. However, I can't access to chip today also. Is the outage still active ?"
"3261770","71460823","2025-09-04 17:41:57","HPC Slurm/Software Issue: Cant login to CHIP","Hi [USER], The downtime ran longer than originally anticipated. It was completed yesterday evening. However, as stated in both of the recent myUMBC posts, users may experience a one time issue logging into chip due to the addition of load balancing for the login nodes. You may need to remove the previous entry for chip in your known_hosts SSH file, since the keys have now changed. Once you remove the old entry, you can attempt to SSH again. If you still are experiencing issues, let me know. For more information regarding this one time issue, please checkout the myUMBC post: https://my3.my.umbc.edu/groups/hpcf/posts/152036 On Wed Sep 03 20:19:56 2025, [USER] wrote: Still cant login even after the downtime is completed. If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3261770&ticketsubject=HPC Slurm/Software Issue: Cant login to CHIP If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3261770 Thank You R e s o l u t i o n: Hi [USER], In the reminder post sent yesterday afternoon, there was a typo and it meant to say September 3rd. The post has been corrected to reflect the actual timeline of the outage, September 3rd 0800 - 1800. The cluster was not down yesterday, which is why your jobs were all still running until today. For more information, check out the myUMBC post: https://my3.my.umbc.edu/groups/hpcf/posts/151573 Have a nice day! Kind regards, [STAFF] On Wed Sep 03 13:57:01 2025, [USER] wrote: First Name: Shubhashis Last Name: Roy Dipta Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Cluster I know there was a downtime yesterday, but I still cant login to chip. Also, many of my jobs are automatically cancelled JOB IDS: 95320 86080 94052 95319 Original Request: Requestors: [USER] First Name: Shubhashis Last Name: Roy Dipta Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Cluster I know there was a downtime yesterday, but I still cant login to chip. Also, many of my jobs are automatically cancelled JOB IDS: 95320 86080 94052 95319"
"3261878","71497275","2025-09-05 20:07:52","HPC User Account: [ID] in pi_foord","Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_foord. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/)."
"3262013","71711597","2025-09-15 19:30:39","HPC User Account: [USER] in Protocol Analysis Lab","resolved in #3272500 -- Kind regards [STAFF] On Mon Sep 15 13:17:50 2025 [USER] wrote Hi [USER] It has been over a week is there any progress on the ticket The users are not even able to access their director or the common directory either (base) [bhargvb1@chip-login1 ~]$ cd /umbc/rs/sherman (base) [bhargvb1@chip-login1 sherman]$ cd common/ users/ (base) [bhargvb1@chip-login1 sherman]$ cd users/ -bash: cd: users/: Permission denied On Sun Sep 07 12:09:35 2025 [USER] wrote Hi [STAFF] I was able to confirm access to HPC for all We missed the following name on the initial list It would be really appreciated if you could create the account for them as well Additionally we requested that our group be assigned the Ceph-mounted research volume as we will require more space; however it appears that this is not the case It will be really helpful if you can fix that I was expecting to be assigned 25 TB of storage but that was not the case; instead we were given only 100 GB of storage You mentioned that the primary group is named pi_sherman but that does not seem to be the case The primary group is named sherman Was it just a typo Please let me know if you need any further information Thanks [USER] On Fri Sep 5 2025 at 4:53 PM [STAFF] via RT <[EMAIL]> wrote Ticket Last Update From Ticket Hello I hope this message finds you well The following individuals listed have been added to your pi_group within chip I included messages below confirming creation of their accounts alongside being added to your pi_group If you are able to verify with these individuals that they are able to access their research volumes that would be great Let me know if you have any additional questions Hi [USER] Your account ([USER]) has been created on chip rs umbc edu Your primary group is pi_sherman Your home directory has 500M of storage Please read through the documentation found at hpcf umbc edu User Support All available modules can be viewed using the command 'module avail' Please submit additional questions or issues as separate tickets via the following link (https://doit umbc edu/request-tracker-rt/doit-research-computing/) Best regards [STAFF]"
"3262108","71643953","2025-09-12 19:24:32","Broken Links","I have fixed the issue, the links should be work now. On Wed Sep 10 11:09:17 2025, [STAFF] wrote: Hello [USER]. Thank you for letting us know about this issue. I am currently working on fixing the links. I will let you know once everything is up. On Wed Sep 03 16:30:39 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              Help with something else Hello, I have noticed that the PDF links for the HPCF publications no longer work. For example,  [USER]. A Mathematical Model for Clustered Cell Migration. Senior Thesis, Department of Mathematics and Statistics, University of Maryland, Baltimore County, 2024. (HPCF machines used: taki.) [pdf] is listed third for 2024 but the pdf link is broken. Thanks [USER]."
"3262166","71494139","2025-09-05 18:51:48","HPC Slurm/Software Issue: Adding Haskell/CPSA4 Module(s) to the Cluster","Hi [USER], GHCup/Cabal is not something we are able to install systemwide as a module. It is meant to be installed on a per user basis. You can follow the instructions you included in your original ticket to install cabal, and then compile the software you require to use. Before running the GHCUP install script, this will install ghcup/related programs in ~/.ghcup. However-- since on chip, home directories are limited to 500M, GHCUP will fill this space up. To avoid this, start by creating a directory for ghcup in your research volume, then symbolically link it to your home folder. The commands should look something like... mkdir /umbc/rs/[STAFF]/users/[USER]/.ghcup ln -s  /umbc/rs/[STAFF]/users/[USER]/.ghcup ~/.ghcup Then, you should be able to install GHCUP/cabal, which should let you then compile CPSA/any other software you would need. Unrelated, but Haskell (ghc) specifically has also been installed as a module, however this does not include what you need to compile CPSA. But I figured I would mention it nonetheless. If you run into issues or have further questions, I can do my best to assist you! Have a nice day!-- Kind regards, [STAFF]"
"3262228","71448006","2025-09-04 12:51:29","HPC Slurm/Software Issue: Cannot login to chip server","Hi [USER], We did not complete the downtime until 8:15pm last night. Please try to access chip again, and let us know if you have any issues. If you do have issues, please note the exact command you used to try to get into the cluster, and any errors you received as well as the time of the attempt in the response. On Wed Sep 03 19:18:46 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Hi, I am trying to login to chip server, but cannot login. My access is being denied. Could you please look into this? Thanks. Best, [STAFF]"
"3262241","71443241","2025-09-04 00:19:16","HPC Other Issue: No Access to Chip","I see the most recent email about the maintenance being completed and I have access. Thanks! Greetings, This message has been automatically generated in response to the creation of a ticket regarding: Subject: 'HPC Other Issue: No Access to Chip' Message: Request Type: High Performance Cluster [USER] is trying to access chip over the VPN. When [USER] ssh into the login node with ssh [STAFF]@chip.rs.umbc.edu I am asked for my password, which is denied. I have confirmed that I am using the correct password for my UMBC account. Here's the verbose output of my ssh connection: [USER]@[DEVICE] ~ % ssh -v [STAFF]@chip.rs.umbc.edu OpenSSH_9.0p1, LibreSSL 3.3.6 debug1: Reading configuration data /[PATH]/.ssh/config debug1: /[PATH]/.ssh/config line 5: Applying options for chip.rs.umbc.edu debug1: /[PATH]/.ssh/config line 9: Applying options for chip.rs.umbc.edu debug1: /[PATH]/.ssh/config line 57: Applying options for * debug1: Reading configuration data /etc/ssh/ssh_config debug1: /etc/ssh/ssh_config line 21: include /etc/ssh/ssh_config.d/* matched no files debug1: /etc/ssh/ssh_config line 54: Applying options for * debug1: /etc/ssh/ssh_config line 58: Applying options for * debug1: Authenticator provider $SSH_SK_PROVIDER did not resolve; disabling debug1: Connecting to chip.rs.umbc.edu port 22. debug1: Connection established. debug1: identity file /[PATH]/.ssh/id_rsa type 0 debug1: identity file /[PATH]/.ssh/id_rsa-cert type -1 debug1: Local version string SSH-2.0-OpenSSH_9.0 debug1: Remote protocol version 2.0, remote software version OpenSSH_8.7 debug1: compat_banner: match: OpenSSH_8.7 pat OpenSSH* compat 0x04000000 debug1: Authenticating to chip.rs.umbc.edu:22 as '[STAFF]' debug1: load_hostkeys: fopen /etc/ssh/ssh_known_hosts: No such file or directory debug1: load_hostkeys: fopen /etc/ssh/ssh_known_hosts2: No such file or directory debug1: SSH2_MSG_KEXINIT sent debug1: SSH2_MSG_KEXINIT received debug1: kex: algorithm: curve25519-sha256 debug1: kex: host key algorithm: ssh-ed25519 debug1: kex: server->client cipher: chacha20-poly1305@openssh.com MAC: compression: none debug1: kex: client->server cipher: chacha20-poly1305@openssh.com MAC: compression: none debug1: expecting SSH2_MSG_KEX_ECDH_REPLY debug1: SSH2_MSG_KEX_ECDH_REPLY received debug1: Server host key: ssh-ed25519 SHA"
"3262257","71479333","2025-09-05 13:58:26","HPC Other Issue: Login not working on CHIP","Hi [STAFF], I removed my known_hosts SSH file and was able to log into chip from my home network. Thanks for your support and resolution, you can close this ticket. --  [USER] Ph.D. Student - Computer Science, University of Maryland, Baltimore County."
"3262299","71457171","2025-09-04 16:11:50","HPC Other Issue: How to use [SOFTWARE]","Hi [USER], I wanted to provide some additional clarification regarding the issue. Please disregard the previous response. First off, the main error you are facing is being unable to load the CUDA/12.9.0 module. You are doing everything correctly, however, there were some changes made just yesterday to the module system that resulted in the CUDA modules being unavailable, and thus unable to be loaded. This only affected g20-xx GPU nodes. However-- I have resolved the issue and built the correct CUDA modules, so you will be able to load ollama/CUDA without issue now. Secondly, I wanted to inquire a little bit more about the error you are receiving when attempting to move the ollama directory. I believe you have specified the path to your research volume incorrectly. The path you provided in the ticket was '/umbc/rs/pi_[STAFF]...'. However, the path to your group's research volume is actually '/umbc/rs/[STAFF]'. Research volume directories are only appended with 'pi_' when they have been moved to Ceph, the new storage system we are in the process of migrating to. Currently, [STAFF]'s research volume has not been migrated yet, so it is still using the old naming scheme without the 'pi_'. You should be able to successfully move the .ollama folder to your research volume, and then create a symbolic link (as outlined in the wiki). After that, you should be able to start using ollama! Let me know if you have any questions about this, or run into any further issues! Have a nice day! On Wed Sep 03 22:59:46 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Cluster Hi, I read the https://umbc.atlassian.net/wiki/spaces/faq/pages/1408335873/Running+Ollama+on+chip to try load ollama on chip server. First I type module avai ollama and the output is --------------------------------------------------------------- Core & Custom Modules --------------------------------------------------------------- ollama/0.6.5 ollama/0.8.0 ollama/0.9.2 ollama/0.10.1 ollama/0.11.4 (D) Where: D: Default Module After that I tried (base) [USER]@chip-login1 [USER]$ srun --cluster=chip-gpu --account=[STAFF] --mem=32G --time=1:00:00 --gres=gpu:1 --pty $SHELL [USER]@g20-06 [USER]$ module load ollama/0.11.4 Lmod has detected the following error: The following module(s) are unknown: 'CUDA/12.9.0' Please check the spelling or version number. Also try 'module spider ...' It is also possible your cache file is out-of-date; it may help to try: $ module --ignore_cache load 'CUDA/12.9.0' Also make sure that all modulefiles written in TCL start with the string #%Module It shows the above output, and I can ollama serve > ollama_server.log 2>&1 & normally. But when I mv ~/.ollama /umbc/rs/[STAFF]/users/[USER]/.ollama, it shows the error path. Could you tell me the correct path and how to load ollama in chip server? Thanks Best, [USER]"
"3262441","71641844","2025-09-12 18:21:51","HPC Other Issue: Access to Chip","We apologize for the late reply. We have tried to fix the connection issue that were happening after the down time. Are you still getting the broken pipe error? On Thu Sep 04 14:22:31 2025, [USER] wrote: Hello, I was able to login afterwards thank you. However, every 15 minutes or so, I get a message saying client_loop: send disconnect: Broken pipe. Is this something expected? Thank you. Best, [USER]. On Sep 4, 2025, at 09:49, [STAFF] via RT wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://www.google.com/url?q=https://umbc.us2.qualtrics.com/SE/?SID%3DSV_etfDUq3MTISF6Ly%26customeremail%3D[EMAIL]%26groupid%3DEIS%26ticketid%3D3262441%26ticketowner%3D[STAFF]%26ticketsubject%3DHPC%2520Other%2520Issue%253A%2520Access%2520to%2520Chip. If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3262441. Thank You. R e s o l u t i o n:  Hi [USER], There was an issue with which network can connect to chip.rs.umbc.edu this morning. Off-campus networks or users using the UMBC Visitor network should now be able to access to the cluster without the VPN. I'll mark this as resolved for now, but let me know if there is any related issue. On Thu Sep 04 09:08:09 2025, [USER] wrote: First Name:                [USER]. Last Name:                 [USER]. Email:                     [EMAIL]. Campus ID:                 [USER]. Request Type:              High Performance Cluster. Hello, Since yesterday’s downtime, I’ve been trying to access Chip, but despite using the login line ssh $USER@chip.rs.umbc.edu, I haven’t been able to connect. I keep receiving an operation timed out message. Is this something expected, or when do you think I’ll be able to access Chip? Thanks, [USER]. --  Best, [STAFF] DOIT Unix infra, Graduate Assistant"
"3262473","71453983","2025-09-04 15:06:45","HPC Other Issue: x11 forwarding broken","Hi [STAFF], Thanks for the quick fix, it works again! -[USER] On Thu, Sep 4, 2025 at 10:59 AM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Good morning [USER], It looks like during the downtime yesterday X11 forwarding in Slurm got disabled by mistake. I have re-enabled it, and was able to open a shell with X11 forwarding and run an app via srun. When you have a chance could you verify it's working for you now too? Thank you, [STAFF] On Thu Sep 04 10:05:01 2025, [USER] wrote: I guess I still get my two step trick to work : but we had spent quite a few days getting the earlier one step alias to work, so I'd like that to come back Here is my 'two step' trick which involves two sessions to chip----------------------------------First session : slogin to c24-52 [USER@chip-login1 ~]$ alias schip alias schip='srun --cluster=chip-cpu --account=pi_strow --partition=pi_strow --qos=pi_strow --time=30-00:00:00 --mem=10G --pty $SHELL' [USER@chip-login1 ~]$ schip The following have been reloaded with a version change: 1) slurm/chip-gpu/23.11.4 => slurm/chip-cpu/23.11.4 -----------------------------Then on other session, start ssh [USER@chip-login1 ~]$ ssh c24-52 Last login: Fri Aug 8 17:19:36 2025 The following have been reloaded with a version change: 1) git/2.33.1 => git/2.45.1-GCCcore-13.3.0 On Thu, Sep 4, 2025 at 9:52 AM via RT <[EMAIL]> wrote: Greetings, This message has been automatically generated in response to the creation of a ticket regarding: Subject: 'HPC Other Issue: x11 forwarding broken' Message: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USER] Request Type: High Performance Cluster This worked fine before yesterdays update (after all the tweaks we worked through for a week or so) [USER@chip-login1 ~]$ alias xschip alias xschip='srun --cluster=chip-cpu --account=pi_strow --partition=pi_strow --qos=pi_strow --time=30-00:00:00 --x11 --mem=10G --pty $SHELL' Now I get an error : [USER@chip-login1 ~]$ xschip srun: error: Unable to allocate resources: X11 forwarding not available"
"3262687","71458435","2025-09-04 16:47:22","HPC Other Issue: 'no such user' on RTX 8000 nodes","It works now! Thank you. Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=[ID] > Last Update From Ticket: Hello [USER], It looks like those two issues on the RTX 8000 nodes were remnants from the work we were doing yesterday. I've fixed both issues, and confirmed that I can load modules and can now see your user with 'id [USER]'. Can you try opening a shell via srun on one of the nodes to verify it's working for you now? Thank you, [STAFF] On Thu Sep 04 12:02:42 2025, [USER] wrote: Request Type: High Performance Cluster Attempts to access nodes with RTX 8000s give 'no such user' and I can't load any modules. All other nodes are working. For example: srun --cluster=[CLUSTER] --account=[ACCOUNT] --mem=1000 --time=1:00:00 --gres=gpu:1 --pty $SHELL and srun --cluster=[CLUSTER] --account=[ACCOUNT] --mem=1000 --time=1:00:00 --gres=gpu:1 --constraint=['[GPU_CONSTRAINT]'|'[GPU_CONSTRAINT]'|'[GPU_CONSTRAINT]'|'[GPU_CONSTRAINT]'] --pty $SHELL all work while srun --cluster=[CLUSTER] --account=[ACCOUNT] --mem=1000 --time=1:00:00 --gres=gpu:1 --constraint='RTX_8000' --pty $SHELL results in: id: '[USER]': no such user id: '[USER]': no such user id: '[USER]': no such user [I have no name!@[SERVER] [USER]]$ module load CUDA Lmod has detected the following error: Unable to load module because of error when evaluating modulefile: >>> /cm/local/modulefiles/slurm/.modulerc.lua: Empty or non-existant file >>> Please check the modulefile and especially if there is a the line number specified in the above message [I have no name!@[SERVER] [USER]]$ cat /cm/local/modulefiles/slurm/.modulerc.lua cat: /cm/local/modulefiles/slurm/.modulerc.lua: Permission denied"
"3262735","71482015","2025-09-05 14:39:35","HPC Slurm/Software Issue: JOB PREEMPTION: Job was emptied after 2 hours instead of 72 hours","Hi [USER], You are correct. There is a new preemption model for chip-gpu developed based on guidance from SIG, the Shared Infrastructure Governance subcommittee on advanced GPU resources. They decided that contributors who contributed 2024 GPU nodes should get dedicated access to said nodes, and are now permitted to preempt any job running on their contributed nodes. Since your job was running on g24-04, which was a contributed node. A contributor must have attempted to run a job on their node, which then preempted your job. I recommend checking out the myUMBC post recently made that goes over the changes: https://my3.my.umbc.edu/groups/hpcf/posts/152071 If you have any further questions or require clarification, feel free to ask! Have a good day! -- Kind regards, [STAFF] On Thu Sep 04 12:48:16 2025, [EMAIL] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Hi, I scheduled a job in chip-server but my job was preemptied after 2 hours. Job ID: 95614. This is the error message. 'slurmstepd: error: *** JOB 95614 ON g24-04 CANCELLED AT 2025-09-04T12:40:04 DUE TO PREEMPTION ***' Please help. Is there any new policy on scheduling jobs? Thanks"
"3262780","71488897","2025-09-05 16:36:57","HPC Slurm/Software Issue: Issues with submitting the jobs","On Thu Sep 04 13:10:34 2025, [USER] wrote: Hi I had resubmitted my jobs and they are running right now! Thank you for your reply Best [STAFF] First Name: [USER] Last Name: [STAFF] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Hi My jobs were cancelled yesterday after 9 hours of running, then I resubmitted the job on chip this morning, it says my job is submitted successfully, but I could not see my jobs using squeue -u [USER]. Here are the details of my command and slurm file. Thank you Best [STAFF]"
"3262811","71727616","2025-09-16 15:34:19","HPC User Account: [ID] in Student Group","We are waiting for PI approval, to create this account on CHIP. -- Best, [STAFF]"
"3263154","71478633","2025-09-05 13:45:52","HPC Other Issue: Issue with Contributed Node in Partition [ID]","Hello [USER], There was an issue with the availability of g24-02. I have resolved it and made it available. I checked squeue and saw your job has started running. squeue -u [STAFF] CLUSTER: chip-gpu JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 95744 pi_jianwu train_dp [USER] R 0:43 1 g24-02 Let us know if you encounter the same issue when submitting other jobs. I will mark this ticket resolved. On Thu Sep 04 21:18:38 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USER] Request Type: High Performance Cluster Hello HPC Support Team, I am writing to report an issue with the contributed node assigned to the group pi_jianwu. My account is [USER], under the group pi_jianwu. I submitted a job (JOB ID: 95744, SLURM file attached) to the GPU partition pi_jianwu, but the job remains in the PD state with the reason: (ReqNodeNotAvail, May be reserved for other job) However, when I checked the queue with squeue, I found that no other jobs are running on the pi_jianwu partition node. Therefore, my submitted job should be able to run. Steps I took to verify: 1. Checked assigned node: Using 'scontrol show partition', I confirmed that the node g24-02 is assigned to our partition. Here is the relevant output: ---------- PartitionName=pi_jianwu AllowGroups=ALL AllowAccounts=pi_jianwu AllowQos=ALL AllocNodes=ALL Default=NO QoS=N/A DefaultTime=00:15:00 DisableRootJobs=NO ExclusiveUser=NO GraceTime=0 Hidden=NO MaxNodes=UNLIMITED MaxTime=UNLIMITED MinNodes=0 LLN=NO MaxCPUsPerNode=UNLIMITED MaxCPUsPerSocket=UNLIMITED Nodes=g24-02 ---------- 2. Checked running jobs: I used 'squeue -p pi_jianwu' and confirmed that no other jobs are currently running on g24-02. The only job listed is my own (ID: 95744), which remains pending. ---------- CLUSTER: chip-gpu JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 95744 pi_jianwu train_dp [USER] PD 0:00 1 (ReqNodeNotAvail, May be reserved for other job) ---------- 3. Tried using reservation: Since the system reported the node May be reserved, I added '#SBATCH --reservation=jianwu' to the SLURM file. However, this returned the error: sbatch: error: Batch job submission failed: Requested reservation is invalid Could you please check if there is an issue with the partition pi_jianwu (node g24-02) or with the configuration of the pi_jianwu partition? Thank you very much for your help. Best regards, [USER] Account: [USER] Attachment 1: train_dp_runner.sh"
"3263173","71479632","2025-09-05 14:02:00","HPC User Account: [USER] in [ID] Research Group","Hi [USER], your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. You can find instructions on how to get started on chip at this page: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) On Thu Sep 04 22:09:32 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster Create/Modify account in existing PI group Existing PI Email: [EMAIL] Existing Group: UMBC DAMS Research Group Project Title: IoT KG Project Abstract: Creating an IoT knowledge graph I need permission and an account to use the HCP"
"3263626","71544060","2025-09-09 13:17:19","HPC New Group: [ID]","Close this ticket Friday"
"3263634","72351245","2025-10-17 16:32:53","Migrating Research Storage Volume to Ceph Cluster - [ID]","Thanks!  -[STAFF] On Oct 17, 2025, at 12:31 PM, [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3263634> Last Update From Ticket: Hello [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: * The path has changed, and is now available under /umbc/rs/pi_[USER]. * The alias used to reach the volume is now pi_[USER]_common and pi_[USER]_user. * Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF] On Fri Oct 17 10:04:00 2025, [STAFF] wrote: Good morning [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are no jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF] On Thu Oct 09 12:56:29 2025, [STAFF] wrote: Hello [USER], Sounds good, I've put your group's migration on our schedule for Friday October 17th. We will send you an email alert via this RT ticket when we begin the migration, and again once it has completed. Please let me know if you have any questions or concerns. Best, [STAFF] On Thu Oct 09 12:49:16 2025, [USER] wrote: Random is fine. Thanks, [USER]On Oct 9, 2025 at 12:08 PM -0400, [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3263634> Last Update From Ticket: Hello [USER], This is a reminder email, in case you missed the first. We need a response by October 15th, or we'll be forced to go with Option 2, randomly scheduling a time. As per the communication via myUMBC earlier this summer (https://my3.my.umbc.edu/groups/hpcf/posts/150838), DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 56GB of a 100GB quota on the old storage server. To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at '/umbc/rs/[USER]'. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. Below we've listed two options for handling this data migration - please let us know which of these you'd prefer. Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day. Option 2: If you don't respond to this email by October 15th, DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes. Note: After this process has completed, the new storage volume will have a new name. For example, group 'pi_doit' will find its data under '/umbc/rs/pi_doit', or in your group's case you will find your volume under '/umbc/rs/pi_[USER]'. Thank you, [STAFF] Gregory Ballantine System Administrator for Research and Enterprise Computing UMBC - DoIT"
"3263699","72346780","2025-10-17 14:27:49","Migrating Research Storage Volume to Ceph Cluster","Hello We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed and is now available under /umbc/rs/[STAFF]. The alias used to reach the volume is now [ALIAS] and [ALIAS]. Your new volume has a quota of 10TB. When you have a chance please try running some jobs on Chip using the new volume to verify everything looks good. Thank you On Fri Oct 17 09:31:15 2025 [STAFF] wrote: Hello This is just a reminder that we are starting your migration today. During this time please ensure there are not any jobs being run in your research group otherwise these may be terminated. We will provide an update once completed. On Thu Oct 09 11:58:56 2025 [STAFF] wrote: Hello [USER] Sounds good I've put your group's migration on our schedule for Friday October 17th. We will send you an email alert via this RT ticket when we begin the migration and again once it has completed. Please let me know if you have any questions or concerns. Best [STAFF]."
"3263702","72397510","2025-10-21 15:50:55","Migrating Research Storage Volume to Ceph Cluster","Hello. We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed and is now available under /umbc/rs/[USER]. The alias used to reach the volume is now [ALIAS]_common and [ALIAS]_user. Your new volume has a quota of 10TB. When you have a chance could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you. On Tue Oct 21 09:39:43 2025 [STAFF] wrote: Hello This is just a reminder that we are starting your migration today. During this time please ensure there are not any jobs being run in your research group otherwise these may be terminated. We will provide an update once completed. On Fri Oct 10 13:15:31 2025 [USER] wrote: Thank you. On Fri Oct 10 11:56 AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=[NUMBER]> Last Update From Ticket: Hi I will schedule the migration for October 21. We will email you on Oct 21 when we start the migration. On Thu Oct 09 15:47:27 2025 [USER] wrote: Hello [STAFF] Thank you for the email and my apologies for not responding earlier. May I request Option 1 -- for the week of 20-21 October? Thanks again.[USER]."
"3263703","72517688","2025-10-27 22:17:56","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/[STAFF]. The alias used to reach the volume is now [STAFF]_common and [STAFF]_user. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Mon Oct 27 13:21:28 2025, wrote: Hello [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Fri Oct 17 10:59:03 2025, wrote: [USER]"
"3263706","71641989","2025-09-12 18:27:05","Migrating Research Storage Volume to Ceph Cluster","Will do. Thanks [STAFF].  Typed on phone. Please ignore typos.   On Fri, Sep 12, 2025 at 1:11 PM [STAFF] via RT <[EMAIL]> wrote:  Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3263706 > Last Update From Ticket: Hello [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: * The path has changed, and is now available under /umbc/rs/pi_[USER]. * The alias used to reach the volume is now pi_[USER]_common and pi_[USER]_user. * Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Fri Sep 12 11:00:12 2025, wrote: Ankit, Sounds good, I've started your migration. I expect this to be done this afternoon, and I will send you an email when the migration has completed. Best, [STAFF]. On Fri Sep 12 10:32:19 2025, wrote: Yes, go ahead. Thanks On Fri, Sep 12, 2025 at 10:31 AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3263706 > Last Update From Ticket: Ankit, Not much - the only thing we'll need from you is your permission to terminate any jobs on Chip that are running under your group. I will get this process started shortly if that's okay. Thank you, [STAFF]. On Fri Sep 12 10:26:49 2025, wrote: Today is good. Do I need to do anything from my end? Typed on phone. Please ignore typos. On Fri, Sep 12, 2025 at 10:25 AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3263706 > Last Update From Ticket: Hello [USER], By asap, were you thinking like today? Or would you prefer early next week like Monday or Tuesday? Thank you, [STAFF]. On Thu Sep 11 18:51:54 2025, wrote: Hi [STAFF], I have a new project that is about to start with two new students who will be working on it. Can we schedule the migration asap so that students would not have to switch to the new directory? Thanks Ankit. On 9/5/2025 1:40 PM, via RT wrote: Greetings, This message has been automatically generated in response to the creation of a ticket regarding: Subject: 'Migrating Research Storage Volume to Ceph Cluster' Message: Hello [USER], As per the communication via myUMBC earlier this summer (https://my3.my.umbc.edu/groups/hpcf/posts/150838), DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 34GB of a 100GB quota on the old storage server. To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at '/umbc/rs/pi_[USER]'. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. Below we've listed two options for handling this data migration - please let us know which of these you'd prefer. Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day. Option 2: If you don’t respond to this email by October 15th, DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes. Note: After this process has completed, the new storage volume will have a new name. For example, group 'pi_doit' will find its data under '/umbc/rs/pi_doit', or in your group’s case you will find your volume under '/umbc/rs/pi_[USER]'. Thank you, [STAFF]."
"3263709","71555100","2025-09-09 17:00:52","Migrating Research Storage Volume to Ceph Cluster","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_[STAFF]. The alias used to reach the volume is now pi_[STAFF]_common and pi_[STAFF]_user. Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Tue Sep 09 09:31:27 2025, [EMAIL] wrote: Good morning [USER], This is just a reminder that we are starting your migration today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Mon Sep 08 14:39:51 2025, [EMAIL] wrote: [USER], Sounds good, I've penciled you in for tomorrow to perform the migration. I will send you an email via this RT ticket when we begin the process, and again when it has completed. Best, [STAFF]. On Mon Sep 08 14:36:22 2025, [EMAIL] wrote: sure. I don't have a student actively using it right now, and the ones that use it I can tell not to do tomorrow. regards [USER]. On Mon, Sep 8, 2025 at 2:32 PM [STAFF] via RT <UMBC Help@rt.umbc.edu> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3263709 > Last Update From Ticket: Hello [USER], Sounds good. In that case, would tomorrow work for you to perform the migration? Thank you, [STAFF]."
"3263713","71701929","2025-09-15 15:57:57","Migrating Research Storage Volume to Ceph Cluster","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/[USER]. The alias used to reach the volume is now pi_[USER]_common and pi_[USER]_user. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Also I apologize for not sending an alert when beginning your migration. It slipped through the cracks when I was signing on and getting started this morning. Thank you, [STAFF]."
"3263718","71536925","2025-09-08 20:50:31","[09/08] research volume storage","Hello [USER] and [STAFF], We have finished migrating your volume to the Ceph cluster As far as we can tell everything seems to have gone smoothly There are a few things to note The path has changed and is now available under /umbc/rs/[STAFF] The alias used to reach the volume is now pi_fanza_common and pi_fanza_user Your new volume has a quota of 10TB When you have a chance could you try running some jobs on Chip using the new volume to verify everything looks good Thank you [STAFF] On Mon Sep 08 15:48:50 2025 [USER] wrote Hi [STAFF] Yes this afternoon works For us the earlier the better Please go ahead Sincerely [USER] On Mon Sep 8 2025 at 2:16 PM [STAFF] via RT UMBCHelp@rt umbc edu wrote Ticket URL https rt umbc edu/Ticket/Display html?id=3263718 Last Update From Ticket Nishan Understood Would this afternoon work then It doesn t appear any jobs are running in your group so it shouldn t interrupt anything Else we can aim for tomorrow Thank you [STAFF] On Mon Sep 08 14:08:50 2025 [USER] wrote Hello [STAFF] Thank you for the detailed reply We prefer the 1st option and want to transfer the storage volume as soon as possible since our data is getting bigger by the day Currently no jobs are running and I won t submit any new jobs You can go ahead with the transfer as soon as you can Please let me know the earliest possible date for you Sincerely [USER] On Mon Sep 8 2025 at 1:24 PM [STAFF] via RT UMBCHelp@rt umbc edu wrote Ticket URL https rt umbc edu/Ticket/Display html?id=3263718 Dear [USER] DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster Your group is using 250GB of a 250GB quota on the old storage server To perform these migrations we need to take individual storage volumes offline while we migrate them to the Ceph cluster Thus we are reaching out to schedule a date where we can migrate your volume located at umbc/rs/fanza During the migration we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume Below we ve listed two options for handling this data migration please let us know which of these you d prefer Option 1 Schedule a group-wide downtime date during standard business hours which can be done by responding to this email with your preferred date s to perform the migration During this time DoIT staff will work to migrate your volume to the Ceph storage cluster DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed For most storage volumes this process should take less than a business day Option 2 If you don t respond to this email by October 15th DoIT staff will assign a day over the following month October 16th through November 15th to migrate your volume The day chosen will be random and will occur during business hours You will be notified of the date chosen to perform the migration and will be notified when the migration begins and completes Note After this process has completed the new storage volume will have a new name For example group pi_doit will find its data under umbc/rs/pi_doit or in your group s case you will find your volume under umbc/rs/pi_fanza Thank you [STAFF] On Fri Sep 05 13:46:38 2025 [USER] wrote First Name [USER] Last Name [USER] Email [EMAIL] Campus ID OQ14739 Request Type Other Hello there Our work involves saving very large files in the research volumes Since each PI is provided a 1 TB research volume I was wondering if there is a way to request additional space allocation Currently my personal research usage is approximately 220 GB and is expected to grow in the future I would also like to ask whether the research space is democratically divided among all members of the group with equal storage limits or if allocations can be made based on individual research needs Best regards [USER]"
"3263719","72396743","2025-10-21 15:35:45","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/[STAFF]. The alias used to reach the volume is now pi_<username>_common and pi_[STAFF]_user. Your new volume has a quota of 10TB. Since the path of your storage has changed you will need to update some of your symbolic links in your home directory. When you have a chance, please run some jobs on Chip using the new volume to verify everything looks good. Thank you, [STAFF] On Tue Oct 21 09:40:50 2025, [STAFF] wrote: Hello This is just a reminder that we are starting your migration today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. On Fri Oct 10 14:12:28 2025, [STAFF] wrote: Hello [USER], Sounds good, I've added your group's migration to our schedule for Tuesday October 21st. We will send you an email alert via this RT ticket when we begin the migration, and again once it has completed. Please let us know if you have any questions or concerns. Best, [STAFF] On Fri Oct 10 13:56:23 2025, [USER] wrote: I am okay with any day the week of October 20. Just let me know. Thanks, [USER] On Fri, Oct 10, 2025 at 10:08 AM Elliot Gobbert via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=32363719> Last Update From Ticket: Dear [USER], This is a reminder email, in case you missed the first. We need a response by October 15th, or we'll be forced to go with Option 2, randomly scheduling a time. As per the communication via myUMBC earlier this summer (https://my3.my.umbc.edu/groups/hpcf/posts/150838), DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 97GB of a 500GB quota on the old storage server. To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at '/umbc/rs/[STAFF]'. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. Below we've listed two options for handling this data migration - please let us know which of these you'd prefer. Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day. Option 2: If you don't respond to this email by October 15th, DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes. Note: After this process has completed, the new storage volume will have a new name. For example, group 'pi_doit' will find its data under '/umbc/rs/pi_doit', or in your group's case you will find your volume under '/umbc/rs/[STAFF]'. Thank you, [STAFF]"
"3263721","72539382","2025-10-28 19:43:13","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed and is now available under /umbc/rs/pi_[STAFF]. The alias used to reach the volume is now pi_[STAFF]_common and pi_[STAFF]_user. Your new volume has a quota of 10TB. When you have a chance please try running some jobs on Chip using the new volume to verify everything looks good. Thank you On Tue Oct 28 10:44:09 2025 [STAFF] wrote: Hello This is just a reminder that we are starting your migration today. During this time please ensure there are not any jobs being run in your research group otherwise these may be terminated. We will provide an update once completed. On Fri Oct 17 12:02:40 2025 [STAFF] wrote: Dear [USER] As per our previous communications since you did not schedule a date by October 15 we will be going with Option 2 randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of October 28th for your migration. Let us know if there is a better day for you and within reason we can reschedule that date. You will be notified when the migration begins and completes. Thank you [STAFF]"
"3263723","72456062","2025-10-23 15:43:52","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Dear [STAFF], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 13th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3263728","71796026","2025-09-18 18:35:14","Migrating Research Storage Volume to Ceph Cluster","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/[STAFF]. The alias used to reach the volume is now pi_[STAFF]_common and pi_[STAFF]_user. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Thu Sep 18 10:45:37 2025, [USER] wrote: Hello [USER], This is just a reminder that we are starting your migration today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Mon Sep 08 12:43:11 2025, [USER] wrote: Thanks [STAFF]. -[USER]. On Sep 8, 2025, at 12:00 PM, [STAFF] via RT [EMAIL] wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3263728 Brad, Sounds good, I've got your migration scheduled for September 18th. I will send you an email via this ticket when I begin the migration, and again when it is completed. Best, [STAFF]. On Fri Sep 05 16:21:09 2025, [USER] wrote: Migrating Sept 18th would be great. Thanks,[USER]. On Sep 5, 2025, at 1:52 PM, via RT [EMAIL] wrote: Greetings, This message has been automatically generated in response to the creation of a ticket regarding: Subject: 'Migrating Research Storage Volume to Ceph Cluster' Message: Dear [USER], As per the communication via myUMBC earlier this summer https://my3.my.umbc.edu/groups/hpcf/posts/150838, DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 676GB of a 2TB quota on the old storage server. To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at '/umbc/rs/[STAFF]'. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. Below we've listed two options for handling this data migration - please let us know which of these you'd prefer. Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day. Option 2: If you don't respond to this email by October 15th, DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes. Note: After this process has completed, the new storage volume will have a new name. For example, group 'pi_doit' will find its data under '/umbc/rs/pi_doit', or in your group's case you will find your volume under '/umbc/rs/[STAFF]'. Thank you, [STAFF]."
"3263734","72517740","2025-10-27 22:21:05","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/[STAFF]. The alias used to reach the volume is now [ALIAS] and [ALIAS]. Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Mon Oct 27 13:21:48 2025, [USER] wrote: Hello [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Thu Oct 23 12:00:56 2025, [USER] wrote: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of October 27th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]."
"3263737","72699653","2025-11-04 01:32:23","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_[STAFF]. The alias used to reach the volume is now pi_[STAFF]_common and pi_[STAFF]_user. Your new volume has a quota of 1TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Mon Nov 03 11:41:51 2025, [EMAIL] wrote: Hello [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Fri Oct 17 13:03:43 2025, [EMAIL] wrote: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 3rd for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]."
"3263738","72093328","2025-10-03 20:06:01","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Will look into again after we finish migrating PI-owned volumes. On Fri Oct 03 15:30:10 2025, [STAFF] wrote: Don't know how to mark this in the spreadsheet either."
"3263950","71620976","2025-09-11 19:27:22","HPC Other Issue: Permission denied deleting directory on Chip cluster - request support","Hello [STAFF], Thank you very much — I confirmed that I now have the permissions, and I was able to successfully delete my directory on the Chip cluster. Really appreciate your help! Best regards, [USER] On Thu, Sep 11, 2025 at 11:33 AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3263950> Last Update From Ticket: Hello [USER], It looks like there were some files/directories owned by a different user, which is what was preventing you from deleting them. I've changed the ownership over to you. When you have a chance, could you try removing that directory again? Thank you, [STAFF] On Fri Sep 05 17:27:34 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USER] Request Type: High Performance Cluster Hello HPCF support team, I am encountering a “permission denied” error when attempting to delete the directory from the Chip cluster login node: /umbc/rs/[USER]/common/[USER]/Segmentation-[USER] I have attempted: chmod -R u+rwx Segmentation-[USER] rm -rf Segmentation-[USER] But the system still fails to delete due to write-protected files inside. The operation was performed on the Chip cluster login node (chip-login2). Could you please assist with adjusting permissions or removing this directory? Thank you for your help! [USER]"
"3264159","71557510","2025-09-09 17:46:38","Storage: Request for more storage allocation","Closing this as it's a duplicate of [TICKET NUMBER]"
"3264533","72323734","2025-10-16 14:15:08","Omeka S server","A few updates: I built this VM with RHEL 9; hostname is [SERVER]; Tied it into Puppet to configure Apache w/ SSL and PHP; Installed omeka-s v4.1.1 from Git : https://github.com/omeka/omeka-s/blob/develop/README.md - I assumed this would be the easiest way to keep it updated; Verified I can reach the app at https://[SERVER] and configured a first-time user. Currently I'm working to integrate it with SSO."
"3264549","71526259","2025-09-08 17:17:35","HPC Slurm/Software Issue: Module Issues and Faulty Nodes?","Hi [USER], They were resolved today. Have you actually tested to see if the issues are still present after I replied to the ticket stating they were fixed? Thanks for confirming. If you don't mind, could you please share when those issues were resolved? The issues were persistent as recently as this morning, and I had been facing them since the cluster downtime. Hi [USER], There are issues with the current version of the ollama module that is being used. The communication with the Ollama server takes significantly longer than it is supposed to, and sometimes it terminates because the request takes too long to complete. The ollama version is 0.11.4, the issue was fixed after I switched to the local instance of ollama running version 0.11.10 There are also issues with the GPU node g20-06. The node is not able to access my conda env, I believe, due to which it can't access the Python packages it needs to run the job. The findings can be verified with the logs of job 96148_15. '/cm/local/apps/slurm/var/spool/job96164/slurm_script: line 18: conda: command not found /cm/local/apps/slurm/var/spool/job96164/slurm_script: line 19: conda: command not found /cm/local/apps/slurm/var/spool/job96164/slurm_script: line 20: conda: command not found ERROR: Could not find a version that satisfies the requirement networkx==3.4.2 (from versions: 0.34, 0.35, 0.35.1, 0.36, 0.37, 0.99, 1.0rc1, 1.0, 1.0.1, 1.1, 1.2rc1, 1.2, 1.3rc1, 1.3, 1.4rc1, 1.4, 1.5rc1, 1.5, 1.6rc1, 1.6, 1.7rc1, 1.7, 1.8rc1, 1.8, 1.8.1, 1.9rc1, 1.9, 1.9.1, 1.10rc2, 1.10, 1.11rc1, 1.11rc2, 1.11, 2.0, 2.1, 2.2rc1, 2.2, 2.3rc3, 2.3rc4, 2.3, 2.4rc1, 2.4rc2, 2.4, 2.5rc1, 2.5, 2.5.1, 2.6rc1, 2.6rc2, 2.6, 2.6.1, 2.6.2, 2.6.3, 2.7rc1, 2.7, 2.7.1, 2.8rc1, 2.8, 2.8.1rc1, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.8.5, 2.8.6, 2.8.7, 2.8.8, 3.0b1, 3.0rc1, 3.0, 3.1rc0, 3.1, 3.2rc0, 3.2, 3.2.1) ERROR: No matching distribution found for networkx==3.4.2 Also, I don't have the write permissions to the common directory. Could you please fix that? '(base) [USER@chip-login2 common]$ touch hi touch: cannot touch 'hi': Permission denied (base) [USER@chip-login2 common]$ pwd /umbc/rs/pi_ryus/common (base) [USER@chip-login2 common]$ ls -lhrt total 0 drwxrws---+ 4 USER pi_ryus 2 Jul 11 05:38 ExpShare (base) [USER@chip-login2 common]$ id uid=180794(USER) gid=1081(pi_ryus) groups=1081(pi_ryus),1170(pi_sherman) (base) [USER@chip-login2 common]$ groups pi_ryus pi_sherman Thank you for reporting the issues with the ollama module and the GPU node g20-06. The issue with the ollama module has been fixed by switching to the local instance of ollama running version 0.11.10. The issue with the GPU node g20-06 is being investigated and will be resolved as soon as possible. Additionally, the permission issue with the common directory has been fixed."
"3264577","71525176","2025-09-08 16:53:52","HPC User Account: [ID] in MLSP","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) Kind regards, [STAFF] DoIT Unix Infra Student Worker On Mon Sep 08 10:30:52 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Cluster Create/Modify account in existing PI group Existing PI Email: [STAFF] Existing Group: MLSP Project Title: Multivariate feature selection for fMRI analysis Project Abstract: fMRI has become a widely used imaging tool for exploring the normal neural functions as well as disordered brain functions like schizophrenia. Among all fMRI data analysis strategies, data-driven-based methods have a unique advantage of capturing the whole picture of available information since they effectively minimize assumptions imposed on the brain activity. With the increasing number of multimodal data and multisite data, the problem of balancing the computation cost and analysis performance is becoming more important than ever before. In this project, our interest is in identifying the most informative multivariate features when analyzing multiple fMRI datasets. Our goal is the development of flexible new decomposition methods as well as identifying the best feature extraction strategy for a given problem. I need access to use the cluster to perform fMRI analysis as part of my PhD group's works. Thank you for your consideration."
"3264580","71554634","2025-09-09 16:55:34","HPC User Account: [USER] in MLSP","Thank you=C2=A0On Tue, Sep 9, 2025, 12:38=E2=80=AFPM [STAFF] via RT &lt;[EMAIL]&gt; wrote:Ticket &lt;URL: https://rt.umbc.edu/Ticket/Display.html?id=3D3264580 &gt; Last Update From Ticket: Understood, just wanted to confirm.Hi [USER], Your account ([USER]) has been created on http://chip.rs.umbc.edu.Your primary group is pi_adali.Your home directory has 500M of storage.Please read through the documentation found at http://hpcf.umbc.edu &gt; User Support.All available modules can be viewed using the command 'module avail'.Please submit additional questions or issues as separate tickets via the following link.(https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) Let me know if you have any other questions; otherwise, I'll close this ticket on Friday.[STAFF]"
"3264810","71945872","2025-09-25 16:24:52","HPC Slurm/Software Issue: MPI network error in slurm jobs","Hi [USER], That is unfortunate to hear. Lets try adding some debug options to the mpirun command to see if we can narrow down the exact cause of the issue. Try to add '--debug-daemons' after mpirun. This might provide us some insight on why OTRE daemon is failing. Let me know how that goes! Kind regards, [STAFF] DoIT Unix Infra Student Worker On Sat Sep 20 18:20:44 2025, [USER] wrote: Hi [STAFF], Thank you for your suggestions. I tried not loading OpenMPI but directly using the mpi4py’s mpirun, it works for some time, which means some jobs run without those errors, but some are still experiencing the same error: An ORTE daemon has unexpectedly failed after launch and before communicating back to mpirun. This could be caused by a number of factors, including an inability to create a connection back to mpirun due to a lack of common network interfaces and/or no route found between them. Please check network connectivity (including firewalls and network routing requirements). Please also find those errors in “/umbc/rs/zzbatmos/users/[USER]/CAMRO_Dust/off_track_retrieval/run_ocean_land_combined_MOD/preclear_swath_MOD_2017_06.err”. You could see many other .err files in the same directory are jobs for running the same code but just for different time range of the input datasets. And those jobs are running smoothly. Even I found those errors in those jobs, I could simply re-run it without doing anything, the jobs sometimes could be done smoothly, which is very random. I really think that this error is related to some of the nodes only, but I couldn’t find out which nodes, as it happens in a random way to me. Probably you would have a better idea on that. Thanks, [USER] On Sep 9, 2025, at 12:14 PM, [STAFF] via RT wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3264810> Last Update From Ticket: Hi [USER], Would you be able to attempt running your code without loading OpenMPI via module load? In your python environment, you have mpi4py installed, which also has mpirun. Sometimes, if there are conflicting versions of openmpi packages, it can generate errors. You can see, without loading OpenMPI, which mpirun returns... (jyenv) [USER] which mpirun /umbc/rs/zzbatmos/users/[USER]/miniconda3/envs/jyenv/bin/mpirun I would recommend testing that out, and letting me know if it changes the behavior at all. Have a good day! Kind regards, [STAFF] DoIT Unix Infra Student Worker On Tue Sep 09 10:42:18 2025, [USER] wrote: Hi Elliot, Thank you for your notes and answers, here are my responses: 1. My .slurm file is in “/umbc/rs/zzbatmos/users/[USER]/CAMRO_Dust/off_track_retrieval/run_ocean_land_combined_MYD/”, thank you for helping checking in. 2. I know that modules are not loaded in the login node, so I submit my jobs after I request an interactive node using srun or via JupyterLab running in a node. So I don’t think that is the problem. 3. I don’t see the “Lmod” error from my side when I log in. I only see notes of “The following have been reloaded with a version change”, which should not be a problem. All in all, I think the error is from the mpirun, just don’t know what the cause is, and what the solution is. So far, my loaded MPI is “/usr/ebuild/installs/software/OpenMPI/4.1.6-GCC-13.2.0/bin/mpirun”. Again, the error has never occurred before the recent update on Sept 3rd. And I am not using any GPU partitions, so it should be related to any changes regarding the CPU partitions, or the MPI software, or any rule changes (my guess). Keep me posted. Thank you in advance. -[USER] On Sep 9, 2025, at 9:19 AM, Elliot Gobbert via RT wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3264810> Last Update From Ticket: Hello there, I’d love to help! Some problems, though, and some other things that you might want to check on regardless of this ticket. 1. (Most important) I don’t really know where you’re working on this, i.e, if you could give me the location of the .slurm file you’re working from, that’d be great, then I can look at not just the slurm file, but the environment around it to get a clear picture here. Super simple, just “cd” to the .slurm file, and give me the output of “pwd”. Then I can locate the file and check on it. 2. I noticed that you have a .bashrc file that auto-loads a bunch of modules whenever you log in. This is something you should know regardless of this ticket, but you can’t load modules on the login node. You can only load modules on compute nodes. I.e if the node says: [USERNAME@chip-login2 ~]$ or chip-login1 (We have two login nodes after this recent downtime) Then you’re on a login node; otherwise, the compute nodes are the c(18/21/24)-(NUMBER) that you’ve used before. 3. Also, I noticed that when you log in, you’re getting a lot of “Lmod has detected the following error: The following module(s) are unknown:” errors. Our old clusters (ada and taki) had different modules installed, so if you copied the module loads from there, there may be some incompatible/unknown modules. You can check what modules are available with “module avail MODULENAME”, for more information: https://umbc.atlassian.net/wiki/spaces/faq/pages/1032880207/Available+Software+and+Packages This could very well affect your current problem, because if you’re downloading incompatible/non-existent modules, of course, you may have problems running things. Of course, that’s just a hunch, and I’d want to be certain. To do that, of course, I need to know where this .slurm file is, though. Keep me updated, and let’s keep working through this problem. Elliot Gobbert"
"3264837","71692275","2025-09-15 13:17:30","HPC Other Issue: cudnn outdated","First create a interactive slurm job to use conda/pip to install things srun --time=0:30:00 --mem=5000 --gres=gpu:1 --cluster=chip-gpu --pty /bin/bash Then load Anaconda3 (if its not loaded already) module load Anaconda3 Then create a new conda environment (i am using myenv as an example for a name of a conda environment this can be set to whatever) conda create -n myenv Then activate the conda environment conda activate myenv Then install tensorflow[and-cuda] TMPDIR='/umbc/rs/vjaneja/users/[USER]/' python3 -m pip install 'tensorflow[and-cuda]' Verify the tensorflow install python3 -c 'import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))' You should see at the bottom of the output something that looks like the following [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')] This verifies that tensorflow is working and is able to see the GPUs. Additionally the steps are also available on the tensorflow website (which I believe you linked to previously) but here it is again: https://www.tensorflow.org/install/pip -- Kind regards [STAFF]"
"3265117","72349641","2025-10-17 15:59:21","Migrating Research Storage Volume to Ceph Cluster - [ID]","Dear [STAFF], That's awesome, thank you very much for the update. I submitted a job on Chip, and its status is currently pending. I will check it again to make sure everything is running smoothly. Best regards, [USER] On Fri, Oct 17, 2025 at 10:00 AM [STAFF] via RT wrote: Ticket Last Update From Ticket: Hello [USER], It took a bit longer than expected, but we have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: * The path has changed, and is now available under /umbc/rs/pi_[USER]. * The alias used to reach the volume is now pi_[USER]_common and pi_[USER]_user. * Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF] On Thu Oct 16 11:40:07 2025, [USER] wrote: Hello [USER], This is a reminder that we'll be starting your group's research storage volume migration today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF] On Fri Oct 10 09:52:25 2025, [USER] wrote: That is perfect; thank you. We picked that date because we will all be out at a conference. Best, [USER] On Fri, Oct 10, 2025 at 9:22 AM [STAFF] via RT UMBCHelp@rt.umbc.edu wrote: Ticket Last Update From Ticket: Hello [USER], October 16th is perfectly fine - I've put your group's migration on our schedule for that day. We will alert you via this RT when we begin your migration, and again once it has completed. Please let us know if you have any questions or concerns. Best, [STAFF] On Thu Oct 09 16:57:55 2025, [USER] wrote: Hi [STAFF] A date that could work for us for group migration would be 10/16/25. Let me know if that could work for you. Thank you, [USER] On Mon, Sep 8, 2025 at 3:58 PM via RT UMBCHelp@rt.umbc.edu wrote: Greetings, This message has been automatically generated in response to the creation of a ticket regarding: Subject: 'Migrating Research Storage Volume to Ceph Cluster - pi_[USER]' Message: Hello [USER], As per the communication via myUMBC earlier this summer https://my3.my.umbc.edu/groups/hpcf/posts/150838, DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 7.3TB of a 10TB quota on the old storage server. To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at /umbc/rs/weltyc. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. Below we've listed two options for handling this data migration - please let us know which of these you'd prefer. Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day. Option 2: If you don't respond to this email by October 15th, DoIT staff will assign a day over the following month October 16th through November 15th to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes. Note: After this process has completed, the new storage volume will have a new name. For example, group pi_doit will find its data under /umbc/rs/pi_doit, or in your group's case you will find your volume under /umbc/rs/weltyc. Thank you, [STAFF]"
"3265121","72725809","2025-11-04 18:28:52","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/[STAFF]. The alias used to reach the volume is now [ALIAS] and [ALIAS]. Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF] On Tue Nov 04 12:04:28 2025, [EMAIL] wrote: Hello [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF] On Thu Oct 23 11:24:41 2025, [EMAIL] wrote: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 4th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3265127","72612701","2025-10-30 23:25:47","Migrating Research Storage Volume to Ceph Cluster","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/[SERVER]. The alias used to reach the volume is now [ALIAS]_common and [ALIAS]_user. Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Thu Oct 30 10:33:08 2025, [STAFF] wrote: Hello [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Fri Oct 17 12:27:00 2025, [STAFF] wrote: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of October 30th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]."
"3265132","72517720","2025-10-27 22:19:34","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/[STAFF]. The alias used to reach the volume is now [ALIAS]_common and [ALIAS]_user. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Mon Oct 27 13:21:41 2025, [USER] wrote: Hello [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Fri Oct 17 11:59:43 2025, [USER] wrote: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of October 27th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]."
"3265136","72456014","2025-10-23 15:42:58","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Dear [STAFF], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 13th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3265141","72455888","2025-10-23 15:40:03","Migrating Research Storage Volume to Ceph Cluster","Dear [STAFF], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 13th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3265146","71808985","2025-09-19 14:15:37","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Good morning [USER], We have finished migrating your volume to the Ceph cluster As far as we can tell everything seems to be in working order There are a few things to note The path has changed and is now available under /umbc/rs/pi_[STAFF] The alias used to reach the volume is now pi_[STAFF]_common and pi_[STAFF]_user Your new volume has a quota of 25TB When you have a chance could you try running some jobs on Chip using the new volume to verify everything looks good I apologize for any inconvenience the extended length of your group's migration may have caused Thank you [STAFF] On Wed Sep 17 22:50:57 2025 [EMAIL] wrote Hello [USER] Your migration to the new Ceph storage cluster is taking longer than expected Currently it's sitting around 2TB copied out of 2.7TB total and I expect it to be finished in the morning I apologize for any convenience this may cause your group Best [STAFF] On Wed Sep 17 09:29:49 2025 [EMAIL] wrote Good morning [USER] This is just a reminder that we are starting your migration today During this time please ensure there are not any jobs being run in your research group otherwise these may be terminated We will provide an update once completed Best [STAFF] On Wed Sep 10 14:37:20 2025 [EMAIL] wrote Sounds good On Wed Sep 10 2025 at 1:57 PM [STAFF] via RT UMBCHelp@rt.umbc.edu wrote Ticket URL https://rt.umbc.edu/Ticket/Display.html?id=3265146 Last Update From Ticket [USER] That's fine - how does next Wednesday September 17th sound then Thank you [STAFF] On Wed Sep 10 12:23:45 2025 [EMAIL] wrote My group is pretty flexible here but we would like at least one day's notice -[USER] On Mon Sep 8 2025 at 4:12 PM via RT UMBCHelp@rt.umbc.edu wrote Greetings This message has been automatically generated in response to the creation of a ticket regarding Subject 'Migrating Research Storage Volume to Ceph Cluster - pi_[STAFF]' Message Hello [USER] As per the communication via myUMBC earlier this summer https://my3.my.umbc.edu/groups/hpcf/posts/150838 DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster Your group is using 2.3TB of a 4TB quota on the old storage server To perform these migrations we need to take individual storage volumes offline while we migrate them to the Ceph cluster Thus we are reaching out to schedule a date where we can migrate your volume located at “/umbc/rs/ferraro”. During the migration we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume Below we’ve listed two options for handling this data migration - please let us know which of these you’d prefer Option 1 Schedule a group-wide downtime date during standard business hours which can be done by responding to this email with your preferred date(s) to perform the migration During this time DoIT staff will work to migrate your volume to the Ceph storage cluster DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed For most storage volumes this process should take less than a business day Option 2 If you don’t respond to this email by October 15th DoIT staff will assign a day over the following month October 16th through November 15th to migrate your volume The day chosen will be random and will occur during business hours You will be notified of the date chosen to perform the migration and will be notified when the migration begins and completes Note After this process has completed the new storage volume will have a new name For example group “pi_doit” will find its data under “/umbc/rs/pi_doit or in your group’s case you will find your volume under “/umbc/rs/pi_[STAFF] Thank you [STAFF]"
"3265158","72352593","2025-10-17 17:13:06","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 5th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3265165","72397392","2025-10-21 15:48:39","Migrating Research Storage Volume to Ceph Cluster","Dear [STAFF], As per our previous communications, since [USER] did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for [USER]'s migration. We have assigned the date of November 5th for [USER]'s migration. Let us know if there is a better day for [USER], and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3265167","71589913","2025-09-10 18:00:44","Migrating Research Storage Volume to Ceph Cluster - [ID]","Hello [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_[STAFF]. The alias used to reach the volume is now pi_[STAFF]_common and pi_[STAFF]_user. Your new volume has a quota of 11TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Wed Sep 10 09:47:36 2025, OJ87090 wrote: Good morning [USER], This is just a reminder that we are starting your migration today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Tue Sep 09 09:28:03 2025, OJ87090 wrote: Good morning [USER], Let's schedule the migration for tomorrow September 10th then. I will send you an email via this RT ticket when the migration begins, and again when it completes. Please let me know if you have any questions or concerns. Best, [STAFF]. On Mon Sep 08 18:15:34 2025, OQ73099 wrote: Hi [STAFF], Preferred dates: this week (September 9 to 11th). Thanks [USER]. On Mon, Sep 8, 2025 at 4:19PM via RT <[EMAIL]> wrote: Greetings, This message has been automatically generated in response to the creation of a ticket regarding: 'Migrating Research Storage Volume to Ceph Cluster - pi_[STAFF]'. Message: Hello [USER], As per the communication via myUMBC earlier this summer (https://my3.my.umbc.edu/groups/hpcf/posts/150838), DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 7.4TB of a 11TB quota on the old storage server. To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at '/umbc/rs/[STAFF]'. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. Below we've listed two options for handling this data migration - please let us know which of these you'd prefer. Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day. Option 2: If you don’t respond to this email by October 15th, DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes. Note: After this process has completed, the new storage volume will have a new name. For example, group 'pi_doit' will find its data under '/umbc/rs/pi_doit', or in your group's case you will find your volume under '/umbc/rs/pi_[STAFF]'. Thank you, [STAFF]."
"3265171","72517950","2025-10-27 23:01:58","Migrating Research Storage Volume to Ceph Cluster - [ID]","Thanks [STAFF]. We will try. [USER] On Mon, Oct 27, 2025 at 6:19 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=3265171> Last Update From Ticket: Hello [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: * The path has changed, and is now available under /umbc/rs/pi_[USER]. * The alias used to reach the volume is now pi_[USER]_common and pi_[USER]_user. * Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on [SERVER] using the new volume to verify everything looks good? Thank you, [STAFF] On Mon Oct 27 13:21:39 2025, [USER] wrote: Hello [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF] On Thu Oct 23 11:36:23 2025, [USER] wrote: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of October 27th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3265808","71560947","2025-09-09 18:43:36","HPC New Group: [USER]","Hello. Hi [USER], The account ([USER]) has been created on chip.rs.umbc.edu. The primary group is pi_[STAFF]. Their home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) On [DATE], [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] Request Type:              High Performance Cluster Group Type:            Project Title:        Deep Learning for Radio Map Estimation Project Abstract:     Radio map estimation is a useful tool for wireless network management. In this project, we want to explore machine learning techniques for radio map estimation. Specifically, various deep learning techniques such as convolutional neural networks, graph neural networks, deep metric learning, variational auto encoders, and diffusion methods will be experimented. I need the following students added to the group: > First Name:                [USER] > Last Name:                 [USER] > Email:                     [EMAIL] > Campus ID:                 [CAMPUS_ID]. Best, [STAFF]"
"3266123","71591218","2025-09-10 18:21:21","HPC User Account: [ID] in Student Group","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) Your project information alongside your pi can be found here on our list of research projects page (https://hpcf.umbc.edu/libraries/research-projects-hpcf/?preview_id=76&preview_nonce=1e902d08c9&preview=true) If you have any questions please reach back out! Best regards, [STAFF]"
"3266593","71631433","2025-09-12 13:54:15","HPC Slurm/Software Issue: Conda","Hello [USER], The issue is coming from custom CONDA_* environment variables that you set in your bash files. To resolve this, please try the following first in your current shell: unset CONDA_ENVS_PATH CONDA_PKGS_PATH CONDA_PKGS_DIRS Then, remove or comment out any export CONDA_* lines from your ~/.bashrc and ~/.bash_profile. After that, please follow the instructions here to set up your conda environments properly: https://[DOMAIN]/wiki/spaces/faq/pages/[PAGEID]/Conda+Virtual+Environments Let us know if you still encounter issues after these steps. Best, [STAFF] On Wed Sep 10 11:55:24 2025, [EMAIL] wrote: Hello, I attempted to use a conda environment and recieved the error: 'EnvironmentNameNotFound: Could not find conda environment:' When attempting to create a new environment I recieve the error: 'NoWritablePkgsDirError: No writeable pkgs directories configured. - /path/to/file' I have recieved this error in the past and have already pasted: export CONDA_ENVS_PATH=//path/to/file export CONDA_PKGS_PATH=/path/to/file export CONDA_PKGS_DIRS=/path/to/file into both my bashrc and .bash_profile files How should I proceed?"
"3266653","71868207","2025-09-22 20:13:14","iHARP: AWS New User -- Super User","Nikki, This should be done. Please use the following url https://awsresearchlogin.umbc.edu/ to access the accounts. Let me know if there are problems. -- [STAFF], DoIT, Windows System Administrator, [EMAIL], (###) ########."
"3266664","71593075","2025-09-10 18:45:38","HPC Slurm/Software Issue: SBATCH Invalid Job Specification","Hi [STAFF], I've fixed the issue with the cluster specifications and features not working. I just tested on a few other users to see about reading/writing/executing files in the common directory and all of them seem to work. Could you please verify this? On Wed Sep 10 12:37:21 2025, [USER] wrote: First Name:                [USER] Last Name:                 [LAST NAME] Email:                     [EMAIL] Campus ID:                 [CAMPUS ID] Request Type:              High Performance Cluster Hi, I am trying to submit a job through sbatch, but it is resulting in an error. (base) [[USER]@chip-login2 col]$ sbatch qcc.sh sbatch: error: Batch job submission failed: Invalid feature specification. The error is consistent throughout the user group pi_[USER] at the very least. I am attaching the header of my slurm script for your reference: #!/bin/bash #SBATCH --job-name=[JOB NAME] #SBATCH --output=clog/collect_%A_%a.out #SBATCH --error=clog/collect_%A_%a.err #SBATCH --mem=64G #SBATCH --time=72:00:00 #SBATCH --constraint=rtx_6000 #SBATCH --gres=gpu:4 #SBATCH --array=15-23 #SBATCH --mail-user=[EMAIL] #SBATCH --mail-type=END,FAIL Also, users apart from me do not have write access to the common partition of pi_[USER] user group."
"3267228","71643727","2025-09-12 19:16:42","HPC New Group: [ID]","On Fri Sep 12 14:56:26 2025, [STAFF] wrote: Hello there, Group created; here's the info on that: The group pi_[USER] now exists on the chip cluster. Members of this group can therefore access and contribute to the research storage space allocated to the group. This storage is located at /umbc/rs/pi_[USER] and currently has a quota of 10T. Please review documentation on the hpcf.umbc.edu website. Submit any questions or issues as separate RT Tickets at the following URL: https://doit.umbc.edu/request-tracker-rt/doit-research-computing/. Your personal chip account was also created; info on that: Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[USER]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/)"
"3267293","71631760","2025-09-12 14:03:35","HPC Other Issue: Add [USER] to Unix group","Close this ticket Tuesday"
"3268198","71962502","2025-09-26 15:31:49","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_erill. The alias used to reach the volume is now pi_erill_common and pi_erill_user. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF] On Fri Sep 26 10:03:20 2025, [STAFF] wrote: Good morning [USER], This is just a reminder that we are starting your migration today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF] On Wed Sep 24 09:37:59 2025, [STAFF] wrote: Hello [USER], I've put your group's migration on our schedule for Friday September 26th. We will send you an email alert via this RT ticket when the migration has begun, and again once it has completed. Please let me know if you have any questions or concerns. Thank you, [STAFF] On Wed Sep 24 08:19:29 2025, [USER] wrote: Hi [STAFF], Any day between September 25 and Sept 30 would work best for us. Thank you, [USER] On Fri, Sep 12, 2025 at 5:55 PM via RT [EMAIL] wrote: Greetings, This message has been automatically generated in response to the creation of a ticket regarding: Subject: 'Migrating Research Storage Volume to Ceph Cluster - pi_erill' Message: Hello [USER], As per the communication via myUMBC earlier this summer (https://my3.my.umbc.edu/groups/hpcf/posts/150838), DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 238GB of a 1TB quota on the old storage server. To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at '/umbc/rs/erill'. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. Below we've listed two options for handling this data migration - please let us know which of these you'd prefer. Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day. Option 2: If you don't respond to this email by October 15th, DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes. Note: After this process has completed, the new storage volume will have a new name. For example, group 'pi_doit' will find its data under '/umbc/rs/pi_doit', or in your group's case you will find your volume under '/umbc/rs/pi_erill'. Thank you, [STAFF]"
"3268201","72416262","2025-10-22 01:37:54","Migrating Research Storage Volume to Ceph Cluster","Thank you! Best, [STAFF] On Tue, Oct 21, 2025 at 11:55 AM [EMAIL] via RT wrote: Ticket URL: https://rt.[DOMAIN]/Ticket/Display.html?id=3268201 Last Update From Ticket: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 7th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3268204","72397603","2025-10-21 15:53:09","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 6th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3268210","71752514","2025-09-17 14:52:39","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_[STAFF]. The alias used to reach the volume is now pi_[STAFF]_common and pi_[STAFF]_user. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Wed Sep 17 09:30:20 2025, [EMAIL] wrote: Good morning [USER], This is just a reminder that we are starting your migration today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Fri Sep 12 14:34:01 2025, [EMAIL] wrote: [USER], September 17th is perfectly fine. I've added your migration to our schedule. We will send you an email via this RT ticket when we begin your migration that morning, and again when it has completed. Best, [STAFF]. On Fri Sep 12 14:13:03 2025, [EMAIL] wrote: Hi [STAFF], How about next Wednesday, Sep 17? Otherwise, the following Wednesday Sep 24. Best, [USER]."
"3268228","72397869","2025-10-21 15:57:10","Migrating Research Storage Volume to Ceph Cluster - [ID]","Dear [STAFF], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 7th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3268229","72397981","2025-10-21 15:59:20","Migrating Research Storage Volume to Ceph Cluster - [ID]","Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 7th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3268234","71642131","2025-09-12 18:30:52","Migrating Research Storage Volume to Ceph Cluster","This is an email header, which contains information about the email's origin, routing, and delivery. Here's a breakdown of the key components:  1. **Received**: This line indicates that the email was received by a mail server (mx.mail.umbc.edu) from another mail server (umbc.edu). 2. **From**: The sender's email address is not explicitly stated, but it can be inferred from the `X-OriginatorOrg` header, which suggests that the email originated from utdallas.edu. 3. **To**: The recipient's email address is not specified in this header snippet. 4. **Subject**: The subject line of the email is 'Re: [Research Computing] Migrating to new storage system'. 5. **X-Forefront-Antispam-Report**: This header indicates that the email was scanned by Microsoft Forefront, an anti-spam and anti-virus solution. The report suggests that the email was not marked as spam. 6. **X-MS-Exchange-ATPSafeLinks-Stat**: This header is related to Microsoft Exchange's Advanced Threat Protection (ATP) feature, which checks links in emails for potential threats. 7. **X-OrganizationHeadersPreserved**: This header indicates that some organization-specific headers were preserved during the email's transit. 8. **X-CrossPremisesHeadersPromoted** and **X-CrossPremisesHeadersFiltered**: These headers suggest that the email was processed by a Microsoft Exchange server in a cross-premises scenario, where multiple organizations are involved.  The presence of various Microsoft-related headers (e.g., X-MS-Exchange) suggests that the email passed through a Microsoft Exchange server or a related infrastructure. The header also contains information about the email's routing, including the mail servers and IP addresses involved in its delivery.  Keep in mind that this is just an analysis of the provided header snippet, and there may be additional headers or content not shown here that could provide further context."
"3268236","72487453","2025-10-24 19:52:16","Migrating Research Storage Volume to Ceph Cluster - [ID]","Hello [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/[STAFF]. The alias used to reach the volume is now [SERVER]_common and [SERVER]_user. Your new volume has a quota of 10TB. When you have a chance, please try running some jobs on [SERVER] using the new volume to verify everything looks good. On Thu Oct 23 11:51:24 2025, [EMAIL] wrote: Dear [STAFF], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of October 24th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]. Best, [STAFF], DOIT Unix infra, Graduate Assistant"
"3268239","71944153","2025-09-25 15:38:38","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_[STAFF]. The alias used to reach the volume is now pi_[STAFF]_common and pi_[STAFF]_user. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Thu Sep 25 10:48:44 2025, [USER] wrote: Good morning [USER], This is just a reminder that we are starting your migration today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Fri Sep 12 15:42:59 2025, [USER] wrote: [USER], Great, I put your migration on our schedule for Thursday September 25. I will send you an email via this RT ticket when the volume migration begins and when it has finished. We usually expect the migration to finish by the end of business hours, same day. I've CC'd the users of your group to this email so they can see the migration updates. They will included again for the migration start and completion emails. Let me know if you have any questions or concerns. Best, [STAFF]. On Fri Sep 12 13:24:54 2025, [USER] wrote: Yes, September 25th should work. Are you emailing my group to let them know and then sending a reminder as well? On Fri, Sep 12, 2025, 13:09 [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3268239 > Last Update From Ticket: Joseph, We will start the migration around 9:30am on the day that we schedule, and we will need to have the volume offline for the duration of the migration. Normally we plan for a full business day of downtime, but usually this process is completed within a few hours. With that in mind, does September 25th work for you? Thank you, [STAFF]."
"3268244","72306344","2025-10-15 16:04:09","Migrating Research Storage Volume to Ceph Cluster","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_[STAFF]. The alias used to reach the volume is now pi_[STAFF]_common and pi_[STAFF]_user. Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Wed Oct 15 09:47:24 2025, [USER] wrote: Good morning [USER], I apologize for not responding yesterday as I was out sick, but today works for us for your group's storage migration. I will be beginning this process shortly. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Tue Oct 14 19:44:10 2025, [USER] wrote: Hi, Can you schedule the migration tomorrow October 15? Thanks. On Tue, Oct 14, 2025, 7:41 PM [STAFF] <[EMAIL]> wrote: Hi [STAFF], Quang can decide which data option is the best. Thanks. On Fri, Oct 10, 2025 at 10:44 AM Elliot Gobbert via RT <UMBCHelp@rt.umbc.edu> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3268244 > Last Update From Ticket: Hello [STAFF], This is a reminder email, in case you missed the first. We need a response by October 15th, or we'll be forced to go with Option 2, randomly scheduling a time. As per the communication via myUMBC earlier this summer (https://my3.my.umbc.edu/groups/hpcf/posts/150838), DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 17GB of a 100GB quota on the old storage server. To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at '/umbc/rs/jbrook1'. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. Below we've listed two options for handling this data migration - please let us know which of these you'd prefer. Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day. Option 2: If you don't respond to this email by October 15th, DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes. Note: After this process has completed, the new storage volume will have a new name. For example, group 'pi_doit' will find its data under '/umbc/rs/pi_doit', or in your group's case you will find your volume under '/umbc/rs/pi_[STAFF]'. Thank you, [STAFF]."
"3268246","72399390","2025-10-21 16:18:31","Migrating Research Storage Volume to Ceph Cluster - [ID]","Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 12th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3268247","72218174","2025-10-11 03:11:31","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Thanks for the update! We will run jobs and let you know if we encounter any issues. [STAFF]  On Fri, Oct 10, 2025, 23:08 [STAFF] via RT wrote: Ticket Last Update From Ticket: Hello [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: * The path has changed, and is now available under /umbc/rs/pi_[USER]. * The alias used to reach the volume is now pi_[USER]_common and pi_[USER]_user. * Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF] On Fri Oct 10 13:51:12 2025, [STAFF] wrote: Hello [USER], Understood, we will begin your migration shortly then. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF] On Fri Oct 10 11:13:09 2025, [USER] wrote: Thanks for the reminder! If you can do it today or over the weekend, please go ahead. We don't have jobs running at the moment. Best, [USER] On Fri, Oct 10, 2025 at 10:48 AM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hello [USER], This is a reminder email, in case you missed the first. We need a response by October 15th, or we'll be forced to go with Option 2, randomly scheduling a time. As per the communication via myUMBC earlier this summer (https://my3.my.umbc.edu/groups/hpcf/posts/150838), DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 224GB of a 250GB quota on the old storage server. To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at '/umbc/rs/[USER]'. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. Below we've listed two options for handling this data migration - please let us know which of these you'd prefer. Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day. Option 2: If you don't respond to this email by October 15th, DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes. Note: After this process has completed, the new storage volume will have a new name. For example, group 'pi_doit' will find its data under '/umbc/rs/pi_doit', or in your group's case you will find your volume under '/umbc/rs/pi_[USER]'. Thank you, [STAFF]"
"3268248","72091734","2025-10-03 19:32:32","Migrating Research Storage Volume to Ceph Cluster","Ticket comment just added. Marking these weird ones as 'special'."
"3268249","72398036","2025-10-21 16:00:44","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Dear [STAFF], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 10th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3268251","72329501","2025-10-16 17:01:19","Migrating Research Storage Volume to Ceph Cluster - pi_boot","Hello again everyone, We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_boot. The alias used to reach the volume is now pi_boot_common and pi_boot_user. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Thu Oct 16 11:41:31 2025, [USER] wrote: Hello [USER], James and Lee, This is a reminder that we'll be starting your group's research storage volume migration today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Wed Oct 15 10:51:08 2025, [USER] wrote: Hello [USER], James and Lee, Understood, in that case we'll schedule your group's migration for Thursday October 16th (tomorrow). We can certainly help you with accessing your storage volume! Just let us know what questions you have and we can help you get started. We also have some documentation on our wiki for accessing your storage volume from Chip, if it helps: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip. Best, [STAFF]. On Mon Oct 13 12:12:09 2025, [USER] wrote: Hi [STAFF], We aren't sure what is in that space. Go ahead with the migration at a time that works best for you. We may need your assistance to access and archive that data. Thanks, [USER]. On Mon, Oct 13, 2025 at 9:48 AM [USER] wrote: Dear [STAFF], I just received this email this morning. [USER] and I are working on a solution today. It seems we just need to back up less than 500 GB of storage prior to any migration. I'm not sure what an RRStor Ceph storage cluster is or what that means for our data, but we'll be in touch today. -- [USER]. On Fri, Oct 10, 2025 at 2:01 PM [USER] wrote: Hi [STAFF], I have retired but am copying this to [USER], the new Director of the IRC, and [USER], the Technical Director. Thanks, [USER]. On Fri, Oct 10, 2025 at 10:09 AM Elliot Gobbert via RT wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3268251 Last Update From Ticket: Hello [USER], This is a reminder email, in case you missed the first. We need a response by October 15th, or we'll be forced to go with Option 2, randomly scheduling a time. As per the communication via myUMBC earlier this summer (https://my3.my.umbc.edu/groups/hpcf/posts/150838), DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 429GB of a 500GB quota on the old storage server. To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes. Note: After this process has completed, the new storage volume will have a new name. For example, group 'pi_doit' will find its data under '/umbc/rs/pi_doit', or in your group's case you will find your volume under '/umbc/rs/pi_boot'. Thank you, [STAFF]."
"3268256","71797902","2025-09-18 19:20:34","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","This appears to be a lengthy email thread between Gregory Ballantine, a System Administrator for Research and Enterprise Computing at UMBC (University of Maryland, Baltimore County), and an individual named Lei Zhang. The conversation is about migrating data from an older storage server to a new RRStor Ceph storage cluster.  Here's a summary of the key points:  1. **Data migration**: DoIT (Division of Information Technology) is migrating data from an old storage server to a new RRStor Ceph storage cluster. 2. **Volume name change**: After the migration, the volume will have a new name, e.g., `/umbc/rs/pi_leizhang` instead of `/umbc/rs/leizhang`. 3. **Options for handling data migration**:  * Option 1: Schedule a group-wide downtime date during standard business hours.  * Option 2: If no response by October 15th, DoIT will assign a random day between October 16th and November 15th to perform the migration. 4. **Notification**: DoIT will send an email alert when the migration begins and when it has completed. 5. **New quota**: The new storage volume will have a new quota of 1TB (up from the original 288GB). 6. **Ticket ID**: The ticket number for this request is #3268256.  The conversation appears to be a notification from DoIT to Lei Zhang's group about the upcoming data migration and the options available for handling it."
"3268259","72486300","2025-10-24 19:20:28","Migrating Research Storage Volume to Ceph Cluster - knacc1","We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed and is now available under /umbc/rs/[STAFF]. The alias used to reach the volume is now [ALIAS] and [ALIAS]. Your new volume has a quota of 10TB. When you have a chance please try running some jobs on Chip using the new volume to verify everything looks good On Fri Oct 24 09:05:38 2025 [STAFF] wrote: This is just a reminder that we are starting your migration today. During this time please ensure there are not any jobs being run in your research group otherwise these may be terminated. We will provide an update once completed. On Fri Oct 10 13:44:24 2025 [STAFF] wrote: Hello [USER] I've put your group on our schedule for Friday October 24th. We will send you an email alert via this RT ticket when we begin the migration process and again once it has completed. Please let us know if you have any questions or concerns. Best [STAFF]. On Fri Oct 10 11:06:58 2025 [USER] wrote: Hi I currently don't use UMBC IT services but plan to use it next year. Please follow your schedule as per your convenience. Thanks [USER]. On Fri Oct 10 10:50 AM Elliot Gobbert via RT UMBCHelp@rt.umbc.edu wrote: Ticket URL: https://rt.umbc.edu/Ticket/Display.html?id=3268259 Last Update From Ticket: Hello [USER] This is a reminder email in case you missed the first. We need a response by October 15th or we'll be forced to go with Option 2 randomly scheduling a time. As per the communication via myUMBC earlier this summer https://my3.my.umbc.edu/groups/hpcf/posts/150838 DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 6GB of a 250GB quota on the old storage server. To perform these migrations we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at /umbc/rs/[STAFF]. During the migration we will take your volume offline and will terminate any jobs running on the Chip compute cluster that are accessing this volume. Below we've listed two options for handling this data migration - please let us know which of these you'd prefer. Option 1: Schedule a group-wide downtime date during standard business hours which can be done by responding to this email with your preferred date(s) to perform the migration. During this time DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes this process should take less than a business day. Option 2: If you don't respond to this email by October 15th DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration and will be notified when the migration begins and completes. Note: After this process has completed the new storage volume will have a new name. For example group pi_doit will find its data under /umbc/rs/pi_doit or in your group's case you will find your volume under /umbc/rs/[STAFF]. Thank you Elliot. Best Beamlak Bekele DOIT Unix infra Graduate Assistant"
"3268261","72351229","2025-10-17 16:31:53","Migrating Research Storage Volume to Ceph Cluster - [ID]","Hello [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_[STAFF]. The alias used to reach the volume is now pi_[STAFF]_common and pi_[STAFF]_user. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Fri Oct 17 10:03:47 2025, [USER] wrote: Good morning [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Mon Oct 13 09:01:38 2025, [USER] wrote: Good morning [USER], Sounds good, I've added your group's migration to our schedule for Friday October 17th. We will send you an email alert via this RT ticket when we begin the migration, and again once it has completed. Please let us know if you have any questions or concerns. Best, [STAFF]. On Sun Oct 12 18:08:49 2025, [USER] wrote: Hi [STAFF] - Thank you for reaching out. Any of the following dates work for us (Option 1): 10/17, 10/24 or 10/31 Thank you! [USER]. On Fri, Oct 10, 2025, [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=326821 > Last Update From Ticket: Hello [USER], This is a reminder email, in case you missed the first. We need a response by October 15th, or we'll be forced to go with Option 2, randomly scheduling a time. As per the communication via myUMBC earlier this summer (https://my3.my.umbc.edu/groups/hpcf/posts/150838), DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 2.5GB of a 250GB quota on the old storage server. To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at '/umbc/rs/lkelly'. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. Below we've listed two options for handling this data migration - please let us know which of these you'd prefer. Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day. Option 2: If you don't respond to this email by October 15th, DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes. Note: After this process has completed, the new storage volume will have a new name. For example, group 'pi_doit' will find its data under '/umbc/rs/pi_doit', or in your group's case you will find your volume under '/umbc/rs/pi_[STAFF]'. Thank you, [STAFF]."
"3268263","72721197","2025-11-04 17:12:38","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly other than it taking longer than expected. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_[USER]. The alias used to reach the volume is now pi_[USER]_common and pi_[USER]_user. Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? I apologize if the extended length of the migration caused any issues for you and your group. Thank you, [STAFF]. On Mon Nov 03 21:06:37 2025, [STAFF] wrote: Hello again [USER], Your group's storage migration to the Ceph storage cluster is taking a bit longer than expected. I'll leave the copy running overnight and will send you an email in the morning with a status update. I apologize for any inconvenience this may cause you and your group. Best, [STAFF]. On Mon Nov 03 11:42:24 2025, [STAFF] wrote: Hello [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Wed Oct 15 10:48:11 2025, [STAFF] wrote: [USER], Awesome, I've put your group's storage migration on our schedule for November 3rd. We will send you an email notification via this RT ticket when we begin the migration, and again once it has completed. Please let us know if you have any questions or concerns. Best, [STAFF]. On Wed Oct 15 10:34:00 2025, [USER] wrote: Yes [STAFF]. November 3 works for my group."
"3268264","72210836","2025-10-10 17:13:32","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_[STAFF]. The alias used to reach the volume is now pi_[STAFF]_common and pi_[STAFF]_user. Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Tue Sep 16 16:17:21 2025, [USER] wrote: I currently have one active student using the cluster, and all of his most recent data is in his user directory. We would like to retain the old data (at least until he graduates), but there are no upcoming deadlines that would make taking it offline for a day or two a particular problem. Feel free to pick a day at your convenience. On Fri, Sep 12, 2025 at 12:52 PM via RT [EMAIL] wrote: Greetings, This message has been automatically generated in response to the creation of a ticket regarding: Subject: 'Migrating Research Storage Volume to Ceph Cluster - pi_[STAFF]' Message: Hello [USER], As per the communication via myUMBC earlier this summer (https://my3.my.umbc.edu/groups/hpcf/posts/150838), DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 42GB of a 130GB quota on the old storage server. To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at '/umbc/rs/[STAFF]'. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. Below we've listed two options for handling this data migration - please let us know which of these you'd prefer. Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day. Option 2: If you don't respond to this email by October 15th, DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes. Note: After this process has completed, the new storage volume will have a new name. For example, group 'pi_doit' will find its data under '/umbc/rs/pi_doit', or in your group's case you will find your volume under '/umbc/rs/pi_[STAFF]'. Thank you, [STAFF]."
"3268265","71884001","2025-09-23 16:02:30","Migrating Research Storage Volume to Ceph Cluster - [ID]","Handling this in RT#[TICKETNUMBER] now, as [STAFF] opened up a new ticket asking for more storage space."
"3268267","72488934","2025-10-24 21:06:25","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Leaving this as stalled for now while I figure out what to do with data such as this. On Thu Oct 23 15:27:57 2025, [EMAIL] wrote: Hi there, I did not receive an earlier correspondence- it may have gotten filtered out into my spam box. Apologies for missing it. You can actually delete that volume- I don't need any of those files anymore and you may as well clean them up. Thank you, On Thu, Oct 23, 2025, 8:49 AM [STAFF] via RT wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=326827> Last Update From Ticket: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of October 24th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3268270","72477920","2025-10-24 14:59:23","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Sounds good. Ticket: https://rt.umbc.edu/Ticket/Display.html?id=3268270 Last Update From Ticket: Hello This is just a reminder that we are starting your migration today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. On Mon Oct 13 07:52:03 2025, [STAFF] wrote: All sounds great. Thanks for your help. Mark On Fri, Oct 10, 2025 at 1:43 PM [STAFF] via RT UMBCHelp@rt.umbc.edu wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3268270 Last Update From Ticket: Hello Mark, No worries I've put your group on our schedule for Friday October 24th. We will send you an email alert via this RT ticket when we begin the migration process, and again once it has completed. Please let us know if you have any questions or concerns. Best, [STAFF] On Fri Oct 10 11:52:50 2025, [USER] wrote: Elliot, Thanks for checking in on this, and apologies for not responding sooner. I had to check with my students. I think we're flexible on timing. Please schedule when it's good for you and just let me know when this will be.Thanks, Mark On Fri, Oct 10, 2025 at 10:54 AM [STAFF] via RT UMBCHelp@rt.umbc.edu wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3268270 Last Update From Ticket: Hello Mark, This is a reminder email. We need a response by October 15th, or we'll be forced to go with Option 2, randomly scheduling a time. As per the communication via myUMBC earlier this summer https://my3.my.umbc.edu/groups/hpcf/posts/150838, DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 219GB of a 2TB quota on the old storage server. To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at /umbc/rs/marten. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. Below we've listed two options for handling this data migration - please let us know which of these you'd prefer. Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day. Option 2: If you don't respond to this email by October 15th, DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes. Note: After this process has completed, the new storage volume will have a new name. For example, group pi_doit will find its data under /umbc/rs/pi_doit, or in your group's case you will find your volume under /umbc/rs/pi_marten. Thank you, [STAFF]"
"3268273","72271262","2025-10-14 18:53:47","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/[STAFF]. The alias used to reach the volume is now [STAFF]_common and [STAFF]_user. Your new volume has a quota of 10TB. When you have a chance, please run some jobs on Chip using the new volume and verify everything looks good. Thank you, On Tue Oct 14 09:40:13 2025, [EMAIL] wrote: Hello This is just a reminder that we are starting your migration today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. On Fri Oct 10 14:34:14 2025, [EMAIL] wrote: Hello Matt, Sounds good, I've added your group's migration to our schedule for Tuesday October 14th. We will send you an email alert via this RT ticket when we begin the migration, and again once it has completed. Please let us know if you have any questions or concerns. Best, [STAFF] On Fri Oct 10 14:20:49 2025, [EMAIL] wrote: Hi Elliot You can perform the migration on the 14th. Cheers, [USER] On Fri, Oct 10, 2025 at 10:55 AM [EMAIL] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3268273> Last Update From Ticket: Hello [USER], This is a reminder email, in case you missed the first. We need a response by October 15th, or we'll be forced to go with Option 2, randomly scheduling a time. As per the communication via myUMBC earlier this summer (https://my3.my.umbc.edu/groups/hpcf/posts/150838), DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 3.3TB of a 10TB quota on the old storage server. To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at '/umbc/rs/mbaker'. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. Below we've listed two options for handling this data migration - please let us know which of these you'd prefer. Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day. Option 2: If you don't respond to this email by October 15th, DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes. Note: After this process has completed, the new storage volume will have a new name. For example, group 'pi_doit' will find its data under '/umbc/rs/pi_doit', or in your group's case you will find your volume under '/umbc/rs/pi_mbaker'. Thank you, [STAFF]"
"3268426","71728209","2025-09-16 15:48:57","HPC User Account: [USER] in pi_[ID]","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) On Fri Sep 12 16:25:24 2025, [STAFF] wrote: Thank you for sending this message; I approve of this request. On Fri, Sep 12, 2025 at 3:21 PM RT API via RT <[EMAIL]> wrote: This e-mail is a notification that a UMBC user: [USER] <[EMAIL]> has requested an account within UMBC's HPC environment in your group <pi_[STAFF]>. As the PI, we request that you acknowledge and approve this account creation by replying to this message. Alternatively, you can go to this link and review the ticket and indicate your decision here: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3268426> Once we have your approval, we will create the account and you and the new user will receive another e-mail notifying you that the account has been created. If you have any other questions or concerns please contact us. -- Best, [STAFF]"
"3268494","71702447","2025-09-15 16:06:06","HPC Slurm/Software Issue: Storage Issues","Thank you I'll keep du -sh ~/* .[^.]* | sort -h in mind for later use On Mon Sep 15 2025 at 9:53 AM [STAFF] via RT <[EMAIL]> wrote If you agree your issue is resolved please give us feedback on your experience by completing a brief satisfaction survey https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3268494&ticketowner=[STAFF]&ticketsubject=HPC Slurm/Software Issue: Storage Issues If you believe your issue has not been resolved please respond to this message which will reopen your ticket Note A full record of your request can be found at Ticket https://rt.umbc.edu/Ticket/Display.html?id=3268494 Thank You Hi Sometimes other hidden directories besides .cache can also fill up It depends on your workflow which ones are more likely to fill up To identify which directories exist ls -la ~ Hidden directories start with a period '.' Generally .conda .cache .local fill up a lot To show you all the sizes of the folders in your home directory use this command du -sh ~/* .[^.]* | sort -h I checked this on [USER] account and it appears that the .conda directory is the directory that is full To mitigate this [USER] can move the directory to research volume then create a symbolic link Please follow the documentation on our wiki to move the directory and create a link https://umbc.atlassian.net/wiki/spaces/faq/pages/1118765095/What+to+do+if+I+run+out+of+space+in+my+chip+home+directory#2.-Use-Symbolic-Links-to-redirect-data-to-your-research-volume Be sure to replace the variables/example path names with the actual paths for [USER] account Have a nice day Kind regards [STAFF] DoIT Unix Infra Student Worker On Fri Sep 12 16:37:08 2025 [USER] wrote First Name [USER] Last Name [USER] Email [EMAIL] Campus ID [ID] Request Type High Performance Cluster Storage is full unsure why Already removed cache with rm -rf /home/[USER]/.cache rm -rf /umbc/rs/laramar/users/[USER]/.cache Thanks Original Request Requestors [USER] First Name [USER] Last Name [USER] Email [EMAIL] Campus ID [ID] Request Type High Performance Cluster Storage is full unsure why Already removed cache with rm -rf /home/[USER]/.cache rm -rf /umbc/rs/laramar/users/[USER]/.cache Thanks"
"3272079","71712153","2025-09-15 19:42:07","HPC New Group: [ID]","Hi [USER], The group pi_[STAFF] now exists on the chip cluster. Members of this group can therefore access and contribute to the research storage space allocated to the group. This storage is located at /umbc/rs/pi_[STAFF] and currently has a quota of 10T. Additionally, Your account ([STAFF]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link: (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) Lastly, regarding cryoSPARC. Currently, this is not installed on the cluster. This may be something that you are able to install for yourself on a per user basis, however we can also look into installing it cluster wide (however this would be a bit more complicated). We can certainly look into this if you would like to submit a new ticket for the install! Have a great day! -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Mon Sep 15 09:21:31 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Group Type: Project Title: [PROJECTTITLE] Project Abstract: [PROJECTABSTRACT] My name is [USER], I'm an Associate Professor in Chemistry and Biochemistry, and I'm looking to set up a new user account and group on the high-performance cluster. We would specifically like to have access to the cluster to use cryoSparc, the gold-standard software for cryo-EM data processing (https://guide.cryosparc.com), which is something we cannot run locally on our machines due to its high computing needs."
"3272116","71789147","2025-09-18 16:00:22","HPC Other Issue: matlab plotting issues","Hi [USER], As far as I know, nothing was changed on the machine. But I am glad that the issue resolved itself. Have a nice day! -- Kind regards, [STAFF] On Tue Sep 16 14:46:18 2025, [USER] wrote: Hi [STAFF], Was anything reset on the machine after I submitted the ticket? Because an hour later, things started working. a) I now force interactive Matlab session to start with matlab -nodesktop -softwareopengl but in any case even without that, and before submitting the ticket, Matlab was printing 'MATLAB is selecting SOFTWARE OPENGL rendering' b) regarding the mysterious resizing, i found the way to force Matlab to stick with the specified figure size is to use set(handle,'resize','off') before issuing the size command So for now, I'm happy with Matlab ... -[USER] On Tue, Sep 16, 2025 at 12:57 PM [STAFF] via RT wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3272116 > Last Update From Ticket: Hi [USER], Could you please paste/include a log file with all the errors you are getting? Personally, when testing with c24-52, I received no errors/issues when using MATLAB and testing the commands you provided. Thanks -- Kind regards, [STAFF] On Mon Sep 15 09:51:50 2025, [USER] wrote: > First Name:                               Sergio > Last Name:                               De souza-machad > Email:                                         [EMAIL] > Campus ID:                               VR64161 > > Request Type:                         High Performance Cluster > > For the last few days, when I am trying to plot using Matlab on c24-52, I randomly get tons of warnings >> Couldn't create JOGL canvas--using painters > I've googled around, tried >>> matlab -softwareopengl from https://www.mathworks.com/matlabcentral/answers/157894-resolving-low-level-graphics-issues-in-matlab > but its not getting resolved, Can you look into this and tell me what's wrong? > > In addition, these commands(admittedly, from Google AI), worked before to resize a graphics window, but no longer work. Can you see if they work for you? I am trying to open a  plot that is twice as wide ie instead of default 560x420, I want to have one that is 1120x420 > % Create a figure (or get the handle of the current figure) f = figure; % Create a new figure and get its handle > > % Define new position and size parameters new_x = 50; new_y = 50; new_width = 560*2; new_height = 420; > > % Set the Position property of the figure set(f, 'Position', [new_x, new_y, new_width, new_height]); > > % Alternatively, if you want to modify the current figure (gcf) % set(gcf, 'Position', [new_x, new_y, new_width, new_height]); > > Thanks"
"3272362","71713287","2025-09-15 20:00:05","HPC Slurm/Software Issue: RuntimeError: Data processing error: CAS service error : IO Error: No space left on device (os error 28)","Hi, Now it appears that your .cache is filled up. It also does not appear that your .cache is actually symbolically linked to the .cache inside your research volume (so that space is not being utilized). While it appears there is a symbolic link, it does not appear to be correct. The location of the symbolic link is actually inside the research volume, instead of inside your home folder. First, unlink the old .cache: unlink /umbc/rs/pi_laramar/users/[USER]/.cache Move current .cache: mv ~/.cache /umbc/rs/pi_laramar/users/[USER]/ Create link: ln -s /umbc/rs/pi_laramar/users/[USER]/.cache ~/.cache Here is the link to the steps: https://umbc.atlassian.net/wiki/spaces/faq/pages/1118765095/What+to+do+if+I+run+out+of+space+in+my+chip+home+directory#2.-Use-Symbolic-Links-to-redirect-data-to-your-research-volume Now this will actually move the .cache folder to the new location, and will prevent your home directory from being filled up further by python cache. Let me know if you have any questions or issues! -- Kind regards, [STAFF] On Mon Sep 15 12:23:51 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Cluster Attempted to run a python script. Attached error message I already cleared both caches with: rm -rf /home/[USER]/.cache rm -rf /umbc/rs/laramar/users/[USER]/.cache I still recieved the error. How should I proceed? Thank you. Attachment 1: error.txt"
"3272500","71711413","2025-09-15 19:27:54","HPC Slurm/Software Issue: Updates on RT #[ID]","I added you as a requestor to the ceph migration ticket, please continue our discussion there! I will go ahead and close this ticket (and the previous ticket, RT #[STAFF]) now! Have a nice day! On Mon Sep 15 15:10:14 2025, [USER] wrote: Could you please let me know the estimated downtime and when we are scheduling it, so I can have everyone informed. Thanks. On Mon, Sep 15, 2025, 3:05 PM [STAFF] via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=[STAFF]&ticketowner=[STAFF]&ticketsubject=HPC Slurm/Software Issue: Updates on RT #[STAFF]. If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=[STAFF] >. Thank You. _______________________________________. R e s o l u t i o n: = = = = = = = = = = = = = = = = = = = Sure, no problem. Thanks for letting me know. -- Kind regards, [STAFF]. On Mon Sep 15 15:01:48 2025, [USER] wrote: > Thank you so much. Could you please copy me onto the migration ticket, as we will require more space; however, it appears that this is not the case. It will be really helpful if you can fix that. We were expecting to be assigned 25 TB of storage, but that was not the case; instead, we were given only 100 GB of shared storage. It was mentioned that the primary group is named pi_sherman, but that does not seem to be the case. The primary group is named sherman. > 3. Account creation for Bill Bardon [EMAIL] Bill Bardon [STAFF] [EMAIL]. Thanks, [USER]. _______________________________________. Original Request: Requestors: [USER]. First Name: [USER]. Last Name: [USER]. Email: [EMAIL]. Campus ID: [STAFF]. Request Type: High Performance Cluster. Hi, It has been over a week since any activity or update on RT #[STAFF].. The delay is holding back the research group significantly. Your prompt attention to the matter will be greatly appreciated. Main action items on the ticket: 1. Users are not even able to access their user directory in the research group. Please fix all the permission issues. (base) [USER@chip-login1 ~]$ cd /umbc/rs/sherman. (base) [USER@chip-login1 sherman]$ cd common/ users/. (base) [USER@chip-login1 sherman]$ cd users/. -bash: cd: users/: Permission denied. (base) [USER@chip-login1 sherman]$. 2. We requested that our group be assigned the Ceph-mounted research volume, as we will require more space; however, it appears that this is not the case. It will be really helpful if you can fix that. We were expecting to be assigned 25 TB of storage, but that was not the case; instead, we were given only 100 GB of shared storage. It was mentioned that the primary group is named pi_sherman, but that does not seem to be the case. The primary group is named sherman. 3. Account creation for Bill Bardon [EMAIL] Bill Bardon [STAFF] [EMAIL]. Thanks, [USER]."
"3272538","71730569","2025-09-16 16:33:11","Access to CHIP","The account [USER] has been created on chip.rs.umbc.edu. The primary group is iharp. The home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/). Approved. The student needs access to /umbc/rs/iharp/projects/Satellite_data for data analysis."
"3272578","71753532","2025-09-17 15:11:10","pi_sherman: Research Volume Ceph Migration","Thanks and will do. On Wed, Sep 17, 2025, 11:09 AM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hello [USER] and [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: * The path has changed, and is now available under /umbc/rs/pi_[USER]. * The alias used to reach the volume is now pi_[USER]_common and pi_[USER]_user. * Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Wed Sep 17 09:26:31 2025, [STAFF] wrote: Good morning [USER] and [USER], This is just a reminder that we are starting your migration today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Mon Sep 15 16:47:14 2025, [USER] wrote: I approve. Please schedule as soon as possible. Thanks. Dr. [USER], Director, Cyber Defense Lab (CDL). On Mon, Sep 15, 2025 at 3:26 PM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hi [USER], I added you as a requestor for this ticket. Unfortunately, we still would need written approval for the downtime/migration from your PI. If we could get just a quick approval from your PI to move forward, that would be great. Regarding timeline for the migration, the soonest we can migrate your group is this Wednesday. Currently, it is too late in the day to begin that, and tomorrow there is some ongoing maintenance with Ceph that could impact migrations, so we want to schedule around it. I do not expect the migration to take long, given your current research volume has roughly 6.4 GB of usage. Depending on what time the migration begins, I expect that it will only last a couple hours at most. Of course, you can continue using the previously allocated 100GB on isilon in the mean time. Let me know if you have any additional questions! -- Kind regards, [STAFF] (she/her/hers). DoIT Unix Infra Student Worker. On Mon Sep 15 14:52:05 2025, [STAFF] wrote: Dear [USER], As per the communication via myUMBC earlier this summer (June HPCF Newsletter), DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at '/umbc/rs/[USER]'. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. Below we've listed two options for handling this data migration - please let us know which of these you'd prefer. Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day. Option 2: If you don't respond to this email by October 15th, DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes. Note: After this process has completed, the new storage volume will have a new name. For example, group 'pi_doit' will find its data under '/umbc/rs/pi_doit', or in your group's case you will find your volume under '/umbc/rs/pi_[USER]'. -- Kind regards, [STAFF] (she/her/hers). DoIT Unix Infra Student Worker."
"3272780","71729399","2025-09-16 16:10:08","HPC User Account: [USER] in [ID]","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) On Mon Sep 15 17:48:26 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [USER] Request Type:              High Performance Cluster Create/Modify account in existing PI group Existing PI Email:    [EMAIL] Existing Group:       pi_[STAFF] Project Title:        Emergency Triage Benchmark: Bridging Hospital-Rich and MCI-Like Field Simulation Project Abstract:     Research on emergency and mass casualty incident (MCI) triage has been limited by the absence of openly usable, reproducible benchmarks. Yet these scenarios demand rapid identification of the patients most in need, where accurate deterioration prediction can guide timely interventions. While the MIMIC-IV-ED database is openly available to credentialed researchers, transforming it into a triage-focused benchmark requires extensive preprocessing, feature harmonization, and schema alignment---barriers that restrict accessibility to only highly technical users. We address these gaps by first introducing an open, LLM-assisted emergency triage benchmark for deterioration prediction (ICU transfer, in-hospital mortality). The benchmark then defines two regimes: (i) a hospital-rich setting with vitals, labs, notes, chief complaints, and structured observations, and (ii) an MCI-like field simulation limited to vitals, observations, and notes. Large language models (LLMs) contributed directly to dataset construction by (i) harmonizing noisy fields such as AVPU and breathing devices, (ii) prioritizing clinically relevant vitals and labs, and (iii) guiding schema alignment and efficient merging of disparate tables. We further provide baseline models and SHAP-based interpretability analyses, illustrating predictive gaps between regimes and the features most critical for triage. Together, these contributions make triage prediction research more reproducible and accessible---a step toward dataset democratization in clinical AI. professor has granted permission"
"3272781","71729046","2025-09-16 16:03:32","HPC User Account: [ID] in pi_[STAFF]","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) On Mon Sep 15 17:49:14 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Create/Modify account in existing PI group Existing PI Email:    [EMAIL] Existing Group:       pi_[STAFF] Project Title:        Emergency Triage Benchmark: Bridging Hospital-Rich and MCI-Like Field Simulation Project Abstract:     Research on emergency and mass casualty incident (MCI) triage has been limited by the absence of openly usable, reproducible benchmarks. Yet these scenarios demand rapid identification of the patients most in need, where accurate deterioration prediction can guide timely interventions. While the MIMIC-IV-ED database is openly available to credentialed researchers, transforming it into a triage-focused benchmark requires extensive preprocessing, feature harmonization, and schema alignment---barriers that restrict accessibility to only highly technical users. We address these gaps by first introducing an open, LLM-assisted emergency triage benchmark for deterioration prediction (ICU transfer, in-hospital mortality). The benchmark then defines two regimes: (i) a hospital-rich setting with vitals, labs, notes, chief complaints, and structured observations, and (ii) an MCI-like field simulation limited to vitals, observations, and notes. Large language models (LLMs) contributed directly to dataset construction by (i) harmonizing noisy fields such as AVPU and breathing devices, (ii) prioritizing clinically relevant vitals and labs, and (iii) guiding schema alignment and efficient merging of disparate tables. We further provide baseline models and SHAP-based interpretability analyses, illustrating predictive gaps between regimes and the features most critical for triage. Together, these contributions make triage prediction research more reproducible and accessible---a step toward dataset democratization in clinical AI. Professor has granted permission. Best, [STAFF]"
"3272783","71883080","2025-09-23 15:46:19","HPC Other Issue: Storage Inquiries","I have tested it on my side and you are correct the change in server install path doesn't work anymore. I will investigate the issue and update the wiki. Another way to change where vscode-server is located is to move it to your research directory, then create a symbolic link from home directory to research storage. This are the commands you will need to run mv .vscode-server /umbc/rs/pi_ryus/users/[USER]/. ln -s /umbc/rs/pi_ryus/users/[USER]/.vscode-server ~/.vscode-server Let me know if your home directory is still filling up with vscode stuff after making this change. On Sat Sep 20 13:47:32 2025, [STAFF] wrote Hi I've been following the instructions for the vscode location but it seems to still be in my home directory and not the location I specified. Is there a step that I did incorrectly? If you agree your issue is resolved please give us feedback on your experience by completing a brief satisfaction survey https//umbc.us2.qualtrics.com/SE/SID=[SURVEY_ID]&customeremail=[EMAIL]&groupid=EIS&ticketid=3272783&ticketowner=[STAFF_EMAIL]&ticketsubject=HPC Other Issue Storage Inquiries. If you believe your issue has not been resolved please respond to this message which will reopen your ticket. Note A full record of your request can be found at Ticket <https//rt.umbc.edu/Ticket/Display.html?id=3272783>. Hi [USER] We have documentation on how to use our clusters ollama here https//umbc.atlassian.net/wiki/spaces/faq/pages/1408335873/Running+Ollama+on+chip. It has 'Pulling Modules' section that will show you how to move your .ollama directory to your research volume which has a bigger storage than your home directory. We also have documentation on how to set up vs code so it will not fill up your home directory here https//umbc.atlassian.net/wiki/spaces/faq/pages/1141800970/How+to+connect+to+chip+with+VSCode. You will need to change server install path once that is configured you can delete your existing .vscode-server in your home directory. Your home directory is only 500MB. We recommend that all of your projects be stored in your research volume which is /umbc/rs/pi_ryus/users/[USER] so you won't fill up your home directory. I will mark this ticket resolved but let us know if you still have issues. On Mon Sep 15 17:51:15 2025 [REQUESTOR_NAME] wrote First Name [USER_FIRST_NAME] Last Name [USER_LAST_NAME] Email [EMAIL] Campus ID [CAMPUS_ID] Request Type High Performance Cluster I’m trying to run and edit my project on the cluster but I’m unable to save files due to being over my storage quota. After checking it looks like most of the space is being used by Ollama and the VS Code server. I recall hearing that Ollama is already installed on the cluster — if that’s the case could you provide guidance on how I should be accessing it instead of maintaining my own copy in ~/.ollama Additionally are there recommended practices for handling the VS Code server storage so it doesn’t quickly exceed quota limits? Thank you"
"3272820","71791192","2025-09-18 16:50:14","HPC Other Issue: Frequent Chip Deactivation Issue","I cannot find anything server side that would be causing these issues. Do you get any output/error printed to the terminal from the ssh session when it terminates? Also, how are you sshing? Are you using something like putty, or just your computer's command prompt/terminal? Do you by chance have any locally configured SSH settings that could be causing the timeout? Perhaps in ~/.ssh/config or a similar location? Values such as ConnectTimeout, ServerAliveInterval, or ServerAliveCountMax could potentially cause timeout issues. I have a couple of things for you to try out. First, when ssh'ing, you can try to specify certain client side config values to ensure you do not get timed out. ssh -o ServerAliveInterval=30 -o TCPKeepAlive=yes username@chip.rs.umbc.edu This would send a keepalive packet every 30 seconds and ensure that TCPKeepAlive is set to yes. Let me know if this changes the behavior you are receiving. Additionally, could you confirm if you are using GlobalProtect VPN when connecting to chip? If you aren't, perhaps attempt to use that and see if it changes the behavior. Lastly, if possible, to eliminate the possibility of it being client side, have you/are you able to test logging in from another machine? Let me know if this works for you! If not we can continue to look. Have a nice day! -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Thu Sep 18 10:50:07 2025, [USER] wrote: Hello, I'd like to follow up with our previous conversation about frequent time out of my session. My session timeout after 10 minutes of inactivity . Usually, I have to re-login to my session whenever I need to work on another tab and then come back to my session, this is very inconvenient for me. Could you please help me to fix it. Thanks! Best, [USER]"
"3272833","71730120","2025-09-16 16:25:08","HPC Slurm/Software Issue: Installing new commands within Stata program on chip","Hi [USER], I was initially going to suggest looking into moving the install directory for the command to a different location, however after taking a look at your home folder, I can see that the issue is actually not from stata/the ado directory. It appears that Anaconda is actually the issue. Anaconda attempts to write to a hidden folder in your home folder, that can get filled up after creating conda environments and installing packages. Luckily this is a very simple solution, you just need to move the problem directory to a new location (on your research volume), and then create a symbolic link in your home folder that points to the new location. Here is a wiki page that outlines the steps: https://umbc.atlassian.net/wiki/spaces/faq/pages/1118765095/What+to+do+if+I+run+out+of+space+in+my+chip+home+directory For future reference, this command is quite helpful for determining what directory in your home dir is full: du -sh ~/* .[^.]* | sort -h 1. First, move the .conda directory to your research volume mv ~/.conda /umbc/rs/[GROUP]/users/[USER]/.conda 2. Create a symbolic link ln -s /umbc/rs/[GROUP]/users/[USER]/.conda ~/.conda Now the directory should be moved to a location with additional storage space, thus allowing you to continue using stata as expected. I will say that, if the issue was actually from the stata directories in your home folder, you could repeat the same steps above with those if they end up getting filled up. I know a lot of programs like writing to folders inside users home directories, which can result in it filling up. Let me know if you run into any issues with this process! Have a nice day! -- Kind regards, [STAFF] On Mon Sep 15 20:25:15 2025, [USER] wrote: First Name:                [USER] Last Name:                 [LASTNAME] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster I am trying to install two new commands (drdid and csdid) within Stata. The standard command once Stata is loaded is 'ssc install drdid' but the program says it can't write to the directory and I can't seem to upload anything to the /home/[USER]/ folder. The system says I am using the full 500M but I don't think I have that many files so I'm not sure what's going on. Regardless, Stata needs to be able to install new programs somewhere. If the home folder is too small then I need to put them elsewhere. I'm not sure if I need to request that these be loaded by a system administrator. (See output below) Thanks! STATA ERROR: . ssc install drdid checking drdid consistency and verifying not already installed... cannot write in directory /home/[USER]/ado/plus/d r(603); SYSTEM OUTPUT: Filesystem                            Size  Used Avail Use% Mounted on nfs.iss:/ifs/data/chip/home/[USER]  500M  500M     0 100% /home/[USER]"
"3272860","71728541","2025-09-16 15:54:13","HPC User Account: [USER] in pi_[ID]","Hi [USER], your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) On Mon Sep 15 22:54:22 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [ID] Request Type:              High Performance Cluster Create/Modify account in existing PI group Existing PI Email:    [EMAIL] Existing Group:       pi_[STAFF] Project Title:         Advanced time integration for large-scale multiphysics applications Project Abstract:     The [STAFF] research group in the UMBC Department of Mathematics and Statistics designs novel time integration algorithms for large-scale multiphysics applications."
"3273118","71880751","2025-09-23 15:01:11","Access to CUERE Servers","Hi [STAFF], Many of these machines are in the Engineering Building Data Center, Departmental Computer Room, Rack K7. I'd be happy to show you these machines, just drop a time onto my calendar: https://calendar.google.com/calendar/embed?src=[EMAIL]&ctz=America/New_York. I'm on campus every day. On Thu Sep 18 07:48:50 2025, [USER] wrote: These are servers and/or computer components maintained in the Engineering building (886). On Wed, Sep 17, 2025 at 2:47 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3273118 > Last Update From Ticket: Hi, Can you provide more information on these servers and what they do? I'm trying to locate them to understand who manages them. Best regards, [STAFF]. On 2025-09-16 11:23:50, [USER] wrote: First Name: [USER], Last Name: [USER], Email: [EMAIL], Campus ID: [USER]. The [DEPARTMENT] department will be conducting an inventory on 9/30 and requires access to the CUERE Servers."
"3273570","71893498","2025-09-23 19:35:40","HPC Other Issue: Deleting data from a [USER] in PI group","In the previous step, I just revoked access to chip for the users = and gave ownership of their directories to the Prof. [STAFF] as requested.  In order to free up space, prof. [STAFF] needs to delete files and folders saved by the removed users. On Tue Sep 23 15:21:52 2025, [USER] wrote: One additional question, our goal was to free up some of the 20 TB storage space in nfs.iss.rs.[DOMAIN]:/ifs/data/rs/[STAFF]. However, it was showing 1.5 TB of free space before you performed the above, and still shows 1.5 TB of free space after you have performed the above. Can you please comment on if the above operation that you performed is supposed to free up storage space? Thanks [USER] On Tue, Sep 23, 2025 at 9:28 AM Beamlak Bekele via RT <[EMAIL]> wrote: Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=[NUMBER] > Last Update From Ticket: I have removed both users and granted you access to their directories. This means they no longer have login access to CHIP. You are now the owner of the following directories: /umbc/rs/[STAFF]/users/n[USER] /umbc/rs/[STAFF]/users/v[USER]. Let me know if you need any other users removed or if you have any questions. On Fri Sep 19 10:47:21 2025, [USER] wrote: Hi Beamlak, The second option works (removing user and giving me access). Could you also do the same for user v[USER]? When you give me access, will you send me the list of directories? Best, Tejas--[STAFF] Assistant Professor University of Maryland, Baltimore County. On Fri, Sep 19, 2025 at 06:30 Beamlak Bekele via RT <[EMAIL]> wrote: Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=[NUMBER] > Last Update From Ticket: Hello There are two ways to proceed in deleting the data for n[USER]. I can delete all the data in n[USER] user space per your request. The other option is, I can remove n[USER] access to chip and give ownership of all their directories to the PI ([STAFF]). This will make sure I don't delete data that you may need in the future. Which one works better ? On Tue Sep 16 20:07:28 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID]. Request Type: High Performance Cluster Hi, I am [USER], a Comp. Sci. PhD student under supervision of Dr. [STAFF]. With permission from Dr. [STAFF] (cc'd here), I am trying to delete all data from the user n[USER] in our PI group's chip research storage, but do not have permission to delete files owned by n[USER]. This is a path (or symlink) to the data occupied by this user: /umbc/rs/[STAFF]/users/n[USER]. Can you please either delete all data from /umbc/rs/[STAFF]/users/n[USER] yourself or give me permission so that I can do so? Thanks for your attention on this matter. Thanks [USER]."
"3273828","71810005","2025-09-19 14:45:21","Subnet Access to NFS Exports","Thank you! It is working fine now."
"3275061","72029609","2025-09-30 21:55:43","HPC User Account: [ID] in SONG","Hi [STAFF], Sorry for the wait here. The account for [USER] was created, and we missed the additional request near the bottom of the account creation ticket. In the future, please submit separate RT tickets for separate requests so that tasks don't get lost in this way. For the collaborators, there should be no issue granting access to UMBC's infrastructure via the campus VPN to these users. Please sponsor their accounts via the link below and instruct the users to complete chip account requests with their UMBC credentials and to select PI group pi_[STAFF] (link below). Please be aware that these users would be required to operate through the campus VPN in order to gain access to our infrastructure. I'll resolve this ticket for now, but feel free to reopen if there are questions about the sponsored account process or VPN access from non-North American IP addresses. Sponsored account wiki page: https://umbc.atlassian.net/wiki/spaces/faq/pages/30739140/ RT Ticket Link: https://rtforms.umbc.edu/rt_authenticated/doit/DoIT-support.php?auto=Research%20Computing On Wed Sep 17 21:13:54 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Create/Modify account in existing PI group Existing PI Email: [EMAIL] Existing Group: SONG Project Title: DIDSSI project collaboration Project Abstract: This is an NSF project that collaborate across universities. DIDSSI is a blockchain-based decentralized identity system designed to streamline student mobility programs worldwide. The platform empowers students with full control over their academic credentials through digital wallets, while enabling universities to seamlessly engage in mobility exchanges. The system provides secure, transparent credential verification and reduces bureaucracy in academic processes. Initial focus targets EU and US universities, with plans to expand to third-party service providers and public entities. The project aims to create a comprehensive academic ecosystem supporting global educational mobility. Our collaborater is asking to gain access to cluster in our University to demostrate the software development and cross country connections. Since our collaborater is outside the US, they need accounts to access the cluster. They are requesting 3 accounts, can you help us to gain access to the cluster? Thanks, [USER]"
"3275919","72056190","2025-10-02 13:27:29","HPC Slurm/Software Issue: SSH Connection closing","Next time this happens can you give me the following information: Date and time of login, Date and time of dropped connection, Are you on/off campus?, Are you on a wired/or wireless network?, Are you using the VPN?, Which login node did you connect to initially (chip-login1/2)?. On Tue Sep 30 00:15:03 2025, [USER] wrote: Hi, sorry for the late response! I've been on chip for about a year now. This happens when using any computer, regardless of what wifi network I use, or whether I use a VPN or not. I can connect to other remote HPCs fine. On Fri, Sep 26, 2025 at 12:33 PM [STAFF] via RT wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3275919>. Last Update From Ticket: Hi [USER], Checking in on this. Have you still been experiencing this? Can you tell me a little bit more about your setup? Are you on-campus/off-campus, wired/wireless, using vpn or not?. On Tue Sep 23 12:55:36 2025, [USER] wrote: Hi [STAFF], How long have you been on chip? We only recently added the second login node. On Fri Sep 19 12:04:50 2025, [USER] wrote: This has been happening as long as I have been using chip, regardless of which login node On Fri, Sep 19, 2025 at 8:55 AM [STAFF] via RT wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3275919>. Last Update From Ticket: Hi [USER], Have you noticed this happening on both login hosts (chip-login1 and chip-login2) or just one of them? Can you also give me a rough time period when you were logged in and seeing this happen?. On Fri Sep 19 08:47:10 2025, [USER] wrote: First Name: [USER], Last Name: [USER], Email: [EMAIL], Campus ID: [CAMPUSID]. Request Type: High Performance Cluster. When I connect to chip, there's no issue. However, the connection automatically closes almost every 5-10 minutes for some reason. It works fine, but its extremely annoying. Is this fixable?. Best, [STAFF]."
"3276158","71883577","2025-09-23 15:55:11","HPC User Account: [USER] in Drill Pipeline","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) On Fri Sep 19 12:42:02 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Create/Modify account in existing PI group Existing PI Email:    [EMAIL] Existing Group:       Drill Pipeline Project Title:        Searching for Continuous Gravitational Waves using the data from recent LIGO run Project Abstract:     With a better sensitivity of the Advanced LIGO detectors and longer observational runs, the detection of continuous gravitational waves is expected to be within reach, based on our understanding of neutron star structure. However, the search remains computationally intensive due to the weak and long duration nature of the signals. A detection of continuous gravitational waves will open a new path in a multi-messenger astronomy. The project title and abstract listed here are just a rough idea of what I'll be working on with Dr. [STAFF]."
"3276232","71818619","2025-09-19 19:00:26","HPC User Account: [USER] in pi_[ID]","Hi [USER], Since you have not already requested an account, you are unable to access the cluster. However, since you just put in the request (and approval was granted), I created an account on chip for you. You should now be able to connect using ssh. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) Have a nice day! -- Kind regards, [STAFF] On Fri Sep 19 13:59:51 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Create/Modify account in existing PI group Existing PI Email:    [EMAIL] Existing Group:       pi_[STAFF] Project Title:        Advanced time integration for large-scale multiphysics applications Project Abstract:     The [STAFF] research group in the UMBC Department of Mathematics and Statistics designs novel time integration algorithms for large-scale multiphysics applications.  We perform core numerical methods research, implement these within open-source software libraries, and directly collaborate with applications scientists.   Hello,  My name is [USER] and I am part of the [STAFF] Research Group in the UMBC Department of Mathematics. I am unable to access Chip whenever I enter my password, after entering the ssh command: ssh umbc_username@chip.rs.umbc.edu in my terminal.  Is there anything else I need to do to access Chip?  Thank you. [USER]."
"3276393","72318557","2025-10-16 02:24:52","Migrating Research Storage Volume to Ceph Cluster","Hello [USER], At long last, we have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to look normal (other than the length of the migration, of course). There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_[USER]. The alias used to reach the volume is now pi_[USER]_common and pi_[USER]_user. Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? In regards to the cybertrn and hpcreu volumes: we don't yet have a timeline as for when we'll want to start migrating those volumes. While these volumes aren't technically any different from the PI volumes, we still have some planning to do on the logical side of things before we'll want to move them over. I don't expect this process to start until December at the earliest. And thanks! Thankfully whatever cold/illness I had ended up being a quick one. Thank you, [STAFF] On Wed Oct 15 20:36:43 2025, [EMAIL] wrote: Hi, [STAFF], I will check with some students tomorrow if they saw problems. But with the users running, I think, we both used different areas than pi_[USER]. Which begs the question: when should we plan on copying hpcreu and cybertrn? We did okay with the timing, after all. I hope you feel better again. [USER]"
"3276394","72454522","2025-10-23 15:12:16","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Sorry about that, a lot of migrations to get through. Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 13th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3276396","71998017","2025-09-29 19:09:21","Migrating Research Storage Volume to Ceph Cluster - [ID]","My student has indeed been able to start jobs on the new volume. Thanks! On Mon, Sep 29, 2025 at 2:16 PM [STAFF] via RT <[EMAIL]> wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3276396 Last Update From Ticket: Hello [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: * The path has changed, and is now available under /umbc/rs/pi_burnsm. * The alias used to reach the volume is now pi_burnsm_common and pi_burnsm_user. * Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF] On Mon Sep 29 10:21:36 2025, [USER] wrote: Good morning [USER], This is just a reminder that we are starting your migration today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF] On Mon Sep 22 13:05:02 2025, [STAFF] wrote: Yep, I've put your group on our schedule for September 29th. We will send you an email via this ticket when we begin the migration, and again once it has completed. Please let us know if you have any questions or concerns. Best, [STAFF] On Mon Sep 22 12:48:06 2025, [USER] wrote: Hello [STAFF], Could we schedule the migration for next Monday, September 29th? On Fri Sep 19 16:37:05 2025, [STAFF] wrote: Hello [USER], As per the communication via myUMBC earlier this summer (https://my3.my.umbc.edu/groups/hpcf/posts/150838), DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 94GB of a 250GB quota on the old storage server. To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at “/umbc/rs/burnsm”. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. Below we’ve listed two options for handling this data migration - please let us know which of these you’d prefer. Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day. Option 2: If you don’t respond to this email by October 15th, DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes. Note: After this process has completed, the new storage volume will have a new name. For example, group “pi_doit” will find its data under “/umbc/rs/pi_doit”, or in your group’s case you will find your volume under “/umbc/rs/pi_burnsm”. Thank you, [STAFF]"
"3276397","71821853","2025-09-19 20:40:16","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hi [STAFF], I retired a year ago and do not have a group anymore. You can erase those files. thanks, [USER] On Sep 19, 2025, at 4:38 PM, via RT [EMAIL] wrote: Greetings, This message has been automatically generated in response to the creation of a ticket regarding: Subject: 'Migrating Research Storage Volume to Ceph Cluster - pi_[USER]' Message: Hello [USER], As per the communication via myUMBC earlier this summer (https://my3.my.umbc.edu/groups/hpcf/posts/150838), DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 544MB of a 100GB quota on the old storage server. To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at '/umbc/rs/[USER]'. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. Below we've listed two options for handling this data migration - please let us know which of these you'd prefer. Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day. Option 2: If you don't respond to this email by October 15th, DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes. Note: After this process has completed, the new storage volume will have a new name. For example, group 'pi_[STAFF]' will find its data under '/umbc/rs/pi_[USER]', or in your group's case you will find your volume under '/umbc/rs/pi_[USER]'. Thank you, [STAFF]"
"3276398","71846834","2025-09-22 17:11:01","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello [USER], Understood. I'll coordinate with my group and see about when we'll want to deactivate Dr. [STAFF]'s volume. As for the Ada error, that is because we migrated all of our Ada systems into our new Chip compute cluster. Chip can be accessed by SSHing to chip.rs.[DOMAIN], and your group's storage volume is located at /umbc/rs/[STAFF]. More information on accessing Chip can be found on our wiki: https://[DOMAIN].atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip#Accessing-chip. Please let me know if you have any questions or issues! Best, [STAFF] On Mon Sep 22 11:27:10 2025, [EMAIL] wrote: Hello, This is to respond to the email about PI Dr. [STAFF]'s lab's research storage volume. We haven't used the HPCF cluster for a long time, so you can take our storage volumes offline anytime you prefer. In another note, I just tried to login to ada.rs.[DOMAIN] with our old login information, but got an 'Operation timed out' error. Best, [USER]."
"3276399","72422276","2025-10-22 13:54:04","Migrating Research Storage Volume to Ceph Cluster","Hello We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed and is now available under /umbc/rs/pi_halem. The alias used to reach the volume is now pi_halem_common and pi_halem_user. Your new volume has a quota of 25TB. When you have a chance please try running some jobs on Chip using the new volume to verify everything looks good. Thank you On Tue Oct 21 11:39:19 2025 [STAFF] wrote: As per your request in the other ticket your migration has been moved up to Oct. 28. Best [STAFF]."
"3276401","72337030","2025-10-16 19:32:59","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_[USER]. The alias used to reach the volume is now pi_[USER]_common and pi_[USER]_user. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Thu Oct 16 11:41:11 2025, [STAFF] wrote: Hello [USER], This is a reminder that we'll be starting your group's research storage volume migration today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Mon Sep 22 11:40:34 2025, [USER] wrote: Thanks, I put this in our calendar. Regards, [USER]. On Mon, Sep 22, 2025 at 9:37AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3276401> Last Update From Ticket: Hello [USER], I'll schedule your migration for October 16th then. Let me know if anything changes and you need to move your migration. Best, [STAFF]. On Sat Sep 20 19:34:47 2025, [USER] wrote: Any day between October 16th through November 15th works for us. Thanks."
"3276406","72732023","2025-11-04 20:30:04","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","It appears that the text you provided is a collection of email signatures and some text from an email conversation. It's not clear what specific information or question you are looking for.  However, I can try to extract some relevant information from the text:  * The emails seem to be related to a topic about research computing at UMBC (University of Maryland, Baltimore County). * There are mentions of people named Naghmeh Karimi and Gregory Ballantine, who appear to be faculty members or administrators at UMBC. * The emails mention something about migrating data to a new system called 'Ceph' and discuss issues related to the migration process.  If you could provide more context or clarify what specific information you are looking for, I'd be happy to try and assist you further."
"3276408","72639730","2025-10-31 18:19:42","Migrating Research Storage Volume to Ceph Cluster","Hello [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_[STAFF]. The alias used to reach the volume is now pi_[STAFF]_common and pi_[STAFF]_user. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF] On Fri Oct 31 10:43:32 2025, [EMAIL] wrote: Good morning [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF] On Thu Oct 23 12:06:20 2025, [EMAIL] wrote: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of October 31st for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3276410","72506997","2025-10-27 16:29:06","Migrating Research Storage Volume to Ceph Cluster","10 TB is great. Thanks [STAFF]. On Mon, Oct 27, 2025 at 10:41 AM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Good morning [USER], On the Ceph storage cluster your group will have a quota of 10TB. If that is not enough, we can certainly work together to purchase more storage. Just let us know if you need more storage and we can get the process started. Best, [STAFF] On Fri Oct 24 09:33:16 2025, [USER] wrote: Hi [STAFF], First apologies for not getting back to you. I put the responses to the RT ticket like emails in a different label which I forget to check. November 5th is fine by my team for the migration. Is there a way to increase our storage quota? The center is happy to pay if that is something that can be done. -[USER] On Thu, Oct 23, 2025 at 11:23 AM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 5th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3276703","71889909","2025-09-23 18:09:43","HPC Slurm/Software Issue: slurm_load_jobs error","Hi [USER],  The issue is resolved and now I can access my job status. Thank you.  Best regards, [STAFF]   If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3276703&ticketowner=[STAFF]&ticketsubject=HPC Slurm/Software Issue: slurm_load_jobs error  If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3276703   Thank You    R e s o l u t i o n  Hello [USER]  We have identified and resolved the issue, thus the slurm commands should work as expected. Let us know, if you still get an error.  Best, [STAFF] DOIT Unix infra, Graduate Assistant   Original Request:  Requestors: [USER] First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID]  Request Type:              High Performance Cluster   I got an abrupt 'slurm_load_jobs error: Unexpected message received' in chip when i try to see the status of my jobs by writing 'squeue -u username'. When I do squeue I can see the gpu jobs but CLUSTER: chip-cpu shows the 'slurm_load_jobs error: Unexpected message received'. I had three actively running batch jobs and one interactive job which also got abruptly cancelled."
"3276836","72407397","2025-10-21 19:09:44","GraphRag Implementation question/issue","I've reviewed your SLURM script and directories. As you mentioned a small dataset of 0.5MB shouldn't take that long to process. I didn't notice any issues with your script. However one issue I've seen before is that job distribution may not scale properly to the GPUs - even if they are detected. It's likely your job was running on the CPU instead of the GPU. We've made changes on our end to ensure that Ollama can now detect an NVIDIA GPU by default. I'm hopeful that this update will improve the performance of your job. For future runs you can monitor GPU usage by running the nvidia-smi command after logging in to the allocated node (e.g. ssh g20-12). This will help confirm whether your job is utilizing the GPU as expected. [USER] wrote: Hello again I haven't run the process recently as I'd shifted my focus to other processes I run after getting its output but I will eventually need to run it again. I do not have an expected speed to reach but I would like to know if there are common ways I can speed it up if possible. As for the paths: * Base Directory: /umbc/ada/manas/users/[USER]/GraphRAG-Local-UI/ * 1-hour runtime data (0.5 MB): indexing/input/ * These are txt documents. Each contains 10 entities and a description of each one. * 6-hour runtime data (3.2 MB): indexing/input/ms_qa_slice * These are also txt documents. Each contains 10 paragraphs. * SLURM script: run_test_queries.sh Where the SLURM script is: #!/bin/bash #SBATCH --job-name=grag_test #SBATCH --cluster=chip-gpu #SBATCH --mail-user=[EMAIL] #SBATCH --mem=7000 #SBATCH --gres=gpu:2 #SBATCH --time=06:00:00 #SBATCH --error=slurm.err #SBATCH --output=slurm.out source /home/${USER}/.bashrc conda activate graphrag module load ollama python run_test.py It seemed to me that an hour is a little egregious for 0.5 MB of data but I do not know if the process is simply that slow or if my setup is to blame. [STAFF] wrote: Hi Are you still having slow downs when using LLM on Chip? On Tue Sep 30 12:45:10 2025 [USER] wrote: It seems the actual 'problem' got cut off when Tim created the ticket - that info is additional context to my setup. I have been running a process called 'GraphRAG' that needs to make repeated LLM calls. The runtime is pretty slow as seen above so I was looking for information about how I might speed it up if possible. Other info that got cut off: * I currently run with 2 GPUs (unspecified type) and 7 GB RAM. * The LLM is hosted on ollama since GraphRAG needs a URL to communicate with. Regards [USER]"
"3277050","71889383","2025-09-23 17:58:14","HPC Other Issue: X11","Unfortunately this is due to the fact we had to deviate from the slurm configuration our cluster manager provided. While we have disabled its ability to manage the slurm configuration, it has since started to revert some of the changes we've made like enabling X11 forwarding. We have submitted a ticket with the vendor to understand why this is happening all of a sudden. We apologize that this keeps happening, and we ask that you please bear with us while we work with the vendor to get this issue resolved. Hello [STAFF], Great thanks, it's working again. Was there a recent chip hiccup I was not aware of, that turned off the X11 forwarding? Ticket https://rt.umbc.edu/Ticket/Display.html?id=3277050 Last Update From Ticket: Hello [USER], I have re-enabled X11 forwarding on the chip-cpu cluster and verified it works for me now. Can you login to verify it works for you again? Thank you, [STAFF] On Mon Sep 22 11:06:32 2025, [USER] wrote: First Name: [USER] Last Name: De souza-machad Email: [EMAIL] Campus ID: [USER] Request Type: High Performance Cluster X11 has stopped working again, can you fix it? thanks [sergio@chip-login2 ~]$ alias xschip alias xschip='srun  --cluster=chip-cpu --account=pi_strow --partition=pi_strow --qos=pi_strow --time=30-00:00:00 --x11 --mem=10G --pty $SHELL' [sergio@chip-login2 ~]$ xschip srun: error: Unable to allocate resources: X11 forwarding not available"
"3277190","71989133","2025-09-29 15:22:49","HPC Other Issue: Connection Issue on Chip","Hi [USER], I apologize for the time it took to see this ticket. We have had some sporadic communications from a few researchers that have said they have a similar issue to you, but we've been unable to lock down any specific reason for this. A little more information might help us: - First, can you give us exact times and dates for some of the disconnects you are seeing? This will help us look at the connection logs to find where it happened. - Second, what kind of connection do you have? Wired or wireless? Are you on the vpn when connecting to [SERVER]? - Third, are you experiencing it on one of the login nodes more than another? Let me know the above and we can go from there. If you experience anymore of these disconnects please write down the exact date and time you experienced it so we can look into it further. On Mon Sep 29 11:16:22 2025, [USER] wrote: Hello, Is there any update on this ticket? I am still facing similar issues. Thanks. [USER]. On Mon, Sep 22, 2025 at 12:41PM via RT [EMAIL] wrote: Greetings, This message has been automatically generated in response to the creation of a ticket regarding: Subject: '[SYSTEM] Issue: Connection Issue on [SERVER]' Message: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID]. Request Type: High Performance Cluster. Hello, I hope this message finds you well. I am reaching out regarding some recurring connection issues with [SERVER]. Over the past couple of weeks, I have been experiencing random connection losses when accessing [SERVER] from our lab's desktop. These interruptions have been fairly regular, even though we are connected via a wired internet connection. Could you please let me know if this might be related to a network issue in the Engineering building, or if it is specific to the HPCF system itself? Have similar issues been reported by other users recently? Any guidance you can provide to help us pinpoint the reason would be greatly appreciated. Thank you very much for your assistance. Best regards, [USER]. Attachment 1: Screenshot 2025-09-22 123740.png (https://[URL]). There is no need to reply to this message right now. Your ticket has been assigned an ID of [TICKETID] or you can go there directly by clicking the link below. Ticket [URL]. You can login to view your open tickets at any time by visiting http://my.[DOMAIN] and clicking on 'Help' and 'Request Help'. Alternately you can click on http://my.[DOMAIN]/help. Best, [STAFF]"
"3277289","72016054","2025-09-30 14:45:22","HPC Other Issue: Can [USER] run cronjob on chip?","Hi [USER], as a user, without needing root permission, you can create a cron job. That will allow you to run a scheduled script to check updates. I will mark this ticket resolved, but let us know if you have more questions. On Mon Sep 22 13:40:17 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] On Behalf Of:             [USER] ([EMAIL], [USER]) Request Type:              High Performance Cluster [USER] will share what a collaborator in Germany uses for some git CI/CD workflow, could we support [USER] running the same sort of flow on chip?"
"3278233","72146362","2025-10-07 18:44:53","HPC Other Issue: Need Space in Chip","Same email thread with all personal information (names, emails, campus IDs, phone numbers) removed or replaced:  [Email Thread]  ...   Hello [USER],  We are in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. As such we are no longer expanding volumes on the old storage server and instead migrating groups to the new Ceph cluster, where your group will have a quota of 10TB.  To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at '/umbc/rs/[GROUP]'. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume.  Below we've listed two options for handling this data migration - please let us know which of these you'd prefer.  Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day.  Option 2: If you don't respond to this email by October 15th, DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes.  Note: After this process has completed, the new storage volume will have a new name. For example, group 'pi_doit' will find its data under '/umbc/rs/pi_doit', or in your group's case you will find your volume under '/umbc/rs/[GROUP]'.  Thank you, [ADMINISTRATOR]  ...   Request Type: High Performance Cluster  Hello,  We are happy to get the [LAB NAME] account in Chip, we need to have storage space, maybe 1 or 2 Teras do download the NIH data we had approved to use.  Thanks! [USER]  ..."
"3278275","71894647","2025-09-23 20:05:03","HPC Slurm/Software Issue: Issues after migration","I was able to remove and then create new symlinks for those directories. Everything looks to be working perfectly now. Thanks, [USER]. On Tue, Sep 23, 2025 at 1:15 PM [STAFF] via RT wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3278275 Last Update From Ticket: Hello [USER], This seems to be a two-part issue. The first issue was the CephFS client for your group's storage volume wasn't responding to a 'capabilities release', and thus was causing /umbc/rs/pi_jkestner/users/ to hang, and is what was causing your terminal to freeze. I have corrected this issue and I'm able to see your user directory now - can you login and verify this is working for you now too? As for your issues with Julia, it looks like you have a broken symlink in your home directory: /home/[USER]/.julia is pointing to /umbc/rs/pi_jkestner/users/[USER]/.Julia which doesn't exist. I'm guessing you need to update this to /umbc/rs/pi_jkestner/users/[USER]/.julia? Can you try recreating the symlink to see if that fixes your issue? We also noticed a circular symlink at /home/[USER]/jkestner_common/.julia that was pointing to itself. We have removed this symlink in case this was causing any issues, and apologize for any inconvenience this may cause. Thank you, [STAFF] On Mon Sep 22 16:26:50 2025, [USER] wrote: First Name:  [USER] Last Name:  [USER] Email:  [EMAIL] Campus ID:  [CAMPUSID] Request Type:  High Performance Cluster Ok, so the issue I have is kind of weird, so I'll try to layout exactly what happened. After the migration, I could run jobs fine, but it looked like I had to redownload all of my packages that I use for Julia. That's not an issue, but it looked like I still had a .julia directory which caused some issues with redownloading everything. Again, not an issue, I ended up deleting my own .julia directory and starting anew. However, I also have a .julia directory that is in the research storage, ie within pi_jkestner/users/[USER] that houses most of the packages since they have a lot of data, and I previously made a alias to access this directory. Now, because there was also still a .julia directory there causing issues and I didn't immediately realize I could delete that .julia directory and start anew as well, I instead just made the alias directory '.Julia', with a capital J, in the research storage to store the packages and not delete the original .julia directory. This is obviously not the best way to resolve the issue but it worked and I was still able to run jobs just fine. Now, the issue comes when I realized I could in fact delete the .julia directory in the research storage myself. I attempted to delete the .julia directory in the research storage and then renamed the .Julia directory to .julia. I thought it all worked out, but now, I cannot even run any jobs on Julia. What I mean is if I try to even run an interactive job, the interface freezes out when trying to just load Julia itself (this is also only a Julia issue for me, I tried running a quick interactive job on MATLAB and it worked just fine). Not only this, but even trying to go to the research storage via 'cd /umbc/rs/pi_jkestner/users/[USER]' causes the interface to freeze as well. I'm not sure if you can see what I mean from your side of things but any help is appreciated. Thanks."
"3278706","72688130","2025-11-03 18:20:01","Migrating Research Storage Volume to Ceph Cluster - [ID]","Awesome, thanks for the update and for the instructions on where to find the data. I will be in touch if I have any questions. Be well, [USER] On Thu, Oct 30, 2025 at 7:24 PM [STAFF] via RT wrote: Ticket Last Update From Ticket: Hello [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: * The path has changed, and is now available under /umbc/rs/pi_[USER]. * The alias used to reach the volume is now pi_[USER]_common and pi_[USER]_user. * Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF] On Thu Oct 30 10:32:34 2025, [EMAIL] wrote: Hello [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are no jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF] On Sat Oct 25 21:26:23 2025, [EMAIL] wrote: Hi [USER], I am traveling a lot, teaching, writing grants proposals and training new people-so emails are getting delayed. Thanks for the reminder for setting up my migration. The day that you selected is fine. I will be out of the office in preparation for a grant proposal that day, so let me know if I need to do anything on my end. Once the data is migrated over to the Ceph storage please let me know how to access it. Thanks, [USER] On Thu, Oct 23, 2025 at 12:05 PM [STAFF] via RT wrote: Ticket Last Update From Ticket: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of October 30th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3278712","72456792","2025-10-23 15:58:38","Migrating Research Storage Volume to Ceph Cluster","Dear [STAFF], As per our previous communications, since [USER] did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for [USER]'s migration. We have assigned the date of November 12th for [USER]'s migration. Let us know if there is a better day for [USER], and within reason, we can reschedule that date. [USER] will be notified when the migration begins and completes. Thank you, [STAFF]"
"3278717","72088393","2025-10-03 17:46:23","Migrating Research Storage Volume to Ceph Cluster - [ID]","Hello [USER], We have finished migrating your volume to the Ceph cluster. Other than the migration taking a bit longer than expected, as far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/[STAFF]. The alias used to reach the volume is now [ALIAS]_common and [ALIAS]_user. Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]."
"3278721","72456085","2025-10-23 15:44:34","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Dear [STAFF], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 13th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3278728","71885145","2025-09-23 16:29:42","HPC New Group: [ID]","Hi [USER], The group pi_[STAFF] now exists on the chip cluster. Members of this group can therefore access and contribute to the research storage space allocated to the group. This storage is located at /umbc/rs/pi_[STAFF] and currently has a quota of 10T. Additionally, Your account ([STAFF]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please review documentation on the hpcf.umbc.edu website. Submit any questions or issues as separate RT Tickets at: https://doit.umbc.edu/request-tracker-rt/doit-research-computing/. First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Group Type: Project Title: [PROJECTTITLE] Project Abstract: The Volvox carteri somatic regenerator (regA) gene encodes a putative transcription factor that is expressed only in somatic cells and is essential for maintenance of the somatic cell fate. rlsA is one of the closest paralogs of regA and its spatial and temporal expression patterns are very similar to that of regA, suggesting that this gene might also function in somatic cell development. To test this idea, we used CRISPR to generate an early frameshift mutation in rlsA that eliminates rlsA function. We are conducting RNA-seq analysis of the mutant to investigate the possibility of genetic compensation, and to better understand the role of rlsA in regulating the expression of other genes. Sequence reads have been obtained for the wild type and rlsA mutant and an RNAseq pipeline will be used to map the reads to an assembled V. carteri genome then determine the statistical significance of DEGs in different gene functional classes. A group account is being requested for this and other RNAseq analysis projects I anticipate my group will undertake."
"3278729","72527369","2025-10-28 14:41:28","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Ticket [TICKET_NUMBER] Comment just added. Hi, No worries, this migration only affects research cluster data, nothing to do with Box. No worries, nothing you have to do yourself. Best, [STAFF]"
"3278736","72439049","2025-10-22 19:18:19","Migrating Research Storage Volume to Ceph Cluster - [ID]_rvinjam1","We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_[USER],1. The alias used to reach the volume is now pi_[USER]_common and pi_[USER]_user. Your new volume has a quota of 25TB. When you have a chance, please try running some jobs on Chip using the new volume to verify everything looks good. On Wed Oct 22 09:29:24 2025, [STAFF] wrote: Hello This is just a reminder that we are starting your migration today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. On Fri Oct 10 13:41:03 2025, [STAFF] wrote: Hello [USER], Sounds good, I've put your group on our schedule for Wednesday October 22nd. We will send you an email alert via this RT ticket when we begin the migration process, and again once it has completed. Please let us know if you have any questions or concerns. Best, [STAFF] On Fri Oct 10 13:21:46 2025, [USER] wrote: [USER] got back to me and he confirmed we are not using this anymore. Feel free to move at your convenience. On Fri, Oct 10, 2025 at 1:06 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3278736> Last Update From Ticket: It seems most of your data is being taken up by [USER] 157GB ./[USER] 248KB ./fsafavi1 216KB ./rvinjam1 216KB ./polikka1 216KB ./dpei1 Farshad is using a negligible amount of data. To find this, the root path is: /umbc/rs/rvinjam1/users Let me know how/when this changes the transfer of data to Ceph. Best, [STAFF]"
"3278739","72210739","2025-10-10 17:10:12","Migrating Research Storage Volume to Ceph Cluster - [ID]","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_[USER]. The alias used to reach the volume is now pi_[USER]_common and pi_[USER]_user. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Fri Oct 10 09:28:33 2025, [STAFF] wrote: Good morning [USER], This is just a reminder that we are starting your migration today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Wed Oct 08 18:27:33 2025, [STAFF] wrote: Hello [USER], I've added your group's migration to our schedule for Friday the 10th. We will send you an email alert via this RT ticket when we begin the migration, and again once it has completed. Please let us know if you have any questions or concerns. Best, [STAFF]. On Wed Oct 08 15:11:49 2025, [USER] wrote: Dear [STAFF], Thank you for your email regarding the migration, and my apologies for the delayed response. Would it be possible to arrange the transfer for Friday Oct 10 and failing that the following Monday (Oct 13)? Best wishes, [USER]. Greetings, This message has been automatically generated in response to the creation of a ticket regarding: Subject: 'Migrating Research Storage Volume to Ceph Cluster - pi_[USER]'. Message: Hello [USER], As per the communication via myUMBC earlier this summer (https://my3.my.umbc.edu/groups/hpcf/posts/150838), DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 1GB of a 500GB quota on the old storage server. To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at '/umbc/rs/[USER]'. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. Below we've listed two options for handling this data migration - please let us know which of these you'd prefer. Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day. Option 2: If you don't respond to this email by October 15th, DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes. Note: After this process has completed, the new storage volume will have a new name. For example, group 'pi_doit' will find its data under '/umbc/rs/pi_doit', or in your group's case you will find your volume under '/umbc/rs/pi_[USER]'. Thank you, [STAFF]."
"3278741","72218242","2025-10-11 04:07:01","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","I retired from [INSTITUTION] ten years ago and I don't believe anyone is using my area on the Cluster.  I have referred this to [STAFF] who replaced me in the Physics Department and the labelling of the storage area can be decided by him.  On Tue Sep 23 11:21:40 2025, [EMAIL] wrote:  Hello [USER],  As per the communication via [SYSTEM] earlier this summer, [DEPARTMENT] is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 445MB of a 100GB quota on the old storage server.  To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at '/[INSTITUTION]/rs/[USER]'. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume.  Below we've listed two options for handling this data migration - please let us know which of these you'd prefer.  Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, [DEPARTMENT] staff will work to migrate your volume to the Ceph storage cluster. [DEPARTMENT] staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day.  Option 2: If you don't respond to this email by October 15th, [DEPARTMENT] staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes.  Note: After this process has completed, the new storage volume will have a new name. For example, group '[DEPARTMENT]' will find its data under '/[INSTITUTION]/rs/[DEPARTMENT]', or in your group's case you will find your volume under '/[INSTITUTION]/rs/[USER]'.  Thank you, [STAFF]  [INSTITUTION] - [DEPARTMENT]"
"3278750","72539070","2025-10-28 19:36:05","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/[STAFF]. The alias used to reach the volume is now [ALIAS] and [ALIAS]. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Tue Oct 28 10:48:57 2025, [STAFF] wrote: Hello [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Thu Oct 23 12:03:10 2025, [STAFF] wrote: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of October 28th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]."
"3278754","72215767","2025-10-10 19:46:01","Migrating Research Storage Volume to Ceph Cluster - [ID]","Hello [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_roma. The alias used to reach the volume is now pi_roma_common and pi_roma_user. Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Fri Oct 10 13:50:21 2025, [USER] wrote: Hello [USER], Sounds good, we will begin your migration shortly. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Fri Oct 10 13:30:25 2025, [USER] wrote: Either works for me. On Fri, Oct 10, 2025 at 1:21 PM Elliot Gobbert via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3287854 > Last Update From Ticket: Hey, Just to check with you, by Friday, do you mean today (Oct. 10)? Or next Friday (Oct. 17)? Best, [STAFF]."
"3278759","72454738","2025-10-23 15:16:23","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Dear [STAFF], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 10th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3278767","72254151","2025-10-14 12:19:38","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Thanks we will check and let you know --- [STAFF] On Mon Oct 13 2025 at 6:37 PM [USER] via RT [EMAIL] wrote Ticket URL https rt umbc edu Ticket Display html id=3278767 Last Update From Ticket Hello [USER] We have finished migrating your volume to the Ceph cluster As far as we can tell everything seems to have gone smoothly There are a few things to note * The path has changed and is now available under /umbc/rs/pi_[USER] * The alias used to reach the volume is now pi_[USER]_common and pi_[USER]_user * Your new volume has a quota of 25TB When you have a chance could you try running some jobs on Chip using the new volume to verify everything looks good Thank you [STAFF] On Mon Oct 13 09:03:11 2025 [USER] wrote Good morning [USER] We will be starting your migration shortly During this time please ensure there are not any jobs being run in your research group otherwise these may be terminated We will provide an update once completed Best [STAFF]"
"3278768","72518561","2025-10-28 00:38:12","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Will do, thanks!  Best wishes, [USER]. On Mon, Oct 27, 2025 at 6:18 PM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hello [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: * The path has changed, and is now available under /umbc/rs/pi_[USER]. * The alias used to reach the volume is now pi_[USER]_common and pi_[USER]_user. * Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Mon Oct 27 13:21:34 2025, [EMAIL] wrote: Hello [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]."
"3278774","72699663","2025-11-04 01:33:29","Migrating Research Storage Volume to Ceph Cluster - [ID]","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_[USER]. The alias used to reach the volume is now pi_[USER]_common and pi_[USER]_user. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Mon Nov 03 11:42:54 2025, [EMAIL] wrote: Hello [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Thu Oct 23 12:07:16 2025, [EMAIL] wrote: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 3rd for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]."
"3278812","72469752","2025-10-23 23:39:28","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","That date works for me. Thanks. -- [STAFF]  Associate Professor Department of Mechanical Engineering  [BUILDING NAME] University of Maryland, Baltimore County [ADDRESS] USA  On Thu, Oct 23, 2025, 11:46 AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=[NUMBER]> Last Update From Ticket: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 12th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3278815","72735260","2025-11-04 21:44:11","Migrating Research Storage Volume to Ceph Cluster","Thank you!  No inconvenience and thank you for all you are doing!  [STAFF] On Tue, Nov 4, 2025 at 4:38 PM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hello again [USER], Your group's storage migration to the Ceph storage cluster is taking a bit longer than expected. I'll leave the copy running overnight and will send you an email in the morning with a status update. I apologize for any inconvenience this may cause you and your group. Best, [STAFF] On Tue Nov 04 12:05:00 2025, [USER] wrote: Hello [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF] On Fri Oct 17 14:57:49 2025, [USER] wrote: I am so very sorry for failing to communicate in a timely fashion: this date is 100% fine for me, and I thank you for your care and thoughtfulness [STAFF] On Fri, Oct 17, 2025 at 1:07 PM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 4th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3278817","72454801","2025-10-23 15:18:44","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 7th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3278821","72352677","2025-10-17 17:16:07","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 5th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3278823","72603638","2025-10-30 17:13:58","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hi, I have not been faculty at UMBC since 2012 so no longer need my data to be maintained. Thank you, [USER] On Oct 30, 2025 12:56 PM, [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3278823> Last Update From Ticket: Hello [USER], It took longer than expected, but we have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: > * The path has changed, and is now available under /umbc/rs/[USER]. > * The alias used to reach the volume is now [USER]_common and [USER]_user. > * Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? I apologize if the extended length of the migration caused any issues for you or your group. Thank you, [STAFF] On Wed Oct 29 13:49:37 2025, [USER] wrote: > Hello, > This is just a reminder that we are starting your migration today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. On Thu Oct 23 11:34:17 2025, [USER] wrote: >> Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of October 29th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF] Best, [USER] DOIT Unix infra, Graduate Assistant Gregory Ballantine System Administrator for Research and Enterprise Computing UMBC - DoIT"
"3278826","72205421","2025-10-10 14:39:51","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Ticket Comment just added. This wasn't marked as 'scheduled' in the spreadsheet, so I updated that. LMK if that was a mistake."
"3278830","72620875","2025-10-31 14:31:27","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello [USER], It took a bit longer than expected, but we have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/[STAFF]. The alias used to reach the volume is now [ALIAS] and [ALIAS]. Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? I apologize if the extended wait for your group's migration has caused any issues. Thank you, [STAFF] On Thu Oct 30 10:32:15 2025, [EMAIL] wrote: Hello [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF] On Thu Oct 23 11:31:05 2025, [EMAIL] wrote: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of October 30th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3278834","72735136","2025-11-04 21:37:28","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello [USER],<br /> We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_finin. The alias used to reach the volume is now pi_finin_common and pi_finin_user. Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF] On Tue Nov 04 12:05:19 2025, [USER] wrote: Hello [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF] On Fri Oct 17 13:06:11 2025, [USER] wrote: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 4th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3278893","71889442","2025-09-23 17:59:02","HPC Other Issue: No X11 forwarding","This is a duplicate of RT#[NUMBER] which has been handled."
"3279121","72454642","2025-10-23 15:13:36","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 12th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3279123","72721147","2025-11-04 17:12:33","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly other than it taking longer than expected. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_[USER]. The alias used to reach the volume is now pi_[USER]_common and pi_[USER]_user. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? I apologize if the extended length of the migration caused any issues for you and your group. Thank you, [STAFF]. On Mon Nov 03 21:07:15 2025, [EMAIL] wrote: Hello again [USER], Your group's storage migration to the Ceph storage cluster is taking a bit longer than expected. I'll leave the copy running overnight and will send you an email in the morning with a status update. I apologize for any inconvenience this may cause you and your group. Best, [STAFF]. On Mon Nov 03 11:43:04 2025, [EMAIL] wrote: Hello [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Thu Oct 23 11:25:48 2025, [EMAIL] wrote: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 3rd for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]."
"3279124","72146286","2025-10-07 18:44:10","Migrating Research Storage Volume to Ceph Cluster","We tried a couple of jobs today and all appears to be fine. Thanks! Best, [USER] On Oct 6, [STAFF] wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3279124 Last Update From Ticket: Hello [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: * The path has changed, and is now available under /umbc/rs/pi_adali. * The alias used to reach the volume is now pi_adali_common and pi_adali_user. * Your new volume has a quota of 60TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF] On Mon Oct 06, [USER] wrote: Thanks! [USER] On Oct 6, [STAFF] wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3279124 Last Update From Ticket: Good morning [USER], This is just a reminder that we are starting your migration today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF] On Thu Oct 02, [USER] wrote: That's perfectly fine for us - I've put your group's migration on our schedule for October 6th. We will send you a notification via this RT ticket when we begin the migration, and again once the migration has completed. Please let me know if you have any questions or concerns. Best, [STAFF] On Thu Oct 02, [USER] wrote: We can schedule a group-wide downtime on October 6 to complete the migration. Will that work for you? Thanks! Best, [USER] On Sep 23, via RT wrote: Greetings, This message has been automatically generated in response to the creation of a ticket regarding: Subject: 'Migrating Research Storage Volume to Ceph Cluster - pi_adali' Message: Hello [USER], As per the communication via myUMBC earlier this summer (https://my3.my.umbc.edu/groups/hpcf/posts/150838), DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 51TB of a 60TB quota on the old storage server. To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at “/umbc/rs/adali”. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. Below we’ve listed two options for handling this data migration - please let us know which of these you’d prefer. Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day. Option 2: If you don’t respond to this email by October 15th, DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes. Note: After this process has completed, the new storage volume will have a new name. For example, group “pi_doit” will find its data under “/umbc/rs/pi_doit”, or in your group’s case you will find your volume under “/umbc/rs/pi_adali”. Thank you, [STAFF]"
"3279127","71955406","2025-09-26 03:24:09","Migrating Research Storage Volume to Ceph Cluster - [ID]","We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: * The path has changed, and is now available under /umbc/rs/pi_[GROUP]. * The alias used to reach the volume is now pi_[GROUP]_common and pi_[GROUP]_user. * Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Thu Sep 25 11:20:04 2025, [USER] wrote: > Thank you![USER] On Thu, Sep 25, 2025 at 10:49 AM [STAFF] via RT <[EMAIL]> wrote: >> Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=[TICKET_ID] >> Last Update From Ticket: >> Good morning [USER], >> This is just a reminder that we are starting your migration today. >> During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. >> We will provide an update once completed. >> Best, >> [STAFF] >> On Wed Sep 24 12:52:38 2025, [USER] wrote: >> > Sounds good, thanks! I've informed my group.[USER] On Wed, Sep 24, 2025 at 9:34 AM [STAFF] via RT <[EMAIL]> wrote: >>> Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=[TICKET_ID] >>> Last Update From Ticket: >>> [USER], >>> I've put your group on our schedule for tomorrow 9/25. We'll send you an email alert via this RT when we begin the migration, and again when the migration has completed. >>> Best, >>> [STAFF] >>> On Tue Sep 23 21:57:44 2025, [USER] wrote: >>> > Hi there! I checked with the group - now is the best time, actually. >>> We'd prefer 9/24 or 9/25. Best, >>> [USER] On Tue, Sep 23, 2025 at 4:21 PM via RT <[EMAIL]> wrote: >>>> Greetings, >>>> This message has been automatically generated in response to the creation of a ticket regarding: >>>> 'Migrating Research Storage Volume to Ceph Cluster - pi_[GROUP]' >>>> Message: >>>> Hello [USER], >>>> As per the communication via myUMBC earlier this summer (https://my3.my.umbc.edu/groups/hpcf/posts/150838), DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 615GB of a 2TB quota on the old storage server. >>>> To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at '/umbc/rs/[GROUP]'. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. >>>> Below we've listed two options for handling this data migration - please let us know which of these you'd prefer. >>>> Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day. >>>> Option 2: If you don't respond to this email by October 15th, DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes. >>>> Note: After this process has completed, the new storage volume will have a new name. For example, group '[GROUP]' will find its data under '/umbc/rs/[GROUP]', or in your group's case you will find your volume under '/umbc/rs/pi_[GROUP]'. >>>> Thank you, >>>> [STAFF]."
"3279128","72620242","2025-10-31 14:16:25","Migrating Research Storage Volume to Ceph Cluster - knacc1","Hello We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/[USER]. The alias used to reach the volume is now [ALIAS]_common and [ALIAS]_user. Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you On Thu Oct 23 11:54:23 2025, [STAFF] wrote: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of October 31st for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you [STAFF]"
"3279185","71953901","2025-09-25 20:43:52","HPC Slurm/Software Issue: Backup/Snapshot of Data","Hello [USER], We do not currently have home directory backups running on Chip, so we cannot recover your directory for you. I apologize for any inconvenience this will cause. Best, [STAFF] On Tue Sep 23 17:38:08 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Hi, I accidentally deleted a very important folder. Is it possible to recover from backups or snapshots? Thanks The path was: /home/[USER]/.nsga_exp/ga_params/lvlbndsnew/col"
"3279219","72013071","2025-09-30 13:53:40","HPC Slurm/Software Issue: sbatch: error: Batch job submission failed: Invalid partition name specified","Thank you. I will try it out. Best [USER]. On Tue, Sep 30, 2025, 9:26 AM [STAFF] via RT wrote: Ticket URL: https://rt.umbc.edu/Ticket/Display.html?id=3279219 Last Update From Ticket: Good morning, Thank you for following up. The gpu-general partition is now up, and that is the one that excludes contributor nodes. If you want to avoid jobs being preempted on contributor GPUs, please continue using gpu-general. Let us know if it is working or not. Best [STAFF]. On Mon Sep 29 10:21:20 2025, [USER] wrote: Hi, I am just following up on my last email. Could you please suggest a way to schedule jobs at chip-server without using the contributor's GPUs? Thanks. Best [USER]. On Wed, Sep 24, 2025 at 10:04 AM [USER] <[EMAIL]> wrote: Hi, According to your gpu partition page, the default partition is 'gpu' which uses all nodes including the contributors one. So if I schedule a job and it uses the contributor node, they can empty my task[it happened to me]. I don't want my job to be emptied. So I prefer to use the 'gpu-general' partition which excludes the contributors node. This is my understanding of your wiki page. If your policy has changed, please let me know. Also let me know the gpu partition name which excludes the contributors nodes. Thank you. Best [USER]. On Wed, Sep 24, 2025, 9:53 AM [STAFF] via RT wrote: Ticket URL: https://rt.umbc.edu/Ticket/Display.html?id=3279219 Last Update From Ticket: Hello [USER], The issue is that the chip-gpu cluster generally does not require the partition flag (--partition) to be specified, as there is only one primary partition for the GPU cluster, which is simply named gpu. Corrected Script: #!/bin/bash #SBATCH --cluster chip-gpu #SBATCH --job-name TES3_camb #SBATCH --gres=gpu:1 #SBATCH --output=ada_files/TES3camb.out #SBATCH --error=ada_files/TES3camb.err #SBATCH --time=72:00:00 #SBATCH --mem=30000 #SBATCH --account=[ACCOUNT] export CUDA_LAUNCH_BLOCKING=1 ... Or if you prefer to keep a partition specified, you would use: Corrected Script (Option 2: Use gpu partition name): #SBATCH --partition=gpu Let us know if it's working or not. Thank you. Best [STAFF]. On Tue Sep 23 20:07:18 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Hi, I am trying to submit a batch job but getting error. 'sbatch: error: Batch job submission failed: Invalid partition name specified'. I am trying to use the gpu-general partition. #!/bin/bash #SBATCH --cluster chip-gpu #SBATCH --job-name TES3_camb #SBATCH --gres=gpu:1 #SBATCH --output=ada_files/TES3camb.out #SBATCH --error=ada_files/TES3camb.err #SBATCH --time=72:00:00 #SBATCH --mem=30000 #SBATCH --account=[ACCOUNT] #SBATCH --partition=gpu-general export CUDA_LAUNCH_BLOCKING=1 python TES3_main_ada.py --model_name camb --batch_size 128 --lr 0.001 --scheduler None --func Joint_L2_Binary_sig --w1 1 --w2 15 --w3 1 --patch_size 64 --num_epochs 2000 --patience 50 I am not using the contributor partition where my job could be emptied. Thanks"
"3279439","72454720","2025-10-23 15:15:24","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 11th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3279443","72454844","2025-10-23 15:19:57","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Dear [STAFF], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 6th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3279447","72474983","2025-10-24 13:45:15","Migrating Research Storage Volume to Ceph Cluster - [ID]","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/[STAFF]. The alias used to reach the volume is now [STAFF]_common and [STAFF]_user. Your new volume has a quota of 25TB. When you have a chance, please try running some jobs on Chip using the new volume to verify everything looks good. Thank you, On Wed Sep 24 10:21:43 2025, [STAFF] wrote: Hello [USER], As per the communication via myUMBC earlier this summer (https://my3.my.umbc.edu/groups/hpcf/posts/150838), DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 1.8GB of a 100GB quota on the old storage server. To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at '/umbc/rs/[STAFF]'. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. Below we've listed two options for handling this data migration - please let us know which of these you'd prefer. Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day. Option 2: If you don't respond to this email by October 15th, DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes. Note: After this process has completed, the new storage volume will have a new name. For example, group '[STAFF]' will find its data under '/umbc/rs/[STAFF]', or in your group's case you will find your volume under '/umbc/rs/[STAFF]'. Thank you, [STAFF]. Best, [STAFF]."
"3279452","72207321","2025-10-10 15:25:23","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Ticket [TICKET NUMBER] Comment just added. It's been a week since they transferred, so up to you if you want to resolve this one?"
"3279454","72456680","2025-10-23 15:56:25","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Dear [STAFF], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 11th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3279458","72462068","2025-10-23 17:59:17","Migrating Research Storage Volume to Ceph Cluster - [USER]","Hello [STAFF], Sorry for my late response. I have asked my student to run jobs on Chip using the new volume. Everything seems good! Thank you, [USER]  On Oct 16, 2025, at 1:00 PM, [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3279458> Last Update From Ticket: Hello [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: * The path has changed, and is now available under /umbc/rs/pi_[USER]. * The alias used to reach the volume is now pi_[USER]_common and pi_[USER]_user. * Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF] On Thu Oct 16 11:40:28 2025, wrote: Hello [USER], This is a reminder that we'll be starting your group's research storage volume migration today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF] On Mon Sep 29 15:12:24 2025, wrote: That sounds great. Thanks! [USER] On Sep 29, 2025, at 2:27 PM, [STAFF] via RT <[EMAIL]> wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3279458 Last Update From Ticket: Hello [USER], Thanks for getting back to us! I've put your group on our schedule for October 16th. We'll send you an email alert via this RT when we begin the migration, and again when the migration has completed. Best, [STAFF] On Mon Sep 29 12:32:18 2025, wrote: Hello [STAFF], Thank you for your email. I would like to schedule a group-wide downtime date on October 16th for this data migration. Thank you,[USER] On Sep 24, 2025, at 10:27 AM, via RT <[EMAIL]> wrote: Greetings, This message has been automatically generated in response to the creation of a ticket regarding: Subject: 'Migrating Research Storage Volume to Ceph Cluster - pi_[USER]' Message: Hello [USER], As per the communication via myUMBC earlier this summer (https://my3.my.umbc.edu/groups/hpcf/posts/150838), DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 379GB of a 2TB quota on the old storage server. To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at “/umbc/rs/[USER]”. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. Below we’ve listed two options for handling this data migration - please let us know which of these you’d prefer. Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day. Option 2: If you don’t respond to this email by October 15th, DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes. Note: After this process has completed, the new storage volume will have a new name. For example, group “pi_doit” will find its data under “/umbc/rs/pi_doit”, or in your group’s case you will find your volume under “/umbc/rs/pi_[USER]”. Thank you, [STAFF]"
"3279461","72207365","2025-10-10 15:27:54","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Ticket [TICKET] Comment just added. I would tell them that we're going with the Oct. 17 date. LMK via [PLATFORM], I'm not cc'ed in these tickets, if I should send the reminder"
"3279463","72331965","2025-10-16 18:11:03","Migrating Research Storage Volume to Ceph Cluster - [ID]","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_[USER]. The alias used to reach the volume is now pi_[USER]_common and pi_[USER]_user. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Thu Oct 16 11:40:50 2025, [EMAIL] wrote: Hello [USER], This is a reminder that we'll be starting your group's research storage volume migration today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Wed Sep 24 10:34:25 2025, [EMAIL] wrote: Hello DoIT team, Thanks for letting me know about the migration! Please just assign a day that is suitable for you. I am not using the cluster from October 16th through November 15th. Best, [USER]. On Wed, Sep 24, 2025 at 10:30 AM via RT [EMAIL] wrote: Greetings, This message has been automatically generated in response to the creation of a ticket regarding: Subject: 'Migrating Research Storage Volume to Ceph Cluster - pi_[USER]' Message: Hello [USER], As per the communication via myUMBC earlier this summer (https://my3.my.umbc.edu/groups/hpcf/posts/150838), DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 936GB of a 1TB quota on the old storage server. To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at '/umbc/rs/[USER]'. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. Below we've listed two options for handling this data migration - please let us know which of these you'd prefer. Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day. Option 2: If you don't respond to this email by October 15th, DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes. Note: After this process has completed, the new storage volume will have a new name. For example, group 'pi_doit' will find its data under '/umbc/rs/pi_doit', or in your group's case you will find your volume under '/umbc/rs/pi_[USER]'. Thank you, [STAFF]."
"3279464","72660911","2025-11-03 15:23:31","Migrating Research Storage Volume to Ceph Cluster - [ID]","Good morning [USER], Yes, the data migration for zzbatmos is still underway, and it will still take awhile to complete. We do not currently have a good estimate for completion to give. The data is definitely not lost, so hopefully that eases your anxiety! Best, [STAFF] On Mon Nov 03 08:27:57 2025, [USER] wrote: Hi [STAFF], Good morning. For a follow-up question, has the data migration for zzbatmos been completed? I noticed that some of my critical codes from the previous path (/umbc/rs/zzbatmos/users/[USER]) are missing, which makes me quite anxious. Hopefully, they’re still in the process of being migrated and not lost. Thanks, [USER] On Fri, Oct 31, 2025 at 12:14 PM [USER] wrote: Thanks, [STAFF]! Looks awesome. Wishing you a great day and a fun Halloween weekend! -[USER] On Fri, Oct 31, 2025 at 12:04 PM [STAFF] via RT wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3279464 Last Update From Ticket: [USER], That’s great, thanks for confirming for us! To answer your questions: * The 10TB quota is combined for all of the data under /umbc/rs/pi_[USER], so you can have any amount of data in both common and users up until the total. You can check your storage quota and usage by logging into Chip and running “df -h /umbc/rs/pi_[USER]”. * Yes, that should be fine. Slurm doesn’t care about where the data is stored as long as your user has access to run jobs on the hardware partition you’re requesting, and the job will run as long as your user has access to read the data in [STAFF]'s research volume. However, [STAFF] doesn't have a hardware partition on Chip for special access - were you referring to slurm hardware partitions in this question, or were you referring to something else? * Yes, the zzbatmos research volume is being migrated today and will be available under /umbc/rs/pi_zzbatmos when the migration is completed. Currently we’re expecting the migration to last over the weekend, though it may take longer to complete as the volume is so large (~500TB). I hope this helps, and please let us know if you have any more questions or concerns! Thank you, [STAFF] On Fri Oct 31 11:12:59 2025, [USER] wrote: Hi [STAFF], Thanks very much for all your efforts in migrating the data. I tried running from the new path, and everything looks good. I just have a few questions regarding my CHIP account: * It’s great to hear that the quota is now 10 TB. Could you please let me know how much of that applies to the ‘user’ and ‘common’ paths separately? * Since I also have access to the ‘zzbatmos’ account, if I create my program under the ‘pi_[USER]’ path, can I still submit jobs using ‘zzbatmos’ so that they benefit from its higher queue priority? * I currently don’t have access to the ‘zzbatmos’ directory. Is this path also undergoing data migration? When do we expect that process to be completed? Thanks again for your help. Best regards, [USER]"
"3279592","72398692","2025-10-21 16:06:10","Migrating Research Storage Volume to Ceph Cluster - [ID]_limadri1","Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 11th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3279595","72699615","2025-11-04 01:27:24","Migrating Research Storage Volume to Ceph Cluster","Hello [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/[STAFF]. The alias used to reach the volume is now pi_[STAFF]_common and pi_[STAFF]_user. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Mon Nov 03 11:41:38 2025, [STAFF] wrote: Hello [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Fri Oct 17 12:57:15 2025, [STAFF] wrote: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 3rd for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]."
"3279598","72527688","2025-10-28 14:45:42","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hi, Yes, you have almost no data to migrate, so it shouldn't take very much time at all. The files on chip. We have a policy to not delete data, so if you can't find your taki files, I'm sure they've been archived somewhere so submit another ticket and we can work with you to reaccess them. Best, [STAFF]"
"3279600","72093279","2025-10-03 20:05:23","Migrating Research Storage Volume to Ceph Cluster - [ID]","We will look at archiving and/or removing storage volumes that are no longer used after we finish migrating the PI-owned volumes. On Fri Oct 03 15:28:31 2025, [STAFF] wrote: I have no idea how to mark this in the spreadsheet lol. [STAFF], does this mean like deleting their data? If so, when is/has that happened?"
"3280631","72239869","2025-10-13 16:01:56","Cloud: Request for AWS Account and Cloud Resources for [USER]'s Research Project","Hi [STAFF], Sorry for the lag here. UMBC DoIT only generates the project and accounts. In doing so, the project is made within UMBC's AWS contract, which offers some discounts and minor integration with our existing infrastructure. The costs of any project are the sole responsibility of the project owner -- one of the first things we do after generating the project is assign a campus PCard to the owner's department. The department would then work with you to ensure the charges land where you expect. The owner and other users are given administrative access to the AWS project after it's creation. We also give the owner access to monitor and manage the project via UMBC's Kion instance. All of that said, the best way to estimate costs is to use the AWS Calculator: https://calculator.aws/#/ This will likely be a slight overestimate since our contract grants up to 5% off in some areas. If this is something you'd like to engage with, we can have something setup and delivered to you by the end of the week. We'd just need to identify any other users that you'd like to have access to the space as well as a contact for the department PCard information. On Fri Oct 10 10:41:30 2025, [USER] wrote: Hello Roy Prouty I wanted to follow up on the status of the AWS account request, as it has been more than a week. As Dr. Williams mentioned, the data we will be working with is de-identified and not sensitive. Could you also please share some details about how the costs for the AWS resources are managed or allocated? Thank you for your time and assistance. On Tue, Sep 30, 2025 at 3:21PM [STAFF] via RT wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3280631 > Last Update From Ticket: Hello! The data is not sensitive, as it is de-identified. can you tell me a little more about how the costs work? On Tue, Sep 30, 2025 at 3:13PM [STAFF] via RT wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3280631 > Last Update From Ticket: Hi [USER], We can get this going for you a little later in the week. In order to determine what security we should associated with the account: Could you share whether or not the data associated with this project is sensitive in any way? Further, I just want to be clear that we will generate this AWS account, then give the details to our AWS vendor who will work to generate a payment process via CSEE. If that sounds right to you, we'll move forward. On Wed Sep 24 16:01:22 2025, [USER] wrote: First Name: Kartik Last Name: Sethi Email: ksethi1@umbc.edu Campus ID: YI42419 On Behalf Of: Rebecca Williams (rmwillia@umbc.edu, KC16614) Request Type: Cloud Computing Cloud Service: AWS Requesting the setup of an AWS account under UMBC's cloud resources to support my project Visualization Education. This project requires cloud infrastructure for storage, computation, and application development. Specifically, I would like to request the following AWS resources: 1. Storage & Compute 2. Database Services 3. User Management (Cognito) 4. AWS Amplify 5. API Management and Lambda 6. Ec2 Access to these services will allow me to efficiently build, test, and scale the project while adhering to best practices for security and compliance. -- [STAFF] DoIT Research Computing Team"
"3280726","71935866","2025-09-25 12:48:21","HPC Slurm/Software Issue: Urgent: chip slurm seems not to be found","This is resolved. The root of the issue came from a change in permissions to the configuration file on chip-cpu. We're working to make sure this doesn't happen again. On Wed Sep 24 20:30:43 2025, [USER] wrote: First Name: [USER] Last Name: [STAFF] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster Hi, Sunday 8:30 pm. A student alerted me to slurm throwing weird general error messages. I confirmed. It sounds like something is not found. Notice that my slurm file contains the --cluster despite the message. I copy 'pwd' and result of sbatch and farther below the slurm file in that directory. [USER@c24-44 ver0.0test]$ pwd -P /umbc/rs/[STAFF]/users/[USER]/teaching/math627/homework/hw3_power/250925_Fall2025/ver0.0test [USER@c24-44 ver0.0test]$ sbatch run-power_parallel.slurm sbatch: error: s_p_parse_file: unable to read '/cm/shared/apps/slurm/var/etc/chip-cpu/slurm.conf': Permission denied sbatch: error: ClusterName needs to be specified sbatch: fatal: Unable to process configuration file [USER@c24-44 ver0.0test]$ more run-power_parallel.slurm #!/bin/bash #SBATCH --job-name=power # Job name #SBATCH --output=slurm_%j.out # Output file name #SBATCH --error=slurm_%j.err # Error file name #SBATCH --account=[ACCOUNT] # Account #SBATCH --cluster=chip-cpu # Cluster #SBATCH --partition=match # Partition #SBATCH --qos=shared # Queue #SBATCH --nodes=1 # Number of nodes #SBATCH --ntasks-per-node=1 # MPI processes per node #SBATCH --time=00:05:00 # Time limit #SBATCH --mem=8G # Memory per node module load intel/2024a unset I_MPI_PMI_LIBRARY export I_MPI_JOB_RESPECT_PROCESS_PLACEMENT=0 mpirun -print-rank-map ./power 4 1.0e-12 50"
"3280889","71945408","2025-09-25 16:06:50","HPC Slurm/Software Issue: [USER] having issue getting space on CHIP gpu","Ok great! Glad you figured it out. As I said, partition info can be found on this wiki page: https://[DOMAIN]/wiki/spaces/faq/pages/[PAGE_ID]/chip Partitions and Usage If you don't have any more questions, I'll close this ticket on Friday. [STAFF]"
"3280927","71946774","2025-09-25 16:56:10","HPC Slurm/Software Issue: GPU Job QoS not Permitted","Hi [USER], I see that your job is currently running without issue. Did you get that output from squeue? If so, you can see that the job status is 'PD' which means pending. I am not 100% sure why it is showing this exact error, but it seems the nodes were allocated shortly after the start of the job. Are there any actual errors with the job itself? We are looking into the cause of this message, however it does not seem to actually be causing any errors. Kind regards, [STAFF] DoIT Unix Infra Student Worker. #!/bin/bash #SBATCH --job-name=[JOBNAME] #SBATCH --output=klog/collect_%A_%a.out #SBATCH --error=klog/collect_%A_%a.err #SBATCH --mem=64G #SBATCH --time=72:00:00 #SBATCH --constraint=rtx_6000 #SBATCH --gres=gpu:4 #SBATCH --array=6,7,12,13,20 #SBATCH --mail-user=[EMAIL] #SBATCH --mail-type=END,FAIL #SBATCH --partition=gpu-general"
"3281158","72021159","2025-09-30 17:10:20","HPC User Account: [ID] in Student Group","Ticket Last Update From Ticket I confirm [USER] is also an iHARP student besides his current group setup Thanks On Tue Sep 30 2025 at 946 AM [STAFF] via RT wrote Ticket URL https rt umbc edu Ticket Display html id=3281158 Last Update From Ticket Hello We just need the written permission from [STAFF] and [STAFF] They are cc'd Then I can add you to the iHarp group as usual No rush Elliot Gobbert"
"3281243","71954925","2025-09-26 00:00:06","HPC Other Issue: Nodes on partition [ID] being used in partition 2024","I was unaware of the 10 minute grace period. Many apologies. My calculations did run. I appreciate your help and information on this. Thank you! [USER] On Thu, Sep 25, 2025 at 4:41 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3281243> Last Update From Ticket: Hello [USER], That is correct - nodes in the pi_bennettj partition will preempt jobs from users that are not in the pi_bennettj group after a 10 minute grace period. It looks like your jobs were submitted at 3:48pm EST and started ~10 minutes later at 3:58pm EST. Can you confirm that your job is running now? Thank you, [STAFF] On Thu Sep 25 15:55:41 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Cluster Hello, I'm trying to run jobs on the pi_bennettj partition, however, 4 of our nodes are being used on partition 2024. I was under the impression that the pi researchers would preempt anyone using our nodes. I've attached a list of the nodes being used. Thank you, [USER] Attachment 1: nodes.txt"
"3281293","71992213","2025-09-29 16:34:21","HPC Other Issue: jobs getting killed on 2024 queue","Yes had much better success over the weekend Thanks [USER] On Mon Sep 29 2025 at 12:03 PM [STAFF] via RT <[EMAIL]> wrote Ticket https://rt.umbc.edu/Ticket/Display.html?id=3281293 Last Update From Ticket I see Is everything working as intended now Kind regards [STAFF] DoIT Unix Infra Student Worker On Fri Sep 26 16:41:53 2025 [USER] wrote Whoops sorry was submitting the batch file designed for taki ... -[USER] On Fri Sep 26 2025 at 4:38 PM [USER] <[EMAIL]> wrote Hi [STAFF] Thanks for the info I tried this just now #SBATCH --job-name=3DFIT_TILE_TRENDS ## name #SBATCH -N1 ## number of job step is to be allocated per instance of matlab #SBATCH --cpus-per-task 1 ## tasks per node/number of cores per matlab session will be #SBATCH --partition=2024 ## desired partition #SBATCH --partition=match ## desired partition #SBATCH --cluster=chip-cpu ## desired cluster #SBATCH --account=pi_strow #SBATCH --qos=shared ## qos to get as many cpu2024 as possible else put pi_strow and get bin/rm: cannot remove '*~': No such file or directory /bin/rm: cannot remove 'slurm*.err': No such file or directory sbatch: error: Missing: '--gres' sbatch: error: You must specify a Generic RESource to use in your job. sbatch: error: See this webpage for more details: https://hpcf.umbc.edu/compute/overview/. sbatch: error: Batch job submission failed: Unspecified error which according to the webpage you pointed me to should be used for gpu processors Thanks [USER] On Fri Sep 26 2025 at 9:52 AM [STAFF] via RT <[EMAIL]> wrote If you agree your issue is resolved please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customeremail=[EMAIL]&groupid=EIS&ticketid=3281293&ticketowner=desposi1%40umbc.edu&ticketsubject=HPC Other Issue: jobs getting killed on 2024 queue If you believe your issue has not been resolved please respond to this message which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3281293 Thank You _________________________________________ R e s o l u t i o n Hi [USER] First off let me elaborate on the slurm job ID's you are seeing. When submitting an array job there is the main job ID which is 402067 in this case along with the array tasks for each which are like 402067_90. However each individual array task also gets its own actual job ID. For example the actual job ID for array task 402067_90 is 402157. Next your job was likely canceled due to someone in pi_bennettj attempting to run a job on their nodes. Nodes c24-[01-10] are all nodes contributed from pi_bennettj therefore they have priority access and the ability to preempt other users not in their group. If you want to run your jobs on 2024 nodes but do not want to risk preemption use the 'match' partition. If you would like more information on which partitions allow/disallow preemption check out this wiki page: https://umbc.atlassian.net/wiki/spaces/faq/pages/1249509377/chip+Partitions+and+Usage#Partitions Let me know if that helps Have a nice day Kind regards [STAFF] DoIT Unix Infra Student Worker On Thu Sep 25 16:56:36 2025 [USER] wrote First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USER] Request Type: High Performance Cluster For some reason many of my jobs are getting killed/preempted slurmsteps. I thought I had an issue with the code but seems fine to me. Haven't had that before Is there a way to limit the jobs only to Larrabee's computer Wierd this is suppose the slurm job ID is 402067 I keep getting told eg 402166 has been killed makes no sense [USER]@chip-login1 AI_RTA$ grep -in slurmst slurm* slurm-402067_90.out:17:.........+slurmstepd: error: *** JOB 402157 ON c24-02 CANCELLED AT 2025-09-25T15:58:40 DUE TO PREEMPTION ***"
"3281491","72083445","2025-10-03 15:01:47","Srun not working for a parallel task","I apologize for the late reply. I wanted to suggest trying to add --mpi=pmix to srun commands (srun --mpi=pmix -n 8 /path/to/your/test --verbose). I think srun might be defaulting to a single rank, which could explain why you're seeing the 'Insufficient processes' error even when requesting multiple tasks and srun working when task is set to 1. pmix (Process Management Interface for Exascale) is the plugin that enables Slurm to correctly launch and manage MPI tasks across multiple ranks. Without specifying it, srun may not properly initialize the MPI environment. Let me know if that doesn't resolve the issue. On Fri Sep 26 12:00:58 2025, [USER] wrote: Hi, I have listed the 6 files (SLURM scripts, job outputs, executable outputs) in the next section. In short, the 'mpirun' launches my program successfully, while 'srun' leads to several invalid memory access issues. Both SLURM scripts launch 31 executables at the same time (on 1 CPU node with 8 CPU cores). The only difference is the MPI launcher 'srun' v.s. 'mpirun'. 'srun' version: - Work directory for the 'srun' version: [DIRECTORY] - 'srun' job script: [DIRECTORY]/job.sh - 'srun' job output: [DIRECTORY]/[OUTPUT FILE].out - Actual 'srun' commands and output: [DIRECTORY]/LastTest.log 'mpirun' version: - Work directory for the 'mpirun' version: [DIRECTORY] - 'mpirun' job script: [DIRECTORY]/job.sh - 'mpirun' job output: [DIRECTORY]/[OUTPUT FILE].out - Actual 'mpirun' commands and output: [DIRECTORY]/LastTest.log The 'mpirun' command I use for this test is from a Spack build of OpenMPI with the following spec: -- linux-rhel9-cascadelake / %c,cxx,fortran=gcc@13.3.0 ---------- openmpi@5.0.8+atomics~cuda~debug+fortran~gpfs~internal-hwloc~internal-libevent~internal-pmix~ipv6~java~lustre~memchecker~openshmem~rocm~romio+rsh~static~two_level_namespace+vt+wrapper-rpath build_system=autotools fabrics:=none romio-filesystem:=none schedulers:=none Best, [USER] On Sep 26, 2025, at 10:38 AM, via RT <[EMAIL]> wrote: Greetings, This message has been automatically generated in response to the creation of a ticket regarding: Subject: 'Srun not working for a parallel task' Message: [USER] had an office hour with [STAFF] and [STAFF]. We weren't able to provide an immediate solution. [USER], please add the errors you get, your slurm script, and the working directory. There is no need to reply to this message right now. Your ticket has been assigned an ID of [Research Computing #[NUMBER]] or you can go there directly by clicking the link below. Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=[NUMBER]> You can login to view your open tickets at any time by visiting https://my.umbc.edu and clicking on 'Help' and 'Request Help'. Alternately you can click on https://my.umbc.edu/help Thank you -- Best, [STAFF] DOIT Unix infra, Graduate Assistant"
"3281714","71968970","2025-09-26 18:20:20","HPC Slurm/Software Issue: Cannot create slurm job","Hi [STAFF], Chip is not down. That being said, I did notice that the configuration was acting strange, and it turns out that it was trying to submit jobs to the 'gpu-contrib' partition which is non-submittable partition. I've changed that the 'gpu' partition is back to being the default partition and should work. In the future you can always check to see if chip is really down by using the 'sinfo' command. Additionally you can also specify the partition using the '--partition=${gpu_partition}'. Let me know if you have more questions about this, I'll leave the ticket open for a few days.  Hello! I attempted to run a slurm job: srun --cluster=chip-gpu --account=pi_[STAFF] --mem=20000 --time=12:00:00 --gres=gpu:1 --pty $SHELL Recieved: srun: Requested partition configuration not available now. I am pretty sure chip is down, would it be possible to recieve an update when chip is available again? Thank you!"
"3282078","72617448","2025-10-31 13:11:06","Cloud: Google Vision","Waiting for info from [LOCATION] to get GCP billing in place -- [STAFF], Associate Director of Research and Enterprise Computing, Enterprise Infrastructure Solutions, [ORGANIZATION]."
"3282188","72713394","2025-11-04 16:49:54","HPC Slurm/Software Issue: Please install newer Matlab","The text appears to be an email conversation between Matthias Gobbert and Max Breitmeyer, a system administrator at the University of Maryland, Baltimore County (UMBC). The conversation is about installing MATLAB R2025b on the university's High-Performance Cluster (HPC) system.  Here's a summary of the conversation:  * Matthias Gobbert requests that Max install MATLAB R2025b on the HPC system, as the current version (R2023b) is two years old. * Max responds that he has added MATLAB 2025b to some partitions and is working on installing it on others. He asks Matthias to try it out and report any issues. * Matthias reports an error when trying to run a job with MATLAB 2025b and provides details of the error message. * Max investigates the issue and determines that there was a problem with the installation. He fixes the issue and informs Matthias that MATLAB 2025b should now be available on all partitions.  The conversation also includes some extraneous text, including an automated email about closing a ticket and a signature block from Max Breitmeyer."
"3282261","71992977","2025-09-29 16:59:49","HPC User Account: [ID] in Pi_ksolaima","Hi [USER],<br /> Your account ([USER]) has been added to the pi_[STAFF] group on chip.rs.umbc.edu .<br /> Please read through the documentation found at hpcf.umbc.edu > User Support.<br /> All available modules can be viewed using the command 'module avail'.<br /> Please submit additional questions or issues as separate tickets via the following link.<br /> (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/)<br /> Kind regards,<br /> [STAFF] (she/her/hers)<br /> DoIT Unix Infra Student Worker<br /> On Mon Sep 29 05:51:37 2025, [USER] wrote:<br /> First Name:                [USER]<br /> Last Name:                 [USER]<br /> Email:                     [EMAIL]<br /> Campus ID:                 [ID]<br /> Request Type:              High Performance Cluster<br /> Create/Modify account in existing PI group Existing PI Email:    [EMAIL]<br /> Existing Group:       Pi_[STAFF]<br /> Project Title:        Multimodal information retriever<br /> Project Abstract:     This project focuses on the development of a robust system for anomaly detection in multivariate, irregularly-sampled time-series data, with an application to identifying electricity theft from the Smart Grid Generated Data (SGCC) dataset. The primary methodology involves the implementation and training of Neural Controlled Differential Equations, a deep learning architecture designed to capture complex temporal dependencies.<br /> I am developing and training a series of deep learning models for my time-series analysis research. On my current resources, the training process is prohibitively slow, with each epoch taking approximately 40-45 minutes to complete. This makes iterative development, debugging, and essential hyperparameter tuning impractical. Access to the HPC cluster would significantly accelerate this research by enabling me to run multiple experiments in parallel and iterate on model architectures and feature engineering more efficiently. Thank you for your time and consideration."
"3282435","72016856","2025-09-30 15:09:21","Need to create account in the chip cluster under [STAFF]'s group","Correct request was submitted: https://rt.umbc.edu/Ticket/Display.html?id=[TICKET_ID] --  [STAFF]"
"3282455","72080990","2025-10-03 13:48:18","HPC Other Issue: client_loop: send disconnect: Broken pipe happens every few minutes","Hi [USER], We've made a change to the ssh config that we are hoping will solve the issue. Could you keep an eye on it let us know if you notice a difference? On Mon Sep 29 13:24:40 2025, [STAFF] wrote: Hi [USER], we've received reports from other researchers who are experiencing something similar and we are currently investigating the issue. A little more information might help us: - First, can you give us exact times and dates for some of the disconnects you are seeing? This will help us look at the connection logs to find where it happened. - Second, what kind of connection do you have? Wired or wireless? Are you on the vpn when connecting to chip? - Third, are you experiencing it on one of the login nodes more than another? Let me know the above and we can go from there. If you experience anymore of these disconnects please write down the exact date and time you experienced it so we can look into it further. On Mon Sep 29 11:46:36 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Cluster Hello, since last week I have been disconnected repeatedly after logging into chip after only a few minutes of waiting for jobs to progress. I am using the standard 'ssh [USER]@chip.rs.umbc.edu' command that has been working for months, but it is disconnecting me too frequently. Why is the Connection to chip.rs.umbc.edu closed by remote host closed so much while I'm working? This is interrupting our research. Is there a different way to login now of which I am unaware? Thank you!"
"3282508","72028002","2025-09-30 20:11:03","HPC Other Issue: Need to install a module for WRF Simulation.","Hello [USER], good afternoon. Thank you very much for providing this information. Actually, I tried to find the module using 'module spider gfortran' to check if it is available or not. I will try to load the module using the way you mentioned and complete my work. If not I will ask for further help. Regards [STAFF]. On Mon Sep 29 12:57:26 2025, [EMAIL] wrote: Hi [USER], What happens when you attempt to use gfortran? Without loading any modules, there is a library for gfortran located in /usr/bin/gfortran, which should be on your PATH. Additionally, you can load more specific versions of gfortran through other modules. For example, if you load GCCcore with 'module load GCCcore', you can see that the gfortran library is also present, now located at '/usr/ebuild/installs/software/GCCcore/13.3.0/bin/gfortran' (you can verify yourself with 'which gfortran' to show you the location of the gfortran library). Let me know if this helps! -- Kind regards [STAFF]. On Mon Sep 29 12:33:11 2025, [EMAIL] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Cluster Hello, I need to run the WRF climate simulation model to generate datasets for my project. To run this simulation model, I need to use 'gfortran' library, but this is not available in the CHIP cluster. It would be very helpful if you could install the library. Please check the given link if you need further information about running the WRF model. WRF Tutorial Link: https://www2.mmm.ucar.edu/wrf/OnLineTutorial/compilation_tutorial.php#STEP1"
"3282986","72517731","2025-10-27 22:20:16","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_[USER]. The alias used to reach the volume is now pi_[USER]_common and pi_[USER]_user. Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Mon Oct 27 13:21:50 2025, [STAFF] wrote: Hello [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Fri Oct 17 11:52:31 2025, [STAFF] wrote: [USER]."
"3282987","72452175","2025-10-23 14:16:12","Migrating Research Storage Volume to Ceph Cluster - [ID]","Dear [STAFF], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 14th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3282989","72725795","2025-11-04 18:28:42","Migrating Research Storage Volume to Ceph Cluster - [ID]","Hello [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_[STAFF]. The alias used to reach the volume is now pi_[STAFF]_common and pi_[STAFF]_user. Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Tue Nov 04 12:04:40 2025, [EMAIL] wrote: Hello [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Fri Oct 17 13:09:09 2025, [EMAIL] wrote: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 4th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]."
"3282995","72602966","2025-10-30 16:55:51","Migrating Research Storage Volume to Ceph Cluster - [ID]","Hello [USER], It took longer than expected, but we have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_bsol. The alias used to reach the volume is now pi_bsol_common and pi_bsol_user. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? I apologize if the extended length of the migration caused any issues for you or your group. Thank you, [STAFF] On Wed Oct 29 13:43:53 2025, [EMAIL] wrote: Hello , This is just a reminder that we are starting your migration today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. On Fri Oct 17 12:16:06 2025, [EMAIL] wrote: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of October 29th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF] Best, [STAFF]."
"3282997","72539090","2025-10-28 19:36:46","Migrating Research Storage Volume to Ceph Cluster - [ID]","Hello [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_[STAFF]. The alias used to reach the volume is now pi_[STAFF]_common and pi_[STAFF]_user. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Tue Oct 28 10:49:25 2025, [EMAIL] wrote: Hello [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Fri Oct 17 12:04:45 2025, [EMAIL] wrote: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of October 28th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]."
"3283002","72619186","2025-10-31 13:53:06","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello. We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed and is now available under /umbc/rs/[STAFF]. The alias used to reach the volume is now [STAFF]_common and [STAFF]_user. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you. On Fri Oct 17 12:35:08 2025, [EMAIL] wrote: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of October 31st for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]."
"3283005","72422708","2025-10-22 14:01:34","Migrating Research Storage Volume to Ceph Cluster - [ID]","Hello We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed and is now available under /umbc/rs/pi_[USER]. The alias used to reach the volume is now pi_[USER]_common and pi_[USER]_user. Your new volume has a quota of 25TB. When you have a chance please try running some jobs on Chip using the new volume to verify everything looks good. Thank you On Wed Oct 22 09:30:55 2025 [STAFF] wrote: Hello This is just a reminder that we are starting your migration today. During this time please ensure there are not any jobs being run in your research group otherwise these may be terminated. We will provide an update once completed. On Fri Oct 10 13:37:41 2025 [STAFF] wrote: Hello [USER] I've put your group on our schedule for Wednesday October 22nd. We will send you an email alert via this RT ticket when we begin the migration process and again once it has completed. Please let us know if you have any questions or concerns. Best [STAFF] On Fri Oct 10 11:17:29 2025 [USER] wrote: Good Morning It is fine with me if you schedule the transfer of /umbc/rs/[USER] for an arbitrary date 10/16 - 11/15. [USER] On Fri Oct 10 2025 at 10:26 AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=[NUMBER]> Last Update From Ticket: Hello [USER] This is a reminder email in case you missed the first. We need a response by October 15th or we'll be forced to go with Option 2 randomly scheduling a time. As per the communication via myUMBC earlier this summer https://my3.my.umbc.edu/groups/hpcf/posts/150838 DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 0GB of a 500GB quota on the old storage server. To perform these migrations we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at '/umbc/rs/[USER]'. During the migration we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. Below we've listed two options for handling this data migration - please let us know which of these you'd prefer. Option 1: Schedule a group-wide downtime date during standard business hours which can be done by responding to this email with your preferred date(s) to perform the migration. During this time DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes this process should take less than a business day. Option 2: If you don't respond to this email by October 15th DoIT staff will assign a day over the following month October 16th through November 15th to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration and will be notified when the migration begins and completes. Note: After this process has completed the new storage volume will have a new name. For example group 'pi_doit' will find its data under '/umbc/rs/pi_doit' or in your group's case you will find your volume under '/umbc/rs/pi_[USER]'. Thank you [STAFF] -- [STAFF] System Administrator for Research and Enterprise Computing UMBC - DoIT -- Best [STAFF] DOIT Unix infra Graduate Assistant"
"3283011","72612724","2025-10-30 23:26:51","Migrating Research Storage Volume to Ceph Cluster","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/[SERVER]. The alias used to reach the volume is now [ALIAS]_common and [ALIAS]_user. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Thu Oct 30 10:33:42 2025, [EMAIL] wrote: Hello [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Sat Oct 18 07:28:24 2025, [EMAIL] wrote: Hi, No worries, you don't need to do anything except NOT use the cluster on Oct. 30th. To transfer the files, we make the old directory read only, so just don't use the cluster while we transfer things. We will email you in this ticket when we start and finish the migration. Best, [STAFF]."
"3283013","72612692","2025-10-30 23:25:03","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_[USER]. The alias used to reach the volume is now pi_[USER]_common and pi_[USER]_user. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Thu Oct 30 10:32:46 2025, [EMAIL] wrote: Hello [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Fri Oct 17 12:30:41 2025, [EMAIL] wrote: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of October 30th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]."
"3283015","72639783","2025-10-31 18:20:42","Migrating Research Storage Volume to Ceph Cluster - [ID]","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/[USER]. The alias used to reach the volume is now [ALIAS] and [ALIAS]. Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF] On Fri Oct 31 10:42:00 2025, wrote: Good morning [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF] On Fri Oct 17 12:48:06 2025, wrote: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of October 31st for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3283018","72451113","2025-10-23 13:53:20","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 14th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3283023","72707701","2025-11-04 15:03:43","Migrating Research Storage Volume to Ceph Cluster - [ID]","Excellent, cheers!  We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: * The path has changed, and is now available under /umbc/rs/pi_[USER]. * The alias used to reach the volume is now pi_[USER]_common and pi_[USER]_user. * Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are no jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 3rd for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3283027","72218159","2025-10-11 03:05:56","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello [USER], Thanks for getting back to us I put your group's migration on our schedule for Wednesday October 29th We will send you an email alert via this RT ticket when we begin the migration, and again once it has completed Please let us know if you have any questions or concerns Best, [STAFF] On Fri Oct 10 17:36:42 2025, [USER] wrote Hi [STAFF], Thank you for reaching out to me I prefer 10.29,30,31 Thanks, [USER] On Fri, Oct 10, 2025 at 11:32 PM [STAFF] via RT [EMAIL] wrote Ticket https://rt.umbc.edu/Ticket/Display.html?id=3283027 Last Update From Ticket Hello [USER], This is a reminder email, in case you missed the first We need a response by October 15th, or we'll be forced to go with Option 2, randomly scheduling a time As per the communication via myUMBC earlier this summer https://my3.my.umbc.edu/groups/hpcf/posts/150838, DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster Your group is using 0GB of a 500GB quota on the old storage server To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster Thus we are reaching out to schedule a date where we can migrate your volume located at '/umbc/rs/[STAFF]' During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume Below we've listed two options for handling this data migration - please let us know which of these you'd prefer Option 1 Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed For most storage volumes, this process should take less than a business day Option 2 If you don't respond to this email by October 15th, DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume The day chosen will be random and will occur during business hours You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes Note After this process has completed, the new storage volume will have a new name For example, group 'pi_doit' will find its data under '/umbc/rs/pi_doit', or in your group's case you will find your volume under '/umbc/rs/[STAFF]' Thank you [STAFF]"
"3283030","72346415","2025-10-17 14:14:08","Migrating Research Storage Volume to Ceph Cluster","Hello We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed and is now available under /umbc/rs/pi_dli. The alias used to reach the volume is now pi_dli_common and pi_dli_user. Your new volume has a quota of 25TB. When you have a chance please try running some jobs on Chip using the new volume to verify everything looks good. On Fri Oct 17 09:43:32 2025 [STAFF] wrote: Hello This is just a reminder that we are starting your migration today. During this time please ensure there are not any jobs being run in your research group otherwise these may be terminated. We will provide an update once completed. On Thu Oct 02 10:17:53 2025 [STAFF] wrote: Good morning [USER] Sounds good I've put your group's migration on our schedule for October 17th. We will send you a notification via this RT ticket when we begin the migration and again once the migration has completed. Please let me know if you have any questions or concerns. On Thu Oct 02 09:34:10 2025 [USER] wrote: Hi [STAFF] Thank you for reaching out. Any day before October 30th works for me for migrations. Best [USER]."
"3283033","72639739","2025-10-31 18:20:05","Migrating Research Storage Volume to Ceph Cluster - [ID]","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_[STAFF]. The alias used to reach the volume is now pi_[STAFF]_common and pi_[STAFF]_user. Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Fri Oct 31 10:42:33 2025, [USER] wrote: Good morning [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Fri Oct 17 12:50:43 2025, [USER] wrote: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of October 31st for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]."
"3283034","72434819","2025-10-22 18:02:33","Migrating Research Storage Volume to Ceph Cluster - [ID]","We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/[USER]. The alias used to reach the volume is now [USER]_common and [USER]_user. Your new volume has a quota of 10TB. When you have a chance, please try running some jobs on Chip using the new volume to verify everything looks good. Thank you. On Wed Oct 22 09:29:50 2025, [STAFF] wrote: This is just a reminder that we are starting your migration today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. On Fri Oct 10 13:48:10 2025, [STAFF] wrote: Great, thank you! On Fri, Oct 10, 2025 at 1:38 PM Greg Ballantine via RT [EMAIL] wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3283034 Hello [USER], Sounds good, I've put your group on our schedule for Wednesday October 22nd. We will send you an email alert via this RT ticket when we begin the migration process, and again once it has completed. Please let us know if you have any questions or concerns. Best, Greg On Fri Oct 10 10:40:46 2025, [STAFF] wrote: Thank you Elliot, I am fine with it whenever it gets migrated, as I have yet to store data on the server. Thanks, [USER]."
"3283037","72046066","2025-10-01 18:36:19","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_egreen. The alias used to reach the volume is now pi_egreen_common and pi_egreen_user. Your new volume has a quota of 10TB. We know you're not actively using it right now, but please don't hesitate to reach out if you hit any snags once you start working with the new volume. Best, [STAFF] On Wed Oct 01 10:38:55 2025, [EMAIL] wrote: Good morning [USER], Understood. We will send you an email later today with the details for your storage volume after the migration. Best, [STAFF] On Tue Sep 30 15:20:57 2025, [USER] wrote: Hi [STAFF], We don't currently have any data stored yet, so you are welcome to do any migration at any time-- it won't impact us at the moment. Thanks, [USER] On Mon, Sep 29, 2025 at 4:35PM via RT [EMAIL] wrote: Greetings, This message has been automatically generated in response to the creation of a ticket regarding: Subject: 'Migrating Research Storage Volume to Ceph Cluster - pi_egreen' Message: Hello [USER], As per the communication via myUMBC earlier this summer (https://my3.my.umbc.edu/groups/hpcf/posts/150838), DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 0GB of a 250GB quota on the old storage server. To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at “/umbc/rs/egreen”. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. Below we’ve listed two options for handling this data migration - please let us know which of these you’d prefer. Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day. Option 2: If you don’t respond to this email by October 15th, DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes. Note: After this process has completed, the new storage volume will have a new name. For example, group “pi_doit” will find its data under “/umbc/rs/pi_doit”, or in your group’s case you will find your volume under “/umbc/rs/pi_egreen”. Thank you, [STAFF]"
"3283044","72734810","2025-11-04 21:27:21","Migrating Research Storage Volume to Ceph Cluster - [ID]","Hello [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_ece. The alias used to reach the volume is now pi_ece_common and pi_ece_user. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF] On Tue Nov 04 12:05:33 2025, [EMAIL] wrote: Hello [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF] On Fri Oct 17 13:02:36 2025, [EMAIL] wrote: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 4th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3283046","72589150","2025-10-29 21:28:36","Migrating Research Storage Volume to Ceph Cluster - [ID]","Hello again [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_[STAFF]. The alias used to reach the volume is now pi_[STAFF]_common and pi_[STAFF]_user. Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Wed Oct 29 09:48:02 2025, [USER] wrote: Hello [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Fri Oct 17 12:22:56 2025, [USER] wrote: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of October 29th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]."
"3283048","72392280","2025-10-21 14:09:34","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello. We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed and is now available under /umbc/rs/[USER]. The alias used to reach the volume is now [ALIAS1] and [ALIAS2]. Your new volume has a quota of 25TB. When you have a chance please try running some jobs on Chip using the new volume to verify everything looks good. On Tue Oct 21 09:40:27 2025, [STAFF] wrote: Hello This is just a reminder that we are starting your migration today. During this time please ensure there are not any jobs being run in your research group otherwise these may be terminated. We will provide an update once completed. On Fri Oct 10 13:45:17 2025, [STAFF] wrote: Hello [USER] Sounds good I've put your group on our schedule for Tuesday October 21st. We will send you an email alert via this RT ticket when we begin the migration process and again once it has completed. Please let us know if you have any questions or concerns. Best Greg On Fri Oct 10 10:38:11 2025 [USER] wrote: Option 2 works for me Sent from my iPhone On Oct 10 2025 at 10:18 AM Elliot Gobbert via RT UMBCHe lp@rt.umbc.edu wrote Ticket URL https://rt.umbc.edu/Ticket/Display.html?id=3283048 Last Update From Ticket Hello [USER] This is a reminder email in case you missed the first. We need a response by October 15th or we'll be forced to go with Option 2 randomly scheduling a time. As per the communication via myUMBC earlier this summer https://my3.my.umbc.edu/groups/hpcf/posts/150838 DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 0GB of a 500GB quota on the old storage server. To perform these migrations we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at /umbc/rs/[USER]. During the migration we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. Below we've listed two options for handling this data migration - please let us know which of these you'd prefer. Option 1: Schedule a group-wide downtime date during standard business hours which can be done by responding to this email with your preferred date(s) to perform the migration. During this time DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes this process should take less than a business day. Option 2: If you don't respond to this email by October 15th DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration and will be notified when the migration begins and completes. Note: After this process has completed the new storage volume will have a new name. For example group pi_doit will find its data under /umbc/rs/pi_doit or in your group's case you will find your volume under /umbc/rs/[USER]. Thank you Elliot"
"3283387","72018279","2025-09-30 15:55:36","HPC User Account: [ID] in pi_[USER]","Hi [USER], your account ([USER]) has been added to the pi_[STAFF] group on chip.rs.umbc.edu . You can find a short tutorial on how to use chip here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip . Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link: https://doit.umbc.edu/request-tracker-rt/doit-research-computing/ . On Tue Sep 30 11:30:11 2025, [STAFF] wrote: Approve it. Thanks! This e-mail is a notification that a UMBC user: [USER] <[EMAIL]> has requested an account within UMBC's HPC environment in your group <pi_[STAFF>>. As the PI, we request that you acknowledge and approve this account creation by replying to this message. Alternatively, you can go to this link and review the ticket and indicate your decision here: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3283387> . Once we have your approval, we will create the account and you and the new user will receive another e-mail notifying you that the account has been created. If you have any other questions or concerns please contact us. Best, [STAFF] DOIT Unix infra, Graduate Assistant"
"3283454","72021378","2025-09-30 17:15:05","HPC User Account: [ID] in Student Group","Hello there, Here is how to request an account on chip: https://umbc.atlassian.net/wiki/spaces/faq/pages/[REMOVED]/How+to+request+a+[REMOVED]+account+on+[REMOVED] Let me know if that helps, [STAFF]"
"3283590","72035681","2025-10-01 13:55:24","HPC User Account: [ID] in pi_[STAFF]","Your account [USER] has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. You can find a short tutorial on how to use chip here: https://[EMAIL]/wiki/spaces/faq/pages/[NUMBER]/Getting+Started+on+chip. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. On Tue Sep 30 14:29:01 2025, [STAFF] wrote: Yes, [USER] is a PhD student working in my group. Thanks. Ticket <URL: https://[EMAIL]/Ticket/Display.html?id=[NUMBER]> First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USER] Request Type: High Performance Cluster Create/Modify account in existing PI group Existing PI Email: [EMAIL] Existing Group: pi_[STAFF] Project Title: Password Leak Detection with Machine Learning Project Abstract: Training Machine Learning Models to Detect Password Leaks."
"3283593","72025803","2025-09-30 19:09:58","HPC Other Issue: recent publication","Hello [USER], I have added this publication to our website: https://hpcf.umbc.edu/publications/ On Tue Sep 30 13:52:23 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Hi [STAFF], Geophysical Trends Inferred From 20 Years of AIRS Infrared Global Observations [USER], L. Larrabee Strow, R. J. Kramer First published: 11 August 2025 https://doi.org/10.1029/2025JD043501 See the link for bib info [USER] Best, [STAFF] DOIT Unix infra, Graduate Assistant"
"3283767","72140063","2025-10-07 16:00:19","HPC Slurm/Software Issue: Deleting .julia directories","Hi [USER], The solution is still to run chmod -R u+wrx DataFrames before attempting to remove the directory. The process is hanging because there are many files and directories to modify, which takes time. While the command is running, if your session is idle for too long, you may get logged out before it completes. To avoid this, I recommend using a tmux session to run the command so it can finish without interruption. You can learn more about tmux here (https://www.geeksforgeeks.org/linux-unix/tmux-in-linux/). Once the permissions have been updated, you can remove the directory. I have already removed the /umbc/rs/pi_jkestner/users/[USER]/.julia/packages/DataFrames directory for you after changing the permissions. Please reply to the ticket if you still have questions. On Tue Sep 30 16:50:49 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Ok, so this goes back to an issue I was at office hours last Friday with [STAFF]. We thought we resolved it, and it is kind of resolved, but I still have an issue deleting what I think are essentially corrupted directories. So, I have been dealing with issues downloading packages in Julia on the cluster, and I narrowed down the issue to the specific package 'DataFrames', which is actually quite a simple package, all it does is allows you to read CSV and other text files. The workaround that I have to do is that I just wrote my code in such a way that does not require the usage of DataFrames which is fine, but I still have a few directories in my research storage that house DataFrames package that I need to be deleted. Specifically, under /umbc/rs/pi_jkestner/users/[USER] I have 2 directories, '.julia' and '.julia_new' both of which need to be deleted as they house the package DataFrame which prevents me from really running anything. I also have the directory '.julia_test' which I am currently using and does work, so it shouldn’t be deleted. I also have another .julia directory under /umbc/rs/pi_jkestner/common that needs to be deleted as well. I have tried running 'rm -rf .julia' for hours on end and it hangs. Even going into the directory itself, following the path, '/umbc/rs/pi_jkestner/users/[USER]/.julia/packages' and then doing 'rm -rf DataFrames' will hang as well. What ended up working on Friday, which was doing 'chmod -R u+wrx DataFrames' hangs as well now too. I have narrowed the issue all the way down to a specific file in DataFrames, it would be in the path '/umbc/rs/pi_jkestner/users/[USER]/.julia/packages/DataFrames/C5AEe/src' which is the source code for this specific package. The file in 'subdataframe' in the source directory is always the issue, which is weird because looking on github, the subdataframe.jl file, with which this is located, looks perfectly fine to me. Regardless, I would still like there to be a way to delete these excess directories in my research storage. Thanks."
"3284012","72080904","2025-10-03 13:44:54","HPC Slurm/Software Issue: sbatch job is not running","Yes, it is working. Thank you.  Best [STAFF] On Fri, Oct 3, 2025, 9:43 AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=[NUMBER]> Last Update From Ticket: Hello, I wanted to follow up to make sure everything is working as expected now. If so, I’ll close out this ticket, but you can always reach back out if you need more help. Best, [STAFF]"
"3284272","72085635","2025-10-03 16:05:31","HPC User Account: [USER] in Student Group","The user account has been created: Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is student. Your home directory has 500M of storage. You can find a short tutorial on how to use chip here: https://[DOMAIN].atlassian.net/wiki/spaces/faq/pages/[PAGEID]/Getting+Started+on+chip Please read through the documentation found at hpcf.[DOMAIN]. [STAFF] has added [USER] to pi_nilanb as a secondary group. Your home directory has additional symbolic links to your group storage space. Please read through the documentation found at hpcf.[DOMAIN]. Please submit additional questions or issues as separate tickets via the following link (https://[DOMAIN]/request-tracker-rt/[TRACKER]). As you can see, [STAFF] added [USER] to both the 'student' group and also added him to pi_nilanb. Let me know if that was an error, and I can remove him from any unnecessary groups. For the 'premium access' question, I'll forward you to [STAFF]. Best, [STAFF]"
"3284322","72056251","2025-10-02 13:28:43","HPC User Account: [USER] in pi_[ID]","Your account has been created: Hi [USER], Your account ([USER]) has been created on [SERVER]. Your primary group is [GROUP]. Your home directory has 500M of storage. You can find a short tutorial on how to use chip here: [URL]. Please read through the documentation found at [URL] > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://[EMAIL]) Let me know if you have any more questions, [STAFF]"
"3284639","72139665","2025-10-07 15:49:45","HPC Other Issue: slurm mem error","Hi [USER] OK I'll keep an eye out. The job asked for 240 processors, which had issues when I started them out but then magically worked fine after doing the unset SLURM_MEM_PER_CPU SLURM_MEM_PER_GPU SLURM_MEM_PER_NODE Last two days I started jobs which asked for 64 cpus, all ran fine! SO like you, I have no idea why this happened. Cheers [STAFF] Hi [USER] I've tried this a few times and am not able to replicate the issue you're having. My first thought was that something was getting set in your files and then not being unset in future runs on the same terminal, but I've tried a few times and am unable to replicate. My runs I did today can be found in the output of CLUST_MAKE_ERA_RTP-442284.out and CLUST_MAKE_ERA_RTP-442245.out. Without being able to replicate the issue there's not much else I can do to debug, as I've looked through your file and didn't see anything that stood out to me. I would advise removing as many of the commented SBATCH directives as possible as it could be reading them in funny unexpected ways, but as a policy, we don't make changes to people's files without their presence so they can confirm the changes that are being made. If you see this pop up again, feel free to reopen this ticket, but for now I'll going to close it. Try it with argument 10 or with argument 4 eg sbatch --array=241-276 sergio_matlab_chip.sbatch 10 The problem is intermittent ie does not happen each time I submit a job. Looking backwards at history,I believe it happened last night with job 435223 - [USER] Hi [STAFF], I added a .err and a .out file location to your sbatch to help with debugging a little bit. First, I must recommend cleaning up all the stray SBATCH directives. There are quite a few that will conflict with each other if you're not careful (see line 45 and 55 in your sbatch file). Second, I ran the sbatch file myself and didn't get the same error you did. Instead, I got [USER@chip-login1 CLUSTMAKE_ERA5]$ cat CLUST_MAKE_ERA_RTP-435429.err Unrecognized function or variable 'clustbatch_make_eracloudrtp_sergio_sarta_filelist'. Which seems to be missing some sort of command. When you run this file are you doing it from the login node? Do you normally have any modules loaded? First Name: [USER] Last Name: [STAFF] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster For some reason the last couple days I have been getting the following error on a script that (I think) has worked for ages on eg taki, now modified for chip srun: fatal: SLURM_MEM_PER_CPU, SLURM_MEM_PER_GPU, and SLURM_MEM_PER_NODE are mutually exclusive. And googling, I finally found a solution on https://harvardmed.atlassian.net/wiki/spaces/O2/pages/1586793613/Troubleshooting+Slurm+Jobs which says at the command line to first do unset SLURM_MEM_PER_CPU SLURM_MEM_PER_GPU SLURM_MEM_PER_NODE Can you look at the following to see if there is a double call to srun or something? /home/[USER]/MATLABCODE/RTPMAKE/CLUST_RTPMAKE/CLUSTMAKE_ERA5/sergio_matlab_chip.sbatch Thanks [USER]"
"3284658","72320184","2025-10-16 12:23:42","Assistance using [ID] HPCF Cluster to run LS Dyna simulations","Hi [USER], I saw the groups were created for the class and the lab. I finally heard back from our licensing team, and it seems like we are unable to install the program that [STAFF] asked for on a system wide scale available for all users. That being said, it's probably possible to install the program for individual users. [USER], have you been added to the class yet? If not I can add you now. If you have, have you taken a shot at installing the program yourself? If you have any issues you can schedule an office hours with our team here: https://hpcf.umbc.edu/help/office-hours/. I'll leave this open for a few days in case there is any questions about it. On Thu Oct 09 12:55:44 2025, [USER] wrote: Just did. One group for class, one for my research lab. On Thu, Oct 9, 2025 at 11:40 AM Max Breitmeyer via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3284658 > Last Update From Ticket: Hi all, Checking in on this. Were you able to submit a group request? On Tue Oct 07 13:04:16 2025, [USER] wrote: This is awesome. I will setup this up after lunch. Thank you immensely Max! On Tue, Oct 7, 2025 at 11:33 AM Max Breitmeyer via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3284658 > Last Update From Ticket: Sorry for the late response to this. We're looking at making this available on our shared resource, but am waiting to hear back about our licenses. In the meantime it might be possible to install these programs in your user directory. What I would like for your professor to do is set up a new group as a class, so if possible have them go here: https://rtforms.umbc.edu/rt_authenticated/doit/DoIT-support.php?auto=Research%20Computing and request a new group under a PI, and in the notes write that this is for the ENME 444 class. Once that's done we can get you on the cluster, and if we still don't know anything about the license, we'll work to try to set up the software for you as an individual. On Thu Oct 02 08:39:49 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID]."
"3285275","72085033","2025-10-03 15:45:44","HPC User Account: [USER] in pi_[ID]","The accounts have been created: Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. You can find a short tutorial on how to use chip here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/). Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. You can find a short tutorial on how to use chip here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/). Let me know if you have any more questions! [STAFF]"
"3285334","72140321","2025-10-07 16:09:58","HPC User Account: [USER] in [STAFF]","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_mkann. Your home directory has 500M of storage. You can find a short tutorial on how to use chip here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) On Thu Oct 02 17:05:48 2025, [STAFF] wrote: Please approve the account for [USER]. Sent from my iPhone > On Oct 2, 2025, at 3:42PM, RT API via RT <[EMAIL]> wrote: This e-mail is a notification that a UMBC user: [USER] <[EMAIL]> has requested an account within UMBC's HPC environment in your group <[STAFF]>. As the PI, we request that you acknowledge and approve this account creation by replying to this message. Alternatively you can go to this link and review the ticket and indicate your decision here: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3285334> Once we have your approval, we will create the account and you and the new user will receive another e-mail notifying you that the account has been created. If you have any other questions or concerns please contact us. - UMBC DoIT Research Computing Support Staff Best, [STAFF] DOIT Unix infra, Graduate Assistant"
"3285426","72087802","2025-10-03 17:25:32","HPC Other Issue: Resource Usage Concern on Shared Compute Node","Thank you for your reply. That makes sense. On Fri Oct 03 10:50:43 2025, [STAFF] wrote: Hello, I understand the concern about shared node performance. However, as long as jobs are submitted within the set limits, they are considered valid and within policy. If we see repeated issues that affect the whole system, we can look at changing the limits. For now, the user is working within their allowed usage. Best, [STAFF]. On Thu Oct 02 16:49:15 2025, [STAFF] wrote: I would like to bring to your attention that one of the users (ID:[USER], see attached) appears to be occupying a significant portion of the compute resources on our shared node. This high usage may impact the efficiency and workflow of other users. Could you please remind this user to be mindful of resource usage and try to avoid monopolizing the node, so that everyone can work more smoothly?"
"3285512","72090698","2025-10-03 19:05:03","HPC User Account: [USER] in pi_[STAFF]","Hi [USER], your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. You can find a short tutorial on how to use chip here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link: (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/)."
"3286322","72107853","2025-10-06 14:39:34","HPC Other Issue: Can [USER] request for a cpu and a gpu using sbatch?","Hi [USER], All nodes on chip have CPUs, as they are required to function. However, nodes on chip-gpu also have GPUs available. So yes, when using chip-gpu you can request both GPUs and CPU cores. You would request this the same way as chip-cpu. For more information about the hardware specification, check out this page: https://[DOMAIN]/wiki/spaces/faq/pages/[ID]/Cluster+Specifications#CPU-and-GPU-Specifications For more information on requesting CPU cores, check out this page: https://[DOMAIN]/wiki/spaces/faq/pages/[ID]/Basic+Slurm+Commands#Jobs%2C-Tasks%2C-CPU-cores%2C-and-Nodes Let me know if you have any additional questions or clarification. -- Kind regards, [STAFF]"
"3286362","72123731","2025-10-06 20:24:14","HPC Other Issue: c24-01 tmp area full","Thanks, interesting suggestion. I solved the problem by going to a different node. [STAFF], Ph.D., Professor of Mathematics Department of Mathematics and Statistics Center for Interdisciplinary Research and Consulting (circ.[DOMAIN]) [DOMAIN] High Performance Computing Facility ([DOMAIN]) REU Site: Online Interdisciplinary Big Data Analytics ([DOMAIN]) University of Maryland, Baltimore County 1000 Hilltop Circle, Baltimore, MD 21250 http://www.[DOMAIN]/~[STAFF] On Mon, Oct 6, 2025 at 10:21 AM [STAFF] via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://[DOMAIN].us2.qualtrics.com/SE/?SID=SV_[ID]&customeremail=[EMAIL]&groupid=EIS&ticketid=3286362&ticketowner=[STAFF]%40[DOMAIN]&ticketsubject=HPC%20Other%20Issue:%20c24-01%20tmp%20area%20full If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=3286362> Thank You Hi [STAFF], Thank you for letting us know. The issue has been resolved. Additionally, if this occurs in the future, you could attempt to change the location that the compiler uses to temporarily store files. I believe this would be achieved by setting the $TMPDIR environment variable. For example, you could try to run... TMPDIR=/scratch/$JOB_ID/ mpiicc -O3 trap.c -o trap -- Kind regards, [STAFF] (she/her/hers) DoIT Unix Infra Student Worker On Sun Oct 05 20:20:51 2025, [USER] wrote: First Name: [STAFF] Last Name: [STAFF] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Hi, This is surely a funky error, but if trying to compile on c24-01 in an interactive session, for Intel MPI, it says [gobbert@c24-01 ver1.0solution]$ mpiicc -O3 trap.c -o trap icx: error #10295: error generating temporary file name, check disk space and permissions A student also reported this to me. The /tmpfs area or something like seems to be full. [STAFF] Original Request: Requestors: [STAFF] First Name: [STAFF] Last Name: [STAFF] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Hi, This is surely a funky error, but if trying to compile on c24-01 in an interactive session, for Intel MPI, it says [gobbert@c24-01 ver1.0solution]$ mpiicc -O3 trap.c -o trap icx: error #10295: error generating temporary file name, check disk space and permissions A student also reported this to me. The /tmpfs area or something like seems to be full."
"3286765","72120417","2025-10-06 19:11:20","HPC Other Issue: Can I get the H100","Hi [USER], Chip is a shared resource. Unless your group has contributed the H100 nodes, access to the node is shared between all of the cluster's users. Normally, your job would run after their job has completed. I suggest waiting until the currently running jobs complete, then your job will run. Or, if your job does not actually require two H100s, you could try to run it on other GPU hardware, such as L40S's or RTX_8000s. There is a greater amount of these nodes available, which would reduce the time it takes for your job to run. Let me know if you have any additional questions. Have a nice day! Kind regards, [STAFF] On Mon Oct 06 12:49:34 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster I've submitted a SLURM job requesting 2 H100 GPUs, but it's currently pending. I'd like to request access to those resources. I'm working with the UMBC-CREM Center. CLUSTER: chip-gpu JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 101669 gpu gemma_fi [USER] PD 0:00 1 (Priority)"
"3286853","72210005","2025-10-10 16:40:56","HPC Other Issue: need authorization in the common directories","The issue should now be resolved. If you continue to have issues with this, feel free to let us know. Have a nice day! Thank you for your help I will talk with [STAFF] to see if I understand the issue, [USER]. Sent from my iPhone  On Oct 10, 2025, at 9:41 AM, [STAFF] via RT <[EMAIL]> wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3286853 Last Update From Ticket: Hi [USER], I have verified again that the permissions for the common directory are correct-- So I do not understand why your students are unable to access the common directory. Please see below where I tested the permissions for the common directory using a student account. Could either you or the student who submitted an additional ticket provide some more information with exactly what you are attempting to do? Thanks [ptembei1@chip-login2 ~]$ pi_mkann_common [ptembei1@chip-login2 common]$ pwd /umbc/rs/pi_mkann/common [ptembei1@chip-login2 common]$ touch test [ptembei1@chip-login2 common]$ ls dbraw downloaded_data Projects test [ptembei1@chip-login2 common]$ -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Thu Oct 09 19:23:10 2025, [USER] wrote: My student still gets access denied when she tried maybe you can see what the problem is, M. Sent from my iPhone On Oct 6, 2025, at 1:57 PM, [STAFF] via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_etfDUq3MTISF6Ly&customere mail=[EMAIL]&groupid=EIS&ticketid=3286853&ticketowner=[STAFF]&ticketsubject=HPC%20Other%20Issue:%20need%20authorization%20in%20the%20common%20directories If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3286853 Thank You R e s o l u t i o n: Hi [USER], I resolved the permission issues with pi_mkann/common. Let me know if you continue to experience errors when accessing that directory. Have a nice day! -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Mon Oct 06 13:41:02 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Hello, I have recently had taki files transfer to chip, could you helps setting up the new common directory so all users in my lab have access and can edit, etc. The way it is now we don't have permissions set up for that. Thanks, [USER]."
"3286959","72129727","2025-10-07 13:27:01","HPC User Account: [ID] in Student Group","Hello there, If you're under [STAFF], if he has an HPC account, he could easily sponsor your account, making things much easier on the cluster. Feel free to join the student group if [STAFF] requested you to do that, however. Anyways, here is the official link (A guide on how to create an HPC account): https://umbc.atlassian.net/wiki/spaces/faq/pages/1327431728/How+to+request+a+user+group+account+on+chip Remember that if [STAFF] is sponsoring your account, we would need written permission from him. That's as simple as cc'ing him to the ticket creation, and having him say 'I approve' or something similar in a reply. Best, [STAFF]"
"3287359","72204785","2025-10-10 14:26:50","HPC Slurm/Software Issue: Module Not Available","All the documentation for these programs are publicly available online. We are able to assist with HPC related issues you encounter along the way, however we are unable to walk you through everything. We mainly provide support with HPC/Slurm related issues, and utilizing all of those modules is a little out of scope. If you have any specific questions to help get started, I can do my best to answer them. Otherwise, I recommend taking a look at the documentation for the modules you requested to utilize them. Thanks! Yes, I loaded CGNS successfully. Now I am not sure how to use all of the modules for my code compilation and run the cases eventually. Could you please help me out with this? Ticket <URL: https://rt.[USER]/Ticket/Display.html?id=[ID]> Last Update From Ticket: I attempted to install CGNS as a custom module. You should be able to load the module with 'module load CGNS/4.5.0'. Can you attempt to load/use the module to verify it works as expected? If you run into issues with the module, let me know. -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Thu Oct 09 12:05:07 2025, [USER] wrote: Hi [USER], You do not need to reinstall the software every time you log in/out. After you compile the software, it is installed to whichever directory of your choosing. From there, all you need to do is add the path to your install directory to your PATH environment variable (or just run the binaries from inside the install directory). The software is not readily supported by the module system, easybuild. There are some ways to possibly working around this, but for most use cases, to ensure compatibility it is recommended to just compile from source. I can take a crack at installing it as a custom module though. Also, could you elaborate on what you mean by 'a bash file so that I don't have to install all of the modules'? All the modules have already been installed, and just need to be loaded using 'module load $MODULE_NAME'. -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Thu Oct 09 11:52:15 2025, [USER] wrote: Hi Danielle, Thank you very much for the update. Couldn't you please load the CGNS also? Because I could be wrong as I am not that much familiar with this chip system yet. My assumption is, if I install it by myself, then I have to do it again and again whenever I enter into the system, and run some cases. Please correct me if I am wrong! And I also need your help to make a bash file so that I don't have to install all of the modules that I need to run my cases every time separately. I need lots of modules to run every single test case of mine. Thanks, [USER] On Thu, Oct 9, 2025 at 11:27 AM [STAFF] via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://[USER].us2.qualtrics.com/SE/?SID=SV_[ID]&customeremail=[EMAIL]&groupid=[GROUP]&ticketid=[ID]&ticketowner=[OWNER]&ticketsubject=[SUBJECT] If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket <URL: https://rt.[USER]/Ticket/Display.html?id=[ID]> Thank You _________________________________________ R e s o l u t i o n: Hi [USER], Yes, I was just about to update this ticket. I installed MPICH versions 4.2.2 and 4.2.1, along with PETSc 3.20.3. For CGNS, I recommend that you compile it from source. The instructions for compiling CGNS from source are located on their github page: https://github.com/CGNS/CGNS. You should be able to load the module with 'module load CGNS/4.5.0'. Can you attempt to load/use the module to verify it works as expected? If you run into issues with the module, let me know. -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Thu Oct 09 11:20:57 2025, [USER] wrote: Hello, Is there any update on the ticket? Thanks, [USER] On Tue, Oct 7, 2025 at 10:15 AM via RT <[EMAIL]> wrote: Greetings, This message has been automatically generated in response to the creation of a ticket regarding: -------------------------------------------------------------- Subject: 'HPC Slurm/Software Issue: Module Not Available' Message: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster Hello, I need MPICH, CGNS, PETSC modules to run my cases on hpcf cluster. But these modules are not available there to load! Could you please load the latest version of these three modules to the cluster and let me know when it's ready? Thanks, [USER] -------------------------------------------------------------- There is no need to reply to this message right now. Your ticket has been assigned an ID of [ID] or you can go there directly by clicking the link below. Ticket <URL: https://rt.[USER]/Ticket/Display.html?id=[ID]> You can login to view your open tickets at any time by visiting http://my.[USER] and clicking on 'Help' and 'Request Help'. Alternately you can click on http://my.[USER]/help Thank you ______________________________________ Original Request: Requestors: [USER] First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster Hello, I need MPICH, CGNS, PETSC modules to run my cases on hpcf cluster. But these modules are not available there to load! Could you please load the latest version of these three modules to the cluster and let me know when it's ready? Thanks, [USER]"
"3287360","72144736","2025-10-07 18:04:47","HPC Slurm/Software Issue: Job Resource Allocation Failing","Seems to be working now. Thank you! On Tue, Oct 7, 2025 at 1:59 PM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Ha, I think you cleared out *too much*. The file '.bashrc' is what's generally in charge of creating your environment. If you just deleted everything in your home directory, it doesn't know how to create your environment. I added it back in with the default set up we create for users in their bashrc and was able to confirm that your environment now looks normal: [jrubins1@chip-login2 ~]$ srun --cluster=chip-gpu --time=01:00:00 --mem=4000 --gres=gpu:1 --cpus-per-task=1 --pty $SHELL srun: job 101868 queued and waiting for resources srun: job 101868 has been allocated resources [jrubins1@g24-01 ~]$ Let me know if you still have issues. On Tue Oct 07 13:08:07 2025, [USER] wrote: Thank you for the quick reply, I cleared out my home directory. [jrubins1@chip-login2 ~]$ df -h /home/jrubins1/ Filesystem Size Used Avail Use% Mounted on nfs.iss:/ifs/data/chip/home/jrubins1 500M 0 500M 0% /home/jrubins1 But when I try and run an interactive session I still have the same issue [jrubins1@chip-login2 ~]$ srun --cluster=chip-gpu --time=01:00:00 --mem=4000 --gres=gpu:1 --cpus-per-task=1 --pty /bin/bash srun: job 101858 queued and waiting for resources srun: job 101858 has been allocated resources bash-5.1$ On Tue, Oct 7, 2025 at 11:24 AM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hi [USER], Your home directory is completely filled which can sometimes cause unexpected things to happen when creating new sessions (like what happens slurm starts a new interactive shell). Please remove some of the stuff from your home directory. If you're still having an issue after that, please let me know. bash-5.1$ df -h /home/jrubins1/ Filesystem Size Used Avail Use% Mounted on nfs.iss:/ifs/data/chip/home/jrubins1 500M 500M 0 100% /home/jrubins1 On Tue Oct 07 10:16:15 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster I was trying to get a conda environment set up, but after running conda create to make one, the next time I started an interactive job (command was: srun --cluster=chip-gpu --time=04:00:00 --mem=40000 --gres=gpu:1 --constraint=rtx_6000 --cpus-per-task=18 --pty /bin/bash) I noticed that instead of putting me into a node like normal, my terminal now says 'bash-5.1$' instead of showing what node I'm on and when I try to run: module load Anaconda3/2024.02-1 I get a note saying: Note: Modules do not function on the login node If I then exit I am returned to the login node and I have to exit again to leave my ssh session."
"3287721","72140988","2025-10-07 16:32:20","HPC User Account: [USER] in oates","Hi [USER], Your account ([STAFF]) has been added to your primary group is pi_[STAFF]. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) On Tue Oct 07 11:56:14 2025, [STAFF]@cs.umbc.edu wrote: I approve. On Tue, 7 Oct 2025, RT API via RT wrote: > This e-mail is a notification that a UMBC user: [USER] <[EMAIL]> has requested an account within UMBC's HPC environment in your group <[STAFF]>. As the PI, we request that you acknowledge and approve this account creation by replying to this message. Alternatively you can go to this link and review the ticket and indicate your decision here: > Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=[NUMBER]> > Once we have your approval, we will create the account and you and the new user will receive another e-mail notifying you that the account has been created. If you have any other questions or concerns please contact us. > - UMBC DoIT Research Computing Support Staff. Best, [STAFF]."
"3287907","72176056","2025-10-09 00:52:09","URGENT: Software Access Policy Hindering Research - Request for Immediate Remote Desktop Access","Excellent! Glad to hear this is working. I'll mark this as resolved -- do reopen if there are related issues. On Wed Oct 08 15:59:49 2025, [STAFF] wrote: The student was able to download the software. Thank you for your help on this matter! I have no further requests. Best, [STAFF] On Tue, Oct 7, 2025 at 3:00 PM [STAFF] <[EMAIL]> wrote: Thank you for your prompt response! I will reach out to the student and update you accordingly. With appreciation, [STAFF] On Tue, Oct 7, 2025 at 2:57 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3287907 > Last Update From Ticket: Hi [STAFF], Could you have your student try this environment? https://elum.in/umbc-desktop-sosc I believe it offers the appropriate access. -- [STAFF] DoIT Research Computing Team"
"3287915","72539085","2025-10-28 19:36:23","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_[STAFF]. The alias used to reach the volume is now pi_[STAFF]_common and pi_[STAFF]_user. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Tue Oct 28 10:49:13 2025, [EMAIL] wrote: Hello [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Fri Oct 17 12:13:50 2025, [EMAIL] wrote: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of October 28th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]."
"3287918","72146122","2025-10-07 18:40:58","Migrating Research Storage Volume to Ceph Cluster - [ID]","Dear [STAFF], As per the communication via myUMBC earlier this summer (June HPCF Newsletter ), DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 0 GB of a 488.3 GB quota on the old storage server. To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at '/umbc/rs/[STAFF]'. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. Below we've listed two options for handling this data migration - please let us know which of these you'd prefer. Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day. Option 2: If you don't respond to this email by October 15th, DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes. Note: After this process has completed, the new storage volume will have a new name. For example, group 'pi_doit' will find its data under '/umbc/rs/pi_doit', or in your group's case you will find your volume under '/umbc/rs/[STAFF]'. Thank you, [STAFF]."
"3287921","72589143","2025-10-29 21:28:31","Migrating Research Storage Volume to Ceph Cluster","Hello again [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/[STAFF]. The alias used to reach the volume is now [STAFF]_common and [STAFF]_user. Your new volume has a quota of 25TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Wed Oct 29 09:47:56 2025, [EMAIL] wrote: Hello [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Fri Oct 17 12:21:16 2025, [EMAIL] wrote: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of October 29th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]."
"3287925","72612748","2025-10-30 23:27:40","Migrating Research Storage Volume to Ceph Cluster - [ID]","Hello [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/[STAFF]. The alias used to reach the volume is now [ALIAS]_common and [ALIAS]_user. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Thu Oct 30 10:33:54 2025, [USER] wrote: Hello [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Fri Oct 17 12:28:50 2025, [USER] wrote: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of October 30th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]."
"3287928","72210852","2025-10-10 17:14:46","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/[STAFF]. The alias used to reach the volume is now [ALIAS] and [ALIAS]. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF] On Tue Oct 07 15:15:59 2025, [EMAIL] wrote: [USER]"
"3287931","72639759","2025-10-31 18:20:24","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/[STAFF]. The alias used to reach the volume is now [ALIAS]_common and [ALIAS]_user. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Fri Oct 31 10:42:15 2025, [USER] wrote: Good morning [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Fri Oct 17 12:49:18 2025, [USER] wrote: Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of October 31st for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]."
"3287935","72352529","2025-10-17 17:10:28","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Dear [USER], as per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 5th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3287940","72397567","2025-10-21 15:52:25","Migrating Research Storage Volume to Ceph Cluster - [ID]","On Tue Oct 21 11:50:01 2025, [USER] wrote: Dear [STAFF], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 6th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF] Dear [STAFF], Thank you for your email and for letting me know. It sounds good to me. Best regards, [USER]"
"3287942","72397526","2025-10-21 15:51:13","Migrating Research Storage Volume to Ceph Cluster - [ID]","Dear [STAFF], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 6th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3287945","72397781","2025-10-21 15:56:02","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 6th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3287949","72397924","2025-10-21 15:58:29","Migrating Research Storage Volume to Ceph Cluster - [ID]","Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 7th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3287950","72210894","2025-10-10 17:15:32","Migrating Research Storage Volume to Ceph Cluster - [ID]","Hello [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_[USER]. The alias used to reach the volume is now pi_[USER]_common and pi_[USER]_user. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]"
"3287957","72398525","2025-10-21 16:04:53","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Yes, please proceed. [STAFF] [TITLE], Center for Accelerated Real Time Analytics (CARTA) Professor, Information Systems Department ITE 424, UMBC [PHONE NUMBER] [EMAIL] On Tue, Oct 21, 2025 at 12:02 PM [USER] via RT <[UMBCHelp EMAIL]> wrote: Ticket [URL: https://rt.umbc.edu/Ticket/Display.html?id=3287957 ] Last Update From Ticket: Dear [STAFF], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 10th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [USER]"
"3287959","72398124","2025-10-21 16:03:03","Migrating Research Storage Volume to Ceph Cluster","Dear [STAFF], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 10th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3287961","72398297","2025-10-21 16:04:01","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Dear [USER], as per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 10th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3287965","72527039","2025-10-28 14:35:37","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Ticket [TICKET_URL] Comment just added. Hello, Yes, the data you currently have will be moved to '/umbc/rs/pi_[USER]'. Looking at your storage personally, apologies, it seems our estimate was off, it seems your pi actually has around 69 GB used in '/umbc/rs/[USER]', and will be moved to '/umbc/rs/pi_[USER]'. No worries, the transfer process will still be very quick. Best, [STAFF]"
"3287967","72731652","2025-11-04 20:25:12","Migrating Research Storage Volume to Ceph Cluster","Thanks a lot for the update I saw that some additional disk has been allocated to our disk partition I really appreciate it Hopefully the migration process can finish soon and successfully  On Tue Nov 4 2025 at 10 18 AM [STAFF] via RT <[EMAIL]> wrote Ticket Last Update From Ticket Hello [USER] The migration is still moving along thankfully and I can confirm that your new volume was almost full The Ceph storage server may have some slight differences in how it compresses and de-duplicates data which would be the most likely reason why the storage usage number is different from what was on the old server On your old storage volume your group was using 486TB out of a 505TB quota - we will make sure you have at least 20TB of free space on the new storage server when the migration completes Please let me know if you have any more questions or concerns Best [STAFF] On Tue Nov 04 09 33 10 2025 [USER] wrote Hi [STAFF] I just check the new storage volume located at /umbc/rs/[VOLUME NAME] and it seems to be working fine However I noticed that some of my data is missing Can you please look into this issue and let me know what happened to my data Thanks [USER] On Tue Oct 07 21 29 13 2025 [USER] wrote Hi [STAFF] We will choose option 1 Schedule a group-wide downtime date during standard business hours which can be done by responding to this email with your preferred date(s) to perform the migration During this time DoIT staff will work to migrate your volume to the Ceph storage cluster DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed For most storage volumes this process should take less than a business day [USER] On Tue Oct 07 21 29 13 2025 via RT <[EMAIL]> wrote Greetings This message has been automatically generated in response to the creation of a ticket regarding Migrating Research Storage Volume to Ceph Cluster - [VOLUME NAME] Dear [USER] As per the communication via myUMBC earlier this summer June HPCF Newsletter DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster Your group is using 458 94 TB of a 505 0000 TB quota on the old storage server To perform these migrations we need to take individual storage volumes offline while we migrate them to the Ceph cluster Thus we are reaching out to schedule a date where we can migrate your volume located at /umbc/rs/[VOLUME NAME] During the migration we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume Below we’ve listed two options for handling this data migration - please let us know which of these you’d prefer Option 1 Schedule a group-wide downtime date during standard business hours which can be done by responding to this email with your preferred date(s) to perform the migration During this time DoIT staff will work to migrate your volume to the Ceph storage cluster DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed For most storage volumes this process should take less than a business day Option 2 If you don’t respond to this email by October 15th DoIT staff will assign a day over the following month October 16th through November 15th to migrate your volume The day chosen will be random and will occur during business hours You will be notified of the date chosen to perform the migration and will be notified when the migration begins and completes Note After this process has completed the new storage volume will have a new name For example group “pi_doit” will find its data under /umbc/rs/pi_doit or in your group’s case you will find your volume under /umbc/rs/[VOLUME NAME] Thank you [STAFF]"
"3287969","72207457","2025-10-10 15:31:13","Migrating Research Storage Volume to Ceph Cluster","I'll look into this and try and resend the email. Cc'ing [STAFF] to this ticket for updates."
"3287971","72301642","2025-10-15 14:16:57","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Hello [USER], We have finished migrating your volume to the Ceph cluster. As far as we can tell everything seems to have gone smoothly. There are a few things to note: The path has changed, and is now available under /umbc/rs/pi_[USER]. The alias used to reach the volume is now pi_[USER]_common and pi_[USER]_user. Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF]. On Wed Oct 15 09:44:38 2025, [EMAIL] wrote: Hello [USER], I was out yesterday, so I will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF]. On Mon Oct 13 11:42:33 2025, [EMAIL] wrote: Dear [USER], I will be away Tues and Wed, so that would be the optimal time to execute the change. However, I do not think that the move would affect any of my ongoing projects at any time over the next month. So, I leave it to your discretion to schedule. Please keep me apprised. [USER]. On 10/7/25 3:25 PM, via RT wrote: Greetings, This message has been automatically generated in response to the creation of a ticket regarding: Subject: 'Migrating Research Storage Volume to Ceph Cluster - pi_[USER]' Message: Dear [USER], As per the communication via myUMBC earlier this summer (June HPCF Newsletter), DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 0 GB of a 48.8 GB quota on the old storage server. To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at '/umbc/rs/kturpie'. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. Below we've listed two options for handling this data migration - please let us know which of these you'd prefer. Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day. Option 2: If you don't respond to this email by October 15th, DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes. Note: After this process has completed, the new storage volume will have a new name. For example, group 'pi_doit' will find its data under '/umbc/rs/pi_doit', or in your group's case you will find your volume under '/umbc/rs/pi_[USER]'. Thank you, [STAFF]."
"3287973","72452396","2025-10-23 14:20:25","Migrating Research Storage Volume to Ceph Cluster - [ID]","Dear [STAFF], As per our previous communications, since [USER] did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for [USER]'s migration. We have assigned the date of November 14th for [USER]'s migration. Let us know if there is a better day for [USER], and within reason, we can reschedule that date. [USER] will be notified when the migration begins and completes. Thank you, [STAFF]."
"3287979","72452299","2025-10-23 14:18:38","Migrating Research Storage Volume to Ceph Cluster - [ID]","Dear [USER], as per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 14th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]."
"3288361","72318376","2025-10-16 01:37:55","HPC Other Issue: [USER] access to chip?","Yes, she has! Thanks for checking!  [STAFF] (she/her/hers) Associate Professor Department of Biological Sciences University of Maryland, Baltimore County [ADDRESS] Office: +1 ([PHONE NUMBER]) [WEBSITE] On Wed, Oct 15, 2025, 1:08 PM [USER] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=[NUMBER]> Last Update From Ticket: Hi [STAFF], Just checking in, was your student able to access the cluster? On Fri Oct 10 11:46:59 2025, [USER] wrote: Please do! I'll also ask that you submit an RT ticket to formally add the student to your group (https://rtforms.umbc.edu/rt_authenticated/doit/DoIT-support.php?auto=Research Computing). I looked into the VPN issue, and it seems like the student should be fine as long as they install the vpn. Once they're added we'll test it out and see what happens from there. On Thu Oct 09 16:26:28 2025, [USER] wrote: OK! I've just received notice that the student's affiliation has been reinstated; her name is [USER] and her ID# is [ID NUMBER]. She should have access through 6/30/2026. What would be the next step for allowing her to access my lab's volume on chip? Should I direct her to download the VPN too? On Thu, Oct 9, 2025 at 11:55 AM [USER] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=[NUMBER]> Last Update From Ticket: Hi [STAFF], Typically we don't allow for users into UMBC services if they are not in North America (even with VPN). That being said, we can make some exceptions to this rule. For now start by sponsoring an account for the student (information for that can be found here: https://umbc.atlassian.net/wiki/spaces/faq/pages/30739140/How+do+I+request+myUMBC+accounts+for+non-UMBC+users+Create+a+Sponsored+Account), and we'll go from there. On Wed Oct 08 11:01:26 2025, [USER] wrote: First Name: [STAFF] Last Name: [STAFF] Email: [EMAIL] Campus ID: [ID NUMBER] Request Type: High Performance Cluster Hello, I have a Brazilian graduate student on fellowship, [USER], who generated a large genomic dataset while working in my lab, and who now is trying to analyze this dataset using the program Stacks. She has submitted jobs to servers at her home institution of U Sao Paolo and the UK school where her fellowship continued, but they haven't been running due to timeouts and/or job backlogs. She would like to access chip via my lab's login, but we have a couple of questions about this. 1) Is this allowed? My lab has tried to access chip while abroad but was unsuccessful, but this may have been because the hotel internet was slow. I know the GlobalProtect VPN would probably need to be downloaded too. 2) Can I create a log-in for her? She was assigned a UMBC account while working here in 2023, but I assume that has lapsed. Thank you for the help!"
"3288390","72207384","2025-10-10 15:28:16","Utilizing matched nodes on chip-cpu","Hello To run a job across 12 nodes, you can submit a job to the contrib partition and request 12 nodes. SLURM will allocate your 6 dedicated nodes first (--nodelist=c24-[14-19]) and then fill the remaining slots from available match nodes. Here's an example sbatch script you can use: #SBATCH --cluster=chip-cpu #SBATCH --mem=5000M #SBATCH --time=01:00:00 #SBATCH --account=pi_[STAFF] #SBATCH --partition=contrib #SBATCH --nodes=12 #SBATCH --qos=shared #SBATCH --nodelist=c24-[14-19] Let us know if that doesn't work. On Wed Oct 08 11:26:08 2025, [USER] wrote: From [STAFF]: 'We need to help to understand how the PI partitions are working in Chip. When I look at the pi_[STAFF], I can see that we have nodes 14 to 19 (6 in total) assigned to it. But I should have access also to the +6 additional nodes from the matching funding, right? How can we use these additional nodes? We will have to run some very large simulations, which will require using all 12 nodes at once. We don't know how to queue such a job, since my partition only shows 6 nodes.' -- [STAFF] DOIT Research Computing Team"
"3288602","72189897","2025-10-09 17:20:23","HPC Other Issue: [USER] cannot log into chip","Hi [USER], I just wanted to give you an update regarding the status of chip. Access to the cluster was restored yesterday afternoon, and access to ada volumes have also been restored. For more information, please check out the myUMBC post: https://my3.my.umbc.edu/groups/hpcf/posts/153425 -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Wed Oct 08 14:43:59 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] Request Type:              High Performance Cluster Completely Hangs after Last login : Wed Oct 8 ......"
"3288614","72189864","2025-10-09 17:19:20","HPC Other Issue: Unable to connect to chip","Hi [USER], I just wanted to give you an update regarding the status of chip. Access to the cluster was restored yesterday afternoon, and access to ada volumes have also been restored. For more information, please check out the myUMBC post: https://my3.my.umbc.edu/groups/hpcf/posts/153425 -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Wed Oct 08 16:00:52 2025, [EMAIL] wrote: Nilanjana"
"3288634","72189966","2025-10-09 17:21:27","HPC Other Issue: Unable to access login shell after connecting to chip.rs.umbc.edu","Hi [USER], I just wanted to give you an update regarding the status of chip. Access to the cluster was restored yesterday afternoon, and access to ada volumes have also been restored. For more information, please check out the myUMBC post: https://my3.my.umbc.edu/groups/hpcf/posts/153425. -- Kind regards, [STAFF]. On Thu Oct 09 12:13:04 2025, [USER] wrote: I appreciate your clarification~. On Wed Oct 08 16:03:51 2025, [USER] wrote: Hello [USER], Our team is aware of the issue, and we are working on resolving this at the moment. We understand the inconvenience this may cause you, but we will send an update once this issue has been fixed. Best regards, [STAFF]."
"3288676","72189880","2025-10-09 17:19:49","HPC Slurm/Software Issue: SSH Connection Hanging","Hi [USER], I just wanted to give you an update regarding the status of chip. Access to the cluster was restored yesterday afternoon, and access to ada volumes have also been restored. For more information, please check out the myUMBC post: https://my3.my.umbc.edu/groups/hpcf/posts/153425 Have a nice day! -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Wed Oct 08 15:55:51 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Good afternoon, When I ssh into chip.rs.umbc.edu, I am able to be successfully logged in. However, the connection just hangs there without presenting a shell prompt afterwards. Is there any way I could resolve this issue? This happens when I try to use putty and my windows powershell."
"3288709","72189922","2025-10-09 17:20:47","HPC Slurm/Software Issue: Can't log in","Hi [USER], I just wanted to give you an update regarding the status of chip. Access to the cluster was restored yesterday afternoon, and access to ada volumes have also been restored. For more information, please check out the myUMBC post: https://my3.my.umbc.edu/groups/hpcf/posts/153425 Kind regards, [STAFF] On Wed Oct 08 16:26:02 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster I cant log in to chip"
"3288849","72187131","2025-10-09 15:58:20","HPC Slurm/Software Issue: ADA storage","Hi [USER], Thanks for your patience and understanding. The Ada volume are back! https://my3.my.umbc.edu/groups/hpcf/posts/153425 On Wed Oct 08 23:32:33 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [ID] Request Type:              High Performance Cluster I know the ada storage is not working and its under maintenance. But do you have any timeframe on how much time it will take? My all experiment data is stored in ada, so i cant work on rs without access to that data. Thanks for your understanding. Best, [STAFF]"
"3288952","72398956","2025-10-21 16:10:21","Migrating Research Storage Volume to Ceph Cluster - [ID]","Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 11th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3288957","72450993","2025-10-23 13:51:15","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 14th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3288960","72452058","2025-10-23 14:12:36","Migrating Research Storage Volume to Ceph Cluster - [ID]","Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 14th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3288964","72451669","2025-10-23 14:06:28","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Dear [STAFF], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 14th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3288965","72450932","2025-10-23 13:50:09","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Dear [USER], as per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 14th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]."
"3288967","72527248","2025-10-28 14:40:05","Migrating Research Storage Volume to Ceph Cluster - knacc1","Hi, No worries, you don't have to migrate anything; this is all on our end. We're just letting you know what day we're doing it, so you don't use the cluster that day. Yes, you have almost no data on the cluster. I expect the migration to take almost no time at all. The only thing you have to do is not use the cluster on November 14th, and you'll be all set. Best, [STAFF]"
"3288968","72452016","2025-10-23 14:11:53","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Dear [STAFF], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 14th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3288973","72451242","2025-10-23 13:55:50","Migrating Research Storage Volume to Ceph Cluster - [ID]","Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 14th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3288975","72398908","2025-10-21 16:09:26","Migrating Research Storage Volume to Ceph Cluster - [ID]","Dear [STAFF], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 11th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3288979","72399083","2025-10-21 16:12:43","Migrating Research Storage Volume to Ceph Cluster - [ID]","Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 12th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3288980","72399594","2025-10-21 16:20:21","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Dear [STAFF], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 14th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3288982","72399670","2025-10-21 16:21:27","Migrating Research Storage Volume to Ceph Cluster - [ID]","Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 14th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3288983","72399720","2025-10-21 16:22:17","Migrating Research Storage Volume to Ceph Cluster - [ID]","Dear [STAFF], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 14th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3288987","72451147","2025-10-23 13:54:18","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 14th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3288988","72451198","2025-10-23 13:55:08","Migrating Research Storage Volume to Ceph Cluster","Dear [STAFF], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 14th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3288991","72451583","2025-10-23 14:04:39","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Dear [STAFF], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 14th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3288993","72464521","2025-10-23 19:01:22","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","That is fine. Thank you for letting me know. Best Regards, [USER]. On Thu, Oct 23, 2025 at 10:07 AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.[DOMAIN]/Ticket/Display.html?id=[ID] > Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 14th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3288998","72452211","2025-10-23 14:17:11","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 14th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3289003","72207416","2025-10-10 15:29:16","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Ticket  Comment just added. I'll also mark him as 'Special Case' in the spreadsheet"
"3289011","72527475","2025-10-28 14:42:59","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Ticket [ID] Comment just added. Hi, No worries, no meeting of any kind. The only thing you have to do is not use the cluster on Nov. 14, and we'll do the migration for you. Best, [STAFF]"
"3289012","72451285","2025-10-23 13:56:44","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Dear [USER], As per our previous communications, since you did not schedule a date by October 15, we will be going with Option 2, randomly assigning a date between October 16 and November 15 for your migration. We have assigned the date of November 14th for your migration. Let us know if there is a better day for you, and within reason, we can reschedule that date. You will be notified when the migration begins and completes. Thank you, [STAFF]"
"3289018","72336371","2025-10-16 19:09:44","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","That's okay, take your time with checking out your volume. I hope you get well soon! Best, [STAFF] On Thu Oct 16 15:05:22 2025, [USER] wrote: Hi [STAFF], Thanks for the message. I'll do that next week as I am unwell right now. [USER] On Wed, Oct 15, 2025 at 10:16 AM via RT [EMAIL] wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3289018> Last Update From Ticket: Hello [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: > * The path has changed, and is now available under /umbc/rs/pi_[USER]. > * The alias used to reach the volume is now pi_[USER]_common and pi_[USER]_user. > * Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF] On Wed Oct 15 09:53:44 2025, [STAFF] wrote: > Good morning [USER], > This is a reminder that we will be migrating your group's research storage volume to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. > We will provide an update once completed. > Best, [STAFF] On Thu Oct 09 14:14:50 2025, [STAFF] wrote: >> Hello [USER], >> Sounds good, I've put your group's migration on our schedule for Wednesday October 15th. We will send you an email alert via this RT ticket when we begin the migration, and again once it has completed. >> Please let me know if you have any questions or concerns. >> Best, [STAFF] On Thu Oct 09 13:45:18 2025, [USER] wrote: >>> Hello, The needed migration can be done sometime next week (Oct 15, 16,17); any or some of those would work fine with me. Thanks [USER]"
"3289025","72549278","2025-10-29 13:46:59","Migrating Research Storage Volume to Ceph Cluster - [ID]","I've updated my files with the new file path and run a couple of them. Things seem to be working fine as far as I can tell.  Thanks and good luck with the rest of the migration process! [USER] On Tue, Oct 28, 2025 at 3:37 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3289025> Last Update From Ticket: Hello [USER], We have finished migrating your volume to the Ceph cluster! As far as we can tell everything seems to have gone smoothly. There are a few things to note: * The path has changed, and is now available under /umbc/rs/pi_[USER]. * The alias used to reach the volume is now pi_[USER]_common and pi_[USER]_user. * Your new volume has a quota of 10TB. When you have a chance, could you try running some jobs on Chip using the new volume to verify everything looks good? Thank you, [STAFF] On Tue Oct 28 10:49:40 2025, [STAFF] wrote: Hello [USER], This is a reminder that we will be performing your group's migration to the Ceph storage cluster today. During this time, please ensure there are not any jobs being run in your research group, otherwise these may be terminated. We will provide an update once completed. Best, [STAFF] On Thu Oct 09 11:54:13 2025, [STAFF] wrote: Hello [USER], Sounds good, I've put your group's migration on our schedule for October 28th. We will send you an email alert via this RT ticket when we begin the migration, and again once it has completed. Please let me know if you have any questions or concerns. Best, [STAFF] On Thu Oct 09 11:31:27 2025, [USER] wrote: October 28 would be great. Or Oct 29 if that isn't possible. Thanks! Greetings, This message has been automatically generated in response to the creation of a ticket regarding: Subject: 'Migrating Research Storage Volume to Ceph Cluster - pi_[USER]' Message: Dear [USER], As per the communication via myUMBC earlier this summer (June HPCF Newsletter), DoIT is in the process of migrating data off of an older storage server to our new RRStor Ceph storage cluster. Your group is using 502.9 GB of a 488.3 GB quota on the old storage server. To perform these migrations, we need to take individual storage volumes offline while we migrate them to the Ceph cluster. Thus we are reaching out to schedule a date where we can migrate your volume located at “/umbc/rs/[USER]”. During the migration, we will take your volume offline and will terminate any jobs running on the chip compute cluster that are accessing this volume. Below we’ve listed two options for handling this data migration - please let us know which of these you’d prefer. Option 1: Schedule a group-wide downtime date during standard business hours, which can be done by responding to this email with your preferred date(s) to perform the migration. During this time, DoIT staff will work to migrate your volume to the Ceph storage cluster. DoIT staff will send an email alert on this email thread when the migration has begun and when it has completed. For most storage volumes, this process should take less than a business day. Option 2: If you don’t respond to this email by October 15th, DoIT staff will assign a day over the following month (October 16th through November 15th) to migrate your volume. The day chosen will be random and will occur during business hours. You will be notified of the date chosen to perform the migration, and will be notified when the migration begins and completes. Note: After this process has completed, the new storage volume will have a new name. For example, group “pi_doit” will find its data under “/umbc/rs/pi_doit”, or in your group’s case you will find your volume under “/umbc/rs/pi_[USER]”. Thank you, [STAFF]"
"3289155","72396333","2025-10-21 15:27:18","HPC New Group: [ID]","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[USER]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) Welcome to chip, UMBC's High Performance Computing Cluster! The group, pi_[USER], now exists on the chip cluster. Members of this group can access and contribute to the research storage space allocated to the group. This storage space is located at /umbc/rs/pi_[USER], and currently has a quota of 25T. For information on accessing the cluster, adding accounts to your group, and getting started using the cluster, check out the tutorial on our wiki: https://umbc.atlassian.net/wiki/x/R4BPQg Additional documentation is also available here: https://umbc.atlassian.net/wiki/x/FwCHQ If you have any questions or issues, please submit a new RT ticket at: https://doit.umbc.edu/request-tracker-rt/doit-research-computing/ Account creation for users: Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[USER]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) Let me know if you have any more questions! [STAFF]"
"3289186","72188998","2025-10-09 16:54:34","Start a new group under [STAFF]","First Name: [USER] Last Name: [STAFF] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: Help with something else I’d like to start two new groups. 1) for a class “ENME444 - Mechanical Engineering Capstone Design” 2) my research group “eMACS Lab” Thank you"
"3289187","72191668","2025-10-09 18:11:12","Start a new group under a [STAFF]","Hi [USER], I created two groups for you, along with an account for your user. First, Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[USER]. Your home directory has 500M of storage. You can find a short tutorial on how to use chip here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Secondly, The group pi_[USER] now exists on the chip cluster. Members of this group can therefore access and contribute to the research storage space allocated to the group. This storage is located at /umbc/rs/pi_[USER] and currently has a quota of 25T. And lastly, The group [GROUPNAME] now exists on the chip cluster. Members of this group can therefore access and contribute to the research storage space allocated to the group. This storage is located at /umbc/class/[GROUPNAME] and currently has a quota of 5T. Please review documentation on the hpcf.umbc.edu website. Submit any questions or issues as separate RT Tickets at: https://doit.umbc.edu/request-tracker-rt/doit-research-computing/. Feel free to let us know if you encounter any issues with either of your groups! Have a good day! -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Thu Oct 09 12:54:38 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: Help with something else I’d like to start two new groups. 1) for a class “[CLASSNAME]” 2) my research group “eMACS Lab” Thank you"
"3289431","72211306","2025-10-10 17:33:55","HPC Other Issue: Users lack global access in the common directory in [ID] lab space on CHIP","It works for me now. Thank you so much for your help. Best, [USER]. On Fri, Oct 10, 2025 at 12:36 PM [STAFF] via RT <[EMAIL]> wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3289431 Hi [USER], When you have a chance, try again. It should all be working now. Let me know if it works as expected! -- Kind regards, [STAFF] DoIT Unix Infra Student Worker. On Fri Oct 10 11:33:35 2025, [USER] wrote: Hi [STAFF], I just tried again and attached a screenshot of my attempt. I’m able to create and work freely within folders that I created inside the common directory. However, I can’t perform any operations in subfolders within common that I didn’t create. For example, the folder downloaded_data was created by my PI, Dr. [USER]. To illustrate the issue, I tried creating a test folder within downloaded_data, but I was denied permission. I also tried moving some data into a subfolder within downloaded_data and received the same error. Everything works fine when I’m working within folders I created myself in common. This is what I mean by a global access issue in the common directory. Best, [USER]. On Fri, Oct 10, 2025 at 9:37 AM [STAFF] via RT <[EMAIL]> wrote: Ticket https://rt.umbc.edu/Ticket/Display.html?id=3289431 Hi [USER], Students in your group do have access to the common directory of the research volume. I have tested permissions with multiple student accounts, and there are no issues with the common directory. Please share exactly what you are attempting to do, and what directory you are in. Please see below: [ptembei1@chip-login2 ~]$ pi_mkann_common [ptembei1@chip-login2 common]$ pwd /umbc/rs/pi_mkann/common [ptembei1@chip-login2 common]$ touch test [ptembei1@chip-login2 common]$ ls dbraw downloaded_data Projects test [ptembei1@chip-login2 common]$ -- Kind regards, [STAFF] DoIT Unix Infra Student Worker. On Thu Oct 09 18:22:47 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID]. Request Type: High Performance Cluster. I work in Dr. [USER]’s lab, where we collaborate using shared directories. Without global rwx access to the common directory, we’re unable to move files, create subdirectories, or delete files that are no longer needed in directories created by other users. We would really appreciate your help with this."
"3289503","72214706","2025-10-10 19:14:02","HPC User Account: [ID] in Center for Navigation, Timing & Frequency Research","Hi [USER], Your account ([STAFF]) has been created on chip.rs.umbc.edu. Your primary group is pi_menyuk. Your home directory has 500M of storage. You can find a short tutorial on how to use chip here: https://[EMAIL]/wiki/spaces/faq/pages/[NUMBER]/Getting+Started+on+chip Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://[EMAIL]/request-tracker-rt/[EMAIL]-research-computing/) Let me know if you have any more questions, [STAFF]"
"3289659","72223269","2025-10-12 20:10:29","RCD Consult: Deep Lab Cut","Thanks [STAFF]! I have submitted a group request. Please let me know if you need additional information. Thanks, [USER]. On Fri, Oct 10, 2025 at 1:08PM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hi [USER], First we'll have you start by putting a group request. Documentation on how to do that can be found here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1219461147/Connecting#Requesting-a-User-Account-on-chip, with a link to the RT form to request a group being found here: https://rtforms.umbc.edu/rt_authenticated/doit/DoIT-support.php?auto=Research+Computing. Additionally, once you've been set up on the cluster, there is a getting started tutorial that can be found here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip. If you have trouble with any of the above let me know and we can walk through it. On Fri Oct 10 10:18:16 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID]. Request Type: Research Computing & Data Consultation. Good Morning, I am a Prof in the Math/Stat department. My area of research is not high performance computing, but I am working on a project that may need access to a machine with GPUs. We need to use software called Deep Lab Cut https://deeplabcut.github.io/DeepLabCut/docs/installation.html to analyze experimental data. As I understand it, the first step is to use Deep Lab Cut on a laptop to recreate an *.eml file. That file would then be used within a batch job on a GPU computer to generate other files. I have two undergraduate students who will be working on this project. I am also collaborating with a postdoc at JHU. I am not sure where to begin, which is why I am submitting this request. Thanks, [USER]."
"3289689","72216003","2025-10-10 19:52:19","HPC New Group: [ID]","Hi [USER], Welcome to chip, UMBC's High Performance Computing Cluster! The group, [GROUPNAME], now exists on the chip cluster. Members of this group can access and contribute to the research storage space allocated to the group. This storage space is located at /umbc/rs/[GROUPNAME], and currently has a quota of 10TB. For information on accessing the cluster, adding accounts to your group, and getting started using the cluster, check out the tutorial on our wiki: https://umbc.atlassian.net/wiki/x/R4BPQg. Additional documentation is also available here: https://umbc.atlassian.net/wiki/x/FwCHQ. Submit any questions or issues as separate RT tickets at: https://doit.umbc.edu/request-tracker-rt/doit-research-computing/. Kind regards, [STAFF]. On Fri Oct 10 10:47:09 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Group Type: Project Title: Sampling strategy and design for Chesapeake Bay habitat assessment Project Abstract: The Chesapeake Bay has had a large monitoring program for water quality for the last four decades. Given the advancement of continuous monitoring infrastructure, recent studies pointed to the high values of small numbers of in-situ monitoring stations with high temporal frequency to provide a sound basis for water quality assessment. In addition, a coupling of on-shore and off-shore monitoring can further inform the habitat assessment. This study will couple big data from hydrodynamic models to evaluate the monitoring strategies that incorporate novel continuous in-situ monitoring technologies. The computing needs involve storage of large NetCDF files generated from a high-resolution hydrodynamic model covering the Chesapeake Bay, as well as Monte Carlo simulations to evaluate a large collection of potential sampling scenarios."
"3289693","72329932","2025-10-16 17:12:44","HPC New Group: [USER]","Hi [STAFF], Welcome to chip, UMBC's High Performance Computing Cluster! The group, pi_[USER]2, now exists on the chip cluster. Members of this group can access and contribute to the research storage space allocated to the group. This storage space is located at /umbc/rs/pi_[USER]2, and currently has a quota of 10T. For information on accessing the cluster, adding accounts to your group, and getting started using the cluster, check out the tutorial on our wiki: [URL]. Additional documentation is also available here: [URL]. If you have any questions or issues, please submit a new RT ticket at: [URL]. -- Kind regards, [STAFF] On Tue Oct 14 16:14:47 2025, [EMAIL] wrote: Leveraging HPC Resources to Accelerate LiDAR and Remote Sensing Workflows"
"3289694","72327037","2025-10-16 15:32:18","HPC New Group: pi_[ID]","Hi [USER], Welcome to chip, UMBC's High Performance Computing Cluster! The group, pi_[USER], now exists on the chip cluster. Members of this group can access and contribute to the research storage space allocated to the group. This storage space is located at /umbc/rs/pi_[USER], and currently has a quota of 10T. For information on accessing the cluster, adding accounts to your group, and getting started using the cluster, check out the tutorial on our wiki: https://umbc.atlassian.net/wiki/x/R4BPQg Additional documentation is also available here: https://umbc.atlassian.net/wiki/x/FwCHQ If you have any questions or issues, please submit a new RT ticket at: https://doit.umbc.edu/request-tracker-rt/doit-research-computing/ Project title: Deep Structural Feature Extraction from Maize Proteins and Gene Sequences Using DNA Language Models Abstract: Understanding the relationship between the maize (Zea mays) genome and its corresponding protein structures remains a major challenge in computational biology. This project applies advanced machine learning approaches to analyze large-scale maize gene and protein sequence data, aiming to uncover novel structural and functional insights encoded within DNA. We propose to develop and implement a DNA language model trained on maize genomic sequences to learn biologically meaningful representations that capture the intrinsic syntax and semantics of DNA. These learned embeddings will be integrated with our custom k-mer distance–based model and deep neural architectures to predict tertiary structural and physicochemical features directly from gene and protein sequences. The large-scale data processing, model training, and structural mapping tasks require access to GPU-enabled high-performance computing (HPC) resources with distributed processing capabilities. This project is conducted in collaboration with the Maize Genetics and Genomics Database (MaizeGDB), USDA-ARS, Corn Insects and Crop Genetics Research Unit, Iowa State University, Ames, IA, leveraging their extensive maize genomic and proteomic datasets. Expected outcomes include (1) novel computational methods for extracting structural features from biological sequences, (2) deeper understanding of gene-to-structure relationships in maize, and (3) new machine learning tools to support functional genomics and crop improvement research within the MaizeGDB community. Please let me know if you have any questions. Thank you, [STAFF] Kind regards, [STAFF] DoIT Unix Infra Student Worker"
"3289695","72638112","2025-10-31 17:48:54","HPC New Group: [ID]","Hi [USER], An account was created for [STAFF] at the time the group was created. They should be able to follow the log in instructions located on our wiki to connect to the cluster. Please find documentation for that at this link: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip#Accessing-chip Additionally, the broken link has been fixed, here is the corrected link: https://rtforms.umbc.edu/rt_authenticated/doit/DoIT-support.php?auto=Research%20Computing Have a nice day! Kind regards, [STAFF] On Thu Oct 30 10:27:39 2025, [EMAIL] wrote: Good morning, Can you kindly create an account for [STAFF] for this group? From the information provided, I see a group was created, but I do not see any account for her. The link https://doit.umbc.edu/request-tracker-rt/doit-research-computing/ is broken. Thanks. Sincerely, [USER] On Thu Oct 16 12:16:29 2025, [EMAIL] wrote: Greetings, Please find attached the projects title and abstract."
"3289729","72207588","2025-10-10 15:34:14","Migrating Research Storage Volume to Ceph Cluster - [STAFF]","Ticket [ID] Comment just added. Cc'ing myself to this ticket, in case there's any more problems"
"3289747","72214552","2025-10-10 19:07:35","HPC User Account: [USER] in Student Group","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_burnsm. Your home directory has 500M of storage. You can find a short tutorial on how to use chip here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) Let me know if you have any more questions! [STAFF]"
"3289785","72209705","2025-10-10 16:32:34","HPC User Account: [USER] in misc-lab","First Name: [USER] Last Name: [STAFF] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster Create/Modify account in existing PI group Existing PI Email: [EMAIL] Existing Group: misc-lab Project Title: Misc Lab Project Abstract: group for the Misc Lab requesting new PI group"
"3289788","72209865","2025-10-10 16:36:53","create new HPC [USER] group","First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: Help with something else group name: misc-lab list of members: [EMAIL]"
"3290086","72268108","2025-10-14 17:31:42","HPC Other Issue: Not able to connect to JupyterLab on Chip","I identified two nodes (c21-15 and c21-16) that had a missing symbolic link in /usr/ebuild/installs. This is what likely prevented you from finding the jupyter-lab binaries. It has now been resolved, so you shouldn't experience issues now. I will close this ticket now, however if you do encounter another issue, feel free to submit a new ticket. Have a nice day! On Mon Oct 13 23:11:20 2025, [USER] wrote: Hi [STAFF], I have seen this error a few times, but I did not note the node on which it occurred. I will do that the next time I notice it. You are right about 'some of the more recent .err/.out files in the working directory ... running fine recently.' I actually restarted my machine, and SSHed into CHIP again, and got it to run. It could very well be a node issue. In the meantime, please keep the ticket open so that we can address the issue the next time it pops up. For the Office Hours tomorrow, if I still don't observe the same issue, I was wondering if we can do it anyway to discuss a new thing I'm trying to do - open two jupyter notebooks on chip (through two tunnels) using a single jupyter.slurm file from a single folder. Is that possible? Or do we need two jupyter.slurm files for that? Thank you. On Mon, Oct 13, 2025 at 12:36 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL> Last Update From Ticket: Hi [USER], Based on the error you attached as a screenshot, it appears that the system was unable to find the binary for jupyter-lab. This binary is provided via the Anaconda3 package, which is loaded at the start of the Jupyter SBATCH file. The PATH for this module is also already present in your PATH env variable. This is as expected, however it is still unable to find the binary. Do you happen to know what node the job was running on? It is possible that this could be due to a specific node. Is this error reproducible? Based on some of the more recent .err/.out files in your working directory, it seems like the notebooks have been running fine recently. Let me know! On Sat Oct 11 12:40:16 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USER] Request Type: High Performance Cluster Hello, I am referring to this guide - https://umbc.atlassian.net/wiki/spaces/faq/pages/1104805915/How+do+I+run+a+new+jupyter+notebook+on+chip - to run 'an existing jupyter notebook on chip' in the '/umbc/rs/pi_slaha/users/[USER]/astrophysics-anom_det' folder. I am stuck on Step 7 - i.e. in the .err file, I am not able to see the required section. I cannot find the line that starts with “http://127.0.0.1”. What I see instead is attached as a screenshot. It says the following: /usr/bin/which: no jupyter-lab in (/usr/ebuild/installs/software/Anaconda3/2024.02-1:/usr/ebuild/installs/software/Anac<...> onda3/2024.02-1/sbin:/usr/ebuild/installs/software/Anaconda3/2024.02-1/bin:/usr/ebuild/installs/software/Anaconda3/2024.<...> 02-1/condabin:/cm/shared/apps/git/2.33.1/bin:/cm/shared/apps/slurm/current/sbin:/cm/shared/apps/slurm/current/bin:/usr<...> /local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/[USER]) /cm/local/apps/slurm/var/spool/job456706/slurm_script: line 63: jupyter-lab: command not found Can you please help fix this? Thank you. Regards, [USER]"
"3290310","72240064","2025-10-13 16:06:20","HPC User Account: [USER] in [USER]'s electric fish project","Hi [USER], Welcome to chip, UMBC's High Performance Computing Cluster! The group, pi_[STAFF], now exists on the chip cluster. Members of this group can access and contribute to the research storage space allocated to the group. Additionally, I created user accounts for you, and the two students requested. This storage space is located at /umbc/rs/pi_[STAFF], and currently has a quota of 10T. For information on accessing the cluster, adding accounts to your group, and getting started using the cluster, check out the tutorial on our wiki: https://umbc.atlassian.net/wiki/x/R4BPQg Additional documentation is also available here: https://umbc.atlassian.net/wiki/x/FwCHQ For the software, Deep Lab Cut, you should be able to install it via a Conda environment. Here is a wiki page for getting started with anaconda on chip: https://umbc.atlassian.net/wiki/x/LYCPPQ If you have any questions or issues, please submit a new RT ticket at: https://doit.umbc.edu/request-tracker-rt/doit-research-computing/ First Name: [USER] Last Name: [STAFF] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Cluster Create/Modify account in existing PI group Existing PI Email: [EMAIL] Existing Group: [GROUP_NAME] Project Title: Computational Mechanisms for State-Driven Active Sensing Project Abstract: Dr. [STAFF] and an undergraduate student supervised by Dr. [STAFF] will perform the research for the project “Computational Mechanisms for State-Driven Active Sensing” at UMBC. The overall goal of the project is to understand sensing and information gathering behaviors through experiments with electric fish. The experiments will be conducted at partner institutions, and Dr. [STAFF]'s team at UMBC will focus on advanced time-series analysis of experimental data for all three specific aims. The deliverables will be analysis of time-series data for identifying causal relationships among neural and behavioral signals, analysis of time-series data for detecting changes in neural and behavioral data, and informing control-theoretic models of the observed behaviors. We need to use software called Deep Lab Cut https://deeplabcut.github.io/DeepLabCut/docs/installation.html to analyze experimental data. As I understand it, the first step is to use Deep Lab Cut on a laptop to recreate an *.eml file. That file would then be used within a batch job on a GPU computer to generate other files. I have two undergraduate students who will be working on this project. A guess is that each batch run will generate 5G of files. The undergraduate students working on this project are [STUDENT_1] and [STUDENT_2]."
"3291129","72250889","2025-10-13 21:58:15","HPC User Account: [ID] in Student Group","This has been fixed. Please try again and let us know if there is still a permission denied issue. [STAFF]"
"3291162","72712867","2025-11-04 16:40:26","HPC Other Issue: change with Intel C compiler?","You shouldn't need to recompile on each node, just each partition since each partition is using the same cpu architecture On Tue Nov 04 11:11:19 2025, [STAFF] wrote: So, lets say i want to run the ver 1.4 on every node in the cluster, to test performance. Do you think I should recompile it on each node? or just run the same executable?"
"3291564","72337137","2025-10-16 19:35:40","HPC Other Issue: g24-12 issue","Hi [USER], We've confirmed the machine is functioning normally again. Thank you for the email! On Tue Oct 14 12:18:39 2025, [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster One gpu on g24-12 is not working. attached screenshot. Attachment 1: Screenshot 2025-10-14 at 12.17.01.png Best, [STAFF]"
"3293453","72309050","2025-10-15 17:13:25","HPC Other Issue: [USER]'s jobs not running on Chip today","My jobs are now running. There must have been a very big job using up computing power and delaying mine more than usual. You can disregard this issue. Thanks! Greetings, This message has been automatically generated in response to the creation of a ticket regarding: Subject: 'HPC Other Issue: My jobs not running on [SERVER] today' Message: First Name: [USER] Last Name: [STAFF] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster Hi, I'm using the same code that has been running fine the past few weeks but today my jobs are sitting in [SERVER] and not running. Is there a migration going on? Or another reason that would prevent me from accessing [SERVER] nodes like I usually do? I can't run on the general nodes either. Thank you! [USER@SERVER-login1 USER]$ squeue -u [USER] CLUSTER: [SERVER]-cpu JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 526469 general weather [USER] PD 0:00 1 (Priority) 517473 match temp [USER] PD 0:00 1 (Priority) 526413 match cal [USER] PD 0:00 1 (Priority) 526432 match dhsregs [USER] PD 0:00 1 (Priority)"
"3293474","72308965","2025-10-15 17:09:11","CMake issue on Cluster","Hello [USER], I hope this email finds you well. Thank you for working with us during our office hours' time at 12:15-12:45. We wanted to provide you a step-by-step guide on how to use CMake so you are able to use this moving forward. Please also refer to the documents below that talk about 'How to run an interactive job', 'SBATCH', and information on how to use modules. 1. https://umbc.atlassian.net/wiki/spaces/faq/pages/[PAGEID] 2. https://umbc.atlassian.net/wiki/spaces/faq/pages/[PAGEID]/Basic+Slurm+Commands#sbatch 3. https://umbc.atlassian.net/wiki/spaces/faq/pages/[PAGEID]/How+to+use+modules 4. Here is also attached the Cmake documentation for any issues you might have when building (https://cmake.org/cmake/help/latest/guide/tutorial/index.html) When using CMake: 1. Log into [SERVER] 2. run an interactive job using the srun command (This can be found in the 1st article we linked) 3. module load <modulename> (Cmake) 4. Optional (if you would like to view the current modules being ran you can run <module list>) 5. Start working with cmake :) If you have any issues, please reach back out! Best regards, [STAFF]"
"3293526","72398003","2025-10-21 16:00:08","HPC Slurm/Software Issue: Conda environment","This is an email or ticket conversation between a user (Matthew Baker) and the University of Maryland, Baltimore County (UMBC) Research Computing team. The user is experiencing issues with their Conda environment not being applied consistently across all nodes in their High-Performance Computing (HPC) job.  Here's a summary of the issue:  * The user has migrated their storage and now experiences an issue with their Conda environment. * They allocate resources using `srun` and load their computation environment using `module load`. * However, when they test the environment using `mpirun python`, only one node can use the Fiona library, while the others return a `ModuleNotFoundError`. * The user suspects that the issue might be related to how the environment is initialized across nodes in the current cluster setup.  The conversation includes responses from Max Breitmeyer, a DOIT HPC System Administrator, who asks for more information about the issue and suggests potential solutions."
"3294124","72331579","2025-10-16 18:03:42","HPC User Account: [ID] in FSI","Hi [USER], Your account ([STAFF]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. You can find a short tutorial on how to use chip here: https://[EMAIL]/wiki/spaces/faq/pages/[NUMBER]/Getting+Started+on+chip Please read through the documentation found at hpcf.[EMAIL] > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://[EMAIL]/request-tracker-rt/[STAFF]-research-computing/) -- Kind regards, [STAFF] On Thu Oct 16 13:49:55 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [ID] Request Type:              High Performance Cluster Create/Modify account in existing PI group Existing PI Email:    [EMAIL] Existing Group:       FSI Project Title:        Sleep Disorder Monitoring Project Abstract:     This project aims to create a sleep stage monitoring system that utilizes contact-free multi-modal data. The long term goal is to extend the system to be able to detect and monitor sleep disorders. By using cutting-edge signal processing and machine learning methods, the system will be capable of providing precise and non-invasive sleep pattern analysis. In order to make the system scalable and capable of real-time execution, the ultimate solution will be refined for deployment on edge devices. I am requesting access to a GPU cluster to help experiments on contact-free, multi-modal sleep stage monitoring and sleep disorder detection. This is a project to create and train machine learning models that will be used on edge devices."
"3295053","72375618","2025-10-20 18:36:23","HPC User Account: [ID] in FSI","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_dli. Your home directory has 500M of storage. You can find a short tutorial on how to use chip here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Fri Oct 17 15:50:27 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [ID] Request Type:              High Performance Cluster Create/Modify account in existing PI group Existing PI Email:    [EMAIL] Existing Group:       FSI Project Title:        Sleep Disorder Monitoring Project Abstract:     This project aims to create a sleep stage monitoring system that utilizes contact-free multi-modal data. The long term goal is to extend the system to be able to detect and monitor sleep disorders. By using cutting-edge signal processing and machine learning methods, the system will be capable of providing precise and non-invasive sleep pattern analysis. In order to make the system scalable and capable of real-time execution, the ultimate solution will be refined for deployment on edge devices.  I am requesting access to a GPU cluster to help experiments on contact-free, multi-modal sleep stage monitoring and sleep disorder detection. This is a project to create and train machine learning models that will be used on edge devices."
"3295071","72375456","2025-10-20 18:33:56","HPC User Account: [ID] in Machine Learning for Signals Processing Lab","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. You can find a short tutorial on how to use chip here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) Kind regards, [STAFF] On Fri Oct 17 16:17:16 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] Request Type:              High Performance Cluster Create/Modify account in existing PI group Existing PI Email:    [EMAIL] Existing Group:       [GROUP] Project Title:        Multivariate feature selection for fMRI analysis Project Abstract:     fMRI has become a widely used imaging tool for exploring the normal neural functions as well as disordered brain functions like schizophrenia. Among all fMRI data analysis strategies, data-driven-based methods have a unique advantage of capturing the whole picture of available information since they effectively minimize assumptions imposed on the brain activity. With the increasing number of multimodal data and multisite data, the problem of balancing the computation cost and analysis performance is becoming more important than ever before. In this project, our interest is in identifying the most informative multivariate features when analyzing multiple fMRI datasets. Our goal is the development of flexible new decomposition methods as well as identifying the best feature extraction strategy for a given problem."
"3295672","72389751","2025-10-21 13:24:05","Request for Additional Shared Storage (2TB)","Hi [USER], As I write this, your shared research group volume is using 0% of its 25TiB of space. This volume is located at /umbc/rs/pi_dli. I'll mark this as resolved for now. See this wiki page for additional information: https://umbc.atlassian.net/wiki/spaces/faq/pages/1072267344/Storage On Mon Oct [DATE] [TIME], [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              Help with something else Dear HPCF Team, I am a member of the FSI research group led by [STAFF]. For our project titled 'Sleep Disorder Monitoring', we are currently working with large datasets and require an additional 2TB of shared storage to support our ongoing research activities. We would appreciate your support in accommodating this request. Thank you for your understanding. Best regards, [USER]"
"3295788","72378520","2025-10-20 19:08:52","Requesting Additional Shared Storage (2TB)","Hi [USER], As I write this, the pi_dli group has used 0% of its 25TiB allocation on chip. The root for this storage volume is located at /umbc/rs/pi_dli . Let me know if you have any questions about this, but I'll resolve this request for now. On Mon Oct 20 14:51:37 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] Request Type:              Help with something else Dear HPCF Team, I am a member of the FSI research group led by Dr. [STAFF]. For our project titled 'Sleep Disorder Monitoring', we are currently working with large datasets and require an additional 2TB of shared storage to support our ongoing research activities. We would appreciate your support in accommodating this request. Thank you for your understanding. Best regards, [USER]"
"3296672","72458889","2025-10-23 16:45:16","HPC User Account: [USER] in pi_[ID]","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) Kind regards, [STAFF] DoIT Unix Infra Student Worker On Tue Oct 21 13:22:34 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [USER] Request Type:              High Performance Cluster Create/Modify account in existing PI group Existing PI Email:    [EMAIL] Existing Group:       pi_[STAFF] Project Title:        Coupled Groundwater–Surface Water Modeling of Baltimore Using ParFlow.CLM Project Abstract:     This study develops high-resolution ParFlow.CLM models for urban watersheds in Baltimore, Maryland, to investigate the interactions between groundwater and surface water under recent climatic conditions. The model setups include: acquisition and processing of digital elevation data; slope generation using GRASS GIS; an overland flow test to ensure that the domains drain completely; acquisition and reclassification of land cover; generation of hydrogeologic layers with variable permeability; and preparation of NLDAS-2 meteorological forcing data. The models are being used for three objectives: (1) to evaluate the potential to predict whether simulated groundwater levels can predict basement flooding during storms, (2) to apply backward particle tracking with ECOSLIM to assess the correlation between stream water chemistry and land use/land cover, and (3) to compare water quantity results (prediction of stream discharge, aquifer levels) to other hydrologic models (HEC-RAS, SWMM, CityCat) being applied to the watersheds. This implementation provides a basis to evaluate hydrologic model robustness and improve understanding of hydrology in urban settings."
"3296766","72462863","2025-10-23 18:21:16","HPC Other Issue: [USER] running unexpectedly slow","Hi [STAFF], There were some issues with flags that were automatically generating incorrect slurm variables, which may have been causing the slowness. Please try it again and let us know if it seems faster. On Wed Oct 22 13:44:19 2025, [USER] wrote: Hi [STAFF], I followed the instructions on the HPCF wiki page (https://umbc.atlassian.net/wiki/spaces/faq/pages/1408335873/Running+an+LLM+using+Ollama+on+chip) and simply ran the example on that page. It took more than 30minutes to generate only 2 words. I used an interactive job to run the OLLAMA. I even tried to use the GPU partition for [SERVER]. It was a little faster but still super slow. I share the ollama_server.log file in the attachment for your reference. Thank you in advance for your help. On Tue Oct 21 15:20:39 2025, [STAFF] wrote: Hi [USER], I need some more information about your LLM job. Can you please provide your slurm script, and working directory? Are you working with a data, if so how big is it and where is it located? How much time do you expect the job to take ? On Tue Oct 21 14:18:03 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] Request Type:              High Performance Cluster User [USER] reports following ollama setup according to: https://umbc.atlassian.net/wiki/spaces/faq/pages/1408335873/Running+an+LLM+using+Ollama+on+chip User reports that running LLMs via ollama is running unexpectedly slow. Please follow-up with user to replicate the issue and perhaps set a meeting to understand the issue and to resolve."
"3296910","72606850","2025-10-30 18:44:55","HPC Other Issue: Running Hspice software on HPCF","Yes, thanks for all help. Regards, [USER] On Thu, Oct 30, 2025 at 2:11 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3296910 > Last Update From Ticket: Hi all, Is it fair to say this ticket can now be closed? On Thu Oct 30 12:57:01 2025, [USER] wrote: Thanks a lot [STAFF]. Both hspice and waveviewer work. Regards,[USER] On Wed, Oct 29, 2025 at 5:01 PM [STAFF] <[EMAIL]> wrote: Wave view should also be working now, give it a try when you have a chance. ---[STAFF] Specialist, Linux System Administrator & Lab Technical Support On Oct 29, 2025, at 16:12, [USER] <[EMAIL]> wrote: Hi [STAFF], Thanks. Hspice works but we also need WV (waveviewer) to see Hspice results as well. Could you please add that also and let us know to check? Thanks a lot,[USER] On Wed, Oct 29, 2025 at 2:30 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3296910 > Last Update From Ticket: On the HPC cluster, it should now be possible to run hspice using the command: /umbc/software/csee/scripts/launch_synopsys_hspice.sh Please test it and let me know if it works. Also, let me know what other tools you need to use, if any, so I can adapt those scripts as well. -- [USER] Associate Professor Department of Computer Science and Electrical Engineering University of Maryland, Baltimore County Baltimore, MD 21250 Tel: ***-***-**** E-mail: [EMAIL] Web: http://www.csee.umbc.edu/~[USER]/ -- [STAFF] DOIT HPC System Administrator"
"3298342","72456450","2025-10-23 15:52:23","HPC Other Issue: 5-days time limit not enough for jobs","Unfortunately, under the current cluster model only contributing groups have access to the 'shared' QOS option. In your situation, I would recommend seeing if you can optimize your code to run faster, in parallel, or across multiple nodes. You can also attempt to break apart your one large job into two smaller sets of jobs, which would allow you to complete the run in less than 5 days. Let me know if you have any additional questions! Have a nice day! -- Kind regards, [STAFF] On Thu Oct 23 10:09:11 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Hello all! I'd like to ask your help with the jobs I'm submitting in chip cluster. A few of them are pretty heavy, and the 5-days limit to run are not being enough. I saw there's the possibility to run in the partition 'shared', with 14-days limit, but I don't have access to that. Is it possible to give me access to that partition, or maybe to increase the time limit in the partition 'general'? In general my samples run within the 5 days, I would require more time only for samples whose jobs abort after 5 days. Thank you! Best, [USER]"
"3298471","72457824","2025-10-23 16:21:05","HPC Other Issue: [USER] cannot login to their ada account","Many Thanks [STAFF], Regards, [USER] On Thu, Oct 23, 2025 at 12:18PM [STAFF] via RT <[EMAIL]> wrote: If you agree your issue is resolved, please give us feedback on your experience by completing a brief satisfaction survey: https://umbc.us2.qualtrics.com/SE/?SID=SV_[ID]&customeremail=[EMAIL]&groupid=EIS&ticketid=[TICKETID]&ticketowner=[STAFF EMAIL]&ticketsubject=HPC Other Issue: I cannot login to my ada account If you believe your issue has not been resolved, please respond to this message, which will reopen your ticket. Note: A full record of your request can be found at: Ticket [URL] Thank You Hi [USER], The hpc cluster 'ada' has been completely absorbed by 'chip' as of April 10th. Please see this myumbc posting detailing the rollout of chip and the deletion of ada. https://my3.my.umbc.edu/groups/hpcf/posts/147513 On Thu Oct 23 12:01:48 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Hello, I’m currently unable to access my ADA account. When I try to connect via SSH using the command below: ssh [USER EMAIL]@ada.rs.umbc.edu I receive the following error message and do not even get the password prompt: ssh: connect to host ada.rs.umbc.edu port 22: Connection timed out Could you please help me resolve this issue? Thank you, [USER] -- Best, [STAFF] DOIT HPC System Administrator Original Request: Requestors: [USER] First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Hello, I’m currently unable to access my ADA account. When I try to connect via SSH using the command below: ssh [USER EMAIL]@ada.rs.umbc.edu I receive the following error message and do not even get the password prompt: ssh: connect to host ada.rs.umbc.edu port 22: Connection timed out Could you please help me resolve this issue? Thank you, [USER]"
"3298811","72480009","2025-10-24 15:50:45","HPC User Account: [USER] in H.A.R.M.O.N.I. Lab","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. You can find a short tutorial on how to use chip here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) Kind regards, [STAFF] DoIT Unix Infra Student Worker On Thu Oct 23 16:30:39 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster Create/Modify account in existing PI group Existing PI Email: [EMAIL] Existing Group: H.A.R.M.O.N.I. Lab Project Title: Multimodal Stock Price Direction Prediction Project Abstract: This project, Multimodal Stock Price Direction Prediction Using Historical Prices, News, and Sentiment, aims to predict short-term stock movements up, down, or stable by integrating numerical and textual financial data. The approach combines historical stock price features with sentiment analysis of financial news to capture both market trends and investor sentiment. Historical price data are collected from Yahoo Finance, while relevant news articles and headlines are sourced from the News API or GDELT. Sentiment scores are derived using FinBERT, a transformer-based model optimized for financial text, and aggregated on a daily basis. These sentiment features are then merged with technical indicators such as moving averages, relative strength index (RSI), and multi-day returns. The resulting multimodal dataset is labeled according to future price direction and used to train classification models including Random Forest, XGBoost, and Multilayer Perceptrons. Model performance is evaluated using accuracy, F1 score, and confusion matrices to compare the predictive power of price-only, sentiment-only, and combined feature sets. The study explores both early and late fusion approaches to integrate modalities and applies feature importance analysis (e.g., SHAP) to interpret model behavior. The findings aim to demonstrate how combining quantitative and qualitative signals can improve stock trend forecasting and provide insights into the interplay between market sentiment and price dynamics. Attachment 1: Project Guide_ Multimodal Stock Price Direction Prediction.pdf"
"3299581","72523983","2025-10-28 13:33:04","HPC User Account: [ID] in FSI","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_dli. Your home directory has 500M of storage. You can find a short tutorial on how to use chip here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/). On Sat Oct 25 12:59:22 2025, [STAFF] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CID] Request Type:              High Performance Cluster Create/Modify account in existing PI group Existing PI Email:    [EMAIL] Existing Group:       FSI Project Title:        Sleep Disorder Monitoring Project Abstract:     This project aims to create a sleep stage monitoring system that utilizes contact-free multi-modal data. The long term goal is to extend the system to be able to detect and monitor sleep disorders. By using cutting-edge signal processing and machine learning methods, the system will be capable of providing precise and non-invasive sleep pattern analysis. In order to make the system scalable and capable of real-time execution, the ultimate solution will be refined for deployment on edge devices.  I am requesting access to a GPU cluster to help experiments on contact-free, multi-modal sleep stage monitoring and sleep disorder detection. This is a project to create and train machine learning models that will be used on edge devices."
"3299984","72524540","2025-10-28 13:43:27","HPC User Account: [USER] in Quantum Thermodynamics Group","Hi [USER], Your account ([STAFF]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. You can find a short tutorial on how to use chip here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/) On Mon Oct 27 10:31:08 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [ID] Request Type:              High Performance Cluster Create/Modify account in existing PI group Existing PI Email:    [EMAIL] Existing Group:       [GROUP] Project Title:        Noise-Aware Quantum Dynamics Compilation Via Tensor Networks Project Abstract:     Quantum system simulation is quantum native, however compilation of variational simulation circuits is a difficult task. Efficiency of the compiled algorithm is paramount to successful simulation, yet algorithmic methods such as Trotterization result in suboptimal circuits. Prior work has identified machine learning techniques which efficiently improve on Trotterization by several orders of magnitude. This work advances these results by factoring noise into the compilation process, allowing for the generation of circuits which will perform optimally when executed on real, noisy quantum hardware. Dear HPC team, I would like to request HPC access to execute quantum simulation algorithms. My advisor, Dr. [STAFF], already has group access on the system, and I would like to be added to the group. Please let me know if you need anything else from me to complete my application. Thank you, [USER]"
"3300174","72523771","2025-10-28 13:29:02","HPC User Account: [USER] in Deffner","Hi [USER], You weren't able to log in because you didn't have a chip account. Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. You can find a short tutorial on how to use chip here: https://[DOMAIN]/wiki/spaces/faq/pages/[PAGE_ID]/Getting+Started+on+chip Please read through the documentation found at hpcf.[DOMAIN] > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://[DOMAIN]/request-tracker-rt/[REQUEST_TRACKER_ID]) On Mon Oct [DAY] [TIME] [YEAR], [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Cluster Create/Modify account in existing PI group Existing PI Email: [EMAIL] Existing Group: [GROUP_NAME] Project Title: [PROJECT_TITLE] Project Abstract: N/A I am unable to logon to Chip notes. Following the access instructions, I get to the point where I am prompted for my password, but it does not accept the password"
"3300690","72727340","2025-11-04 18:52:46","Data upload and server processing","Hi [USER], Welcome to chip, UMBC's High Performance Computing Cluster! The group, usda-eb, now exists on the chip cluster. Members of this group can access and contribute to the research storage space allocated to the group. This storage space is located at /umbc/rs/usda-eb, and currently has a quota of 50T. For information on accessing the cluster, adding accounts to your group, and getting started using the cluster, check out the tutorial on our wiki: https://umbc.atlassian.net/wiki/x/R4BPQg. Additional documentation is also available here: https://umbc.atlassian.net/wiki/x/FwCHQ. If you have any questions or issues, please submit a new RT ticket at: https://rtforms.umbc.edu/rt_authenticated/doit/DoIT-support.php?auto=Research%20Computing. Currently, [STAFF] is the 'owner' of the group, and is the only member of the group. To request users to be added to your group, please submit an RT ticket from the following link: https://rtforms.umbc.edu/rt_authenticated/doit/DoIT-support.php?auto=Research%20Computing. Additionally, I will need a little bit more information regarding your grant. Could you please provide an award number, title, and abstract? If you have any additional concerns, questions, or run into any problems, please feel free to submit a new ticket! Have a great day! On Tue Nov 04 09:32:16 2025, [USER] wrote: Maybe we can use the following name - 'USDA-EB' for the cluster. On Tue, Nov 4, 2025 at 9:26 AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3300690>. Last Update From Ticket: Hi, Just checking back in with you guys. Any specific name for the Center that we should use for the cluster? Best, [STAFF]."
"3301107","72562517","2025-10-29 17:44:30","HPC User Account: [ID] in [USER]","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is [STAFF]. Your home directory has 500M of storage. You can find a short tutorial on how to use chip here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1112506439/Getting+Started+on+chip Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link (https://doit.umbc.edu/request-tracker-rt/doit-research-computing/). You can also view your project information here on our wiki (https://hpcf.umbc.edu/libraries/research-projects-hpcf/?preview_id=76&preview_nonce=ee7c2f7bd1&preview=true) Best regards, [STAFF]"
"3301187","72636518","2025-10-31 17:12:23","HPC New Group: [ID]","Hi [USER], Welcome to chip, UMBC's High Performance Computing Cluster! The group, pi_[STAFF], now exists on the chip cluster. Members of this group can access and contribute to the research storage space allocated to the group. This storage space is located at /umbc/rs/pi_[STAFF], and currently has a quota of 25T. For information on accessing the cluster, adding accounts to your group, and getting started using the cluster, check out the tutorial on our wiki: https://umbc.atlassian.net/wiki/x/R4BPQg Additional documentation is also available here: https://umbc.atlassian.net/wiki/x/FwCHQ If you have any questions or issues, please submit a new RT ticket at: https://rtforms.umbc.edu/rt_authenticated/doit/DoIT-support.php?auto=Research%20Computing -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Tue Oct 28 16:05:31 2025, [USER] wrote: First Name:                [USER] Last Name:                 [STAFF] Email:                     [EMAIL] Campus ID:                 XXXXXXXX Request Type:              High Performance Cluster Group Type:            Project Title:        Towards Designing for Resilience: Community-Centered Deployment of an AI Business Planning Tool in a Feminist Makerspace Project Abstract:     Entrepreneurs in resource-constrained communities often lack the time and support to translate ideas into actionable business plans. While generative AI promises assistance, most systems assume high digital literacy and overlook community infrastructures that shape adoption. We report on the community-centered design and deployment of BizChat, an LLM-powered tool for business plan development, introduced across four workshops at a feminist busi- ness incubator and makerspace. BizChat was designed to center entrepreneurs' knowledge and workflows while providing just-in-time micro-learning and low-floor-high-ceiling accessibility. Through system log data (N=30) and semi-structured interviews (N=10) with entrepreneurs, we show how the design and deploy- ment of BizChat with existing community contexts lowered bar- riers to accessing capital, encouraged reflection, and empowered entrepreneurs to support AI-literacy within their own communities. We contribute insights into how AI tools can be deployed within local support networks, and implications for design that strengthen community resilience amid rapid technological change."
"3301564","72605706","2025-10-30 18:16:49","HPC Other Issue: very slow editing on /home/[USER] on c24-52","Hi [USER], OK all logged outta chip and our machine -[STAFF] On Thu, Oct 30, 2025 at 2:10 PM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: Hi [USER], Please exit out of /umbc/xfs2/strow on all devices where you may be logged in. We can't unmount the device until it's no longer active. On Thu Oct 30 13:44:40 2025, [USER] wrote: Hi [STAFF] Thanks for the reply. Maybe you should also cc [STAFF] as you all work on this ([STAFF]) [USER] On Thu, Oct 30, 2025 at 1:30 PM [STAFF] via RT <[EMAIL]> wrote: Ticket Last Update From Ticket: [USER], There is currently some degradation on the file system that sits on xfs2. We're investigating into how to resolve, but out of an abundance of caution, we are going to unmount xfs2 so that the degradation doesn't spread. We'll let you know when we have more information for you, but expect to not have access to your mount for a while. On Thu Oct 30 13:23:27 2025, [USER] wrote: Hi [USER], We are aware of the issue and are currently investigating. I'm going to merge this with the other ticket since they are related. On Thu Oct 30 12:53:30 2025, [USER] wrote: First Name: [USER] Last Name: [STAFF] Email: [EMAIL] Campus ID: [USER] Request Type: High Performance Cluster Have the disk issues been worked on yet (ticket #3301564)? I still can't edit files And now Matlab took about 3 minutes to start up on c24-52 There is something seriously wrong! Thanks [USER]"
"3302104","72622232","2025-10-31 15:07:37","HPC Other Issue: Need cuDNN 8.4.1.50 module on CHIP","Hello I have installed the module cuDNN/8.4.1.50-CUDA-11.7.0 let us know if you still unable to find the module. On Wed Oct 29 14:22:27 2025 [STAFF] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Hi I need to work on TensorFlow 2.11 which uses CUDA 11.7 version and cuDNN 8.4. I saw CUDA 11.7 however there is no cuDNN 8.4. The previous cluster (ADA) has module 'cuDNN/8.4.1.50-CUDA-11.7.0'. Can you install that module on CHIP also? Thank you so much [USER] Attachment 1: Screenshot.png -- Best [STAFF]"
"3304171","72603896","2025-10-30 17:23:27","HPC Other Issue: so slooooooooow, can't get anything done","We are aware of the issue and are currently investigating. I'm going to merge this with the other ticket since they are related. On Thu Oct 30 12:53:30 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Have the disk issues been worked on yet (ticket #3301564)? I still can't edit files And now Matlab took about 3 minutes to start up on c24-52 There is something seriously wrong! Thanks [USER]"
"3304395","72643338","2025-10-31 19:53:50","HPC New Group: [ID]","Hi [USER], Welcome to chip, UMBC's High Performance Computing Cluster!  The group, pi_[STAFF], now exists on the chip cluster. Members of this group can access and contribute to the research storage space allocated to the group. This storage space is located at /umbc/rs/pi_[STAFF], and currently has a quota of 10T. For information on accessing the cluster, adding accounts to your group, and getting started using the cluster, check out the tutorial on our wiki: https://umbc.atlassian.net/wiki/x/R4BPQg An account for the PI ([USER]) has been created. To add additional users to the group, please submit a new add user ticket. Additional documentation is also available here: https://umbc.atlassian.net/wiki/x/FwCHQ If you have any questions or issues, please submit a new RT ticket at: https://rtforms.umbc.edu/rt_authenticated/doit/DoIT-support.php?auto=Research%20Computing First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID]  Request Type:              High Performance Cluster  Group Type:            Project Title:        Multiscale Behavior Mapping to Decode Neuronal Health and Diseases in Animal Models Project Abstract:     Automated, high-fidelity behavioral phenotyping is essential for uncover the underlying neural circuits and functional perturbations in vivo. Yet current computer-vision tools often miss the subtle, ethologically relevant kinematic motifs that report changes in internal state. In this project, we will build a neuroscience-focused computational pipeline that couples the broad foundation model with the efficient and specialized detector to identify the animal behavior responded to sensory signal inputs. Specifically, we will distill knowledge from Vision Transformers into customized single-state Convolutional Neural Networks (CNNs) and pretrain these networks on a large, unlabeled corpus of murine behavioral videos spanning diverse common behavior experimental assays. The resulting models will be fine-tuned for high-throughput quantification of classified behavior phenotypes/signatures that serve as proxies for cognitive and affective states.  This pipeline will enable experimenters to (i) stratify behavior with ethological precision, (ii) align these phenotypes with neural activities or perturbations by endogenous and environmental factors, and (iii) standardize assays across labs for reproducible neuroscience. Training and optimization demand large-scale data parallelism and extensive hyperparameter searches; thus, access to the UMBC HPC cluster is indispensable. This work will yield a biologically grounded, scalable toolset for objective behavior measurement in animal models, such as mice.     The PI of this project is Dr. [USER], a Professor at Department of Biological Sciences ([EMAIL]). We would like to setup a new group to use HPC and data storage space.  The lab recently published an analysis pipeline for animal behavior and benchmark comparison with other available tools (IntegraPose: A unified framework for simultaneous pose estimation and behavior classification.  https://doi.org/10.1016/j.neuroscience.2025.10.020).  We need to scale up the model by training with a larger set of image data using the HPC.  Our project members include UMBC students who are familiar with script coding."
"3304442","72705445","2025-11-04 14:26:41","HPC Other Issue: more hardware details","Everything is EDR. On Thu Oct 30 21:44:22 2025, [USER] wrote: Hi, [STAFF], Thanks for the Dell model. Yes, I read that Wiki page. My request is to know more precisely than 'high speed backend Infiniband network supporting 100 Gbps'. That phrase is well-written to cover all nodes from 2018 to 2024. But is the 2024 network not a newer one? Purchased in 2024? Either way, I am asking for a technical term like DDR = dual data rate, QDR = quad data rate, EDR = extended data rate, like I am recalling from the past. Does the 2024 portion's network not have a phrase like that with it? On Thu, Oct 30, 2025 at 7:03 PM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=33404442 > Last Update From Ticket: Hi [USER], The model for the nodes used in the 2024 are PowerEdge R660. Specifications on the network abilities and cpus themselves can be found here: https://umbc.atlassian.net/wiki/spaces/faq/pages/1289486353/Cluster+Specifications On Thu Oct 30 16:07:02 2025, [USER] wrote: > First Name: [USER] > Last Name: [USER] > Email: [EMAIL] > Campus ID: [USER] > Request Type: High Performance Cluster > Hi, I would like some more fine points of hardware information. I am referring to the 2024 portion of chip. - CPU: what is the model number of the node from Dell for the 2024 compute nodes? - The 2024 CPU nodes are connected by which InfiniBand? EDR? Some specs available? [USER] Best, [STAFF], DOIT HPC System Administrator"
"3304534","72612575","2025-10-30 22:55:41","HPC Other Issue: Reset [USER] Password","Your password is linked to your [INSTITUTION] account. So you would just need to use the my[INSTITUTION] reset password. https://[INSTITUTION].atlassian.net/wiki/spaces/faq/pages/30736467/I+have+forgotten+my+my[INSTITUTION]+password.+What+should+I+do Note that it may take a minute to update on [SERVER]. On Thu Oct 30 17:52:57 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Dear Sir/Madam, I would like to access the [SERVER] server, but after logging in with my ID “[USERNAME]”, my password does not work. I am not sure of the reason. Could you please provide me with a link or instructions to reset my password? Thank you very much for your assistance. Regards, [USER] ID: [CAMPUSID]"
"3304703","72621395","2025-10-31 14:44:35","HPC Other Issue: Request for sample SLURM job script to run WRF on CHIP","Hi [USER], First off, I wanted to clarify a couple points. 1. 'I was advised that running ./wrf.exe interactively is not permitted': This is untrue. You are able to run interactive jobs, where you create a slurm allocation on a node, then connect to it and run your code directly. You are not permitted to run jobs on the login node, which I believe is what you are thinking of. If you would like some documentation on how to run an interactive job, I'll include a link to a page with the commands required to do that. How to run interactive job: https://umbc.atlassian.net/wiki/x/CYCbQw 2. There is also a WRF module available to be loaded on chip. You can load WRF with: 'module load WRF/4.4-foss-2022a-dmpar'. WPS is also available, and can be loaded with: 'module load WPS/4.4-foss-2022a-dmpar'. These installations should work, however it is a slightly older version (4.4), whereas you compiled a newer one (4.5). 3. For your locally installed and compiled copy of WRF, if you desire to use it you must use the compiled binaries located under /umbc/rs/pi_cichoku/users/[USER]/model2/sources/WRF/main. This is where the actual WRF binaries are stored, the directory you provided was a test directory for testing the software. You will want to add this location to your PATH environment variable to utilize the binaries. It is also possible, depending on how your install was compiled, that it would need to be recompiled for MPI support. For more info, check out the Building WRF section of this page: https://www2.mmm.ucar.edu/wrf/OnLineTutorial/compilation_tutorial.php We do not have any existing documentation on running WRF/WPS explicitly, however we have documentation on running MPI jobs, including some example SBATCH scripts: https://umbc.atlassian.net/wiki/x/AQCKV There is documentation on WRF's website for running WRF using mpi, take a look here: https://www2.mmm.ucar.edu/wrf/users/wrf_users_guide/build/html/running_wrf.html If you have any additional questions or need clarification, please feel free to let me know. For now I will mark this as resolved. Have a good day! -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Fri Oct 31 05:37:55 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [USER] Request Type: High Performance Cluster Hi HPC Team, I’m a graduate student working on the WRF model on the UMBC CHIP cluster. I was advised that running ./wrf.exe interactively is not permitted and that I should submit the run via SLURM because of the job’s size and runtime. Could you please provide (or point me to) a sample SLURM job script for a parallel WRF run on CHIP? A template with the recommended directives and module loads would be very helpful. Specifically, I’m looking for guidance on: For context (in case it helps tailor the template): Executable(s): real.exe and wrf.exe (WRF-ARW) Input: single domain (d01) for a short 48-hour case; netCDF met_em and boundary files are ready Code location: /umbc/rs/pi_cichoku/users/[USER]/model2/sources/WRF/test/em_real/ I can rebuild with the cluster’s preferred MPI stack if needed. If there’s existing documentation or example scripts for CHIP users running WRF (or other large MPI jobs), a link would be great. Thank you very much for your help! Best regards, [USER] Graduate Student, GES UMBC"
"3305879","72731618","2025-11-04 20:24:14","HPC Other Issue: [USER] not able to login to the cluster (chip) through terminal","Hi [STAFF], Apologies for late reply Yes, still I face the issue and I tried with campus vpn and also my personal wifi. Both are giving the same problem. Could you help me in checking the issue. Thankyou for your help.  Regards, [USER]. Campus ID: [CAMPUS_ID] On Mon, Nov 3, 2025 at 11:01 AM [STAFF] via RT <[EMAIL]> wrote: Ticket <URL: https://rt.umbc.edu/Ticket/Display.html?id=3305879> Last Update From Ticket: Hi [USER], Is this still an issue? We haven't seen any other reports of people being unable to login. Are you on campus vpn? What sort of internet connection do you have (wifi or wired)? On Fri Oct 31 15:04:48 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Cluster Previously, I was able to login through the cluster (chip) but suddenly the login to cluster is not working. Attachment 1: Screenshot 2025-10-31 at 3.03.21PM.png Best, [STAFF] DOIT HPC System Administrator"
"3305960","72712232","2025-11-04 16:29:06","HPC User Account: [USER] in [ID]","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link (https://rtforms.umbc.edu/rt_authenticated/doit/DoIT-support.php?auto=Research Computing) -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Fri Oct 31 16:25:15 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUS_ID] Request Type:              High Performance Cluster Create/Modify account in existing PI group Existing PI Email:    [STAFF_EMAIL] Existing Group:       pi_[STAFF] Project Title:        A Human-Centered Approach to Building Generative AI System for Small Business Owners Project Abstract:     Entrepreneurs in resource-constrained communities often lack the time and support to translate ideas into actionable business plans. While generative AI promises assistance, most systems assume high digital literacy and overlook community infrastructures that shape adoption. We report on the community-centered design and deployment of BizChat, an LLM-powered tool for business plan development, introduced across four workshops at a feminist business incubator and makerspace in a city. BizChat was designed to center entrepreneurs' knowledge and workflows while providing just-in-time micro-learning and low-floor-high-ceiling accessibility. Through system log data (N=30) and semi-structured interviews (N=10) with entrepreneurs, we show how the design and deployment of BizChat with existing community contexts lowered barriers to accessing capital, encouraged reflection, and empowered entrepreneurs to support AI-literacy within their own communities. We contribute insights into how AI tools can be deployed within local support networks, and implications for design that strengthen community resilience amid rapid technological change. I am a PhD student and my advisor is Dr. [STAFF]. I am requesting an account in order to join this existing group."
"3306147","72647496","2025-11-01 17:20:44","HPC Slurm/Software Issue: Cannot Cancel [USER] Jobs","Understood and no problem. I've cancelled all of your jobs submitted to the match partition that were pending. When canceling your own jobs, be sure to specify the cluster with something like `scancel -M chip-cpu JOBID`. On Sat Nov 01 12:18:16 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUS_ID] Request Type: High Performance Cluster Hello, I am having an issue with chip where I cannot cancel a number of jobs that are in queue. I used a script to create and submit the jobs last night but realized that I had a small mistake. I have tried to cancel all jobs under my username, [USER], and cancel specific jobs by id but they remain in the queue. The jobs have remained in the queue for more than 12 hours since I first tried to cancel them. All pending jobs on the match partition under my username name need to be cancelled."
"3306171","72712777","2025-11-04 16:38:35","HPC Other Issue: software request","Hi [USER], The modules, RSEM and BOWTIE2 have been installed on chip! I installed RSEM/1.3.3-foss-2022a, and Bowtie2/2.4.5-GCC-11.3.0. These can be loaded with 'module load RSEM/1.3.3-foss-2022a' (note, RSEM depends on BOWTIE2, so the correct version of BOWTIE2 is loaded when you load RSEM). If you encounter any issues using the modules, or need any additional modules, feel free to submit a new ticket! Have a great day! -- Kind regards, [STAFF] On Sat Nov 01 13:50:40 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [CAMPUSID] Request Type:              High Performance Cluster Is it possible to request modules/packages to be added to the cluster? I would like to be able to use RSEM and BOWTIE2. Thanks!"
"3306427","72684558","2025-11-03 16:57:43","HPC Slurm/Software Issue: SSH connection failing","Hi [USER], Since the load balancer issue was fixed, we have not seen any other reports of this issue. I am currently testing myself, and have not encountered any disconnects. Would you mind sharing a bit more about your setup? How are you sshing (ie, a dedicated client like putty, or just through your terminal)? Do you have any local SSH configuration? Are you logged in using GlobalProtect VPN? Let me know and I can look into this further for you! Have a nice day! Kind regards, [STAFF] On Sun Nov 02 19:04:14 2025, [EMAIL] wrote: First Name:                [USER] Last Name:                 [LAST NAME] Email:                     [EMAIL] Campus ID:                 [CAMPUS ID] Request Type:              High Performance Cluster I have a few ssh sessions open connecting to chip and they keep disconnecting every few minutes. Previously, this had been a problem and it was resolved (something to do with a load balancer) but its back now."
"3306608","72660450","2025-11-03 15:16:42","HPC Slurm/Software Issue: Slurm Not Loading Anaconda Module - Job ID 113232-113234","Hi [USER], There appears to have been a minor configuration error with the node that job was running on (g24-11). This has now been resolved. If you continue to experience issues, please feel free to submit a new ticket! Have a nice day! -- Kind regards, [STAFF] DoIT Unix Infra Student Worker On Mon Nov 03 09:47:01 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [ID] Request Type: High Performance Cluster I went to run a job this morning that I have run quite often. The first request for this job (ID 113231) started just fine. Subsequent requests error out in my Python script indicating issues loading modules from my Conda environment. The job log shows that 'conda' is not a known command, indicating an issue loading the Anaconda module."
"3308276","72687865","2025-11-03 18:12:12","HPC Other Issue: Data missing from '[ID]/rs/[ID]/users/[ID]'","Hi [USER], Currently, the research volume for pi_zzbatmos is undergoing migration to a new storage server (ceph). This date was scheduled with your PI in advance, and during the time of migration we request that all users in the group do not use chip to avoid disturbing your groups migration. Your PI should have more information regarding the specifics. However, since pi_zzbatmos has a very large research volume, the migration is taking a long time (it was started on Friday, and is still going). After the migration properly completes, you should have access to your data. Something that you already noticed, the new Ceph research volumes start with 'pi_'. For example, the old volume was mounted at '/umbc/rs/zzbatmos', where the new volume (the one you noticed) is located at '/umbc/rs/pi_zzbatmos'. Your PI should let the group know when the migration is finished. But if you have any additional questions in the meantime, feel free to let us know! Have a good day! -- Kind regards, [STAFF] On Mon Nov 03 12:23:11 2025, [USER] wrote: First Name: [USER] Last Name: [USER] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster Hi, I hope this email finds you well. I noticed that my data from 'umbc/rs/zzbatmos/users/[USER]' is missing. I found that there is another directory 'umbc/rs/pi_zzbatmos/users/[USER]' in a similar path but this new directory contains partial data. Could you please let me know what happened to my original data or if it was moved somewhere else? thank you."
"3308743","72705040","2025-11-04 14:20:34","HPC Slurm/Software Issue: Pending Jobs Not Cancelling","Hi, Well, when I squeued for your jobs just now, none of them came up, meaning I suppose they finished. If you could give me the exact path to the jobs you were trying to cancel, I could test some things myself. Without more information, I can't test much myself. However, looking at the history of your 'scancel' commands, I do notice a mistake you made, which could very well be the reason it didn't work. You ran: scancel -u [USER] This is not correct on the Chip cluster; the correct command would've been: scancel --cluster=chip-cpu -u [USER] or scancel --cluster=chip-gpu -u [USER] Yes, I know it's a bit confusing, but you have to specify the cluster CPU/GPU to cancel all jobs for your user. Here's some wiki documentation about that: https://[DOMAIN]/wiki/spaces/faq/pages/[PAGEID]/Basic+Slurm+Commands#Managing-and-Controlling-Jobs Let me know if that was the issue. Best, [STAFF]"
"3308993","72712610","2025-11-04 16:34:11","HPC User Account: [USER] in pi_[ID]","Hi [USER], Your account ([USER]) has been created on chip.rs.umbc.edu. Your primary group is pi_[STAFF]. Your home directory has 500M of storage. Please read through the documentation found at hpcf.umbc.edu > User Support. All available modules can be viewed using the command 'module avail'. Please submit additional questions or issues as separate tickets via the following link. (https://rtforms.umbc.edu/rt_authenticated/doit/DoIT-support.php?auto=Research%20Computing) -- Kind regards, [STAFF] (she/her/hers) DoIT Unix Infra Student Worker On Tue Nov 04 09:43:25 2025, [USER] wrote: First Name:                [USER] Last Name:                 [USER] Email:                     [EMAIL] Campus ID:                 [ID] Request Type:              High Performance Cluster Create/Modify account in existing PI group Existing PI Email:    [EMAIL] Existing Group:       pi_[STAFF] Project Title:        Towards Designing for Resilience: Community-Centered Deployment of an AI Business Planning Tool in a Feminist Makerspace Project Abstract:     Entrepreneurs in resource-constrained communities often lack the time and support to translate ideas into actionable business plans. While generative AI promises assistance, most systems assume high digital literacy and overlook community infrastructures that shape adoption. We report on the community-centered design and deployment of BizChat, an LLM-powered tool for business plan development, introduced across four workshops at a feminist busi- ness incubator and makerspace. BizChat was designed to center entrepreneurs’ knowledge and workflows while providing just-in-time micro-learning and low-floor-high-ceiling accessibility. Through system log data (N=30) and semi-structured interviews (N=10) with entrepreneurs, we show how the design and deploy- ment of BizChat with existing community contexts lowered bar- riers to accessing capital, encouraged reflection, and empowered entrepreneurs to support AI-literacy within their own communities. We contribute insights into how AI tools can be deployed within local support networks, and implications for design that strengthen community resilience amid rapid technological change. I am a master’s student and requesting this account to join in existing group. I am working under [STAFF]'s Lab."
"3309956","72724591","2025-11-04 17:57:29","HPC Slurm/Software Issue: Request to reserve GPU space for a deadline in December ACL 2026","First Name: [STUDENT] Last Name: [STUDENT] Email: [EMAIL] Campus ID: [CAMPUSID] Request Type: High Performance Cluster My student, [STUDENT], would like to reserve GPU nodes (preferably H100) for 2 weeks to complete her experiments for the ACL deadline. Can you please assist her with this?"
"3310226","72733891","2025-11-04 21:01:54","N-Mode cavity laser simulation - In need of computing power","Please disregard this ticket request."
